{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was written to demonstrate Gradient Descent. It is not the most efficient way of doing things and in practice, make sure to use the built in methods to do it\n",
    "\n",
    "Hopefully this will demonstrate things what is actually going on in .fit() and how it figures out the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for our old friend Linear Regression but others could be written similarly. As much as possible I am avoiding loops unless I think it will better demonstrate what's going on.\n",
    "\n",
    "Firstly we need a function that calculates the error. I am using MSE\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{1}{2m}\\sum (\\widehat{y_i} - y_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "where $\\widehat{y_i} = w_0+w_1x_1+w_2x_2+....$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X,y,w):\n",
    "    div = 2*len(y)\n",
    "    return ((np.dot(X,w) - y)**2).sum()/div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the best way of doing things, but let's make a function for calculating the change for one particular $w_c$\n",
    "\n",
    "c is the column number we're checking, the gradient for one particular one is\n",
    "\\begin{equation}\n",
    "\\frac{\\partial L}{\\partial w_c} = \\frac{1}{m}\\sum (\\widehat{y_i}-y_i)*x_c\n",
    "\\end{equation}\n",
    "\n",
    "which you should see reflected below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(X,y,w,c):\n",
    "    div = len(y)\n",
    "    return (X[:, c]*(np.dot(X,w) - y)).sum()/div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's me writing a loop (usually you don't do this, it increases the computational time and when doing this training - every optimisation counts, but I think it will demonstrate things better)\n",
    "\n",
    "full grad loops over all the weights, finds out the change for each individual w and puts it into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loopfullgrad(X,y,w):\n",
    "    allgrad = np.array([])\n",
    "    for i in range(len(w)):\n",
    "        allgrad = np.append(allgrad, grad(X,y,w,i))\n",
    "    return allgrad   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's a better one that doesn't use a loop so faster\n",
    "def fullgrad(X,y,w):\n",
    "    div = len(y)\n",
    "    prediction = np.dot(X,w)\n",
    "    allgrad = X.T.dot((prediction - y))/div\n",
    "    return allgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for performing one step of gradient descent is done. Now let's set up the thing we want to find the best weights for.\n",
    "\n",
    "Like sklearn, this requires each row in X correspond to one from the sample. If we want an intercept ($w_0$), we need to add that in with feature 0 being all 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2],[1,5],[1,8],[1,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [ 1,  5],\n",
       "       [ 1,  8],\n",
       "       [ 1, 12]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y is a 1-d as normal y[0] is the true value for X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([4,11,19,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 11, 19, 25])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to now pick initial weights to start with, there are two weights required\n",
    "\n",
    "I've just picked 20 and 50. You could set this with random numbers or maybe try 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([20, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How bad is the current model of \n",
    "\\begin{equation}\n",
    "\\hat{y} = 20 + 50x\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74420.375"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(X,y,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the gradient now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 342.75, 2968.75])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onestep = loopfullgrad(X,y,w)\n",
    "onestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 342.75, 2968.75])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onestep = fullgrad(X,y,w)\n",
    "onestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that\n",
    "\\begin{equation}\n",
    "\\nabla L = (342.75, 2968.75)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now update the weights using the learning rate of $\\alpha=1$\n",
    "\n",
    "\\begin{equation}\n",
    "\\textbf{w}^1 = \\textbf{w}^0 - \\alpha*\\nabla L\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -322.75, -2918.75])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newweight = w - alpha*onestep\n",
    "newweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259169836.8671875"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(X,y,newweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that was a terrible attempt! Our $\\alpha$ is far too big. Let's try 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.5725, 20.3125])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_1 = w - alpha*onestep\n",
    "weight_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11913.470811718747"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(X,y,weight_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An improvement! \n",
    "\n",
    "Let's do another step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.18318125,  8.4462    ])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_2 = weight_1 - alpha*fullgrad(X,y,weight_1)\n",
    "weight_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1923.257547730489"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(X,y,weight_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no way of avoiding loops now, so let's do 50 steps and see where we are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [14.60873094  3.70446177] , error: 326.492271589584\n",
      "Weights: [14.36009246  1.81097883] , error: 71.20501095436816\n",
      "Weights: [14.24175046  1.05616763] , error: 30.31903149997327\n",
      "Weights: [14.17554164  0.75657015] , error: 23.699990551816963\n",
      "Weights: [14.13021774  0.63895328] , error: 22.55802661361252\n",
      "Weights: [14.09328622  0.59408376] , error: 22.291816152387437\n",
      "Weights: [14.0597527   0.57829231] , error: 22.165953739761235\n",
      "Weights: [14.02762044  0.57412081] , error: 22.06290192165977\n",
      "Weights: [13.99609108  0.57458985] , error: 21.963873618182713\n",
      "Weights: [13.96484536  0.57690922] , error: 21.865864474689154\n",
      "Weights: [13.93375553  0.57996344] , error: 21.76839260866761\n",
      "Weights: [13.90277045  0.5833066 ] , error: 21.671379297957742\n",
      "Weights: [13.87186955  0.58676044] , error: 21.574810263022624\n",
      "Weights: [13.84104452  0.59025368] , error: 21.478681531562327\n",
      "Weights: [13.81029195  0.59375787] , error: 21.382990786324065\n",
      "Weights: [13.77961038  0.59726163] , error: 21.28773598223626\n",
      "Weights: [13.74899911  0.60076041] , error: 21.192915125357914\n",
      "Weights: [13.71845779  0.60425243] , error: 21.09852623751458\n",
      "Weights: [13.68798618  0.60773696] , error: 21.004567350611765\n",
      "Weights: [13.65758407  0.61121375] , error: 20.91103650569156\n",
      "Weights: [13.6272513   0.61468268] , error: 20.81793175274763\n",
      "Weights: [13.59698771  0.61814373] , error: 20.72525115066152\n",
      "Weights: [13.56679313  0.6215969 ] , error: 20.632992767158505\n",
      "Weights: [13.53666741  0.6250422 ] , error: 20.54115467876666\n",
      "Weights: [13.50661038  0.62847965] , error: 20.449734970776753\n",
      "Weights: [13.4766219   0.63190926] , error: 20.358731737202227\n",
      "Weights: [13.44670181  0.63533104] , error: 20.268143080739513\n",
      "Weights: [13.41684995  0.63874503] , error: 20.17796711272844\n",
      "Weights: [13.38706616  0.64215123] , error: 20.088201953112897\n",
      "Weights: [13.35735029  0.64554966] , error: 19.998845730401598\n",
      "Weights: [13.32770218  0.64894034] , error: 19.909896581629088\n",
      "Weights: [13.29812169  0.65232329] , error: 19.8213526523169\n",
      "Weights: [13.26860865  0.65569853] , error: 19.733212096434865\n",
      "Weights: [13.23916291  0.65906607] , error: 19.645473076362663\n",
      "Weights: [13.20978432  0.66242593] , error: 19.55813376285149\n",
      "Weights: [13.18047273  0.66577812] , error: 19.471192334985915\n",
      "Weights: [13.15122798  0.66912268] , error: 19.384646980145945\n",
      "Weights: [13.12204992  0.6724596 ] , error: 19.298495893969186\n",
      "Weights: [13.0929384   0.67578892] , error: 19.212737280313284\n",
      "Weights: [13.06389326  0.67911064] , error: 19.127369351218416\n",
      "Weights: [13.03491436  0.68242479] , error: 19.042390326870056\n",
      "Weights: [13.00600154  0.68573138] , error: 18.95779843556187\n",
      "Weights: [12.97715466  0.68903043] , error: 18.87359191365873\n",
      "Weights: [12.94837356  0.69232196] , error: 18.789769005560025\n",
      "Weights: [12.91965809  0.69560598] , error: 18.70632796366296\n",
      "Weights: [12.89100811  0.69888252] , error: 18.62326704832621\n",
      "Weights: [12.86242345  0.70215158] , error: 18.540584527833598\n",
      "Weights: [12.83390399  0.70541319] , error: 18.45827867835801\n",
      "Weights: [12.80544956  0.70866735] , error: 18.37634778392544\n",
      "Weights: [12.77706002  0.7119141 ] , error: 18.294790136379255\n"
     ]
    }
   ],
   "source": [
    "weights = weight_2\n",
    "for i in range(50):\n",
    "    weights = weights - alpha*fullgrad(X,y,weights)\n",
    "    print(\"Weights:\", weights, \", error:\", error(X,y,weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "still getting smaller, let's do some more but I'm going to break if the error flattens or increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [12.74873521  0.71515345] , error: 18.213604035344517\n",
      "Weights: [12.72047501  0.7183854 ] , error: 18.1327877881926\n",
      "Weights: [12.69227924  0.72160999] , error: 18.05233971000584\n",
      "Weights: [12.66414777  0.72482722] , error: 17.97225812354245\n",
      "Weights: [12.63608046  0.72803712] , error: 17.892541359201534\n",
      "Weights: [12.60807715  0.73123969] , error: 17.813187754988295\n",
      "Weights: [12.5801377   0.73443497] , error: 17.734195656479347\n",
      "Weights: [12.55226196  0.73762295] , error: 17.655563416788258\n",
      "Weights: [12.52444979  0.74080367] , error: 17.577289396531192\n",
      "Weights: [12.49670105  0.74397714] , error: 17.49937196379277\n",
      "Weights: [12.46901558  0.74714336] , error: 17.42180949409197\n",
      "Weights: [12.44139325  0.75030237] , error: 17.344600370348356\n",
      "Weights: [12.4138339   0.75345417] , error: 17.267742982848272\n",
      "Weights: [12.38633741  0.75659879] , error: 17.191235729211346\n",
      "Weights: [12.35890362  0.75973623] , error: 17.115077014357038\n",
      "Weights: [12.33153238  0.76286652] , error: 17.03926525047143\n",
      "Weights: [12.30422357  0.76598967] , error: 16.963798856974087\n",
      "Weights: [12.27697703  0.7691057 ] , error: 16.88867626048512\n",
      "Weights: [12.24979263  0.77221462] , error: 16.81389589479235\n",
      "Weights: [12.22267021  0.77531646] , error: 16.739456200818726\n",
      "Weights: [12.19560965  0.77841122] , error: 16.66535562658974\n",
      "Weights: [12.1686108   0.78149892] , error: 16.59159262720113\n",
      "Weights: [12.14167351  0.78457958] , error: 16.51816566478663\n",
      "Weights: [12.11479765  0.78765322] , error: 16.445073208485933\n",
      "Weights: [12.08798309  0.79071984] , error: 16.37231373441277\n",
      "Weights: [12.06122967  0.79377948] , error: 16.29988572562312\n",
      "Weights: [12.03453725  0.79683213] , error: 16.227787672083622\n",
      "Weights: [12.00790571  0.79987783] , error: 16.156018070640044\n",
      "Weights: [11.9813349   0.80291658] , error: 16.084575424985985\n",
      "Weights: [11.95482468  0.8059484 ] , error: 16.013458245631664\n",
      "Weights: [11.92837492  0.80897331] , error: 15.942665049872843\n",
      "Weights: [11.90198547  0.81199132] , error: 15.872194361759973\n",
      "Weights: [11.8756562   0.81500244] , error: 15.802044712067357\n",
      "Weights: [11.84938698  0.8180067 ] , error: 15.732214638262562\n",
      "Weights: [11.82317765  0.82100411] , error: 15.662702684475905\n",
      "Weights: [11.7970281   0.82399468] , error: 15.593507401470108\n",
      "Weights: [11.77093818  0.82697844] , error: 15.524627346610089\n",
      "Weights: [11.74490775  0.82995539] , error: 15.45606108383287\n",
      "Weights: [11.71893669  0.83292555] , error: 15.387807183617651\n",
      "Weights: [11.69302485  0.83588893] , error: 15.319864222956003\n",
      "Weights: [11.66717209  0.83884556] , error: 15.252230785322189\n",
      "Weights: [11.6413783   0.84179545] , error: 15.184905460643645\n",
      "Weights: [11.61564332  0.84473861] , error: 15.11788684527158\n",
      "Weights: [11.58996703  0.84767506] , error: 15.051173541951703\n",
      "Weights: [11.5643493   0.85060481] , error: 14.9847641597951\n",
      "Weights: [11.53878998  0.85352788] , error: 14.918657314249227\n",
      "Weights: [11.51328895  0.85644429] , error: 14.852851627069057\n",
      "Weights: [11.48784607  0.85935404] , error: 14.787345726288342\n",
      "Weights: [11.46246121  0.86225716] , error: 14.722138246190994\n",
      "Weights: [11.43713424  0.86515366] , error: 14.657227827282634\n"
     ]
    }
   ],
   "source": [
    "currenterror = error(X,y,weights)\n",
    "for i in range(50):\n",
    "    weights = weights - alpha*fullgrad(X,y,weights)\n",
    "    newerror = error(X,y,weights)\n",
    "    print(\"Weights:\", weights, \", error:\", newerror)\n",
    "    if newerror >= currenterror:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "    weights = weights - alpha*fullgrad(X,y,weights)\n",
    "    newerror = error(X,y,weights)\n",
    "    #if i = 5000:\n",
    "    #    print(\"Weights:\", weights, \", error:\", newerror)\n",
    "    if newerror >= currenterror:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm curious, what does sklearn get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_intercept is set to false as we already have the intercept included. (The columns of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35616438, 2.13242009])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close! They spent a lot more time writing better code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to do more stuff but I'm writing a function now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcoefficients(X,y,w,alpha,epochs=500,printing=False, plotting=False, showall=False):\n",
    "    weights = w\n",
    "    currenterror = error(X,y,w)\n",
    "    if plotting:\n",
    "        recorderrors = []\n",
    "        recorderrors.append(currenterror)\n",
    "        maxepoch=0\n",
    "    for i in range(epochs):\n",
    "        weights = weights - alpha*fullgrad(X,y,weights)\n",
    "        if printing:\n",
    "            print(\"Step:\", i, \"Weights:\", weights, \", error:\", error(X,y,weights))\n",
    "        #if error(X,y,weights) >= currenterror:\n",
    "        #    break\n",
    "        currenterror = error(X,y,weights)\n",
    "        if plotting:\n",
    "            maxepoch +=1\n",
    "            recorderrors.append(currenterror)\n",
    "    if plotting:\n",
    "        fig,ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "        ax.set_ylabel('MSE')\n",
    "        ax.set_xlabel('Iterations')\n",
    "        _=ax.plot(range(maxepoch+1),recorderrors,'b.')\n",
    "        if not showall:\n",
    "            ax.set_ylim(0, min(recorderrors)+20)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to see, what happens if we pick completely different weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([-20, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Weights: [-33.1525  84.1375] , error: 181236.87581171875\n",
      "Step: 1 Weights: [-38.35275625  37.811325  ] , error: 29139.45226704825\n",
      "Step: 2 Weights: [-40.37399313  19.28442598] , error: 4829.787718598396\n",
      "Step: 3 Weights: [-41.12445195  11.87114812] , error: 943.7261847437571\n",
      "Step: 4 Weights: [-41.36700993   8.90089337] , error: 321.85792516350455\n",
      "Step: 5 Weights: [-41.40665013   7.70688722] , error: 221.6908910783225\n",
      "Step: 6 Weights: [-41.36529852   7.22300542] , error: 204.9079733987772\n",
      "Step: 7 Weights: [-41.2916984    7.02303236] , error: 201.45539554397214\n",
      "Step: 8 Weights: [-41.2053361    6.93657533] , error: 200.1368400071467\n",
      "Step: 9 Weights: [-41.11400157   6.89551463] , error: 199.16284629247866\n",
      "Step: 10 Weights: [-41.02080879   6.87261732] , error: 198.247399071748\n",
      "Step: 11 Weights: [-40.92700237   6.85699615] , error: 197.34477028184415\n",
      "Step: 12 Weights: [-40.83307959   6.84429859] , error: 196.44763569512227\n",
      "Step: 13 Weights: [-40.73923895   6.83278455] , error: 195.55480902498618\n",
      "Step: 14 Weights: [-40.64555952   6.82175833] , error: 194.6660850489728\n",
      "Step: 15 Weights: [-40.55207261   6.81094179] , error: 193.78141541376803\n",
      "Step: 16 Weights: [-40.45879045   6.80022368] , error: 192.90077690842975\n",
      "Step: 17 Weights: [-40.36571765   6.78955951] , error: 192.0241504109137\n",
      "Step: 18 Weights: [-40.27285574   6.77893144] , error: 191.1515175228948\n",
      "Step: 19 Weights: [-40.18020505   6.76833232] , error: 190.2828600316089\n",
      "Step: 20 Weights: [-40.08776543   6.75775926] , error: 189.41815982352367\n",
      "Step: 21 Weights: [-39.99553653   6.74721107] , error: 188.55739887022457\n",
      "Step: 22 Weights: [-39.90351791   6.73668723] , error: 187.70055922584302\n",
      "Step: 23 Weights: [-39.81170912   6.7261875 ] , error: 186.8476230263317\n",
      "Step: 24 Weights: [-39.72010969   6.71571177] , error: 185.9985724890358\n",
      "Step: 25 Weights: [-39.62871913   6.70525995] , error: 185.15338991231354\n",
      "Step: 26 Weights: [-39.53753699   6.69483197] , error: 184.31205767516545\n",
      "Step: 27 Weights: [-39.44656278   6.68442778] , error: 183.4745582368668\n",
      "Step: 28 Weights: [-39.35579602   6.67404731] , error: 182.64087413660224\n",
      "Step: 29 Weights: [-39.26523626   6.66369051] , error: 181.81098799310115\n",
      "Step: 30 Weights: [-39.174883     6.65335733] , error: 180.98488250427548\n",
      "Step: 31 Weights: [-39.08473579   6.64304771] , error: 180.1625404468594\n",
      "Step: 32 Weights: [-38.99479416   6.63276161] , error: 179.34394467604983\n",
      "Step: 33 Weights: [-38.90505762   6.62249896] , error: 178.52907812514894\n",
      "Step: 34 Weights: [-38.81552573   6.61225972] , error: 177.71792380520847\n",
      "Step: 35 Weights: [-38.726198     6.60204382] , error: 176.91046480467577\n",
      "Step: 36 Weights: [-38.63707398   6.59185122] , error: 176.1066842890407\n",
      "Step: 37 Weights: [-38.5481532    6.58168187] , error: 175.30656550048516\n",
      "Step: 38 Weights: [-38.45943519   6.5715357 ] , error: 174.51009175753327\n",
      "Step: 39 Weights: [-38.3709195    6.56141267] , error: 173.717246454704\n",
      "Step: 40 Weights: [-38.28260566   6.55131273] , error: 172.92801306216452\n",
      "Step: 41 Weights: [-38.19449321   6.54123582] , error: 172.14237512538602\n",
      "Step: 42 Weights: [-38.1065817    6.53118189] , error: 171.36031626480036\n",
      "Step: 43 Weights: [-38.01887066   6.52115088] , error: 170.58182017545863\n",
      "Step: 44 Weights: [-37.93135964   6.51114275] , error: 169.8068706266913\n",
      "Step: 45 Weights: [-37.84404817   6.50115745] , error: 169.03545146176978\n",
      "Step: 46 Weights: [-37.75693582   6.49119491] , error: 168.26754659756946\n",
      "Step: 47 Weights: [-37.67002212   6.48125509] , error: 167.5031400242346\n",
      "Step: 48 Weights: [-37.58330662   6.47133794] , error: 166.7422158048446\n",
      "Step: 49 Weights: [-37.49678886   6.46144341] , error: 165.9847580750811\n",
      "Step: 50 Weights: [-37.4104684    6.45157144] , error: 165.23075104289828\n",
      "Step: 51 Weights: [-37.32434479   6.44172198] , error: 164.48017898819273\n",
      "Step: 52 Weights: [-37.23841758   6.43189498] , error: 163.73302626247602\n",
      "Step: 53 Weights: [-37.15268631   6.42209039] , error: 162.98927728854855\n",
      "Step: 54 Weights: [-37.06715055   6.41230816] , error: 162.24891656017476\n",
      "Step: 55 Weights: [-36.98180985   6.40254824] , error: 161.51192864175954\n",
      "Step: 56 Weights: [-36.89666375   6.39281057] , error: 160.77829816802674\n",
      "Step: 57 Weights: [-36.81171183   6.38309511] , error: 160.04800984369894\n",
      "Step: 58 Weights: [-36.72695363   6.37340181] , error: 159.3210484431781\n",
      "Step: 59 Weights: [-36.64238872   6.36373061] , error: 158.59739881022838\n",
      "Step: 60 Weights: [-36.55801665   6.35408146] , error: 157.87704585766025\n",
      "Step: 61 Weights: [-36.47383698   6.34445432] , error: 157.1599745670159\n",
      "Step: 62 Weights: [-36.38984927   6.33484913] , error: 156.44616998825583\n",
      "Step: 63 Weights: [-36.3060531    6.32526585] , error: 155.73561723944786\n",
      "Step: 64 Weights: [-36.22244801   6.31570442] , error: 155.0283015064557\n",
      "Step: 65 Weights: [-36.13903358   6.30616479] , error: 154.32420804263157\n",
      "Step: 66 Weights: [-36.05580937   6.29664692] , error: 153.6233221685073\n",
      "Step: 67 Weights: [-35.97277494   6.28715075] , error: 152.9256292714893\n",
      "Step: 68 Weights: [-35.88992987   6.27767624] , error: 152.23111480555346\n",
      "Step: 69 Weights: [-35.80727371   6.26822333] , error: 151.53976429094217\n",
      "Step: 70 Weights: [-35.72480605   6.25879198] , error: 150.8515633138619\n",
      "Step: 71 Weights: [-35.64252645   6.24938214] , error: 150.16649752618332\n",
      "Step: 72 Weights: [-35.56043448   6.23999376] , error: 149.4845526451418\n",
      "Step: 73 Weights: [-35.47852971   6.23062678] , error: 148.8057144530397\n",
      "Step: 74 Weights: [-35.39681173   6.22128117] , error: 148.12996879694984\n",
      "Step: 75 Weights: [-35.31528009   6.21195687] , error: 147.4573015884208\n",
      "Step: 76 Weights: [-35.23393438   6.20265383] , error: 146.78769880318276\n",
      "Step: 77 Weights: [-35.15277416   6.19337201] , error: 146.12114648085532\n",
      "Step: 78 Weights: [-35.07179903   6.18411135] , error: 145.4576307246564\n",
      "Step: 79 Weights: [-34.99100856   6.17487181] , error: 144.7971377011125\n",
      "Step: 80 Weights: [-34.91040232   6.16565334] , error: 144.13965363977053\n",
      "Step: 81 Weights: [-34.8299799    6.15645589] , error: 143.4851648329102\n",
      "Step: 82 Weights: [-34.74974087   6.14727942] , error: 142.83365763525865\n",
      "Step: 83 Weights: [-34.66968482   6.13812387] , error: 142.18511846370592\n",
      "Step: 84 Weights: [-34.58981134   6.1289892 ] , error: 141.5395337970216\n",
      "Step: 85 Weights: [-34.51011999   6.11987537] , error: 140.89689017557308\n",
      "Step: 86 Weights: [-34.43061038   6.11078231] , error: 140.25717420104476\n",
      "Step: 87 Weights: [-34.35128208   6.10170999] , error: 139.62037253615873\n",
      "Step: 88 Weights: [-34.27213469   6.09265836] , error: 138.9864719043972\n",
      "Step: 89 Weights: [-34.19316778   6.08362737] , error: 138.35545908972483\n",
      "Step: 90 Weights: [-34.11438095   6.07461698] , error: 137.72732093631384\n",
      "Step: 91 Weights: [-34.03577379   6.06562713] , error: 137.10204434826957\n",
      "Step: 92 Weights: [-33.95734588   6.05665779] , error: 136.47961628935747\n",
      "Step: 93 Weights: [-33.87909682   6.0477089 ] , error: 135.86002378273108\n",
      "Step: 94 Weights: [-33.8010262    6.03878041] , error: 135.24325391066185\n",
      "Step: 95 Weights: [-33.72313362   6.02987229] , error: 134.6292938142695\n",
      "Step: 96 Weights: [-33.64541866   6.02098448] , error: 134.01813069325397\n",
      "Step: 97 Weights: [-33.56788093   6.01211693] , error: 133.40975180562887\n",
      "Step: 98 Weights: [-33.49052001   6.00326961] , error: 132.8041444674555\n",
      "Step: 99 Weights: [-33.41333551   5.99444247] , error: 132.20129605257847\n",
      "Step: 100 Weights: [-33.33632702   5.98563545] , error: 131.60119399236245\n",
      "Step: 101 Weights: [-33.25949415   5.97684852] , error: 131.0038257754303\n",
      "Step: 102 Weights: [-33.18283648   5.96808163] , error: 130.4091789474019\n",
      "Step: 103 Weights: [-33.10635362   5.95933473] , error: 129.8172411106349\n",
      "Step: 104 Weights: [-33.03004518   5.95060777] , error: 129.22799992396602\n",
      "Step: 105 Weights: [-32.95391076   5.94190072] , error: 128.64144310245342\n",
      "Step: 106 Weights: [-32.87794995   5.93321352] , error: 128.05755841712127\n",
      "Step: 107 Weights: [-32.80216236   5.92454613] , error: 127.47633369470441\n",
      "Step: 108 Weights: [-32.7265476    5.91589851] , error: 126.89775681739444\n",
      "Step: 109 Weights: [-32.65110527   5.9072706 ] , error: 126.3218157225872\n",
      "Step: 110 Weights: [-32.57583499   5.89866238] , error: 125.74849840263157\n",
      "Step: 111 Weights: [-32.50073635   5.89007378] , error: 125.17779290457841\n",
      "Step: 112 Weights: [-32.42580896   5.88150477] , error: 124.6096873299322\n",
      "Step: 113 Weights: [-32.35105244   5.8729553 ] , error: 124.04416983440247\n",
      "Step: 114 Weights: [-32.2764664    5.86442532] , error: 123.48122862765678\n",
      "Step: 115 Weights: [-32.20205045   5.8559148 ] , error: 122.9208519730752\n",
      "Step: 116 Weights: [-32.12780419   5.84742369] , error: 122.36302818750573\n",
      "Step: 117 Weights: [-32.05372725   5.83895194] , error: 121.80774564102\n",
      "Step: 118 Weights: [-31.97981923   5.8304995 ] , error: 121.25499275667181\n",
      "Step: 119 Weights: [-31.90607976   5.82206635] , error: 120.70475801025492\n",
      "Step: 120 Weights: [-31.83250844   5.81365242] , error: 120.15702993006327\n",
      "Step: 121 Weights: [-31.75910489   5.80525768] , error: 119.61179709665156\n",
      "Step: 122 Weights: [-31.68586874   5.79688209] , error: 119.06904814259727\n",
      "Step: 123 Weights: [-31.61279959   5.78852559] , error: 118.52877175226385\n",
      "Step: 124 Weights: [-31.53989707   5.78018815] , error: 117.99095666156425\n",
      "Step: 125 Weights: [-31.4671608    5.77186972] , error: 117.4555916577268\n",
      "Step: 126 Weights: [-31.3945904    5.76357027] , error: 116.92266557906089\n",
      "Step: 127 Weights: [-31.32218549   5.75528974] , error: 116.39216731472445\n",
      "Step: 128 Weights: [-31.24994569   5.74702809] , error: 115.86408580449223\n",
      "Step: 129 Weights: [-31.17787063   5.73878528] , error: 115.33841003852561\n",
      "Step: 130 Weights: [-31.10595993   5.73056127] , error: 114.81512905714236\n",
      "Step: 131 Weights: [-31.03421322   5.72235601] , error: 114.29423195058858\n",
      "Step: 132 Weights: [-30.96263011   5.71416947] , error: 113.77570785881137\n",
      "Step: 133 Weights: [-30.89121025   5.70600159] , error: 113.25954597123203\n",
      "Step: 134 Weights: [-30.81995326   5.69785234] , error: 112.74573552652097\n",
      "Step: 135 Weights: [-30.74885876   5.68972167] , error: 112.23426581237322\n",
      "Step: 136 Weights: [-30.67792638   5.68160955] , error: 111.72512616528508\n",
      "Step: 137 Weights: [-30.60715576   5.67351592] , error: 111.21830597033184\n",
      "Step: 138 Weights: [-30.53654653   5.66544075] , error: 110.7137946609464\n",
      "Step: 139 Weights: [-30.46609832   5.657384  ] , error: 110.21158171869924\n",
      "Step: 140 Weights: [-30.39581075   5.64934562] , error: 109.71165667307875\n",
      "Step: 141 Weights: [-30.32568347   5.64132556] , error: 109.21400910127306\n",
      "Step: 142 Weights: [-30.25571612   5.6333238 ] , error: 108.71862862795292\n",
      "Step: 143 Weights: [-30.18590831   5.62534029] , error: 108.22550492505528\n",
      "Step: 144 Weights: [-30.1162597    5.61737498] , error: 107.7346277115677\n",
      "Step: 145 Weights: [-30.04676991   5.60942783] , error: 107.24598675331445\n",
      "Step: 146 Weights: [-29.97743859   5.60149881] , error: 106.7595718627428\n",
      "Step: 147 Weights: [-29.90826537   5.59358787] , error: 106.27537289871091\n",
      "Step: 148 Weights: [-29.8392499    5.58569497] , error: 105.7933797662759\n",
      "Step: 149 Weights: [-29.77039181   5.57782007] , error: 105.31358241648418\n",
      "Step: 150 Weights: [-29.70169075   5.56996313] , error: 104.83597084616105\n",
      "Step: 151 Weights: [-29.63314635   5.5621241 ] , error: 104.3605350977029\n",
      "Step: 152 Weights: [-29.56475827   5.55430295] , error: 103.88726525886908\n",
      "Step: 153 Weights: [-29.49652613   5.54649963] , error: 103.41615146257553\n",
      "Step: 154 Weights: [-29.4284496    5.53871412] , error: 102.94718388668903\n",
      "Step: 155 Weights: [-29.3605283    5.53094635] , error: 102.48035275382225\n",
      "Step: 156 Weights: [-29.2927619   5.5231963] , error: 102.01564833113002\n",
      "Step: 157 Weights: [-29.22515003   5.51546392] , error: 101.55306093010661\n",
      "Step: 158 Weights: [-29.15769234   5.50774917] , error: 101.09258090638335\n",
      "Step: 159 Weights: [-29.09038849   5.50005202] , error: 100.63419865952781\n",
      "Step: 160 Weights: [-29.02323812   5.49237242] , error: 100.17790463284354\n",
      "Step: 161 Weights: [-28.95624087   5.48471033] , error: 99.72368931317101\n",
      "Step: 162 Weights: [-28.88939641   5.47706572] , error: 99.27154323068903\n",
      "Step: 163 Weights: [-28.82270439   5.46943854] , error: 98.82145695871728\n",
      "Step: 164 Weights: [-28.75616444   5.46182875] , error: 98.3734211135202\n",
      "Step: 165 Weights: [-28.68977624   5.45423632] , error: 97.9274263541109\n",
      "Step: 166 Weights: [-28.62353943   5.44666119] , error: 97.48346338205656\n",
      "Step: 167 Weights: [-28.55745366   5.43910335] , error: 97.04152294128463\n",
      "Step: 168 Weights: [-28.4915186    5.43156274] , error: 96.60159581788972\n",
      "Step: 169 Weights: [-28.4257339    5.42403932] , error: 96.16367283994177\n",
      "Step: 170 Weights: [-28.36009922   5.41653306] , error: 95.7277448772945\n",
      "Step: 171 Weights: [-28.29461421   5.40904392] , error: 95.29380284139522\n",
      "Step: 172 Weights: [-28.22927853   5.40157186] , error: 94.86183768509538\n",
      "Step: 173 Weights: [-28.16409184   5.39411683] , error: 94.43184040246189\n",
      "Step: 174 Weights: [-28.09905381   5.38667881] , error: 94.0038020285892\n",
      "Step: 175 Weights: [-28.03416409   5.37925775] , error: 93.57771363941289\n",
      "Step: 176 Weights: [-27.96942235   5.37185361] , error: 93.15356635152298\n",
      "Step: 177 Weights: [-27.90482825   5.36446635] , error: 92.73135132197915\n",
      "Step: 178 Weights: [-27.84038144   5.35709595] , error: 92.31105974812624\n",
      "Step: 179 Weights: [-27.7760816    5.34974235] , error: 91.89268286741067\n",
      "Step: 180 Weights: [-27.7119284    5.34240551] , error: 91.47621195719796\n",
      "Step: 181 Weights: [-27.64792148   5.33508541] , error: 91.06163833459061\n",
      "Step: 182 Weights: [-27.58406054   5.32778201] , error: 90.64895335624723\n",
      "Step: 183 Weights: [-27.52034522   5.32049525] , error: 90.23814841820227\n",
      "Step: 184 Weights: [-27.45677519   5.31322512] , error: 89.82921495568672\n",
      "Step: 185 Weights: [-27.39335014   5.30597156] , error: 89.42214444294945\n",
      "Step: 186 Weights: [-27.33006972   5.29873455] , error: 89.01692839307955\n",
      "Step: 187 Weights: [-27.2669336    5.29151403] , error: 88.61355835782926\n",
      "Step: 188 Weights: [-27.20394146   5.28430999] , error: 88.21202592743803\n",
      "Step: 189 Weights: [-27.14109297   5.27712237] , error: 87.812322730457\n",
      "Step: 190 Weights: [-27.0783878    5.26995114] , error: 87.41444043357451\n",
      "Step: 191 Weights: [-27.01582562   5.26279627] , error: 87.01837074144245\n",
      "Step: 192 Weights: [-26.95340612   5.25565771] , error: 86.62410539650318\n",
      "Step: 193 Weights: [-26.89112895   5.24853543] , error: 86.23163617881758\n",
      "Step: 194 Weights: [-26.8289938    5.24142939] , error: 85.84095490589335\n",
      "Step: 195 Weights: [-26.76700035   5.23433956] , error: 85.45205343251479\n",
      "Step: 196 Weights: [-26.70514827   5.22726589] , error: 85.06492365057265\n",
      "Step: 197 Weights: [-26.64343723   5.22020836] , error: 84.6795574888953\n",
      "Step: 198 Weights: [-26.58186692   5.21316692] , error: 84.29594691308034\n",
      "Step: 199 Weights: [-26.52043702   5.20614154] , error: 83.91408392532718\n",
      "Step: 200 Weights: [-26.4591472    5.19913218] , error: 83.53396056427027\n",
      "Step: 201 Weights: [-26.39799715   5.1921388 ] , error: 83.15556890481304\n",
      "Step: 202 Weights: [-26.33698655   5.18516137] , error: 82.77890105796277\n",
      "Step: 203 Weights: [-26.27611508   5.17819985] , error: 82.4039491706661\n",
      "Step: 204 Weights: [-26.21538242   5.17125421] , error: 82.0307054256452\n",
      "Step: 205 Weights: [-26.15478825   5.1643244 ] , error: 81.65916204123498\n",
      "Step: 206 Weights: [-26.09433227   5.1574104 ] , error: 81.28931127122058\n",
      "Step: 207 Weights: [-26.03401415   5.15051217] , error: 80.92114540467624\n",
      "Step: 208 Weights: [-25.97383358   5.14362966] , error: 80.55465676580418\n",
      "Step: 209 Weights: [-25.91379024   5.13676285] , error: 80.18983771377475\n",
      "Step: 210 Weights: [-25.85388383   5.1299117 ] , error: 79.82668064256711\n",
      "Step: 211 Weights: [-25.79411403   5.12307618] , error: 79.4651779808107\n",
      "Step: 212 Weights: [-25.73448054   5.11625624] , error: 79.1053221916272\n",
      "Step: 213 Weights: [-25.67498303   5.10945185] , error: 78.74710577247357\n",
      "Step: 214 Weights: [-25.6156212    5.10266298] , error: 78.39052125498569\n",
      "Step: 215 Weights: [-25.55639474   5.0958896 ] , error: 78.03556120482244\n",
      "Step: 216 Weights: [-25.49730334   5.08913166] , error: 77.68221822151078\n",
      "Step: 217 Weights: [-25.43834669   5.08238912] , error: 77.33048493829158\n",
      "Step: 218 Weights: [-25.37952449   5.07566197] , error: 76.9803540219659\n",
      "Step: 219 Weights: [-25.32083643   5.06895016] , error: 76.6318181727422\n",
      "Step: 220 Weights: [-25.2622822    5.06225365] , error: 76.28487012408398\n",
      "Step: 221 Weights: [-25.2038615    5.05557241] , error: 75.93950264255851\n",
      "Step: 222 Weights: [-25.14557402   5.04890641] , error: 75.59570852768584\n",
      "Step: 223 Weights: [-25.08741946   5.04225561] , error: 75.25348061178876\n",
      "Step: 224 Weights: [-25.02939752   5.03561997] , error: 74.91281175984338\n",
      "Step: 225 Weights: [-24.97150789   5.02899947] , error: 74.57369486933032\n",
      "Step: 226 Weights: [-24.91375028   5.02239407] , error: 74.2361228700866\n",
      "Step: 227 Weights: [-24.85612438   5.01580373] , error: 73.90008872415837\n",
      "Step: 228 Weights: [-24.79862988   5.00922841] , error: 73.56558542565412\n",
      "Step: 229 Weights: [-24.7412665   5.0026681] , error: 73.23260600059848\n",
      "Step: 230 Weights: [-24.68403393   4.99612274] , error: 72.90114350678702\n",
      "Step: 231 Weights: [-24.62693188   4.98959231] , error: 72.57119103364144\n",
      "Step: 232 Weights: [-24.56996004   4.98307677] , error: 72.24274170206542\n",
      "Step: 233 Weights: [-24.51311812   4.97657609] , error: 71.91578866430132\n",
      "Step: 234 Weights: [-24.45640583   4.97009023] , error: 71.59032510378726\n",
      "Step: 235 Weights: [-24.39982286   4.96361916] , error: 71.26634423501521\n",
      "Step: 236 Weights: [-24.34336892   4.95716285] , error: 70.94383930338938\n",
      "Step: 237 Weights: [-24.28704373   4.95072126] , error: 70.62280358508536\n",
      "Step: 238 Weights: [-24.23084698   4.94429437] , error: 70.3032303869101\n",
      "Step: 239 Weights: [-24.17477838   4.93788213] , error: 69.98511304616213\n",
      "Step: 240 Weights: [-24.11883764   4.93148451] , error: 69.66844493049295\n",
      "Step: 241 Weights: [-24.06302446   4.92510148] , error: 69.35321943776842\n",
      "Step: 242 Weights: [-24.00733857   4.918733  ] , error: 69.03942999593143\n",
      "Step: 243 Weights: [-23.95177966   4.91237905] , error: 68.72707006286464\n",
      "Step: 244 Weights: [-23.89634745   4.90603959] , error: 68.41613312625428\n",
      "Step: 245 Weights: [-23.84104165   4.89971459] , error: 68.10661270345412\n",
      "Step: 246 Weights: [-23.78586197   4.89340401] , error: 67.79850234135058\n",
      "Step: 247 Weights: [-23.73080812   4.88710781] , error: 67.4917956162281\n",
      "Step: 248 Weights: [-23.67587981   4.88082598] , error: 67.18648613363513\n",
      "Step: 249 Weights: [-23.62107677   4.87455848] , error: 66.88256752825095\n",
      "Step: 250 Weights: [-23.5663987    4.86830526] , error: 66.58003346375273\n",
      "Step: 251 Weights: [-23.51184532   4.86206631] , error: 66.2788776326838\n",
      "Step: 252 Weights: [-23.45741634   4.85584158] , error: 65.97909375632182\n",
      "Step: 253 Weights: [-23.40311148   4.84963105] , error: 65.68067558454794\n",
      "Step: 254 Weights: [-23.34893046   4.84343468] , error: 65.38361689571671\n",
      "Step: 255 Weights: [-23.294873     4.83725244] , error: 65.087911496526\n",
      "Step: 256 Weights: [-23.24093881   4.8310843 ] , error: 64.79355322188822\n",
      "Step: 257 Weights: [-23.18712761   4.82493022] , error: 64.50053593480153\n",
      "Step: 258 Weights: [-23.13343912   4.81879018] , error: 64.20885352622219\n",
      "Step: 259 Weights: [-23.07987307   4.81266414] , error: 63.9184999149367\n",
      "Step: 260 Weights: [-23.02642917   4.80655207] , error: 63.62946904743564\n",
      "Step: 261 Weights: [-22.97310714   4.80045394] , error: 63.341754897786956\n",
      "Step: 262 Weights: [-22.91990671   4.79436971] , error: 63.05535146751056\n",
      "Step: 263 Weights: [-22.8668276    4.78829936] , error: 62.770252785453266\n",
      "Step: 264 Weights: [-22.81386953   4.78224285] , error: 62.48645290766417\n",
      "Step: 265 Weights: [-22.76103223   4.77620016] , error: 62.20394591727087\n",
      "Step: 266 Weights: [-22.70831541   4.77017124] , error: 61.92272592435601\n",
      "Step: 267 Weights: [-22.65571882   4.76415607] , error: 61.642787065834625\n",
      "Step: 268 Weights: [-22.60324217   4.75815462] , error: 61.364123505331634\n",
      "Step: 269 Weights: [-22.55088518   4.75216685] , error: 61.08672943306049\n",
      "Step: 270 Weights: [-22.49864759   4.74619274] , error: 60.81059906570175\n",
      "Step: 271 Weights: [-22.44652913   4.74023226] , error: 60.53572664628274\n",
      "Step: 272 Weights: [-22.39452951   4.73428536] , error: 60.262106444057345\n",
      "Step: 273 Weights: [-22.34264848   4.72835203] , error: 59.9897327543867\n",
      "Step: 274 Weights: [-22.29088576   4.72243222] , error: 59.71859989862007\n",
      "Step: 275 Weights: [-22.23924107   4.71652592] , error: 59.44870222397662\n",
      "Step: 276 Weights: [-22.18771416   4.71063308] , error: 59.180034103427495\n",
      "Step: 277 Weights: [-22.13630475   4.70475369] , error: 58.91258993557848\n",
      "Step: 278 Weights: [-22.08501258   4.6988877 ] , error: 58.646364144553246\n",
      "Step: 279 Weights: [-22.03383737   4.69303509] , error: 58.3813511798771\n",
      "Step: 280 Weights: [-21.98277887   4.68719582] , error: 58.11754551636129\n",
      "Step: 281 Weights: [-21.9318368    4.68136987] , error: 57.854941653987744\n",
      "Step: 282 Weights: [-21.8810109    4.67555721] , error: 57.5935341177944\n",
      "Step: 283 Weights: [-21.8303009   4.6697578] , error: 57.33331745776127\n",
      "Step: 284 Weights: [-21.77970654   4.66397161] , error: 57.07428624869642\n",
      "Step: 285 Weights: [-21.72922756   4.65819862] , error: 56.816435090123235\n",
      "Step: 286 Weights: [-21.67886369   4.6524388 ] , error: 56.559758606167605\n",
      "Step: 287 Weights: [-21.62861467   4.64669211] , error: 56.304251445446006\n",
      "Step: 288 Weights: [-21.57848024   4.64095853] , error: 56.0499082809537\n",
      "Step: 289 Weights: [-21.52846014   4.63523802] , error: 55.79672380995402\n",
      "Step: 290 Weights: [-21.47855411   4.62953055] , error: 55.544692753867345\n",
      "Step: 291 Weights: [-21.42876188   4.6238361 ] , error: 55.29380985816151\n",
      "Step: 292 Weights: [-21.3790832    4.61815464] , error: 55.044069892242035\n",
      "Step: 293 Weights: [-21.3295178    4.61248613] , error: 54.79546764934299\n",
      "Step: 294 Weights: [-21.28006544   4.60683055] , error: 54.547997946418604\n",
      "Step: 295 Weights: [-21.23072584   4.60118787] , error: 54.30165562403527\n",
      "Step: 296 Weights: [-21.18149877   4.59555805] , error: 54.05643554626366\n",
      "Step: 297 Weights: [-21.13238395   4.58994107] , error: 53.81233260057192\n",
      "Step: 298 Weights: [-21.08338113   4.5843369 ] , error: 53.569341697719054\n",
      "Step: 299 Weights: [-21.03449006   4.57874551] , error: 53.327457771648675\n",
      "Step: 300 Weights: [-20.98571048   4.57316688] , error: 53.086675779383555\n",
      "Step: 301 Weights: [-20.93704214   4.56760096] , error: 52.84699070092037\n",
      "Step: 302 Weights: [-20.88848478   4.56204774] , error: 52.608397539125086\n",
      "Step: 303 Weights: [-20.84003816   4.55650718] , error: 52.37089131962876\n",
      "Step: 304 Weights: [-20.79170201   4.55097925] , error: 52.134467090723874\n",
      "Step: 305 Weights: [-20.74347609   4.54546393] , error: 51.89911992326099\n",
      "Step: 306 Weights: [-20.69536015   4.53996119] , error: 51.66484491054604\n",
      "Step: 307 Weights: [-20.64735392   4.53447099] , error: 51.43163716823817\n",
      "Step: 308 Weights: [-20.59945718   4.52899332] , error: 51.1994918342477\n",
      "Step: 309 Weights: [-20.55166965   4.52352814] , error: 50.96840406863477\n",
      "Step: 310 Weights: [-20.50399111   4.51807542] , error: 50.73836905350859\n",
      "Step: 311 Weights: [-20.45642129   4.51263513] , error: 50.50938199292693\n",
      "Step: 312 Weights: [-20.40895995   4.50720725] , error: 50.281438112795925\n",
      "Step: 313 Weights: [-20.36160684   4.50179175] , error: 50.054532660770946\n",
      "Step: 314 Weights: [-20.31436171   4.4963886 ] , error: 49.82866090615714\n",
      "Step: 315 Weights: [-20.26722432   4.49099777] , error: 49.60381813981098\n",
      "Step: 316 Weights: [-20.22019443   4.48561923] , error: 49.37999967404208\n",
      "Step: 317 Weights: [-20.17327178   4.48025296] , error: 49.157200842515415\n",
      "Step: 318 Weights: [-20.12645614   4.47489893] , error: 48.935417000154104\n",
      "Step: 319 Weights: [-20.07974726   4.4695571 ] , error: 48.714643523042454\n",
      "Step: 320 Weights: [-20.03314489   4.46422746] , error: 48.49487580832968\n",
      "Step: 321 Weights: [-19.98664879   4.45890997] , error: 48.27610927413386\n",
      "Step: 322 Weights: [-19.94025873   4.45360461] , error: 48.05833935944643\n",
      "Step: 323 Weights: [-19.89397445   4.44831134] , error: 47.8415615240371\n",
      "Step: 324 Weights: [-19.84779572   4.44303015] , error: 47.62577124835922\n",
      "Step: 325 Weights: [-19.8017223   4.437761 ] , error: 47.410964033455485\n",
      "Step: 326 Weights: [-19.75575395   4.43250386] , error: 47.197135400864155\n",
      "Step: 327 Weights: [-19.70989042   4.42725871] , error: 46.98428089252582\n",
      "Step: 328 Weights: [-19.66413148   4.42202553] , error: 46.77239607069016\n",
      "Step: 329 Weights: [-19.61847688   4.41680428] , error: 46.5614765178238\n",
      "Step: 330 Weights: [-19.5729264    4.41159493] , error: 46.351517836517885\n",
      "Step: 331 Weights: [-19.5274798    4.40639747] , error: 46.14251564939657\n",
      "Step: 332 Weights: [-19.48213683   4.40121185] , error: 45.93446559902575\n",
      "Step: 333 Weights: [-19.43689726   4.39603807] , error: 45.72736334782212\n",
      "Step: 334 Weights: [-19.39176086   4.39087608] , error: 45.52120457796283\n",
      "Step: 335 Weights: [-19.34672738   4.38572586] , error: 45.315984991295466\n",
      "Step: 336 Weights: [-19.30179661   4.38058739] , error: 45.11170030924837\n",
      "Step: 337 Weights: [-19.25696829   4.37546063] , error: 44.908346272741454\n",
      "Step: 338 Weights: [-19.2122422    4.37034557] , error: 44.70591864209746\n",
      "Step: 339 Weights: [-19.1676181    4.36524217] , error: 44.50441319695356\n",
      "Step: 340 Weights: [-19.12309577   4.3601504 ] , error: 44.30382573617326\n",
      "Step: 341 Weights: [-19.07867496   4.35507025] , error: 44.104152077759025\n",
      "Step: 342 Weights: [-19.03435545   4.35000169] , error: 43.90538805876479\n",
      "Step: 343 Weights: [-18.99013701   4.34494468] , error: 43.707529535209446\n",
      "Step: 344 Weights: [-18.94601941   4.33989921] , error: 43.51057238199033\n",
      "Step: 345 Weights: [-18.90200241   4.33486524] , error: 43.314512492797135\n",
      "Step: 346 Weights: [-18.85808579   4.32984275] , error: 43.11934578002647\n",
      "Step: 347 Weights: [-18.81426932   4.32483171] , error: 42.92506817469654\n",
      "Step: 348 Weights: [-18.77055277   4.3198321 ] , error: 42.73167562636232\n",
      "Step: 349 Weights: [-18.72693591   4.31484389] , error: 42.539164103031105\n",
      "Step: 350 Weights: [-18.68341851   4.30986706] , error: 42.347529591078484\n",
      "Step: 351 Weights: [-18.64000035   4.30490158] , error: 42.15676809516461\n",
      "Step: 352 Weights: [-18.5966812    4.29994742] , error: 41.96687563815089\n",
      "Step: 353 Weights: [-18.55346084   4.29500455] , error: 41.77784826101723\n",
      "Step: 354 Weights: [-18.51033904   4.29007296] , error: 41.58968202277927\n",
      "Step: 355 Weights: [-18.46731558   4.28515262] , error: 41.402373000406335\n",
      "Step: 356 Weights: [-18.42439022   4.28024349] , error: 41.215917288739604\n",
      "Step: 357 Weights: [-18.38156275   4.27534556] , error: 41.030311000410805\n",
      "Step: 358 Weights: [-18.33883295   4.2704588 ] , error: 40.84555026576099\n",
      "Step: 359 Weights: [-18.29620059   4.26558319] , error: 40.661631232759966\n",
      "Step: 360 Weights: [-18.25366545   4.26071869] , error: 40.47855006692603\n",
      "Step: 361 Weights: [-18.21122731   4.25586528] , error: 40.29630295124586\n",
      "Step: 362 Weights: [-18.16888594   4.25102295] , error: 40.11488608609511\n",
      "Step: 363 Weights: [-18.12664113   4.24619165] , error: 39.9342956891591\n",
      "Step: 364 Weights: [-18.08449266   4.24137137] , error: 39.75452799535398\n",
      "Step: 365 Weights: [-18.0424403    4.23656209] , error: 39.57557925674821\n",
      "Step: 366 Weights: [-18.00048384   4.23176377] , error: 39.397445742484464\n",
      "Step: 367 Weights: [-17.95862305   4.2269764 ] , error: 39.22012373870183\n",
      "Step: 368 Weights: [-17.91685773   4.22219994] , error: 39.04360954845834\n",
      "Step: 369 Weights: [-17.87518765   4.21743437] , error: 38.86789949165395\n",
      "Step: 370 Weights: [-17.83361259   4.21267967] , error: 38.69298990495379\n",
      "Step: 371 Weights: [-17.79213234   4.20793582] , error: 38.518877141711826\n",
      "Step: 372 Weights: [-17.75074669   4.20320278] , error: 38.34555757189476\n",
      "Step: 373 Weights: [-17.70945541   4.19848053] , error: 38.17302758200634\n",
      "Step: 374 Weights: [-17.66825829   4.19376906] , error: 38.00128357501212\n",
      "Step: 375 Weights: [-17.62715512   4.18906833] , error: 37.83032197026445\n",
      "Step: 376 Weights: [-17.58614568   4.18437831] , error: 37.660139203427725\n",
      "Step: 377 Weights: [-17.54522976   4.179699  ] , error: 37.49073172640416\n",
      "Step: 378 Weights: [-17.50440714   4.17503035] , error: 37.322096007259795\n",
      "Step: 379 Weights: [-17.46367762   4.17037235] , error: 37.154228530150824\n",
      "Step: 380 Weights: [-17.42304098   4.16572497] , error: 36.98712579525038\n",
      "Step: 381 Weights: [-17.382497     4.16108819] , error: 36.82078431867551\n",
      "Step: 382 Weights: [-17.34204549   4.15646199] , error: 36.65520063241445\n",
      "Step: 383 Weights: [-17.30168622   4.15184633] , error: 36.490371284254564\n",
      "Step: 384 Weights: [-17.26141898   4.1472412 ] , error: 36.326292837710106\n",
      "Step: 385 Weights: [-17.22124357   4.14264657] , error: 36.162961871950735\n",
      "Step: 386 Weights: [-17.18115978   4.13806242] , error: 36.00037498173017\n",
      "Step: 387 Weights: [-17.14116739   4.13348872] , error: 35.83852877731513\n",
      "Step: 388 Weights: [-17.10126621   4.12892545] , error: 35.67741988441473\n",
      "Step: 389 Weights: [-17.06145602   4.12437259] , error: 35.51704494411007\n",
      "Step: 390 Weights: [-17.0217366    4.11983011] , error: 35.357400612784325\n",
      "Step: 391 Weights: [-16.98210777   4.11529799] , error: 35.19848356205289\n",
      "Step: 392 Weights: [-16.94256931   4.11077621] , error: 35.04029047869405\n",
      "Step: 393 Weights: [-16.90312101   4.10626473] , error: 34.88281806457992\n",
      "Step: 394 Weights: [-16.86376267   4.10176355] , error: 34.726063036607684\n",
      "Step: 395 Weights: [-16.82449408   4.09727263] , error: 34.57002212663111\n",
      "Step: 396 Weights: [-16.78531504   4.09279195] , error: 34.41469208139242\n",
      "Step: 397 Weights: [-16.74622535   4.08832148] , error: 34.260069662454484\n",
      "Step: 398 Weights: [-16.70722479   4.08386122] , error: 34.10615164613332\n",
      "Step: 399 Weights: [-16.66831318   4.07941112] , error: 33.952934823430844\n",
      "Step: 400 Weights: [-16.6294903    4.07497117] , error: 33.80041599996795\n",
      "Step: 401 Weights: [-16.59075595   4.07054135] , error: 33.648591995918004\n",
      "Step: 402 Weights: [-16.55210993   4.06612163] , error: 33.49745964594045\n",
      "Step: 403 Weights: [-16.51355204   4.06171198] , error: 33.34701579911486\n",
      "Step: 404 Weights: [-16.47508208   4.0573124 ] , error: 33.1972573188752\n",
      "Step: 405 Weights: [-16.43669984   4.05292284] , error: 33.04818108294457\n",
      "Step: 406 Weights: [-16.39840514   4.0485433 ] , error: 32.8997839832699\n",
      "Step: 407 Weights: [-16.36019776   4.04417374] , error: 32.75206292595732\n",
      "Step: 408 Weights: [-16.32207751   4.03981415] , error: 32.60501483120758\n",
      "Step: 409 Weights: [-16.28404419   4.0354645 ] , error: 32.4586366332519\n",
      "Step: 410 Weights: [-16.2460976    4.03112477] , error: 32.31292528028794\n",
      "Step: 411 Weights: [-16.20823755   4.02679493] , error: 32.16787773441628\n",
      "Step: 412 Weights: [-16.17046383   4.02247497] , error: 32.02349097157706\n",
      "Step: 413 Weights: [-16.13277625   4.01816486] , error: 31.87976198148689\n",
      "Step: 414 Weights: [-16.09517462   4.01386458] , error: 31.736687767576132\n",
      "Step: 415 Weights: [-16.05765873   4.0095741 ] , error: 31.59426534692643\n",
      "Step: 416 Weights: [-16.02022839   4.00529341] , error: 31.452491750208466\n",
      "Step: 417 Weights: [-15.98288341   4.00102248] , error: 31.31136402162013\n",
      "Step: 418 Weights: [-15.9456236    3.99676129] , error: 31.170879218824815\n",
      "Step: 419 Weights: [-15.90844875   3.99250982] , error: 31.031034412890158\n",
      "Step: 420 Weights: [-15.87135867   3.98826804] , error: 30.891826688226878\n",
      "Step: 421 Weights: [-15.83435318   3.98403594] , error: 30.753253142528074\n",
      "Step: 422 Weights: [-15.79743207   3.97981348] , error: 30.61531088670867\n",
      "Step: 423 Weights: [-15.76059516   3.97560066] , error: 30.477997044845218\n",
      "Step: 424 Weights: [-15.72384226   3.97139744] , error: 30.34130875411587\n",
      "Step: 425 Weights: [-15.68717316   3.96720381] , error: 30.205243164740796\n",
      "Step: 426 Weights: [-15.65058769   3.96301974] , error: 30.069797439922663\n",
      "Step: 427 Weights: [-15.61408564   3.95884521] , error: 29.934968755787526\n",
      "Step: 428 Weights: [-15.57766684   3.95468021] , error: 29.800754301326027\n",
      "Step: 429 Weights: [-15.54133108   3.9505247 ] , error: 29.667151278334696\n",
      "Step: 430 Weights: [-15.50507819   3.94637866] , error: 29.534156901357626\n",
      "Step: 431 Weights: [-15.46890797   3.94224208] , error: 29.40176839762846\n",
      "Step: 432 Weights: [-15.43282023   3.93811494] , error: 29.269983007012467\n",
      "Step: 433 Weights: [-15.39681478   3.9339972 ] , error: 29.138797981949168\n",
      "Step: 434 Weights: [-15.36089145   3.92988886] , error: 29.00821058739488\n",
      "Step: 435 Weights: [-15.32505003   3.92578988] , error: 28.878218100765793\n",
      "Step: 436 Weights: [-15.28929035   3.92170025] , error: 28.748817811881185\n",
      "Step: 437 Weights: [-15.25361221   3.91761995] , error: 28.62000702290692\n",
      "Step: 438 Weights: [-15.21801544   3.91354895] , error: 28.491783048299204\n",
      "Step: 439 Weights: [-15.18249984   3.90948724] , error: 28.36414321474855\n",
      "Step: 440 Weights: [-15.14706523   3.90543479] , error: 28.23708486112413\n",
      "Step: 441 Weights: [-15.11171142   3.90139158] , error: 28.11060533841821\n",
      "Step: 442 Weights: [-15.07643824   3.89735759] , error: 27.984702009690974\n",
      "Step: 443 Weights: [-15.0412455   3.8933328] , error: 27.859372250015518\n",
      "Step: 444 Weights: [-15.006133     3.88931719] , error: 27.73461344642317\n",
      "Step: 445 Weights: [-14.97110058   3.88531073] , error: 27.610422997848897\n",
      "Step: 446 Weights: [-14.93614805   3.88131341] , error: 27.48679831507727\n",
      "Step: 447 Weights: [-14.90127523   3.87732521] , error: 27.363736820688263\n",
      "Step: 448 Weights: [-14.86648193   3.8733461 ] , error: 27.241235949003677\n",
      "Step: 449 Weights: [-14.83176797   3.86937607] , error: 27.119293146033627\n",
      "Step: 450 Weights: [-14.79713317   3.86541508] , error: 26.997905869423178\n",
      "Step: 451 Weights: [-14.76257736   3.86146314] , error: 26.877071588399485\n",
      "Step: 452 Weights: [-14.72810035   3.8575202 ] , error: 26.756787783718966\n",
      "Step: 453 Weights: [-14.69370196   3.85358626] , error: 26.637051947614754\n",
      "Step: 454 Weights: [-14.65938201   3.84966128] , error: 26.517861583744477\n",
      "Step: 455 Weights: [-14.62514033   3.84574526] , error: 26.399214207138144\n",
      "Step: 456 Weights: [-14.59097673   3.84183816] , error: 26.281107344146378\n",
      "Step: 457 Weights: [-14.55689104   3.83793998] , error: 26.163538532388827\n",
      "Step: 458 Weights: [-14.52288308   3.83405069] , error: 26.04650532070288\n",
      "Step: 459 Weights: [-14.48895267   3.83017026] , error: 25.930005269092465\n",
      "Step: 460 Weights: [-14.45509963   3.82629869] , error: 25.814035948677255\n",
      "Step: 461 Weights: [-14.4213238    3.82243594] , error: 25.69859494164198\n",
      "Step: 462 Weights: [-14.38762499   3.818582  ] , error: 25.583679841186083\n",
      "Step: 463 Weights: [-14.35400302   3.81473685] , error: 25.469288251473486\n",
      "Step: 464 Weights: [-14.32045773   3.81090047] , error: 25.355417787582617\n",
      "Step: 465 Weights: [-14.28698893   3.80707284] , error: 25.2420660754568\n",
      "Step: 466 Weights: [-14.25359646   3.80325393] , error: 25.12923075185461\n",
      "Step: 467 Weights: [-14.22028014   3.79944374] , error: 25.01690946430071\n",
      "Step: 468 Weights: [-14.18703979   3.79564223] , error: 24.90509987103678\n",
      "Step: 469 Weights: [-14.15387524   3.7918494 ] , error: 24.793799640972672\n",
      "Step: 470 Weights: [-14.12078632   3.78806521] , error: 24.683006453637837\n",
      "Step: 471 Weights: [-14.08777286   3.78428965] , error: 24.572717999132905\n",
      "Step: 472 Weights: [-14.05483468   3.7805227 ] , error: 24.4629319780816\n",
      "Step: 473 Weights: [-14.02197162   3.77676434] , error: 24.3536461015827\n",
      "Step: 474 Weights: [-13.9891835    3.77301455] , error: 24.244858091162406\n",
      "Step: 475 Weights: [-13.95647014   3.76927332] , error: 24.136565678726793\n",
      "Step: 476 Weights: [-13.92383139   3.76554061] , error: 24.028766606514544\n",
      "Step: 477 Weights: [-13.89126707   3.76181642] , error: 23.92145862704986\n",
      "Step: 478 Weights: [-13.85877701   3.75810072] , error: 23.814639503095613\n",
      "Step: 479 Weights: [-13.82636103   3.75439349] , error: 23.708307007606695\n",
      "Step: 480 Weights: [-13.79401898   3.75069472] , error: 23.602458923683628\n",
      "Step: 481 Weights: [-13.76175069   3.74700438] , error: 23.49709304452624\n",
      "Step: 482 Weights: [-13.72955598   3.74332246] , error: 23.392207173387767\n",
      "Step: 483 Weights: [-13.69743468   3.73964893] , error: 23.287799123529048\n",
      "Step: 484 Weights: [-13.66538664   3.73598378] , error: 23.183866718172823\n",
      "Step: 485 Weights: [-13.63341168   3.73232699] , error: 23.08040779045847\n",
      "Step: 486 Weights: [-13.60150963   3.72867854] , error: 22.977420183396774\n",
      "Step: 487 Weights: [-13.56968034   3.7250384 ] , error: 22.87490174982498\n",
      "Step: 488 Weights: [-13.53792363   3.72140657] , error: 22.772850352361996\n",
      "Step: 489 Weights: [-13.50623933   3.71778302] , error: 22.67126386336384\n",
      "Step: 490 Weights: [-13.47462729   3.71416774] , error: 22.570140164879316\n",
      "Step: 491 Weights: [-13.44308734   3.7105607 ] , error: 22.46947714860581\n",
      "Step: 492 Weights: [-13.41161932   3.70696188] , error: 22.36927271584535\n",
      "Step: 493 Weights: [-13.38022305   3.70337127] , error: 22.269524777460898\n",
      "Step: 494 Weights: [-13.34889838   3.69978885] , error: 22.17023125383272\n",
      "Step: 495 Weights: [-13.31764514   3.6962146 ] , error: 22.071390074815053\n",
      "Step: 496 Weights: [-13.28646318   3.6926485 ] , error: 21.97299917969297\n",
      "Step: 497 Weights: [-13.25535232   3.68909053] , error: 21.875056517139402\n",
      "Step: 498 Weights: [-13.22431241   3.68554067] , error: 21.77756004517235\n",
      "Step: 499 Weights: [-13.19334328   3.68199891] , error: 21.680507731112364\n",
      "Step: 500 Weights: [-13.16244477   3.67846523] , error: 21.58389755154009\n",
      "Step: 501 Weights: [-13.13161673   3.6749396 ] , error: 21.48772749225416\n",
      "Step: 502 Weights: [-13.10085898   3.67142202] , error: 21.391995548229126\n",
      "Step: 503 Weights: [-13.07017138   3.66791245] , error: 21.296699723573745\n",
      "Step: 504 Weights: [-13.03955376   3.66441089] , error: 21.20183803148928\n",
      "Step: 505 Weights: [-13.00900595   3.66091732] , error: 21.107408494228117\n",
      "Step: 506 Weights: [-12.97852781   3.65743171] , error: 21.013409143052527\n",
      "Step: 507 Weights: [-12.94811918   3.65395405] , error: 20.919838018193666\n",
      "Step: 508 Weights: [-12.91777988   3.65048432] , error: 20.826693168810607\n",
      "Step: 509 Weights: [-12.88750977   3.6470225 ] , error: 20.733972652949774\n",
      "Step: 510 Weights: [-12.8573087    3.64356858] , error: 20.64167453750443\n",
      "Step: 511 Weights: [-12.82717649   3.64012253] , error: 20.5497968981743\n",
      "Step: 512 Weights: [-12.79711299   3.63668435] , error: 20.45833781942555\n",
      "Step: 513 Weights: [-12.76711806   3.633254  ] , error: 20.36729539445082\n",
      "Step: 514 Weights: [-12.73719152   3.62983147] , error: 20.276667725129442\n",
      "Step: 515 Weights: [-12.70733323   3.62641675] , error: 20.186452921987897\n",
      "Step: 516 Weights: [-12.67754303   3.62300982] , error: 20.09664910416037\n",
      "Step: 517 Weights: [-12.64782076   3.61961066] , error: 20.00725439934963\n",
      "Step: 518 Weights: [-12.61816627   3.61621924] , error: 19.918266943787916\n",
      "Step: 519 Weights: [-12.58857941   3.61283557] , error: 19.829684882198077\n",
      "Step: 520 Weights: [-12.55906002   3.6094596 ] , error: 19.741506367754972\n",
      "Step: 521 Weights: [-12.52960794   3.60609134] , error: 19.653729562046887\n",
      "Step: 522 Weights: [-12.50022303   3.60273076] , error: 19.566352635037227\n",
      "Step: 523 Weights: [-12.47090512   3.59937784] , error: 19.479373765026367\n",
      "Step: 524 Weights: [-12.44165407   3.59603256] , error: 19.392791138613685\n",
      "Step: 525 Weights: [-12.41246973   3.59269492] , error: 19.30660295065975\n",
      "Step: 526 Weights: [-12.38335194   3.58936489] , error: 19.22080740424863\n",
      "Step: 527 Weights: [-12.35430055   3.58604245] , error: 19.13540271065056\n",
      "Step: 528 Weights: [-12.32531541   3.58272758] , error: 19.050387089284484\n",
      "Step: 529 Weights: [-12.29639637   3.57942028] , error: 18.965758767681063\n",
      "Step: 530 Weights: [-12.26754327   3.57612052] , error: 18.881515981445666\n",
      "Step: 531 Weights: [-12.23875598   3.57282828] , error: 18.797656974221596\n",
      "Step: 532 Weights: [-12.21003433   3.56954355] , error: 18.71417999765346\n",
      "Step: 533 Weights: [-12.18137817   3.56626632] , error: 18.631083311350714\n",
      "Step: 534 Weights: [-12.15278737   3.56299655] , error: 18.548365182851402\n",
      "Step: 535 Weights: [-12.12426176   3.55973424] , error: 18.46602388758606\n",
      "Step: 536 Weights: [-12.0958012    3.55647937] , error: 18.384057708841656\n",
      "Step: 537 Weights: [-12.06740555   3.55323193] , error: 18.302464937725915\n",
      "Step: 538 Weights: [-12.03907465   3.54999188] , error: 18.221243873131623\n",
      "Step: 539 Weights: [-12.01080835   3.54675923] , error: 18.140392821701216\n",
      "Step: 540 Weights: [-11.98260652   3.54353395] , error: 18.059910097791395\n",
      "Step: 541 Weights: [-11.954469     3.54031603] , error: 17.97979402343808\n",
      "Step: 542 Weights: [-11.92639564   3.53710544] , error: 17.900042928321312\n",
      "Step: 543 Weights: [-11.8983863    3.53390217] , error: 17.820655149730555\n",
      "Step: 544 Weights: [-11.87044083   3.53070621] , error: 17.74162903252993\n",
      "Step: 545 Weights: [-11.84255909   3.52751754] , error: 17.662962929123747\n",
      "Step: 546 Weights: [-11.81474094   3.52433613] , error: 17.584655199422173\n",
      "Step: 547 Weights: [-11.78698622   3.52116199] , error: 17.506704210806994\n",
      "Step: 548 Weights: [-11.75929479   3.51799508] , error: 17.429108338097652\n",
      "Step: 549 Weights: [-11.73166651   3.51483539] , error: 17.351865963517234\n",
      "Step: 550 Weights: [-11.70410123   3.51168291] , error: 17.274975476658884\n",
      "Step: 551 Weights: [-11.67659882   3.50853762] , error: 17.198435274452137\n",
      "Step: 552 Weights: [-11.64915912   3.5053995 ] , error: 17.12224376112953\n",
      "Step: 553 Weights: [-11.62178199   3.50226854] , error: 17.046399348193308\n",
      "Step: 554 Weights: [-11.5944673    3.49914471] , error: 16.97090045438238\n",
      "Step: 555 Weights: [-11.56721489   3.49602801] , error: 16.895745505639233\n",
      "Step: 556 Weights: [-11.54002464   3.49291842] , error: 16.820932935077224\n",
      "Step: 557 Weights: [-11.51289638   3.48981592] , error: 16.746461182947833\n",
      "Step: 558 Weights: [-11.48582999   3.48672049] , error: 16.67232869660819\n",
      "Step: 559 Weights: [-11.45882533   3.48363213] , error: 16.598533930488713\n",
      "Step: 560 Weights: [-11.43188224   3.4805508 ] , error: 16.52507534606085\n",
      "Step: 561 Weights: [-11.4050006   3.4774765] , error: 16.451951411804995\n",
      "Step: 562 Weights: [-11.37818026   3.47440922] , error: 16.37916060317859\n",
      "Step: 563 Weights: [-11.35142108   3.47134892] , error: 16.306701402584366\n",
      "Step: 564 Weights: [-11.32472292   3.46829561] , error: 16.23457229933862\n",
      "Step: 565 Weights: [-11.29808564   3.46524926] , error: 16.162771789639798\n",
      "Step: 566 Weights: [-11.27150911   3.46220985] , error: 16.091298376537072\n",
      "Step: 567 Weights: [-11.24499318   3.45917738] , error: 16.020150569899226\n",
      "Step: 568 Weights: [-11.21853773   3.45615182] , error: 15.94932688638346\n",
      "Step: 569 Weights: [-11.1921426    3.45313316] , error: 15.878825849404613\n",
      "Step: 570 Weights: [-11.16580766   3.45012139] , error: 15.808645989104232\n",
      "Step: 571 Weights: [-11.13953278   3.44711648] , error: 15.738785842320038\n",
      "Step: 572 Weights: [-11.11331781   3.44411843] , error: 15.66924395255537\n",
      "Step: 573 Weights: [-11.08716263   3.44112721] , error: 15.600018869948826\n",
      "Step: 574 Weights: [-11.06106709   3.43814282] , error: 15.531109151244026\n",
      "Step: 575 Weights: [-11.03503106   3.43516523] , error: 15.462513359759537\n",
      "Step: 576 Weights: [-11.0090544    3.43219443] , error: 15.394230065358942\n",
      "Step: 577 Weights: [-10.98313698   3.4292304 ] , error: 15.326257844420956\n",
      "Step: 578 Weights: [-10.95727866   3.42627313] , error: 15.258595279809821\n",
      "Step: 579 Weights: [-10.93147931   3.42332261] , error: 15.191240960845692\n",
      "Step: 580 Weights: [-10.90573879   3.42037882] , error: 15.124193483275304\n",
      "Step: 581 Weights: [-10.88005698   3.41744174] , error: 15.05745144924261\n",
      "Step: 582 Weights: [-10.85443372   3.41451135] , error: 14.991013467259705\n",
      "Step: 583 Weights: [-10.8288689    3.41158765] , error: 14.92487815217778\n",
      "Step: 584 Weights: [-10.80336238   3.40867062] , error: 14.85904412515826\n",
      "Step: 585 Weights: [-10.77791402   3.40576024] , error: 14.793510013644001\n",
      "Step: 586 Weights: [-10.7525237    3.40285649] , error: 14.728274451330812\n",
      "Step: 587 Weights: [-10.72719128   3.39995937] , error: 14.663336078138803\n",
      "Step: 588 Weights: [-10.70191662   3.39706885] , error: 14.598693540184133\n",
      "Step: 589 Weights: [-10.6766996    3.39418493] , error: 14.534345489750754\n",
      "Step: 590 Weights: [-10.65154009   3.39130758] , error: 14.470290585262335\n",
      "Step: 591 Weights: [-10.62643795   3.3884368 ] , error: 14.40652749125422\n",
      "Step: 592 Weights: [-10.60139305   3.38557256] , error: 14.34305487834569\n",
      "Step: 593 Weights: [-10.57640527   3.38271485] , error: 14.279871423212162\n",
      "Step: 594 Weights: [-10.55147447   3.37986366] , error: 14.216975808557635\n",
      "Step: 595 Weights: [-10.52660052   3.37701897] , error: 14.154366723087247\n",
      "Step: 596 Weights: [-10.5017833    3.37418076] , error: 14.092042861479868\n",
      "Step: 597 Weights: [-10.47702267   3.37134903] , error: 14.030002924360964\n",
      "Step: 598 Weights: [-10.4523185    3.36852376] , error: 13.968245618275455\n",
      "Step: 599 Weights: [-10.42767067   3.36570493] , error: 13.906769655660773\n",
      "Step: 600 Weights: [-10.40307904   3.36289253] , error: 13.845573754819991\n",
      "Step: 601 Weights: [-10.3785435    3.36008654] , error: 13.784656639895147\n",
      "Step: 602 Weights: [-10.35406391   3.35728695] , error: 13.724017040840604\n",
      "Step: 603 Weights: [-10.32964014   3.35449375] , error: 13.663653693396578\n",
      "Step: 604 Weights: [-10.30527206   3.35170691] , error: 13.603565339062785\n",
      "Step: 605 Weights: [-10.28095956   3.34892643] , error: 13.54375072507222\n",
      "Step: 606 Weights: [-10.2567025    3.34615229] , error: 13.484208604365007\n",
      "Step: 607 Weights: [-10.23250075   3.34338448] , error: 13.424937735562404\n",
      "Step: 608 Weights: [-10.2083542    3.34062298] , error: 13.365936882940968\n",
      "Step: 609 Weights: [-10.1842627    3.33786777] , error: 13.30720481640671\n",
      "Step: 610 Weights: [-10.16022615   3.33511885] , error: 13.248740311469533\n",
      "Step: 611 Weights: [-10.13624441   3.3323762 ] , error: 13.190542149217643\n",
      "Step: 612 Weights: [-10.11231736   3.3296398 ] , error: 13.132609116292164\n",
      "Step: 613 Weights: [-10.08844488   3.32690964] , error: 13.074940004861839\n",
      "Step: 614 Weights: [-10.06462683   3.32418571] , error: 13.017533612597838\n",
      "Step: 615 Weights: [-10.04086309   3.32146799] , error: 12.960388742648696\n",
      "Step: 616 Weights: [-10.01715355   3.31875646] , error: 12.903504203615366\n",
      "Step: 617 Weights: [-9.99349808  3.31605112] , error: 12.846878809526366\n",
      "Step: 618 Weights: [-9.96989655  3.31335195] , error: 12.790511379813083\n",
      "Step: 619 Weights: [-9.94634884  3.31065894] , error: 12.734400739285102\n",
      "Step: 620 Weights: [-9.92285483  3.30797206] , error: 12.678545718105786\n",
      "Step: 621 Weights: [-9.8994144   3.30529132] , error: 12.6229451517678\n",
      "Step: 622 Weights: [-9.87602742  3.30261668] , error: 12.567597881068915\n",
      "Step: 623 Weights: [-9.85269377  3.29994815] , error: 12.512502752087753\n",
      "Step: 624 Weights: [-9.82941333  3.2972857 ] , error: 12.457658616159812\n",
      "Step: 625 Weights: [-9.80618598  3.29462932] , error: 12.403064329853464\n",
      "Step: 626 Weights: [-9.7830116  3.291979 ] , error: 12.348718754946148\n",
      "Step: 627 Weights: [-9.75989007  3.28933473] , error: 12.294620758400601\n",
      "Step: 628 Weights: [-9.73682126  3.28669648] , error: 12.240769212341288\n",
      "Step: 629 Weights: [-9.71380506  3.28406425] , error: 12.187162994030825\n",
      "Step: 630 Weights: [-9.69084135  3.28143802] , error: 12.133800985846637\n",
      "Step: 631 Weights: [-9.66793     3.27881779] , error: 12.080682075257599\n",
      "Step: 632 Weights: [-9.6450709   3.27620352] , error: 12.027805154800886\n",
      "Step: 633 Weights: [-9.62226393  3.27359522] , error: 11.975169122058848\n",
      "Step: 634 Weights: [-9.59950897  3.27099287] , error: 11.92277287963606\n",
      "Step: 635 Weights: [-9.5768059   3.26839645] , error: 11.870615335136414\n",
      "Step: 636 Weights: [-9.5541546   3.26580595] , error: 11.818695401140346\n",
      "Step: 637 Weights: [-9.53155495  3.26322136] , error: 11.767011995182202\n",
      "Step: 638 Weights: [-9.50900685  3.26064266] , error: 11.71556403972762\n",
      "Step: 639 Weights: [-9.48651016  3.25806985] , error: 11.66435046215107\n",
      "Step: 640 Weights: [-9.46406477  3.2555029 ] , error: 11.613370194713559\n",
      "Step: 641 Weights: [-9.44167057  3.2529418 ] , error: 11.562622174540284\n",
      "Step: 642 Weights: [-9.41932743  3.25038655] , error: 11.512105343598481\n",
      "Step: 643 Weights: [-9.39703525  3.24783712] , error: 11.461818648675454\n",
      "Step: 644 Weights: [-9.3747939   3.24529351] , error: 11.411761041356508\n",
      "Step: 645 Weights: [-9.35260328  3.24275569] , error: 11.361931478003157\n",
      "Step: 646 Weights: [-9.33046325  3.24022367] , error: 11.312328919731348\n",
      "Step: 647 Weights: [-9.30837372  3.23769741] , error: 11.262952332389784\n",
      "Step: 648 Weights: [-9.28633456  3.23517692] , error: 11.213800686538397\n",
      "Step: 649 Weights: [-9.26434565  3.23266218] , error: 11.164872957426851\n",
      "Step: 650 Weights: [-9.24240689  3.23015317] , error: 11.116168124973223\n",
      "Step: 651 Weights: [-9.22051816  3.22764988] , error: 11.067685173742671\n",
      "Step: 652 Weights: [-9.19867935  3.2251523 ] , error: 11.019423092926317\n",
      "Step: 653 Weights: [-9.17689034  3.22266042] , error: 10.971380876320165\n",
      "Step: 654 Weights: [-9.15515101  3.22017422] , error: 10.92355752230408\n",
      "Step: 655 Weights: [-9.13346126  3.21769369] , error: 10.875952033820962\n",
      "Step: 656 Weights: [-9.11182097  3.21521881] , error: 10.82856341835595\n",
      "Step: 657 Weights: [-9.09023003  3.21274958] , error: 10.781390687915678\n",
      "Step: 658 Weights: [-9.06868833  3.21028598] , error: 10.734432859007727\n",
      "Step: 659 Weights: [-9.04719575  3.207828  ] , error: 10.687688952620128\n",
      "Step: 660 Weights: [-9.02575218  3.20537562] , error: 10.641157994200888\n",
      "Step: 661 Weights: [-9.00435751  3.20292884] , error: 10.594839013637758\n",
      "Step: 662 Weights: [-8.98301164  3.20048763] , error: 10.548731045237922\n",
      "Step: 663 Weights: [-8.96171443  3.198052  ] , error: 10.502833127707921\n",
      "Step: 664 Weights: [-8.9404658   3.19562191] , error: 10.457144304133601\n",
      "Step: 665 Weights: [-8.91926562  3.19319737] , error: 10.411663621960148\n",
      "Step: 666 Weights: [-8.89811379  3.19077836] , error: 10.366390132972228\n",
      "Step: 667 Weights: [-8.87701019  3.18836486] , error: 10.321322893274246\n",
      "Step: 668 Weights: [-8.85595472  3.18595687] , error: 10.276460963270617\n",
      "Step: 669 Weights: [-8.83494726  3.18355437] , error: 10.231803407646234\n",
      "Step: 670 Weights: [-8.8139877   3.18115734] , error: 10.187349295346927\n",
      "Step: 671 Weights: [-8.79307595  3.17876579] , error: 10.143097699560078\n",
      "Step: 672 Weights: [-8.77221188  3.17637969] , error: 10.099047697695259\n",
      "Step: 673 Weights: [-8.75139539  3.17399902] , error: 10.055198371365046\n",
      "Step: 674 Weights: [-8.73062637  3.17162379] , error: 10.01154880636584\n",
      "Step: 675 Weights: [-8.70990471  3.16925397] , error: 9.968098092658812\n",
      "Step: 676 Weights: [-8.68923031  3.16688956] , error: 9.924845324350951\n",
      "Step: 677 Weights: [-8.66860305  3.16453054] , error: 9.881789599676136\n",
      "Step: 678 Weights: [-8.64802283  3.1621769 ] , error: 9.83893002097637\n",
      "Step: 679 Weights: [-8.62748954  3.15982863] , error: 9.796265694683061\n",
      "Step: 680 Weights: [-8.60700308  3.15748571] , error: 9.753795731298377\n",
      "Step: 681 Weights: [-8.58656334  3.15514813] , error: 9.711519245376724\n",
      "Step: 682 Weights: [-8.5661702   3.15281589] , error: 9.669435355506232\n",
      "Step: 683 Weights: [-8.54582357  3.15048896] , error: 9.627543184290468\n",
      "Step: 684 Weights: [-8.52552334  3.14816734] , error: 9.585841858330067\n",
      "Step: 685 Weights: [-8.5052694   3.14585102] , error: 9.544330508204554\n",
      "Step: 686 Weights: [-8.48506165  3.14353997] , error: 9.503008268454188\n",
      "Step: 687 Weights: [-8.46489998  3.1412342 ] , error: 9.46187427756199\n",
      "Step: 688 Weights: [-8.44478429  3.13893369] , error: 9.42092767793569\n",
      "Step: 689 Weights: [-8.42471447  3.13663842] , error: 9.380167615889938\n",
      "Step: 690 Weights: [-8.40469042  3.13434838] , error: 9.339593241628398\n",
      "Step: 691 Weights: [-8.38471203  3.13206357] , error: 9.299203709226154\n",
      "Step: 692 Weights: [-8.3647792   3.12978397] , error: 9.258998176611968\n",
      "Step: 693 Weights: [-8.34489183  3.12750956] , error: 9.218975805550777\n",
      "Step: 694 Weights: [-8.32504981  3.12524035] , error: 9.179135761626227\n",
      "Step: 695 Weights: [-8.30525303  3.1229763 ] , error: 9.139477214223238\n",
      "Step: 696 Weights: [-8.2855014   3.12071742] , error: 9.099999336510717\n",
      "Step: 697 Weights: [-8.26579482  3.11846369] , error: 9.060701305424288\n",
      "Step: 698 Weights: [-8.24613317  3.11621511] , error: 9.021582301649174\n",
      "Step: 699 Weights: [-8.22651635  3.11397164] , error: 8.982641509603074\n",
      "Step: 700 Weights: [-8.20694428  3.1117333 ] , error: 8.943878117419203\n",
      "Step: 701 Weights: [-8.18741683  3.10950006] , error: 8.905291316929317\n",
      "Step: 702 Weights: [-8.16793392  3.10727191] , error: 8.86688030364691\n",
      "Step: 703 Weights: [-8.14849543  3.10504884] , error: 8.828644276750397\n",
      "Step: 704 Weights: [-8.12910127  3.10283085] , error: 8.79058243906646\n",
      "Step: 705 Weights: [-8.10975134  3.10061791] , error: 8.752693997053395\n",
      "Step: 706 Weights: [-8.09044554  3.09841001] , error: 8.714978160784579\n",
      "Step: 707 Weights: [-8.07118376  3.09620715] , error: 8.677434143932013\n",
      "Step: 708 Weights: [-8.0519659   3.09400932] , error: 8.64006116374992\n",
      "Step: 709 Weights: [-8.03279187  3.0918165 ] , error: 8.602858441058412\n",
      "Step: 710 Weights: [-8.01366157  3.08962867] , error: 8.565825200227264\n",
      "Step: 711 Weights: [-7.99457489  3.08744584] , error: 8.528960669159728\n",
      "Step: 712 Weights: [-7.97553173  3.08526799] , error: 8.492264079276454\n",
      "Step: 713 Weights: [-7.95653201  3.0830951 ] , error: 8.455734665499458\n",
      "Step: 714 Weights: [-7.93757561  3.08092716] , error: 8.419371666236142\n",
      "Step: 715 Weights: [-7.91866243  3.07876417] , error: 8.383174323363479\n",
      "Step: 716 Weights: [-7.89979239  3.07660611] , error: 8.347141882212158\n",
      "Step: 717 Weights: [-7.88096538  3.07445298] , error: 8.311273591550838\n",
      "Step: 718 Weights: [-7.8621813   3.07230475] , error: 8.275568703570551\n",
      "Step: 719 Weights: [-7.84344006  3.07016142] , error: 8.24002647386903\n",
      "Step: 720 Weights: [-7.82474155  3.06802298] , error: 8.204646161435265\n",
      "Step: 721 Weights: [-7.80608569  3.06588942] , error: 8.169427028633997\n",
      "Step: 722 Weights: [-7.78747237  3.06376072] , error: 8.134368341190362\n",
      "Step: 723 Weights: [-7.76890149  3.06163688] , error: 8.099469368174598\n",
      "Step: 724 Weights: [-7.75037297  3.05951788] , error: 8.064729381986773\n",
      "Step: 725 Weights: [-7.7318867   3.05740371] , error: 8.030147658341628\n",
      "Step: 726 Weights: [-7.71344258  3.05529436] , error: 7.995723476253494\n",
      "Step: 727 Weights: [-7.69504052  3.05318983] , error: 7.961456118021237\n",
      "Step: 728 Weights: [-7.67668043  3.05109009] , error: 7.9273448692133055\n",
      "Step: 729 Weights: [-7.65836221  3.04899514] , error: 7.893389018652844\n",
      "Step: 730 Weights: [-7.64008576  3.04690497] , error: 7.859587858402831\n",
      "Step: 731 Weights: [-7.62185099  3.04481956] , error: 7.825940683751373\n",
      "Step: 732 Weights: [-7.6036578   3.04273891] , error: 7.792446793196973\n",
      "Step: 733 Weights: [-7.5855061   3.04066301] , error: 7.75910548843391\n",
      "Step: 734 Weights: [-7.56739579  3.03859184] , error: 7.725916074337691\n",
      "Step: 735 Weights: [-7.54932678  3.03652539] , error: 7.69287785895055\n",
      "Step: 736 Weights: [-7.53129897  3.03446365] , error: 7.659990153467032\n",
      "Step: 737 Weights: [-7.51331228  3.03240662] , error: 7.627252272219616\n",
      "Step: 738 Weights: [-7.49536661  3.03035428] , error: 7.594663532664439\n",
      "Step: 739 Weights: [-7.47746185  3.02830661] , error: 7.562223255367046\n",
      "Step: 740 Weights: [-7.45959793  3.02626362] , error: 7.5299307639882445\n",
      "Step: 741 Weights: [-7.44177475  3.02422529] , error: 7.497785385269979\n",
      "Step: 742 Weights: [-7.42399221  3.0221916 ] , error: 7.465786449021319\n",
      "Step: 743 Weights: [-7.40625022  3.02016255] , error: 7.433933288104486\n",
      "Step: 744 Weights: [-7.38854869  3.01813813] , error: 7.402225238420915\n",
      "Step: 745 Weights: [-7.37088752  3.01611832] , error: 7.370661638897433\n",
      "Step: 746 Weights: [-7.35326663  3.01410312] , error: 7.339241831472485\n",
      "Step: 747 Weights: [-7.33568593  3.01209252] , error: 7.30796516108238\n",
      "Step: 748 Weights: [-7.31814531  3.0100865 ] , error: 7.276830975647687\n",
      "Step: 749 Weights: [-7.3006447   3.00808506] , error: 7.245838626059577\n",
      "Step: 750 Weights: [-7.283184    3.00608818] , error: 7.214987466166333\n",
      "Step: 751 Weights: [-7.26576311  3.00409585] , error: 7.184276852759868\n",
      "Step: 752 Weights: [-7.24838195  3.00210807] , error: 7.1537061455623085\n",
      "Step: 753 Weights: [-7.23104042  3.00012482] , error: 7.12327470721267\n",
      "Step: 754 Weights: [-7.21373844  2.99814609] , error: 7.092981903253509\n",
      "Step: 755 Weights: [-7.19647592  2.99617188] , error: 7.062827102117773\n",
      "Step: 756 Weights: [-7.17925276  2.99420216] , error: 7.032809675115594\n",
      "Step: 757 Weights: [-7.16206888  2.99223694] , error: 7.00292899642115\n",
      "Step: 758 Weights: [-7.14492419  2.9902762 ] , error: 6.973184443059672\n",
      "Step: 759 Weights: [-7.12781859  2.98831994] , error: 6.943575394894449\n",
      "Step: 760 Weights: [-7.110752    2.98636813] , error: 6.914101234613861\n",
      "Step: 761 Weights: [-7.09372433  2.98442077] , error: 6.88476134771854\n",
      "Step: 762 Weights: [-7.07673548  2.98247786] , error: 6.85555512250854\n",
      "Step: 763 Weights: [-7.05978539  2.98053937] , error: 6.826481950070612\n",
      "Step: 764 Weights: [-7.04287394  2.97860531] , error: 6.797541224265472\n",
      "Step: 765 Weights: [-7.02600106  2.97667565] , error: 6.768732341715216\n",
      "Step: 766 Weights: [-7.00916665  2.9747504 ] , error: 6.740054701790656\n",
      "Step: 767 Weights: [-6.99237064  2.97282954] , error: 6.711507706598885\n",
      "Step: 768 Weights: [-6.97561293  2.97091305] , error: 6.683090760970774\n",
      "Step: 769 Weights: [-6.95889343  2.96900094] , error: 6.654803272448539\n",
      "Step: 770 Weights: [-6.94221206  2.96709319] , error: 6.626644651273456\n",
      "Step: 771 Weights: [-6.92556873  2.96518979] , error: 6.598614310373483\n",
      "Step: 772 Weights: [-6.90896335  2.96329073] , error: 6.570711665351078\n",
      "Step: 773 Weights: [-6.89239584  2.961396  ] , error: 6.542936134471009\n",
      "Step: 774 Weights: [-6.87586611  2.95950559] , error: 6.5152871386481985\n",
      "Step: 775 Weights: [-6.85937408  2.95761949] , error: 6.48776410143568\n",
      "Step: 776 Weights: [-6.84291965  2.95573769] , error: 6.460366449012555\n",
      "Step: 777 Weights: [-6.82650275  2.95386019] , error: 6.433093610172035\n",
      "Step: 778 Weights: [-6.81012329  2.95198696] , error: 6.405945016309559\n",
      "Step: 779 Weights: [-6.79378117  2.95011801] , error: 6.378920101410915\n",
      "Step: 780 Weights: [-6.77747633  2.94825332] , error: 6.352018302040422\n",
      "Step: 781 Weights: [-6.76120866  2.94639288] , error: 6.325239057329226\n",
      "Step: 782 Weights: [-6.7449781   2.94453668] , error: 6.2985818089635774\n",
      "Step: 783 Weights: [-6.72878454  2.94268472] , error: 6.272046001173181\n",
      "Step: 784 Weights: [-6.71262791  2.94083698] , error: 6.245631080719665\n",
      "Step: 785 Weights: [-6.69650813  2.93899345] , error: 6.219336496884971\n",
      "Step: 786 Weights: [-6.68042511  2.93715413] , error: 6.193161701459912\n",
      "Step: 787 Weights: [-6.66437876  2.935319  ] , error: 6.167106148732769\n",
      "Step: 788 Weights: [-6.64836901  2.93348806] , error: 6.141169295477848\n",
      "Step: 789 Weights: [-6.63239576  2.93166129] , error: 6.115350600944215\n",
      "Step: 790 Weights: [-6.61645894  2.92983869] , error: 6.089649526844372\n",
      "Step: 791 Weights: [-6.60055846  2.92802024] , error: 6.064065537343098\n",
      "Step: 792 Weights: [-6.58469424  2.92620595] , error: 6.038598099046201\n",
      "Step: 793 Weights: [-6.5688662   2.92439578] , error: 6.013246680989471\n",
      "Step: 794 Weights: [-6.55307426  2.92258975] , error: 5.988010754627534\n",
      "Step: 795 Weights: [-6.53731832  2.92078784] , error: 5.962889793822915\n",
      "Step: 796 Weights: [-6.52159832  2.91899003] , error: 5.937883274834995\n",
      "Step: 797 Weights: [-6.50591416  2.91719632] , error: 5.912990676309146\n",
      "Step: 798 Weights: [-6.49026577  2.91540671] , error: 5.88821147926582\n",
      "Step: 799 Weights: [-6.47465307  2.91362117] , error: 5.8635451670897725\n",
      "Step: 800 Weights: [-6.45907597  2.91183971] , error: 5.838991225519237\n",
      "Step: 801 Weights: [-6.44353439  2.91006231] , error: 5.814549142635258\n",
      "Step: 802 Weights: [-6.42802825  2.90828896] , error: 5.7902184088509845\n",
      "Step: 803 Weights: [-6.41255747  2.90651966] , error: 5.76599851690105\n",
      "Step: 804 Weights: [-6.39712197  2.90475439] , error: 5.741888961831005\n",
      "Step: 805 Weights: [-6.38172167  2.90299315] , error: 5.717889240986803\n",
      "Step: 806 Weights: [-6.36635649  2.90123592] , error: 5.6939988540042705\n",
      "Step: 807 Weights: [-6.35102635  2.8994827 ] , error: 5.670217302798733\n",
      "Step: 808 Weights: [-6.33573117  2.89773348] , error: 5.646544091554603\n",
      "Step: 809 Weights: [-6.32047087  2.89598825] , error: 5.6229787267150355\n",
      "Step: 810 Weights: [-6.30524537  2.89424699] , error: 5.599520716971664\n",
      "Step: 811 Weights: [-6.29005459  2.89250971] , error: 5.576169573254319\n",
      "Step: 812 Weights: [-6.27489845  2.89077639] , error: 5.552924808720876\n",
      "Step: 813 Weights: [-6.25977687  2.88904703] , error: 5.529785938747061\n",
      "Step: 814 Weights: [-6.24468978  2.8873216 ] , error: 5.506752480916404\n",
      "Step: 815 Weights: [-6.22963709  2.88560011] , error: 5.483823955010106\n",
      "Step: 816 Weights: [-6.21461872  2.88388255] , error: 5.460999882997088\n",
      "Step: 817 Weights: [-6.19963461  2.8821689 ] , error: 5.438279789024012\n",
      "Step: 818 Weights: [-6.18468466  2.88045916] , error: 5.415663199405324\n",
      "Step: 819 Weights: [-6.16976881  2.87875332] , error: 5.393149642613445\n",
      "Step: 820 Weights: [-6.15488697  2.87705137] , error: 5.370738649268869\n",
      "Step: 821 Weights: [-6.14003907  2.87535331] , error: 5.348429752130428\n",
      "Step: 822 Weights: [-6.12522503  2.87365911] , error: 5.32622248608551\n",
      "Step: 823 Weights: [-6.11044477  2.87196878] , error: 5.304116388140425\n",
      "Step: 824 Weights: [-6.09569821  2.8702823 ] , error: 5.282110997410663\n",
      "Step: 825 Weights: [-6.08098528  2.86859967] , error: 5.260205855111358\n",
      "Step: 826 Weights: [-6.06630591  2.86692087] , error: 5.238400504547711\n",
      "Step: 827 Weights: [-6.05166001  2.8652459 ] , error: 5.216694491105437\n",
      "Step: 828 Weights: [-6.03704751  2.86357476] , error: 5.195087362241297\n",
      "Step: 829 Weights: [-6.02246833  2.86190742] , error: 5.173578667473708\n",
      "Step: 830 Weights: [-6.00792239  2.86024389] , error: 5.152167958373266\n",
      "Step: 831 Weights: [-5.99340963  2.85858414] , error: 5.130854788553492\n",
      "Step: 832 Weights: [-5.97892997  2.85692819] , error: 5.109638713661452\n",
      "Step: 833 Weights: [-5.96448332  2.85527601] , error: 5.088519291368521\n",
      "Step: 834 Weights: [-5.95006962  2.8536276 ] , error: 5.067496081361171\n",
      "Step: 835 Weights: [-5.93568878  2.85198295] , error: 5.046568645331764\n",
      "Step: 836 Weights: [-5.92134074  2.85034204] , error: 5.025736546969458\n",
      "Step: 837 Weights: [-5.90702542  2.84870488] , error: 5.004999351951046\n",
      "Step: 838 Weights: [-5.89274275  2.84707146] , error: 4.984356627931962\n",
      "Step: 839 Weights: [-5.87849265  2.84544175] , error: 4.963807944537234\n",
      "Step: 840 Weights: [-5.86427504  2.84381577] , error: 4.943352873352517\n",
      "Step: 841 Weights: [-5.85008985  2.84219349] , error: 4.922990987915171\n",
      "Step: 842 Weights: [-5.83593701  2.84057491] , error: 4.902721863705352\n",
      "Step: 843 Weights: [-5.82181645  2.83896003] , error: 4.882545078137186\n",
      "Step: 844 Weights: [-5.80772809  2.83734882] , error: 4.862460210549923\n",
      "Step: 845 Weights: [-5.79367185  2.83574129] , error: 4.84246684219921\n",
      "Step: 846 Weights: [-5.77964767  2.83413743] , error: 4.822564556248329\n",
      "Step: 847 Weights: [-5.76565547  2.83253722] , error: 4.802752937759505\n",
      "Step: 848 Weights: [-5.75169518  2.83094066] , error: 4.783031573685293\n",
      "Step: 849 Weights: [-5.73776672  2.82934774] , error: 4.763400052859914\n",
      "Step: 850 Weights: [-5.72387003  2.82775846] , error: 4.743857965990719\n",
      "Step: 851 Weights: [-5.71000502  2.8261728 ] , error: 4.7244049056496475\n",
      "Step: 852 Weights: [-5.69617164  2.82459075] , error: 4.705040466264721\n",
      "Step: 853 Weights: [-5.6823698   2.82301232] , error: 4.685764244111612\n",
      "Step: 854 Weights: [-5.66859943  2.82143748] , error: 4.666575837305196\n",
      "Step: 855 Weights: [-5.65486046  2.81986623] , error: 4.647474845791195\n",
      "Step: 856 Weights: [-5.64115283  2.81829857] , error: 4.628460871337844\n",
      "Step: 857 Weights: [-5.62747646  2.81673448] , error: 4.609533517527551\n",
      "Step: 858 Weights: [-5.61383127  2.81517396] , error: 4.5906923897486696\n",
      "Step: 859 Weights: [-5.6002172  2.813617 ] , error: 4.571937095187257\n",
      "Step: 860 Weights: [-5.58663417  2.81206359] , error: 4.553267242818882\n",
      "Step: 861 Weights: [-5.57308212  2.81051372] , error: 4.534682443400487\n",
      "Step: 862 Weights: [-5.55956098  2.80896738] , error: 4.516182309462252\n",
      "Step: 863 Weights: [-5.54607067  2.80742458] , error: 4.497766455299518\n",
      "Step: 864 Weights: [-5.53261112  2.80588528] , error: 4.479434496964774\n",
      "Step: 865 Weights: [-5.51918227  2.8043495 ] , error: 4.461186052259622\n",
      "Step: 866 Weights: [-5.50578403  2.80281723] , error: 4.443020740726807\n",
      "Step: 867 Weights: [-5.49241636  2.80128844] , error: 4.42493818364233\n",
      "Step: 868 Weights: [-5.47907916  2.79976314] , error: 4.40693800400748\n",
      "Step: 869 Weights: [-5.46577238  2.79824132] , error: 4.3890198265410385\n",
      "Step: 870 Weights: [-5.45249595  2.79672298] , error: 4.371183277671416\n",
      "Step: 871 Weights: [-5.43924979  2.79520809] , error: 4.353427985528888\n",
      "Step: 872 Weights: [-5.42603384  2.79369666] , error: 4.335753579937821\n",
      "Step: 873 Weights: [-5.41284802  2.79218867] , error: 4.318159692408969\n",
      "Step: 874 Weights: [-5.39969228  2.79068413] , error: 4.300645956131788\n",
      "Step: 875 Weights: [-5.38656654  2.78918301] , error: 4.283212005966789\n",
      "Step: 876 Weights: [-5.37347072  2.78768532] , error: 4.2658574784379235\n",
      "Step: 877 Weights: [-5.36040478  2.78619104] , error: 4.248582011725\n",
      "Step: 878 Weights: [-5.34736862  2.78470017] , error: 4.231385245656142\n",
      "Step: 879 Weights: [-5.3343622  2.7832127] , error: 4.2142668217003\n",
      "Step: 880 Weights: [-5.32138543  2.78172862] , error: 4.1972263829597445\n",
      "Step: 881 Weights: [-5.30843826  2.78024793] , error: 4.180263574162653\n",
      "Step: 882 Weights: [-5.29552061  2.77877061] , error: 4.16337804165568\n",
      "Step: 883 Weights: [-5.28263242  2.77729667] , error: 4.1465694333965954\n",
      "Step: 884 Weights: [-5.26977363  2.77582608] , error: 4.129837398946937\n",
      "Step: 885 Weights: [-5.25694415  2.77435885] , error: 4.113181589464729\n",
      "Step: 886 Weights: [-5.24414393  2.77289496] , error: 4.096601657697182\n",
      "Step: 887 Weights: [-5.2313729   2.77143441] , error: 4.080097257973446\n",
      "Step: 888 Weights: [-5.21863099  2.76997719] , error: 4.06366804619745\n",
      "Step: 889 Weights: [-5.20591814  2.7685233 ] , error: 4.047313679840679\n",
      "Step: 890 Weights: [-5.19323429  2.76707272] , error: 4.031033817935043\n",
      "Step: 891 Weights: [-5.18057935  2.76562545] , error: 4.014828121065795\n",
      "Step: 892 Weights: [-5.16795328  2.76418148] , error: 3.998696251364433\n",
      "Step: 893 Weights: [-5.15535599  2.7627408 ] , error: 3.9826378725016482\n",
      "Step: 894 Weights: [-5.14278744  2.7613034 ] , error: 3.966652649680337\n",
      "Step: 895 Weights: [-5.13024754  2.75986929] , error: 3.950740249628595\n",
      "Step: 896 Weights: [-5.11773624  2.75843844] , error: 3.934900340592783\n",
      "Step: 897 Weights: [-5.10525348  2.75701086] , error: 3.9191325923306293\n",
      "Step: 898 Weights: [-5.09279917  2.75558654] , error: 3.9034366761043002\n",
      "Step: 899 Weights: [-5.08037327  2.75416546] , error: 3.887812264673575\n",
      "Step: 900 Weights: [-5.06797571  2.75274762] , error: 3.872259032289025\n",
      "Step: 901 Weights: [-5.05560642  2.75133302] , error: 3.85677665468521\n",
      "Step: 902 Weights: [-5.04326533  2.74992164] , error: 3.84136480907393\n",
      "Step: 903 Weights: [-5.03095239  2.74851348] , error: 3.8260231741374797\n",
      "Step: 904 Weights: [-5.01866752  2.74710853] , error: 3.8107514300219703\n",
      "Step: 905 Weights: [-5.00641068  2.74570678] , error: 3.795549258330639\n",
      "Step: 906 Weights: [-4.99418178  2.74430823] , error: 3.7804163421172126\n",
      "Step: 907 Weights: [-4.98198076  2.74291288] , error: 3.7653523658793384\n",
      "Step: 908 Weights: [-4.96980758  2.7415207 ] , error: 3.7503570155519457\n",
      "Step: 909 Weights: [-4.95766215  2.7401317 ] , error: 3.7354299785007417\n",
      "Step: 910 Weights: [-4.94554442  2.73874586] , error: 3.720570943515676\n",
      "Step: 911 Weights: [-4.93345432  2.73736319] , error: 3.705779600804463\n",
      "Step: 912 Weights: [-4.92139179  2.73598366] , error: 3.6910556419861065\n",
      "Step: 913 Weights: [-4.90935677  2.73460729] , error: 3.6763987600844956\n",
      "Step: 914 Weights: [-4.89734919  2.73323405] , error: 3.661808649521964\n",
      "Step: 915 Weights: [-4.885369    2.73186395] , error: 3.647285006112963\n",
      "Step: 916 Weights: [-4.87341613  2.73049697] , error: 3.6328275270576995\n",
      "Step: 917 Weights: [-4.86149051  2.7291331 ] , error: 3.6184359109358244\n",
      "Step: 918 Weights: [-4.84959209  2.72777235] , error: 3.6041098577001436\n",
      "Step: 919 Weights: [-4.8377208  2.7264147] , error: 3.589849068670363\n",
      "Step: 920 Weights: [-4.82587659  2.72506014] , error: 3.5756532465268824\n",
      "Step: 921 Weights: [-4.81405938  2.72370868] , error: 3.5615220953045617\n",
      "Step: 922 Weights: [-4.80226912  2.72236029] , error: 3.547455320386576\n",
      "Step: 923 Weights: [-4.79050575  2.72101499] , error: 3.533452628498269\n",
      "Step: 924 Weights: [-4.7787692   2.71967274] , error: 3.519513727701031\n",
      "Step: 925 Weights: [-4.76705942  2.71833356] , error: 3.5056383273862197\n",
      "Step: 926 Weights: [-4.75537634  2.71699744] , error: 3.4918261382690967\n",
      "Step: 927 Weights: [-4.74371991  2.71566436] , error: 3.4780768723827973\n",
      "Step: 928 Weights: [-4.73209005  2.71433432] , error: 3.464390243072331\n",
      "Step: 929 Weights: [-4.72048672  2.71300731] , error: 3.4507659649885944\n",
      "Step: 930 Weights: [-4.70890984  2.71168333] , error: 3.4372037540824354\n",
      "Step: 931 Weights: [-4.69735937  2.71036237] , error: 3.423703327598723\n",
      "Step: 932 Weights: [-4.68583524  2.70904442] , error: 3.410264404070459\n",
      "Step: 933 Weights: [-4.67433738  2.70772948] , error: 3.39688670331289\n",
      "Step: 934 Weights: [-4.66286575  2.70641754] , error: 3.383569946417703\n",
      "Step: 935 Weights: [-4.65142028  2.70510858] , error: 3.3703138557471677\n",
      "Step: 936 Weights: [-4.6400009   2.70380262] , error: 3.357118154928375\n",
      "Step: 937 Weights: [-4.62860757  2.70249963] , error: 3.343982568847478\n",
      "Step: 938 Weights: [-4.61724022  2.70119961] , error: 3.3309068236439354\n",
      "Step: 939 Weights: [-4.60589879  2.69990256] , error: 3.317890646704824\n",
      "Step: 940 Weights: [-4.59458323  2.69860846] , error: 3.3049337666591265\n",
      "Step: 941 Weights: [-4.58329346  2.69731732] , error: 3.2920359133721173\n",
      "Step: 942 Weights: [-4.57202945  2.69602911] , error: 3.2791968179396767\n",
      "Step: 943 Weights: [-4.56079112  2.69474385] , error: 3.2664162126827394\n",
      "Step: 944 Weights: [-4.54957842  2.69346152] , error: 3.2536938311416637\n",
      "Step: 945 Weights: [-4.53839129  2.69218211] , error: 3.241029408070713\n",
      "Step: 946 Weights: [-4.52722967  2.69090562] , error: 3.2284226794325175\n",
      "Step: 947 Weights: [-4.5160935   2.68963204] , error: 3.2158733823925507\n",
      "Step: 948 Weights: [-4.50498273  2.68836137] , error: 3.203381255313668\n",
      "Step: 949 Weights: [-4.49389729  2.68709359] , error: 3.1909460377506473\n",
      "Step: 950 Weights: [-4.48283714  2.68582871] , error: 3.1785674704447597\n",
      "Step: 951 Weights: [-4.4718022  2.6845667] , error: 3.166245295318366\n",
      "Step: 952 Weights: [-4.46079243  2.68330758] , error: 3.1539792554695243\n",
      "Step: 953 Weights: [-4.44980777  2.68205133] , error: 3.141769095166657\n",
      "Step: 954 Weights: [-4.43884816  2.68079794] , error: 3.1296145598431875\n",
      "Step: 955 Weights: [-4.42791354  2.67954741] , error: 3.1175153960922635\n",
      "Step: 956 Weights: [-4.41700385  2.67829973] , error: 3.1054713516614556\n",
      "Step: 957 Weights: [-4.40611905  2.6770549 ] , error: 3.0934821754475097\n",
      "Step: 958 Weights: [-4.39525906  2.67581291] , error: 3.081547617491097\n",
      "Step: 959 Weights: [-4.38442384  2.67457375] , error: 3.0696674289716146\n",
      "Step: 960 Weights: [-4.37361333  2.67333741] , error: 3.057841362201995\n",
      "Step: 961 Weights: [-4.36282747  2.67210389] , error: 3.046069170623536\n",
      "Step: 962 Weights: [-4.35206621  2.67087319] , error: 3.0343506088007715\n",
      "Step: 963 Weights: [-4.34132949  2.66964529] , error: 3.0226854324163543\n",
      "Step: 964 Weights: [-4.33061725  2.6684202 ] , error: 3.011073398265946\n",
      "Step: 965 Weights: [-4.31992944  2.6671979 ] , error: 2.999514264253168\n",
      "Step: 966 Weights: [-4.30926601  2.66597838] , error: 2.988007789384521\n",
      "Step: 967 Weights: [-4.29862689  2.66476165] , error: 2.9765537337644115\n",
      "Step: 968 Weights: [-4.28801203  2.66354769] , error: 2.965151858590105\n",
      "Step: 969 Weights: [-4.27742138  2.66233649] , error: 2.9538019261467685\n",
      "Step: 970 Weights: [-4.26685488  2.66112806] , error: 2.94250369980251\n",
      "Step: 971 Weights: [-4.25631247  2.65992239] , error: 2.9312569440034397\n",
      "Step: 972 Weights: [-4.24579411  2.65871947] , error: 2.9200614242687806\n",
      "Step: 973 Weights: [-4.23529973  2.65751928] , error: 2.908916907185942\n",
      "Step: 974 Weights: [-4.22482929  2.65632184] , error: 2.8978231604056863\n",
      "Step: 975 Weights: [-4.21438272  2.65512713] , error: 2.886779952637272\n",
      "Step: 976 Weights: [-4.20395997  2.65393514] , error: 2.875787053643637\n",
      "Step: 977 Weights: [-4.19356099  2.65274587] , error: 2.864844234236584\n",
      "Step: 978 Weights: [-4.18318573  2.65155931] , error: 2.8539512662720186\n",
      "Step: 979 Weights: [-4.17283413  2.65037545] , error: 2.843107922645186\n",
      "Step: 980 Weights: [-4.16250613  2.6491943 ] , error: 2.832313977285937\n",
      "Step: 981 Weights: [-4.15220168  2.64801584] , error: 2.8215692051540184\n",
      "Step: 982 Weights: [-4.14192074  2.64684007] , error: 2.810873382234368\n",
      "Step: 983 Weights: [-4.13166323  2.64566698] , error: 2.8002262855324584\n",
      "Step: 984 Weights: [-4.12142912  2.64449656] , error: 2.7896276930696478\n",
      "Step: 985 Weights: [-4.11121835  2.64332881] , error: 2.779077383878538\n",
      "Step: 986 Weights: [-4.10103086  2.64216373] , error: 2.7685751379983845\n",
      "Step: 987 Weights: [-4.0908666  2.6410013] , error: 2.758120736470494\n",
      "Step: 988 Weights: [-4.08072552  2.63984153] , error: 2.7477139613336763\n",
      "Step: 989 Weights: [-4.07060757  2.6386844 ] , error: 2.7373545956196947\n",
      "Step: 990 Weights: [-4.06051269  2.6375299 ] , error: 2.7270424233487245\n",
      "Step: 991 Weights: [-4.05044083  2.63637804] , error: 2.7167772295248778\n",
      "Step: 992 Weights: [-4.04039194  2.63522881] , error: 2.7065588001317042\n",
      "Step: 993 Weights: [-4.03036597  2.6340822 ] , error: 2.6963869221277372\n",
      "Step: 994 Weights: [-4.02036286  2.6329382 ] , error: 2.6862613834420435\n",
      "Step: 995 Weights: [-4.01038256  2.63179681] , error: 2.676181972969809\n",
      "Step: 996 Weights: [-4.00042502  2.63065802] , error: 2.6661484805679354\n",
      "Step: 997 Weights: [-3.99049018  2.62952183] , error: 2.6561606970506566\n",
      "Step: 998 Weights: [-3.980578    2.62838823] , error: 2.646218414185185\n",
      "Step: 999 Weights: [-3.97068843  2.62725722] , error: 2.636321424687353\n",
      "Step: 1000 Weights: [-3.96082141  2.62612879] , error: 2.626469522217322\n",
      "Step: 1001 Weights: [-3.95097689  2.62500293] , error: 2.6166625013752385\n",
      "Step: 1002 Weights: [-3.94115482  2.62387963] , error: 2.6069001576969995\n",
      "Step: 1003 Weights: [-3.93135514  2.6227589 ] , error: 2.5971822876499395\n",
      "Step: 1004 Weights: [-3.92157782  2.62164072] , error: 2.587508688628633\n",
      "Step: 1005 Weights: [-3.91182279  2.6205251 ] , error: 2.5778791589506405\n",
      "Step: 1006 Weights: [-3.90209     2.61941202] , error: 2.5682934978523146\n",
      "Step: 1007 Weights: [-3.89237942  2.61830147] , error: 2.5587515054846133\n",
      "Step: 1008 Weights: [-3.88269097  2.61719346] , error: 2.5492529829089303\n",
      "Step: 1009 Weights: [-3.87302462  2.61608798] , error: 2.539797732092956\n",
      "Step: 1010 Weights: [-3.86338031  2.61498501] , error: 2.5303855559065407\n",
      "Step: 1011 Weights: [-3.853758    2.61388456] , error: 2.521016258117583\n",
      "Step: 1012 Weights: [-3.84415762  2.61278662] , error: 2.5116896433879448\n",
      "Step: 1013 Weights: [-3.83457915  2.61169119] , error: 2.5024055172693784\n",
      "Step: 1014 Weights: [-3.82502251  2.61059825] , error: 2.493163686199467\n",
      "Step: 1015 Weights: [-3.81548767  2.60950781] , error: 2.4839639574975956\n",
      "Step: 1016 Weights: [-3.80597457  2.60841985] , error: 2.4748061393609313\n",
      "Step: 1017 Weights: [-3.79648316  2.60733437] , error: 2.465690040860421\n",
      "Step: 1018 Weights: [-3.7870134   2.60625137] , error: 2.456615471936813\n",
      "Step: 1019 Weights: [-3.77756523  2.60517084] , error: 2.447582243396702\n",
      "Step: 1020 Weights: [-3.76813861  2.60409277] , error: 2.438590166908572\n",
      "Step: 1021 Weights: [-3.75873349  2.60301716] , error: 2.429639054998874\n",
      "Step: 1022 Weights: [-3.74934981  2.601944  ] , error: 2.4207287210481274\n",
      "Step: 1023 Weights: [-3.73998753  2.60087329] , error: 2.4118589792870178\n",
      "Step: 1024 Weights: [-3.73064661  2.59980503] , error: 2.40302964479252\n",
      "Step: 1025 Weights: [-3.72132698  2.59873919] , error: 2.394240533484055\n",
      "Step: 1026 Weights: [-3.7120286   2.59767579] , error: 2.3854914621196524\n",
      "Step: 1027 Weights: [-3.70275143  2.59661482] , error: 2.3767822482921193\n",
      "Step: 1028 Weights: [-3.69349542  2.59555626] , error: 2.3681127104252404\n",
      "Step: 1029 Weights: [-3.68426051  2.59450012] , error: 2.3594826677699947\n",
      "Step: 1030 Weights: [-3.67504667  2.59344638] , error: 2.3508919404007953\n",
      "Step: 1031 Weights: [-3.66585383  2.59239505] , error: 2.3423403492117165\n",
      "Step: 1032 Weights: [-3.65668196  2.59134612] , error: 2.3338277159127894\n",
      "Step: 1033 Weights: [-3.647531    2.59029957] , error: 2.3253538630262467\n",
      "Step: 1034 Weights: [-3.63840091  2.58925542] , error: 2.3169186138828657\n",
      "Step: 1035 Weights: [-3.62929164  2.58821364] , error: 2.3085217926182526\n",
      "Step: 1036 Weights: [-3.62020315  2.58717425] , error: 2.3001632241691894\n",
      "Step: 1037 Weights: [-3.61113538  2.58613722] , error: 2.2918427342699768\n",
      "Step: 1038 Weights: [-3.60208829  2.58510255] , error: 2.2835601494488142\n",
      "Step: 1039 Weights: [-3.59306183  2.58407025] , error: 2.2753152970241652\n",
      "Step: 1040 Weights: [-3.58405595  2.5830403 ] , error: 2.2671080051011754\n",
      "Step: 1041 Weights: [-3.57507061  2.5820127 ] , error: 2.258938102568076\n",
      "Step: 1042 Weights: [-3.56610576  2.58098744] , error: 2.2508054190926146\n",
      "Step: 1043 Weights: [-3.55716136  2.57996452] , error: 2.242709785118518\n",
      "Step: 1044 Weights: [-3.54823735  2.57894393] , error: 2.2346510318619437\n",
      "Step: 1045 Weights: [-3.53933369  2.57792567] , error: 2.2266289913079738\n",
      "Step: 1046 Weights: [-3.53045034  2.57690974] , error: 2.218643496207091\n",
      "Step: 1047 Weights: [-3.52158724  2.57589612] , error: 2.210694380071717\n",
      "Step: 1048 Weights: [-3.51274436  2.57488481] , error: 2.2027814771727225\n",
      "Step: 1049 Weights: [-3.50392164  2.5738758 ] , error: 2.194904622535983\n",
      "Step: 1050 Weights: [-3.49511904  2.5728691 ] , error: 2.1870636519389337\n",
      "Step: 1051 Weights: [-3.48633651  2.57186469] , error: 2.179258401907146\n",
      "Step: 1052 Weights: [-3.47757401  2.57086258] , error: 2.1714887097109203\n",
      "Step: 1053 Weights: [-3.4688315   2.56986275] , error: 2.1637544133618967\n",
      "Step: 1054 Weights: [-3.46010892  2.56886519] , error: 2.1560553516096674\n",
      "Step: 1055 Weights: [-3.45140623  2.56786992] , error: 2.148391363938428\n",
      "Step: 1056 Weights: [-3.44272339  2.56687691] , error: 2.1407622905636297\n",
      "Step: 1057 Weights: [-3.43406034  2.56588617] , error: 2.133167972428631\n",
      "Step: 1058 Weights: [-3.42541706  2.56489769] , error: 2.125608251201397\n",
      "Step: 1059 Weights: [-3.41679348  2.56391146] , error: 2.1180829692712053\n",
      "Step: 1060 Weights: [-3.40818957  2.56292748] , error: 2.1105919697453333\n",
      "Step: 1061 Weights: [-3.39960528  2.56194574] , error: 2.1031350964458175\n",
      "Step: 1062 Weights: [-3.39104056  2.56096625] , error: 2.095712193906179\n",
      "Step: 1063 Weights: [-3.38249538  2.55998898] , error: 2.0883231073681814\n",
      "Step: 1064 Weights: [-3.37396968  2.55901395] , error: 2.080967682778617\n",
      "Step: 1065 Weights: [-3.36546343  2.55804114] , error: 2.0736457667860853\n",
      "Step: 1066 Weights: [-3.35697657  2.55707054] , error: 2.0663572067377984\n",
      "Step: 1067 Weights: [-3.34850906  2.55610217] , error: 2.0591018506763916\n",
      "Step: 1068 Weights: [-3.34006087  2.55513599] , error: 2.051879547336776\n",
      "Step: 1069 Weights: [-3.33163194  2.55417203] , error: 2.0446901461429565\n",
      "Step: 1070 Weights: [-3.32322223  2.55321026] , error: 2.0375334972049175\n",
      "Step: 1071 Weights: [-3.3148317   2.55225068] , error: 2.0304094513154745\n",
      "Step: 1072 Weights: [-3.30646031  2.55129329] , error: 2.023317859947189\n",
      "Step: 1073 Weights: [-3.298108    2.55033809] , error: 2.016258575249247\n",
      "Step: 1074 Weights: [-3.28977474  2.54938506] , error: 2.0092314500444\n",
      "Step: 1075 Weights: [-3.28146049  2.54843421] , error: 2.0022363378258756\n",
      "Step: 1076 Weights: [-3.27316519  2.54748552] , error: 1.9952730927543347\n",
      "Step: 1077 Weights: [-3.26488881  2.546539  ] , error: 1.9883415696548277\n",
      "Step: 1078 Weights: [-3.25663131  2.54559464] , error: 1.981441624013772\n",
      "Step: 1079 Weights: [-3.24839263  2.54465243] , error: 1.9745731119759318\n",
      "Step: 1080 Weights: [-3.24017274  2.54371237] , error: 1.9677358903414224\n",
      "Step: 1081 Weights: [-3.2319716   2.54277445] , error: 1.9609298165627291\n",
      "Step: 1082 Weights: [-3.22378916  2.54183867] , error: 1.9541547487417246\n",
      "Step: 1083 Weights: [-3.21562538  2.54090503] , error: 1.9474105456267252\n",
      "Step: 1084 Weights: [-3.20748021  2.53997351] , error: 1.9406970666095287\n",
      "Step: 1085 Weights: [-3.19935362  2.53904412] , error: 1.9340141717224981\n",
      "Step: 1086 Weights: [-3.19124557  2.53811685] , error: 1.9273617216356347\n",
      "Step: 1087 Weights: [-3.183156    2.53719169] , error: 1.920739577653678\n",
      "Step: 1088 Weights: [-3.17508488  2.53626864] , error: 1.914147601713208\n",
      "Step: 1089 Weights: [-3.16703216  2.5353477 ] , error: 1.907585656379775\n",
      "Step: 1090 Weights: [-3.15899781  2.53442886] , error: 1.9010536048450282\n",
      "Step: 1091 Weights: [-3.15098178  2.53351211] , error: 1.8945513109238623\n",
      "Step: 1092 Weights: [-3.14298403  2.53259746] , error: 1.8880786390515856\n",
      "Step: 1093 Weights: [-3.13500452  2.53168489] , error: 1.8816354542810858\n",
      "Step: 1094 Weights: [-3.1270432  2.5307744] , error: 1.8752216222800222\n",
      "Step: 1095 Weights: [-3.11910004  2.52986598] , error: 1.8688370093280176\n",
      "Step: 1096 Weights: [-3.111175    2.52895964] , error: 1.8624814823138858\n",
      "Step: 1097 Weights: [-3.10326802  2.52805537] , error: 1.856154908732837\n",
      "Step: 1098 Weights: [-3.09537908  2.52715315] , error: 1.8498571566837212\n",
      "Step: 1099 Weights: [-3.08750812  2.526253  ] , error: 1.8435880948662957\n",
      "Step: 1100 Weights: [-3.07965512  2.52535489] , error: 1.837347592578456\n",
      "Step: 1101 Weights: [-3.07182003  2.52445884] , error: 1.8311355197135424\n",
      "Step: 1102 Weights: [-3.0640028   2.52356483] , error: 1.8249517467576073\n",
      "Step: 1103 Weights: [-3.05620339  2.52267286] , error: 1.8187961447867105\n",
      "Step: 1104 Weights: [-3.04842178  2.52178292] , error: 1.8126685854642668\n",
      "Step: 1105 Weights: [-3.04065791  2.52089501] , error: 1.8065689410383203\n",
      "Step: 1106 Weights: [-3.03291174  2.52000913] , error: 1.8004970843389183\n",
      "Step: 1107 Weights: [-3.02518324  2.51912526] , error: 1.7944528887754398\n",
      "Step: 1108 Weights: [-3.01747236  2.51824341] , error: 1.788436228333975\n",
      "Step: 1109 Weights: [-3.00977907  2.51736358] , error: 1.7824469775746774\n",
      "Step: 1110 Weights: [-3.00210332  2.51648574] , error: 1.776485011629164\n",
      "Step: 1111 Weights: [-2.99444507  2.51560991] , error: 1.7705502061979\n",
      "Step: 1112 Weights: [-2.98680429  2.51473608] , error: 1.7646424375476197\n",
      "Step: 1113 Weights: [-2.97918094  2.51386424] , error: 1.7587615825087375\n",
      "Step: 1114 Weights: [-2.97157496  2.51299439] , error: 1.752907518472778\n",
      "Step: 1115 Weights: [-2.96398633  2.51212652] , error: 1.7470801233898368\n",
      "Step: 1116 Weights: [-2.95641501  2.51126064] , error: 1.7412792757660094\n",
      "Step: 1117 Weights: [-2.94886095  2.51039672] , error: 1.7355048546608858\n",
      "Step: 1118 Weights: [-2.94132412  2.50953478] , error: 1.7297567396850049\n",
      "Step: 1119 Weights: [-2.93380448  2.5086748 ] , error: 1.724034810997364\n",
      "Step: 1120 Weights: [-2.92630198  2.50781678] , error: 1.7183389493029086\n",
      "Step: 1121 Weights: [-2.9188166   2.50696072] , error: 1.7126690358500403\n",
      "Step: 1122 Weights: [-2.91134828  2.50610662] , error: 1.7070249524281693\n",
      "Step: 1123 Weights: [-2.90389699  2.50525445] , error: 1.7014065813652104\n",
      "Step: 1124 Weights: [-2.8964627   2.50440424] , error: 1.6958138055251508\n",
      "Step: 1125 Weights: [-2.88904536  2.50355596] , error: 1.6902465083056182\n",
      "Step: 1126 Weights: [-2.88164493  2.50270962] , error: 1.6847045736354291\n",
      "Step: 1127 Weights: [-2.87426138  2.5018652 ] , error: 1.6791878859721736\n",
      "Step: 1128 Weights: [-2.86689467  2.50102271] , error: 1.6736963302998267\n",
      "Step: 1129 Weights: [-2.85954476  2.50018215] , error: 1.6682297921263112\n",
      "Step: 1130 Weights: [-2.8522116  2.4993435] , error: 1.6627881574811467\n",
      "Step: 1131 Weights: [-2.84489517  2.49850676] , error: 1.6573713129130634\n",
      "Step: 1132 Weights: [-2.83759543  2.49767193] , error: 1.6519791454876267\n",
      "Step: 1133 Weights: [-2.83031233  2.496839  ] , error: 1.6466115427848902\n",
      "Step: 1134 Weights: [-2.82304584  2.49600798] , error: 1.641268392897054\n",
      "Step: 1135 Weights: [-2.81579592  2.49517884] , error: 1.6359495844261245\n",
      "Step: 1136 Weights: [-2.80856253  2.4943516 ] , error: 1.6306550064816001\n",
      "Step: 1137 Weights: [-2.80134564  2.49352625] , error: 1.6253845486781566\n",
      "Step: 1138 Weights: [-2.7941452   2.49270278] , error: 1.6201381011333393\n",
      "Step: 1139 Weights: [-2.78696119  2.49188118] , error: 1.6149155544652825\n",
      "Step: 1140 Weights: [-2.77979356  2.49106146] , error: 1.609716799790421\n",
      "Step: 1141 Weights: [-2.77264227  2.49024361] , error: 1.6045417287212227\n",
      "Step: 1142 Weights: [-2.76550729  2.48942762] , error: 1.5993902333639278\n",
      "Step: 1143 Weights: [-2.75838858  2.4886135 ] , error: 1.5942622063163105\n",
      "Step: 1144 Weights: [-2.75128611  2.48780123] , error: 1.5891575406654117\n",
      "Step: 1145 Weights: [-2.74419983  2.48699081] , error: 1.5840761299853474\n",
      "Step: 1146 Weights: [-2.73712971  2.48618225] , error: 1.5790178683350569\n",
      "Step: 1147 Weights: [-2.73007572  2.48537552] , error: 1.5739826502561165\n",
      "Step: 1148 Weights: [-2.72303781  2.48457064] , error: 1.568970370770523\n",
      "Step: 1149 Weights: [-2.71601595  2.48376759] , error: 1.5639809253785235\n",
      "Step: 1150 Weights: [-2.7090101   2.48296637] , error: 1.5590142100564237\n",
      "Step: 1151 Weights: [-2.70202023  2.48216698] , error: 1.5540701212544192\n",
      "Step: 1152 Weights: [-2.6950463   2.48136941] , error: 1.549148555894447\n",
      "Step: 1153 Weights: [-2.68808827  2.48057366] , error: 1.544249411368026\n",
      "Step: 1154 Weights: [-2.68114611  2.47977972] , error: 1.5393725855341178\n",
      "Step: 1155 Weights: [-2.67421978  2.4789876 ] , error: 1.53451797671701\n",
      "Step: 1156 Weights: [-2.66730924  2.47819728] , error: 1.5296854837041791\n",
      "Step: 1157 Weights: [-2.66041447  2.47740877] , error: 1.5248750057441953\n",
      "Step: 1158 Weights: [-2.65353542  2.47662205] , error: 1.5200864425446037\n",
      "Step: 1159 Weights: [-2.64667205  2.47583713] , error: 1.5153196942698575\n",
      "Step: 1160 Weights: [-2.63982433  2.47505399] , error: 1.51057466153922\n",
      "Step: 1161 Weights: [-2.63299224  2.47427264] , error: 1.505851245424687\n",
      "Step: 1162 Weights: [-2.62617572  2.47349308] , error: 1.501149347448948\n",
      "Step: 1163 Weights: [-2.61937474  2.47271529] , error: 1.4964688695833113\n",
      "Step: 1164 Weights: [-2.61258928  2.47193928] , error: 1.4918097142456657\n",
      "Step: 1165 Weights: [-2.60581929  2.47116503] , error: 1.4871717842984604\n",
      "Step: 1166 Weights: [-2.59906473  2.47039255] , error: 1.4825549830466467\n",
      "Step: 1167 Weights: [-2.59232558  2.46962183] , error: 1.4779592142356992\n",
      "Step: 1168 Weights: [-2.5856018   2.46885287] , error: 1.4733843820495884\n",
      "Step: 1169 Weights: [-2.57889335  2.46808567] , error: 1.4688303911087868\n",
      "Step: 1170 Weights: [-2.5722002   2.46732021] , error: 1.464297146468278\n",
      "Step: 1171 Weights: [-2.56552231  2.4665565 ] , error: 1.459784553615581\n",
      "Step: 1172 Weights: [-2.55885965  2.46579453] , error: 1.4552925184687848\n",
      "Step: 1173 Weights: [-2.55221219  2.4650343 ] , error: 1.4508209473745735\n",
      "Step: 1174 Weights: [-2.54557988  2.4642758 ] , error: 1.4463697471062837\n",
      "Step: 1175 Weights: [-2.5389627   2.46351903] , error: 1.4419388248619596\n",
      "Step: 1176 Weights: [-2.53236061  2.46276399] , error: 1.437528088262415\n",
      "Step: 1177 Weights: [-2.52577357  2.46201067] , error: 1.4331374453493082\n",
      "Step: 1178 Weights: [-2.51920155  2.46125906] , error: 1.428766804583228\n",
      "Step: 1179 Weights: [-2.51264452  2.46050917] , error: 1.4244160748417842\n",
      "Step: 1180 Weights: [-2.50610245  2.45976099] , error: 1.4200851654177025\n",
      "Step: 1181 Weights: [-2.49957529  2.45901452] , error: 1.4157739860169383\n",
      "Step: 1182 Weights: [-2.49306302  2.45826975] , error: 1.411482446756796\n",
      "Step: 1183 Weights: [-2.4865656   2.45752668] , error: 1.4072104581640559\n",
      "Step: 1184 Weights: [-2.48008299  2.4567853 ] , error: 1.4029579311730902\n",
      "Step: 1185 Weights: [-2.47361517  2.45604561] , error: 1.3987247771240372\n",
      "Step: 1186 Weights: [-2.4671621   2.45530761] , error: 1.3945109077609308\n",
      "Step: 1187 Weights: [-2.46072374  2.45457129] , error: 1.390316235229865\n",
      "Step: 1188 Weights: [-2.45430006  2.45383665] , error: 1.3861406720771636\n",
      "Step: 1189 Weights: [-2.44789104  2.45310369] , error: 1.3819841312475598\n",
      "Step: 1190 Weights: [-2.44149663  2.4523724 ] , error: 1.3778465260823816\n",
      "Step: 1191 Weights: [-2.4351168   2.45164277] , error: 1.3737277703177282\n",
      "Step: 1192 Weights: [-2.42875152  2.45091481] , error: 1.3696277780827029\n",
      "Step: 1193 Weights: [-2.42240075  2.45018851] , error: 1.3655464638975947\n",
      "Step: 1194 Weights: [-2.41606447  2.44946387] , error: 1.361483742672105\n",
      "Step: 1195 Weights: [-2.40974263  2.44874088] , error: 1.3574395297035822\n",
      "Step: 1196 Weights: [-2.40343522  2.44801954] , error: 1.3534137406752451\n",
      "Step: 1197 Weights: [-2.39714218  2.44729984] , error: 1.3494062916544303\n",
      "Step: 1198 Weights: [-2.3908635   2.44658178] , error: 1.345417099090834\n",
      "Step: 1199 Weights: [-2.38459914  2.44586536] , error: 1.341446079814784\n",
      "Step: 1200 Weights: [-2.37834906  2.44515058] , error: 1.3374931510354995\n",
      "Step: 1201 Weights: [-2.37211323  2.44443742] , error: 1.3335582303393578\n",
      "Step: 1202 Weights: [-2.36589162  2.44372589] , error: 1.3296412356881853\n",
      "Step: 1203 Weights: [-2.3596842   2.44301599] , error: 1.3257420854175421\n",
      "Step: 1204 Weights: [-2.35349094  2.4423077 ] , error: 1.3218606982350267\n",
      "Step: 1205 Weights: [-2.3473118   2.44160103] , error: 1.3179969932185664\n",
      "Step: 1206 Weights: [-2.34114675  2.44089596] , error: 1.3141508898147527\n",
      "Step: 1207 Weights: [-2.33499576  2.44019251] , error: 1.310322307837135\n",
      "Step: 1208 Weights: [-2.3288588   2.43949066] , error: 1.3065111674645746\n",
      "Step: 1209 Weights: [-2.32273583  2.43879041] , error: 1.302717389239554\n",
      "Step: 1210 Weights: [-2.31662683  2.43809176] , error: 1.2989408940665483\n",
      "Step: 1211 Weights: [-2.31053175  2.4373947 ] , error: 1.2951816032103594\n",
      "Step: 1212 Weights: [-2.30445058  2.43669924] , error: 1.2914394382944723\n",
      "Step: 1213 Weights: [-2.29838327  2.43600535] , error: 1.2877143212994329\n",
      "Step: 1214 Weights: [-2.2923298   2.43531305] , error: 1.2840061745612104\n",
      "Step: 1215 Weights: [-2.28629013  2.43462233] , error: 1.280314920769583\n",
      "Step: 1216 Weights: [-2.28026424  2.43393318] , error: 1.2766404829665325\n",
      "Step: 1217 Weights: [-2.27425208  2.43324561] , error: 1.2729827845446187\n",
      "Step: 1218 Weights: [-2.26825364  2.4325596 ] , error: 1.2693417492454118\n",
      "Step: 1219 Weights: [-2.26226888  2.43187516] , error: 1.2657173011578795\n",
      "Step: 1220 Weights: [-2.25629776  2.43119228] , error: 1.2621093647168131\n",
      "Step: 1221 Weights: [-2.25034026  2.43051095] , error: 1.258517864701251\n",
      "Step: 1222 Weights: [-2.24439635  2.42983118] , error: 1.2549427262329103\n",
      "Step: 1223 Weights: [-2.23846599  2.42915296] , error: 1.2513838747746298\n",
      "Step: 1224 Weights: [-2.23254916  2.42847629] , error: 1.2478412361288036\n",
      "Step: 1225 Weights: [-2.22664581  2.42780115] , error: 1.244314736435853\n",
      "Step: 1226 Weights: [-2.22075593  2.42712756] , error: 1.2408043021726676\n",
      "Step: 1227 Weights: [-2.21487949  2.42645551] , error: 1.237309860151086\n",
      "Step: 1228 Weights: [-2.20901644  2.42578498] , error: 1.2338313375163628\n",
      "Step: 1229 Weights: [-2.20316676  2.42511599] , error: 1.2303686617456526\n",
      "Step: 1230 Weights: [-2.19733042  2.42444852] , error: 1.2269217606465004\n",
      "Step: 1231 Weights: [-2.19150739  2.42378258] , error: 1.2234905623553276\n",
      "Step: 1232 Weights: [-2.18569764  2.42311815] , error: 1.2200749953359415\n",
      "Step: 1233 Weights: [-2.17990114  2.42245524] , error: 1.2166749883780446\n",
      "Step: 1234 Weights: [-2.17411786  2.42179384] , error: 1.2132904705957446\n",
      "Step: 1235 Weights: [-2.16834776  2.42113394] , error: 1.209921371426081\n",
      "Step: 1236 Weights: [-2.16259083  2.42047556] , error: 1.206567620627549\n",
      "Step: 1237 Weights: [-2.15684702  2.41981867] , error: 1.2032291482786404\n",
      "Step: 1238 Weights: [-2.15111631  2.41916328] , error: 1.1999058847763853\n",
      "Step: 1239 Weights: [-2.14539867  2.41850939] , error: 1.1965977608348957\n",
      "Step: 1240 Weights: [-2.13969406  2.41785699] , error: 1.1933047074839225\n",
      "Step: 1241 Weights: [-2.13400247  2.41720607] , error: 1.1900266560674275\n",
      "Step: 1242 Weights: [-2.12832386  2.41655664] , error: 1.1867635382421404\n",
      "Step: 1243 Weights: [-2.12265819  2.41590869] , error: 1.183515285976133\n",
      "Step: 1244 Weights: [-2.11700544  2.41526222] , error: 1.1802818315474126\n",
      "Step: 1245 Weights: [-2.11136559  2.41461722] , error: 1.177063107542495\n",
      "Step: 1246 Weights: [-2.1057386  2.4139737] , error: 1.1738590468550154\n",
      "Step: 1247 Weights: [-2.10012444  2.41333164] , error: 1.1706695826843156\n",
      "Step: 1248 Weights: [-2.09452308  2.41269104] , error: 1.1674946485340585\n",
      "Step: 1249 Weights: [-2.08893449  2.41205191] , error: 1.1643341782108367\n",
      "Step: 1250 Weights: [-2.08335865  2.41141423] , error: 1.1611881058227989\n",
      "Step: 1251 Weights: [-2.07779552  2.41077801] , error: 1.1580563657782728\n",
      "Step: 1252 Weights: [-2.07224508  2.41014324] , error: 1.1549388927843947\n",
      "Step: 1253 Weights: [-2.0667073   2.40950991] , error: 1.1518356218457515\n",
      "Step: 1254 Weights: [-2.06118215  2.40887803] , error: 1.14874648826303\n",
      "Step: 1255 Weights: [-2.05566959  2.40824759] , error: 1.1456714276316575\n",
      "Step: 1256 Weights: [-2.05016961  2.40761859] , error: 1.1426103758404695\n",
      "Step: 1257 Weights: [-2.04468217  2.40699102] , error: 1.13956326907036\n",
      "Step: 1258 Weights: [-2.03920724  2.40636489] , error: 1.1365300437929693\n",
      "Step: 1259 Weights: [-2.0337448   2.40574018] , error: 1.133510636769341\n",
      "Step: 1260 Weights: [-2.02829481  2.4051169 ] , error: 1.1305049850486215\n",
      "Step: 1261 Weights: [-2.02285726  2.40449504] , error: 1.1275130259667274\n",
      "Step: 1262 Weights: [-2.0174321   2.40387459] , error: 1.1245346971450583\n",
      "Step: 1263 Weights: [-2.01201931  2.40325556] , error: 1.1215699364891847\n",
      "Step: 1264 Weights: [-2.00661887  2.40263795] , error: 1.118618682187552\n",
      "Step: 1265 Weights: [-2.00123074  2.40202174] , error: 1.1156808727102003\n",
      "Step: 1266 Weights: [-1.9958549   2.40140693] , error: 1.1127564468074818\n",
      "Step: 1267 Weights: [-1.99049132  2.40079353] , error: 1.109845343508773\n",
      "Step: 1268 Weights: [-1.98513997  2.40018153] , error: 1.1069475021212094\n",
      "Step: 1269 Weights: [-1.97980082  2.39957092] , error: 1.104062862228424\n",
      "Step: 1270 Weights: [-1.97447385  2.39896171] , error: 1.1011913636892872\n",
      "Step: 1271 Weights: [-1.96915903  2.39835388] , error: 1.0983329466366436\n",
      "Step: 1272 Weights: [-1.96385633  2.39774744] , error: 1.095487551476075\n",
      "Step: 1273 Weights: [-1.95856572  2.39714238] , error: 1.0926551188846516\n",
      "Step: 1274 Weights: [-1.95328717  2.39653871] , error: 1.089835589809695\n",
      "Step: 1275 Weights: [-1.94802066  2.39593641] , error: 1.0870289054675537\n",
      "Step: 1276 Weights: [-1.94276616  2.39533548] , error: 1.0842350073423723\n",
      "Step: 1277 Weights: [-1.93752364  2.39473592] , error: 1.0814538371848645\n",
      "Step: 1278 Weights: [-1.93229308  2.39413774] , error: 1.0786853370111167\n",
      "Step: 1279 Weights: [-1.92707445  2.39354091] , error: 1.0759294491013631\n",
      "Step: 1280 Weights: [-1.92186772  2.39294545] , error: 1.0731861159987872\n",
      "Step: 1281 Weights: [-1.91667286  2.39235134] , error: 1.0704552805083234\n",
      "Step: 1282 Weights: [-1.91148984  2.39175859] , error: 1.0677368856954739\n",
      "Step: 1283 Weights: [-1.90631865  2.39116719] , error: 1.0650308748851012\n",
      "Step: 1284 Weights: [-1.90115925  2.39057714] , error: 1.0623371916602713\n",
      "Step: 1285 Weights: [-1.89601161  2.38998843] , error: 1.0596557798610533\n",
      "Step: 1286 Weights: [-1.89087572  2.38940107] , error: 1.0569865835833692\n",
      "Step: 1287 Weights: [-1.88575153  2.38881505] , error: 1.0543295471778151\n",
      "Step: 1288 Weights: [-1.88063903  2.38823036] , error: 1.0516846152485058\n",
      "Step: 1289 Weights: [-1.87553819  2.38764701] , error: 1.0490517326519182\n",
      "Step: 1290 Weights: [-1.87044898  2.38706498] , error: 1.0464308444957446\n",
      "Step: 1291 Weights: [-1.86537138  2.38648429] , error: 1.0438218961377472\n",
      "Step: 1292 Weights: [-1.86030535  2.38590491] , error: 1.0412248331846152\n",
      "Step: 1293 Weights: [-1.85525088  2.38532686] , error: 1.0386396014908352\n",
      "Step: 1294 Weights: [-1.85020794  2.38475013] , error: 1.0360661471575596\n",
      "Step: 1295 Weights: [-1.84517649  2.38417471] , error: 1.0335044165314873\n",
      "Step: 1296 Weights: [-1.84015652  2.38360061] , error: 1.0309543562037389\n",
      "Step: 1297 Weights: [-1.83514799  2.38302781] , error: 1.028415913008744\n",
      "Step: 1298 Weights: [-1.83015089  2.38245632] , error: 1.0258890340231404\n",
      "Step: 1299 Weights: [-1.82516519  2.38188614] , error: 1.0233736665646618\n",
      "Step: 1300 Weights: [-1.82019085  2.38131725] , error: 1.0208697581910422\n",
      "Step: 1301 Weights: [-1.81522785  2.38074966] , error: 1.0183772566989284\n",
      "Step: 1302 Weights: [-1.81027618  2.38018337] , error: 1.015896110122778\n",
      "Step: 1303 Weights: [-1.80533579  2.37961836] , error: 1.013426266733789\n",
      "Step: 1304 Weights: [-1.80040667  2.37905465] , error: 1.0109676750388197\n",
      "Step: 1305 Weights: [-1.7954888   2.37849222] , error: 1.0085202837793061\n",
      "Step: 1306 Weights: [-1.79058213  2.37793107] , error: 1.0060840419302026\n",
      "Step: 1307 Weights: [-1.78568666  2.37737121] , error: 1.0036588986989183\n",
      "Step: 1308 Weights: [-1.78080235  2.37681262] , error: 1.0012448035242445\n",
      "Step: 1309 Weights: [-1.77592918  2.3762553 ] , error: 0.9988417060753212\n",
      "Step: 1310 Weights: [-1.77106712  2.37569925] , error: 0.9964495562505715\n",
      "Step: 1311 Weights: [-1.76621615  2.37514448] , error: 0.9940683041766638\n",
      "Step: 1312 Weights: [-1.76137624  2.37459096] , error: 0.9916979002074724\n",
      "Step: 1313 Weights: [-1.75654737  2.37403871] , error: 0.9893382949230409\n",
      "Step: 1314 Weights: [-1.7517295   2.37348772] , error: 0.9869894391285472\n",
      "Step: 1315 Weights: [-1.74692263  2.37293799] , error: 0.9846512838532895\n",
      "Step: 1316 Weights: [-1.74212672  2.37238951] , error: 0.982323780349655\n",
      "Step: 1317 Weights: [-1.73734174  2.37184228] , error: 0.9800068800921065\n",
      "Step: 1318 Weights: [-1.73256768  2.3712963 ] , error: 0.977700534776172\n",
      "Step: 1319 Weights: [-1.7278045   2.37075156] , error: 0.9754046963174393\n",
      "Step: 1320 Weights: [-1.72305219  2.37020806] , error: 0.9731193168505454\n",
      "Step: 1321 Weights: [-1.71831071  2.36966581] , error: 0.9708443487281915\n",
      "Step: 1322 Weights: [-1.71358005  2.36912479] , error: 0.9685797445201318\n",
      "Step: 1323 Weights: [-1.70886017  2.36858501] , error: 0.9663254570122077\n",
      "Step: 1324 Weights: [-1.70415105  2.36804645] , error: 0.9640814392053432\n",
      "Step: 1325 Weights: [-1.69945268  2.36750912] , error: 0.961847644314573\n",
      "Step: 1326 Weights: [-1.69476502  2.36697302] , error: 0.9596240257680704\n",
      "Step: 1327 Weights: [-1.69008805  2.36643815] , error: 0.9574105372061676\n",
      "Step: 1328 Weights: [-1.68542174  2.36590449] , error: 0.9552071324803988\n",
      "Step: 1329 Weights: [-1.68076608  2.36537205] , error: 0.9530137656525322\n",
      "Step: 1330 Weights: [-1.67612103  2.36484082] , error: 0.9508303909936118\n",
      "Step: 1331 Weights: [-1.67148658  2.3643108 ] , error: 0.9486569629830096\n",
      "Step: 1332 Weights: [-1.66686269  2.363782  ] , error: 0.9464934363074693\n",
      "Step: 1333 Weights: [-1.66224935  2.36325439] , error: 0.944339765860167\n",
      "Step: 1334 Weights: [-1.65764652  2.362728  ] , error: 0.9421959067397689\n",
      "Step: 1335 Weights: [-1.6530542  2.3622028] , error: 0.9400618142494916\n",
      "Step: 1336 Weights: [-1.64847235  2.3616788 ] , error: 0.9379374438961774\n",
      "Step: 1337 Weights: [-1.64390094  2.36115599] , error: 0.935822751389364\n",
      "Step: 1338 Weights: [-1.63933996  2.36063438] , error: 0.9337176926403551\n",
      "Step: 1339 Weights: [-1.63478938  2.36011396] , error: 0.931622223761311\n",
      "Step: 1340 Weights: [-1.63024918  2.35959472] , error: 0.9295363010643286\n",
      "Step: 1341 Weights: [-1.62571933  2.35907667] , error: 0.9274598810605279\n",
      "Step: 1342 Weights: [-1.62119981  2.3585598 ] , error: 0.9253929204591472\n",
      "Step: 1343 Weights: [-1.6166906  2.3580441] , error: 0.9233353761666472\n",
      "Step: 1344 Weights: [-1.61219167  2.35752959] , error: 0.9212872052858008\n",
      "Step: 1345 Weights: [-1.607703    2.35701625] , error: 0.9192483651148091\n",
      "Step: 1346 Weights: [-1.60322457  2.35650407] , error: 0.917218813146405\n",
      "Step: 1347 Weights: [-1.59875635  2.35599307] , error: 0.9151985070669673\n",
      "Step: 1348 Weights: [-1.59429832  2.35548323] , error: 0.9131874047556425\n",
      "Step: 1349 Weights: [-1.58985045  2.35497455] , error: 0.9111854642834665\n",
      "Step: 1350 Weights: [-1.58541273  2.35446704] , error: 0.9091926439124794\n",
      "Step: 1351 Weights: [-1.58098513  2.35396068] , error: 0.907208902094873\n",
      "Step: 1352 Weights: [-1.57656762  2.35345547] , error: 0.9052341974721123\n",
      "Step: 1353 Weights: [-1.57216019  2.35295142] , error: 0.9032684888740758\n",
      "Step: 1354 Weights: [-1.56776281  2.35244852] , error: 0.9013117353181959\n",
      "Step: 1355 Weights: [-1.56337546  2.35194676] , error: 0.8993638960086122\n",
      "Step: 1356 Weights: [-1.55899811  2.35144615] , error: 0.8974249303353096\n",
      "Step: 1357 Weights: [-1.55463074  2.35094668] , error: 0.8954947978732828\n",
      "Step: 1358 Weights: [-1.55027334  2.35044835] , error: 0.8935734583816821\n",
      "Step: 1359 Weights: [-1.54592587  2.34995115] , error: 0.8916608718029801\n",
      "Step: 1360 Weights: [-1.54158831  2.34945509] , error: 0.8897569982621434\n",
      "Step: 1361 Weights: [-1.53726065  2.34896016] , error: 0.8878617980657882\n",
      "Step: 1362 Weights: [-1.53294285  2.34846636] , error: 0.8859752317013626\n",
      "Step: 1363 Weights: [-1.5286349   2.34797368] , error: 0.8840972598363193\n",
      "Step: 1364 Weights: [-1.52433678  2.34748213] , error: 0.8822278433172918\n",
      "Step: 1365 Weights: [-1.52004845  2.3469917 ] , error: 0.8803669431692859\n",
      "Step: 1366 Weights: [-1.51576991  2.34650239] , error: 0.8785145205948593\n",
      "Step: 1367 Weights: [-1.51150112  2.34601419] , error: 0.8766705369733203\n",
      "Step: 1368 Weights: [-1.50724207  2.34552711] , error: 0.8748349538599198\n",
      "Step: 1369 Weights: [-1.50299272  2.34504114] , error: 0.8730077329850404\n",
      "Step: 1370 Weights: [-1.49875307  2.34455627] , error: 0.8711888362534186\n",
      "Step: 1371 Weights: [-1.49452309  2.34407251] , error: 0.8693782257433285\n",
      "Step: 1372 Weights: [-1.49030276  2.34358986] , error: 0.8675758637058102\n",
      "Step: 1373 Weights: [-1.48609204  2.3431083 ] , error: 0.8657817125638658\n",
      "Step: 1374 Weights: [-1.48189093  2.34262785] , error: 0.8639957349116911\n",
      "Step: 1375 Weights: [-1.4776994   2.34214849] , error: 0.8622178935138856\n",
      "Step: 1376 Weights: [-1.47351743  2.34167022] , error: 0.8604481513046807\n",
      "Step: 1377 Weights: [-1.469345    2.34119304] , error: 0.8586864713871658\n",
      "Step: 1378 Weights: [-1.46518208  2.34071695] , error: 0.8569328170325159\n",
      "Step: 1379 Weights: [-1.46102865  2.34024195] , error: 0.8551871516792346\n",
      "Step: 1380 Weights: [-1.4568847   2.33976803] , error: 0.8534494389323808\n",
      "Step: 1381 Weights: [-1.45275019  2.33929519] , error: 0.8517196425628186\n",
      "Step: 1382 Weights: [-1.44862511  2.33882343] , error: 0.8499977265064598\n",
      "Step: 1383 Weights: [-1.44450944  2.33835274] , error: 0.848283654863506\n",
      "Step: 1384 Weights: [-1.44040316  2.33788313] , error: 0.8465773918977078\n",
      "Step: 1385 Weights: [-1.43630624  2.33741459] , error: 0.8448789020356176\n",
      "Step: 1386 Weights: [-1.43221866  2.33694712] , error: 0.843188149865847\n",
      "Step: 1387 Weights: [-1.42814041  2.33648071] , error: 0.8415051001383278\n",
      "Step: 1388 Weights: [-1.42407145  2.33601537] , error: 0.8398297177635798\n",
      "Step: 1389 Weights: [-1.42001177  2.33555108] , error: 0.8381619678119757\n",
      "Step: 1390 Weights: [-1.41596135  2.33508786] , error: 0.8365018155130157\n",
      "Step: 1391 Weights: [-1.41192017  2.3346257 ] , error: 0.8348492262546\n",
      "Step: 1392 Weights: [-1.4078882   2.33416458] , error: 0.8332041655823108\n",
      "Step: 1393 Weights: [-1.40386543  2.33370452] , error: 0.8315665991986896\n",
      "Step: 1394 Weights: [-1.39985183  2.33324551] , error: 0.829936492962531\n",
      "Step: 1395 Weights: [-1.39584738  2.33278754] , error: 0.8283138128881529\n",
      "Step: 1396 Weights: [-1.39185207  2.33233062] , error: 0.8266985251447097\n",
      "Step: 1397 Weights: [-1.38786587  2.33187474] , error: 0.8250905960554713\n",
      "Step: 1398 Weights: [-1.38388875  2.3314199 ] , error: 0.8234899920971286\n",
      "Step: 1399 Weights: [-1.37992071  2.3309661 ] , error: 0.8218966798990895\n",
      "Step: 1400 Weights: [-1.37596171  2.33051333] , error: 0.82031062624279\n",
      "Step: 1401 Weights: [-1.37201175  2.3300616 ] , error: 0.818731798060994\n",
      "Step: 1402 Weights: [-1.36807079  2.32961089] , error: 0.8171601624371105\n",
      "Step: 1403 Weights: [-1.36413881  2.32916122] , error: 0.8155956866045033\n",
      "Step: 1404 Weights: [-1.36021581  2.32871257] , error: 0.8140383379458055\n",
      "Step: 1405 Weights: [-1.35630175  2.32826494] , error: 0.8124880839922504\n",
      "Step: 1406 Weights: [-1.35239661  2.32781833] , error: 0.8109448924229772\n",
      "Step: 1407 Weights: [-1.34850039  2.32737274] , error: 0.809408731064375\n",
      "Step: 1408 Weights: [-1.34461304  2.32692817] , error: 0.8078795678894027\n",
      "Step: 1409 Weights: [-1.34073456  2.32648461] , error: 0.8063573710169193\n",
      "Step: 1410 Weights: [-1.33686493  2.32604206] , error: 0.8048421087110221\n",
      "Step: 1411 Weights: [-1.33300412  2.32560052] , error: 0.8033337493803918\n",
      "Step: 1412 Weights: [-1.32915211  2.32515999] , error: 0.8018322615776221\n",
      "Step: 1413 Weights: [-1.32530889  2.32472046] , error: 0.8003376139985696\n",
      "Step: 1414 Weights: [-1.32147443  2.32428194] , error: 0.7988497754817032\n",
      "Step: 1415 Weights: [-1.31764872  2.32384441] , error: 0.7973687150074489\n",
      "Step: 1416 Weights: [-1.31383173  2.32340789] , error: 0.7958944016975515\n",
      "Step: 1417 Weights: [-1.31002345  2.32297236] , error: 0.7944268048144214\n",
      "Step: 1418 Weights: [-1.30622385  2.32253782] , error: 0.7929658937605001\n",
      "Step: 1419 Weights: [-1.30243291  2.32210427] , error: 0.79151163807762\n",
      "Step: 1420 Weights: [-1.29865062  2.32167171] , error: 0.7900640074463668\n",
      "Step: 1421 Weights: [-1.29487695  2.32124014] , error: 0.7886229716854571\n",
      "Step: 1422 Weights: [-1.29111189  2.32080955] , error: 0.7871885007510955\n",
      "Step: 1423 Weights: [-1.28735542  2.32037994] , error: 0.7857605647363586\n",
      "Step: 1424 Weights: [-1.28360751  2.31995132] , error: 0.7843391338705648\n",
      "Step: 1425 Weights: [-1.27986815  2.31952367] , error: 0.7829241785186616\n",
      "Step: 1426 Weights: [-1.27613732  2.319097  ] , error: 0.7815156691805965\n",
      "Step: 1427 Weights: [-1.27241499  2.31867129] , error: 0.7801135764907159\n",
      "Step: 1428 Weights: [-1.26870115  2.31824656] , error: 0.7787178712171368\n",
      "Step: 1429 Weights: [-1.26499578  2.3178228 ] , error: 0.7773285242611574\n",
      "Step: 1430 Weights: [-1.26129886  2.31740001] , error: 0.7759455066566248\n",
      "Step: 1431 Weights: [-1.25761038  2.31697818] , error: 0.7745687895693545\n",
      "Step: 1432 Weights: [-1.2539303   2.31655731] , error: 0.7731983442965185\n",
      "Step: 1433 Weights: [-1.25025862  2.3161374 ] , error: 0.771834142266044\n",
      "Step: 1434 Weights: [-1.2465953   2.31571845] , error: 0.7704761550360302\n",
      "Step: 1435 Weights: [-1.24294035  2.31530045] , error: 0.7691243542941394\n",
      "Step: 1436 Weights: [-1.23929372  2.31488341] , error: 0.767778711857017\n",
      "Step: 1437 Weights: [-1.23565542  2.31446731] , error: 0.7664391996697013\n",
      "Step: 1438 Weights: [-1.2320254   2.31405217] , error: 0.7651057898050415\n",
      "Step: 1439 Weights: [-1.22840367  2.31363797] , error: 0.7637784544631062\n",
      "Step: 1440 Weights: [-1.2247902   2.31322472] , error: 0.762457165970619\n",
      "Step: 1441 Weights: [-1.22118497  2.31281241] , error: 0.7611418967803605\n",
      "Step: 1442 Weights: [-1.21758795  2.31240104] , error: 0.7598326194706225\n",
      "Step: 1443 Weights: [-1.21399914  2.31199061] , error: 0.7585293067446061\n",
      "Step: 1444 Weights: [-1.21041852  2.31158112] , error: 0.757231931429871\n",
      "Step: 1445 Weights: [-1.20684606  2.31117256] , error: 0.7559404664777647\n",
      "Step: 1446 Weights: [-1.20328175  2.31076493] , error: 0.7546548849628605\n",
      "Step: 1447 Weights: [-1.19972556  2.31035822] , error: 0.7533751600823912\n",
      "Step: 1448 Weights: [-1.19617749  2.30995245] , error: 0.7521012651556948\n",
      "Step: 1449 Weights: [-1.1926375  2.3095476] , error: 0.7508331736236526\n",
      "Step: 1450 Weights: [-1.18910559  2.30914368] , error: 0.7495708590481465\n",
      "Step: 1451 Weights: [-1.18558173  2.30874068] , error: 0.748314295111496\n",
      "Step: 1452 Weights: [-1.18206591  2.30833859] , error: 0.7470634556159126\n",
      "Step: 1453 Weights: [-1.17855811  2.30793743] , error: 0.745818314482961\n",
      "Step: 1454 Weights: [-1.1750583   2.30753717] , error: 0.7445788457530027\n",
      "Step: 1455 Weights: [-1.17156648  2.30713783] , error: 0.7433450235846679\n",
      "Step: 1456 Weights: [-1.16808262  2.3067394 ] , error: 0.7421168222543082\n",
      "Step: 1457 Weights: [-1.1646067   2.30634188] , error: 0.7408942161554595\n",
      "Step: 1458 Weights: [-1.16113871  2.30594527] , error: 0.7396771797983173\n",
      "Step: 1459 Weights: [-1.15767863  2.30554956] , error: 0.7384656878091949\n",
      "Step: 1460 Weights: [-1.15422644  2.30515475] , error: 0.7372597149299982\n",
      "Step: 1461 Weights: [-1.15078212  2.30476085] , error: 0.7360592360177035\n",
      "Step: 1462 Weights: [-1.14734566  2.30436784] , error: 0.7348642260438265\n",
      "Step: 1463 Weights: [-1.14391703  2.30397573] , error: 0.7336746600939046\n",
      "Step: 1464 Weights: [-1.14049622  2.30358451] , error: 0.7324905133669766\n",
      "Step: 1465 Weights: [-1.13708321  2.30319418] , error: 0.7313117611750627\n",
      "Step: 1466 Weights: [-1.13367799  2.30280475] , error: 0.7301383789426554\n",
      "Step: 1467 Weights: [-1.13028053  2.3024162 ] , error: 0.7289703422062024\n",
      "Step: 1468 Weights: [-1.12689082  2.30202854] , error: 0.7278076266136007\n",
      "Step: 1469 Weights: [-1.12350883  2.30164176] , error: 0.7266502079236831\n",
      "Step: 1470 Weights: [-1.12013456  2.30125586] , error: 0.7254980620057188\n",
      "Step: 1471 Weights: [-1.11676799  2.30087085] , error: 0.7243511648389067\n",
      "Step: 1472 Weights: [-1.11340909  2.30048671] , error: 0.7232094925118742\n",
      "Step: 1473 Weights: [-1.11005785  2.30010345] , error: 0.7220730212221826\n",
      "Step: 1474 Weights: [-1.10671426  2.29972106] , error: 0.7209417272758298\n",
      "Step: 1475 Weights: [-1.10337829  2.29933954] , error: 0.7198155870867466\n",
      "Step: 1476 Weights: [-1.10004992  2.2989589 ] , error: 0.7186945771763237\n",
      "Step: 1477 Weights: [-1.09672915  2.29857912] , error: 0.7175786741729068\n",
      "Step: 1478 Weights: [-1.09341595  2.29820021] , error: 0.7164678548113113\n",
      "Step: 1479 Weights: [-1.0901103   2.29782216] , error: 0.7153620959323437\n",
      "Step: 1480 Weights: [-1.0868122   2.29744498] , error: 0.7142613744823156\n",
      "Step: 1481 Weights: [-1.08352161  2.29706865] , error: 0.7131656675125635\n",
      "Step: 1482 Weights: [-1.08023853  2.29669318] , error: 0.7120749521789662\n",
      "Step: 1483 Weights: [-1.07696293  2.29631857] , error: 0.7109892057414725\n",
      "Step: 1484 Weights: [-1.07369481  2.29594482] , error: 0.7099084055636277\n",
      "Step: 1485 Weights: [-1.07043413  2.29557191] , error: 0.7088325291121024\n",
      "Step: 1486 Weights: [-1.0671809   2.29519986] , error: 0.7077615539562156\n",
      "Step: 1487 Weights: [-1.06393508  2.29482865] , error: 0.7066954577674764\n",
      "Step: 1488 Weights: [-1.06069666  2.29445829] , error: 0.7056342183191144\n",
      "Step: 1489 Weights: [-1.05746563  2.29408878] , error: 0.7045778134856131\n",
      "Step: 1490 Weights: [-1.05424197  2.29372011] , error: 0.7035262212422535\n",
      "Step: 1491 Weights: [-1.05102565  2.29335228] , error: 0.7024794196646529\n",
      "Step: 1492 Weights: [-1.04781668  2.29298528] , error: 0.7014373869283081\n",
      "Step: 1493 Weights: [-1.04461502  2.29261913] , error: 0.7004001013081399\n",
      "Step: 1494 Weights: [-1.04142066  2.29225381] , error: 0.6993675411780411\n",
      "Step: 1495 Weights: [-1.03823358  2.29188932] , error: 0.698339685010424\n",
      "Step: 1496 Weights: [-1.03505378  2.29152567] , error: 0.6973165113757753\n",
      "Step: 1497 Weights: [-1.03188122  2.29116284] , error: 0.6962979989422033\n",
      "Step: 1498 Weights: [-1.0287159   2.29080084] , error: 0.6952841264749978\n",
      "Step: 1499 Weights: [-1.0255578   2.29043967] , error: 0.6942748728361854\n",
      "Step: 1500 Weights: [-1.0224069   2.29007931] , error: 0.6932702169840923\n",
      "Step: 1501 Weights: [-1.01926318  2.28971979] , error: 0.692270137972899\n",
      "Step: 1502 Weights: [-1.01612664  2.28936108] , error: 0.6912746149522118\n",
      "Step: 1503 Weights: [-1.01299724  2.28900319] , error: 0.6902836271666186\n",
      "Step: 1504 Weights: [-1.00987498  2.28864611] , error: 0.6892971539552651\n",
      "Step: 1505 Weights: [-1.00675985  2.28828985] , error: 0.6883151747514187\n",
      "Step: 1506 Weights: [-1.00365181  2.2879344 ] , error: 0.68733766908204\n",
      "Step: 1507 Weights: [-1.00055087  2.28757977] , error: 0.6863646165673609\n",
      "Step: 1508 Weights: [-0.99745699  2.28722594] , error: 0.6853959969204526\n",
      "Step: 1509 Weights: [-0.99437017  2.28687292] , error: 0.6844317899468079\n",
      "Step: 1510 Weights: [-0.99129039  2.2865207 ] , error: 0.6834719755439167\n",
      "Step: 1511 Weights: [-0.98821764  2.28616929] , error: 0.6825165337008493\n",
      "Step: 1512 Weights: [-0.98515189  2.28581868] , error: 0.6815654444978403\n",
      "Step: 1513 Weights: [-0.98209313  2.28546886] , error: 0.6806186881058682\n",
      "Step: 1514 Weights: [-0.97904135  2.28511985] , error: 0.6796762447862468\n",
      "Step: 1515 Weights: [-0.97599652  2.28477163] , error: 0.6787380948902126\n",
      "Step: 1516 Weights: [-0.97295864  2.2844242 ] , error: 0.6778042188585138\n",
      "Step: 1517 Weights: [-0.96992769  2.28407757] , error: 0.676874597221003\n",
      "Step: 1518 Weights: [-0.96690365  2.28373173] , error: 0.6759492105962297\n",
      "Step: 1519 Weights: [-0.9638865   2.28338668] , error: 0.6750280396910446\n",
      "Step: 1520 Weights: [-0.96087624  2.28304241] , error: 0.6741110653001863\n",
      "Step: 1521 Weights: [-0.95787284  2.28269893] , error: 0.6731982683058819\n",
      "Step: 1522 Weights: [-0.95487629  2.28235623] , error: 0.6722896296774596\n",
      "Step: 1523 Weights: [-0.95188657  2.28201431] , error: 0.6713851304709405\n",
      "Step: 1524 Weights: [-0.94890367  2.28167318] , error: 0.6704847518286445\n",
      "Step: 1525 Weights: [-0.94592758  2.28133282] , error: 0.669588474978809\n",
      "Step: 1526 Weights: [-0.94295826  2.28099323] , error: 0.6686962812351792\n",
      "Step: 1527 Weights: [-0.93999573  2.28065443] , error: 0.6678081519966288\n",
      "Step: 1528 Weights: [-0.93703994  2.28031639] , error: 0.6669240687467797\n",
      "Step: 1529 Weights: [-0.9340909   2.27997913] , error: 0.6660440130535998\n",
      "Step: 1530 Weights: [-0.93114858  2.27964263] , error: 0.6651679665690287\n",
      "Step: 1531 Weights: [-0.92821297  2.2793069 ] , error: 0.6642959110285948\n",
      "Step: 1532 Weights: [-0.92528406  2.27897194] , error: 0.663427828251028\n",
      "Step: 1533 Weights: [-0.92236182  2.27863774] , error: 0.6625637001378926\n",
      "Step: 1534 Weights: [-0.91944625  2.2783043 ] , error: 0.6617035086731944\n",
      "Step: 1535 Weights: [-0.91653733  2.27797162] , error: 0.6608472359230178\n",
      "Step: 1536 Weights: [-0.91363504  2.27763971] , error: 0.6599948640351512\n",
      "Step: 1537 Weights: [-0.91073937  2.27730855] , error: 0.6591463752387029\n",
      "Step: 1538 Weights: [-0.9078503   2.27697814] , error: 0.6583017518437437\n",
      "Step: 1539 Weights: [-0.90496783  2.27664849] , error: 0.6574609762409338\n",
      "Step: 1540 Weights: [-0.90209192  2.27631959] , error: 0.6566240309011524\n",
      "Step: 1541 Weights: [-0.89922257  2.27599144] , error: 0.6557908983751387\n",
      "Step: 1542 Weights: [-0.89635977  2.27566403] , error: 0.6549615612931173\n",
      "Step: 1543 Weights: [-0.89350349  2.27533738] , error: 0.6541360023644516\n",
      "Step: 1544 Weights: [-0.89065373  2.27501147] , error: 0.6533142043772708\n",
      "Step: 1545 Weights: [-0.88781047  2.2746863 ] , error: 0.6524961501981096\n",
      "Step: 1546 Weights: [-0.88497369  2.27436187] , error: 0.65168182277157\n",
      "Step: 1547 Weights: [-0.88214338  2.27403819] , error: 0.6508712051199375\n",
      "Step: 1548 Weights: [-0.87931952  2.27371524] , error: 0.6500642803428489\n",
      "Step: 1549 Weights: [-0.87650211  2.27339303] , error: 0.6492610316169356\n",
      "Step: 1550 Weights: [-0.87369112  2.27307155] , error: 0.6484614421954626\n",
      "Step: 1551 Weights: [-0.87088653  2.27275081] , error: 0.6476654954079938\n",
      "Step: 1552 Weights: [-0.86808835  2.2724308 ] , error: 0.6468731746600315\n",
      "Step: 1553 Weights: [-0.86529654  2.27211151] , error: 0.6460844634326817\n",
      "Step: 1554 Weights: [-0.8625111   2.27179296] , error: 0.645299345282301\n",
      "Step: 1555 Weights: [-0.85973202  2.27147513] , error: 0.6445178038401578\n",
      "Step: 1556 Weights: [-0.85695927  2.27115803] , error: 0.6437398228120926\n",
      "Step: 1557 Weights: [-0.85419284  2.27084165] , error: 0.6429653859781721\n",
      "Step: 1558 Weights: [-0.85143273  2.27052599] , error: 0.6421944771923576\n",
      "Step: 1559 Weights: [-0.8486789   2.27021105] , error: 0.6414270803821676\n",
      "Step: 1560 Weights: [-0.84593136  2.26989683] , error: 0.6406631795483348\n",
      "Step: 1561 Weights: [-0.84319008  2.26958332] , error: 0.6399027587644844\n",
      "Step: 1562 Weights: [-0.84045506  2.26927054] , error: 0.6391458021767957\n",
      "Step: 1563 Weights: [-0.83772627  2.26895846] , error: 0.638392294003668\n",
      "Step: 1564 Weights: [-0.8350037  2.2686471] , error: 0.6376422185354006\n",
      "Step: 1565 Weights: [-0.83228734  2.26833644] , error: 0.6368955601338582\n",
      "Step: 1566 Weights: [-0.82957718  2.2680265 ] , error: 0.6361523032321463\n",
      "Step: 1567 Weights: [-0.82687319  2.26771726] , error: 0.6354124323342888\n",
      "Step: 1568 Weights: [-0.82417538  2.26740872] , error: 0.6346759320149029\n",
      "Step: 1569 Weights: [-0.82148371  2.26710089] , error: 0.633942786918878\n",
      "Step: 1570 Weights: [-0.81879819  2.26679376] , error: 0.6332129817610549\n",
      "Step: 1571 Weights: [-0.81611878  2.26648734] , error: 0.6324865013259156\n",
      "Step: 1572 Weights: [-0.81344549  2.26618161] , error: 0.6317633304672433\n",
      "Step: 1573 Weights: [-0.81077829  2.26587658] , error: 0.6310434541078345\n",
      "Step: 1574 Weights: [-0.80811718  2.26557224] , error: 0.6303268572391664\n",
      "Step: 1575 Weights: [-0.80546213  2.2652686 ] , error: 0.629613524921093\n",
      "Step: 1576 Weights: [-0.80281314  2.26496565] , error: 0.6289034422815248\n",
      "Step: 1577 Weights: [-0.80017019  2.26466339] , error: 0.6281965945161292\n",
      "Step: 1578 Weights: [-0.79753327  2.26436182] , error: 0.6274929668880147\n",
      "Step: 1579 Weights: [-0.79490236  2.26406094] , error: 0.6267925447274241\n",
      "Step: 1580 Weights: [-0.79227745  2.26376074] , error: 0.6260953134314331\n",
      "Step: 1581 Weights: [-0.78965853  2.26346123] , error: 0.6254012584636384\n",
      "Step: 1582 Weights: [-0.78704557  2.2631624 ] , error: 0.6247103653538669\n",
      "Step: 1583 Weights: [-0.78443858  2.26286425] , error: 0.6240226196978573\n",
      "Step: 1584 Weights: [-0.78183753  2.26256679] , error: 0.6233380071569752\n",
      "Step: 1585 Weights: [-0.77924241  2.26227   ] , error: 0.6226565134579061\n",
      "Step: 1586 Weights: [-0.77665321  2.26197389] , error: 0.6219781243923559\n",
      "Step: 1587 Weights: [-0.77406992  2.26167845] , error: 0.6213028258167645\n",
      "Step: 1588 Weights: [-0.77149252  2.26138369] , error: 0.6206306036520018\n",
      "Step: 1589 Weights: [-0.76892099  2.2610896 ] , error: 0.6199614438830734\n",
      "Step: 1590 Weights: [-0.76635533  2.26079618] , error: 0.6192953325588372\n",
      "Step: 1591 Weights: [-0.76379552  2.26050343] , error: 0.6186322557917052\n",
      "Step: 1592 Weights: [-0.76124154  2.26021134] , error: 0.6179721997573557\n",
      "Step: 1593 Weights: [-0.75869339  2.25991993] , error: 0.6173151506944473\n",
      "Step: 1594 Weights: [-0.75615105  2.25962917] , error: 0.6166610949043285\n",
      "Step: 1595 Weights: [-0.75361451  2.25933908] , error: 0.616010018750755\n",
      "Step: 1596 Weights: [-0.75108376  2.25904966] , error: 0.6153619086596017\n",
      "Step: 1597 Weights: [-0.74855877  2.25876089] , error: 0.6147167511185846\n",
      "Step: 1598 Weights: [-0.74603954  2.25847278] , error: 0.6140745326769779\n",
      "Step: 1599 Weights: [-0.74352606  2.25818533] , error: 0.6134352399453283\n",
      "Step: 1600 Weights: [-0.74101831  2.25789853] , error: 0.612798859595183\n",
      "Step: 1601 Weights: [-0.73851628  2.25761239] , error: 0.6121653783588077\n",
      "Step: 1602 Weights: [-0.73601995  2.2573269 ] , error: 0.6115347830289107\n",
      "Step: 1603 Weights: [-0.73352932  2.25704206] , error: 0.6109070604583693\n",
      "Step: 1604 Weights: [-0.73104436  2.25675787] , error: 0.6102821975599532\n",
      "Step: 1605 Weights: [-0.72856507  2.25647433] , error: 0.6096601813060508\n",
      "Step: 1606 Weights: [-0.72609144  2.25619143] , error: 0.6090409987284047\n",
      "Step: 1607 Weights: [-0.72362345  2.25590918] , error: 0.6084246369178279\n",
      "Step: 1608 Weights: [-0.72116108  2.25562757] , error: 0.6078110830239518\n",
      "Step: 1609 Weights: [-0.71870433  2.25534661] , error: 0.6072003242549442\n",
      "Step: 1610 Weights: [-0.71625319  2.25506629] , error: 0.6065923478772496\n",
      "Step: 1611 Weights: [-0.71380763  2.2547866 ] , error: 0.6059871412153196\n",
      "Step: 1612 Weights: [-0.71136765  2.25450755] , error: 0.605384691651352\n",
      "Step: 1613 Weights: [-0.70893323  2.25422914] , error: 0.6047849866250288\n",
      "Step: 1614 Weights: [-0.70650437  2.25395137] , error: 0.6041880136332488\n",
      "Step: 1615 Weights: [-0.70408104  2.25367423] , error: 0.6035937602298742\n",
      "Step: 1616 Weights: [-0.70166324  2.25339772] , error: 0.6030022140254633\n",
      "Step: 1617 Weights: [-0.69925095  2.25312184] , error: 0.602413362687017\n",
      "Step: 1618 Weights: [-0.69684417  2.25284659] , error: 0.6018271939377247\n",
      "Step: 1619 Weights: [-0.69444287  2.25257197] , error: 0.6012436955566965\n",
      "Step: 1620 Weights: [-0.69204705  2.25229797] , error: 0.6006628553787265\n",
      "Step: 1621 Weights: [-0.68965669  2.2520246 ] , error: 0.6000846612940192\n",
      "Step: 1622 Weights: [-0.68727179  2.25175185] , error: 0.5995091012479532\n",
      "Step: 1623 Weights: [-0.68489232  2.25147972] , error: 0.5989361632408212\n",
      "Step: 1624 Weights: [-0.68251828  2.25120822] , error: 0.5983658353275846\n",
      "Step: 1625 Weights: [-0.68014965  2.25093733] , error: 0.597798105617616\n",
      "Step: 1626 Weights: [-0.67778642  2.25066706] , error: 0.5972329622744644\n",
      "Step: 1627 Weights: [-0.67542858  2.25039741] , error: 0.5966703935155953\n",
      "Step: 1628 Weights: [-0.67307612  2.25012837] , error: 0.5961103876121575\n",
      "Step: 1629 Weights: [-0.67072903  2.24985995] , error: 0.5955529328887239\n",
      "Step: 1630 Weights: [-0.66838728  2.24959214] , error: 0.5949980177230669\n",
      "Step: 1631 Weights: [-0.66605088  2.24932494] , error: 0.5944456305458935\n",
      "Step: 1632 Weights: [-0.6637198   2.24905835] , error: 0.5938957598406245\n",
      "Step: 1633 Weights: [-0.66139405  2.24879236] , error: 0.593348394143145\n",
      "Step: 1634 Weights: [-0.65907359  2.24852699] , error: 0.5928035220415618\n",
      "Step: 1635 Weights: [-0.65675843  2.24826221] , error: 0.5922611321759765\n",
      "Step: 1636 Weights: [-0.65444854  2.24799805] , error: 0.5917212132382387\n",
      "Step: 1637 Weights: [-0.65214392  2.24773448] , error: 0.5911837539717103\n",
      "Step: 1638 Weights: [-0.64984456  2.24747152] , error: 0.590648743171042\n",
      "Step: 1639 Weights: [-0.64755044  2.24720915] , error: 0.5901161696819262\n",
      "Step: 1640 Weights: [-0.64526156  2.24694738] , error: 0.5895860224008723\n",
      "Step: 1641 Weights: [-0.64297789  2.24668621] , error: 0.5890582902749739\n",
      "Step: 1642 Weights: [-0.64069943  2.24642564] , error: 0.588532962301673\n",
      "Step: 1643 Weights: [-0.63842617  2.24616566] , error: 0.5880100275285425\n",
      "Step: 1644 Weights: [-0.63615809  2.24590627] , error: 0.5874894750530427\n",
      "Step: 1645 Weights: [-0.63389518  2.24564748] , error: 0.5869712940223082\n",
      "Step: 1646 Weights: [-0.63163743  2.24538927] , error: 0.5864554736329118\n",
      "Step: 1647 Weights: [-0.62938483  2.24513165] , error: 0.5859420031306446\n",
      "Step: 1648 Weights: [-0.62713737  2.24487463] , error: 0.5854308718102889\n",
      "Step: 1649 Weights: [-0.62489503  2.24461818] , error: 0.5849220690153946\n",
      "Step: 1650 Weights: [-0.62265781  2.24436232] , error: 0.5844155841380623\n",
      "Step: 1651 Weights: [-0.62042569  2.24410705] , error: 0.583911406618715\n",
      "Step: 1652 Weights: [-0.61819866  2.24385236] , error: 0.5834095259458804\n",
      "Step: 1653 Weights: [-0.61597671  2.24359824] , error: 0.5829099316559765\n",
      "Step: 1654 Weights: [-0.61375982  2.24334471] , error: 0.5824126133330862\n",
      "Step: 1655 Weights: [-0.61154799  2.24309176] , error: 0.581917560608746\n",
      "Step: 1656 Weights: [-0.60934121  2.24283938] , error: 0.5814247631617238\n",
      "Step: 1657 Weights: [-0.60713945  2.24258758] , error: 0.5809342107178102\n",
      "Step: 1658 Weights: [-0.60494272  2.24233635] , error: 0.5804458930496023\n",
      "Step: 1659 Weights: [-0.602751   2.2420857] , error: 0.5799597999762842\n",
      "Step: 1660 Weights: [-0.60056427  2.24183561] , error: 0.5794759213634276\n",
      "Step: 1661 Weights: [-0.59838253  2.2415861 ] , error: 0.5789942471227645\n",
      "Step: 1662 Weights: [-0.59620577  2.24133716] , error: 0.5785147672119921\n",
      "Step: 1663 Weights: [-0.59403397  2.24108878] , error: 0.5780374716345541\n",
      "Step: 1664 Weights: [-0.59186712  2.24084097] , error: 0.5775623504394329\n",
      "Step: 1665 Weights: [-0.58970522  2.24059373] , error: 0.577089393720948\n",
      "Step: 1666 Weights: [-0.58754824  2.24034705] , error: 0.5766185916185427\n",
      "Step: 1667 Weights: [-0.58539618  2.24010093] , error: 0.5761499343165818\n",
      "Step: 1668 Weights: [-0.58324903  2.23985537] , error: 0.5756834120441475\n",
      "Step: 1669 Weights: [-0.58110678  2.23961037] , error: 0.5752190150748333\n",
      "Step: 1670 Weights: [-0.57896941  2.23936593] , error: 0.5747567337265431\n",
      "Step: 1671 Weights: [-0.57683692  2.23912205] , error: 0.5742965583612933\n",
      "Step: 1672 Weights: [-0.57470929  2.23887873] , error: 0.5738384793849975\n",
      "Step: 1673 Weights: [-0.57258651  2.23863596] , error: 0.573382487247285\n",
      "Step: 1674 Weights: [-0.57046857  2.23839374] , error: 0.572928572441288\n",
      "Step: 1675 Weights: [-0.56835546  2.23815208] , error: 0.572476725503454\n",
      "Step: 1676 Weights: [-0.56624717  2.23791097] , error: 0.572026937013337\n",
      "Step: 1677 Weights: [-0.56414369  2.2376704 ] , error: 0.5715791975934108\n",
      "Step: 1678 Weights: [-0.56204501  2.23743039] , error: 0.571133497908868\n",
      "Step: 1679 Weights: [-0.55995111  2.23719092] , error: 0.5706898286674285\n",
      "Step: 1680 Weights: [-0.55786199  2.236952  ] , error: 0.5702481806191432\n",
      "Step: 1681 Weights: [-0.55577763  2.23671362] , error: 0.5698085445562023\n",
      "Step: 1682 Weights: [-0.55369802  2.23647579] , error: 0.5693709113127456\n",
      "Step: 1683 Weights: [-0.55162316  2.2362385 ] , error: 0.5689352717646645\n",
      "Step: 1684 Weights: [-0.54955302  2.23600175] , error: 0.5685016168294224\n",
      "Step: 1685 Weights: [-0.54748761  2.23576554] , error: 0.5680699374658549\n",
      "Step: 1686 Weights: [-0.54542691  2.23552987] , error: 0.5676402246739884\n",
      "Step: 1687 Weights: [-0.54337091  2.23529474] , error: 0.5672124694948465\n",
      "Step: 1688 Weights: [-0.54131959  2.23506014] , error: 0.5667866630102711\n",
      "Step: 1689 Weights: [-0.53927296  2.23482608] , error: 0.5663627963427295\n",
      "Step: 1690 Weights: [-0.53723099  2.23459255] , error: 0.5659408606551306\n",
      "Step: 1691 Weights: [-0.53519367  2.23435956] , error: 0.5655208471506429\n",
      "Step: 1692 Weights: [-0.53316101  2.23412709] , error: 0.5651027470725128\n",
      "Step: 1693 Weights: [-0.53113298  2.23389516] , error: 0.5646865517038755\n",
      "Step: 1694 Weights: [-0.52910957  2.23366375] , error: 0.5642722523675765\n",
      "Step: 1695 Weights: [-0.52709078  2.23343288] , error: 0.5638598404259954\n",
      "Step: 1696 Weights: [-0.52507659  2.23320252] , error: 0.5634493072808577\n",
      "Step: 1697 Weights: [-0.52306699  2.2329727 ] , error: 0.5630406443730613\n",
      "Step: 1698 Weights: [-0.52106198  2.2327434 ] , error: 0.5626338431824942\n",
      "Step: 1699 Weights: [-0.51906154  2.23251462] , error: 0.5622288952278652\n",
      "Step: 1700 Weights: [-0.51706566  2.23228636] , error: 0.5618257920665123\n",
      "Step: 1701 Weights: [-0.51507433  2.23205862] , error: 0.5614245252942396\n",
      "Step: 1702 Weights: [-0.51308755  2.23183141] , error: 0.5610250865451356\n",
      "Step: 1703 Weights: [-0.51110529  2.23160471] , error: 0.5606274674914032\n",
      "Step: 1704 Weights: [-0.50912756  2.23137853] , error: 0.5602316598431842\n",
      "Step: 1705 Weights: [-0.50715433  2.23115286] , error: 0.5598376553483815\n",
      "Step: 1706 Weights: [-0.50518561  2.23092771] , error: 0.559445445792496\n",
      "Step: 1707 Weights: [-0.50322137  2.23070307] , error: 0.5590550229984512\n",
      "Step: 1708 Weights: [-0.50126161  2.23047894] , error: 0.558666378826414\n",
      "Step: 1709 Weights: [-0.49930633  2.23025533] , error: 0.5582795051736447\n",
      "Step: 1710 Weights: [-0.4973555   2.23003222] , error: 0.5578943939743097\n",
      "Step: 1711 Weights: [-0.49540912  2.22980963] , error: 0.5575110371993234\n",
      "Step: 1712 Weights: [-0.49346718  2.22958754] , error: 0.5571294268561757\n",
      "Step: 1713 Weights: [-0.49152966  2.22936596] , error: 0.5567495549887697\n",
      "Step: 1714 Weights: [-0.48959657  2.22914488] , error: 0.5563714136772504\n",
      "Step: 1715 Weights: [-0.48766788  2.22892431] , error: 0.555994995037846\n",
      "Step: 1716 Weights: [-0.48574359  2.22870424] , error: 0.555620291222698\n",
      "Step: 1717 Weights: [-0.48382369  2.22848467] , error: 0.5552472944197\n",
      "Step: 1718 Weights: [-0.48190817  2.2282656 ] , error: 0.5548759968523367\n",
      "Step: 1719 Weights: [-0.47999702  2.22804703] , error: 0.554506390779518\n",
      "Step: 1720 Weights: [-0.47809022  2.22782897] , error: 0.5541384684954176\n",
      "Step: 1721 Weights: [-0.47618778  2.22761139] , error: 0.5537722223293191\n",
      "Step: 1722 Weights: [-0.47428967  2.22739432] , error: 0.5534076446454474\n",
      "Step: 1723 Weights: [-0.47239589  2.22717774] , error: 0.5530447278428126\n",
      "Step: 1724 Weights: [-0.47050643  2.22696165] , error: 0.5526834643550538\n",
      "Step: 1725 Weights: [-0.46862127  2.22674606] , error: 0.55232384665028\n",
      "Step: 1726 Weights: [-0.46674042  2.22653095] , error: 0.5519658672309112\n",
      "Step: 1727 Weights: [-0.46486385  2.22631634] , error: 0.5516095186335264\n",
      "Step: 1728 Weights: [-0.46299157  2.22610222] , error: 0.5512547934286989\n",
      "Step: 1729 Weights: [-0.46112355  2.22588859] , error: 0.550901684220856\n",
      "Step: 1730 Weights: [-0.4592598   2.22567544] , error: 0.5505501836481104\n",
      "Step: 1731 Weights: [-0.45740029  2.22546278] , error: 0.5502002843821152\n",
      "Step: 1732 Weights: [-0.45554503  2.2252506 ] , error: 0.5498519791279084\n",
      "Step: 1733 Weights: [-0.45369399  2.22503891] , error: 0.5495052606237616\n",
      "Step: 1734 Weights: [-0.45184718  2.2248277 ] , error: 0.5491601216410281\n",
      "Step: 1735 Weights: [-0.45000458  2.22461697] , error: 0.5488165549839913\n",
      "Step: 1736 Weights: [-0.44816618  2.22440673] , error: 0.5484745534897153\n",
      "Step: 1737 Weights: [-0.44633197  2.22419696] , error: 0.5481341100278986\n",
      "Step: 1738 Weights: [-0.44450194  2.22398767] , error: 0.5477952175007199\n",
      "Step: 1739 Weights: [-0.44267609  2.22377886] , error: 0.5474578688426947\n",
      "Step: 1740 Weights: [-0.4408544   2.22357052] , error: 0.5471220570205241\n",
      "Step: 1741 Weights: [-0.43903687  2.22336266] , error: 0.546787775032952\n",
      "Step: 1742 Weights: [-0.43722348  2.22315527] , error: 0.5464550159106176\n",
      "Step: 1743 Weights: [-0.43541423  2.22294836] , error: 0.546123772715911\n",
      "Step: 1744 Weights: [-0.4336091   2.22274192] , error: 0.5457940385428238\n",
      "Step: 1745 Weights: [-0.43180809  2.22253594] , error: 0.5454658065168116\n",
      "Step: 1746 Weights: [-0.43001118  2.22233044] , error: 0.5451390697946471\n",
      "Step: 1747 Weights: [-0.42821837  2.22212541] , error: 0.5448138215642792\n",
      "Step: 1748 Weights: [-0.42642966  2.22192085] , error: 0.5444900550446894\n",
      "Step: 1749 Weights: [-0.42464502  2.22171675] , error: 0.5441677634857502\n",
      "Step: 1750 Weights: [-0.42286445  2.22151311] , error: 0.5438469401680843\n",
      "Step: 1751 Weights: [-0.42108794  2.22130994] , error: 0.543527578402929\n",
      "Step: 1752 Weights: [-0.41931548  2.22110724] , error: 0.5432096715319901\n",
      "Step: 1753 Weights: [-0.41754706  2.22090499] , error: 0.5428932129273075\n",
      "Step: 1754 Weights: [-0.41578268  2.22070321] , error: 0.5425781959911156\n",
      "Step: 1755 Weights: [-0.41402232  2.22050189] , error: 0.5422646141557037\n",
      "Step: 1756 Weights: [-0.41226597  2.22030103] , error: 0.5419524608832837\n",
      "Step: 1757 Weights: [-0.41051363  2.22010062] , error: 0.5416417296658513\n",
      "Step: 1758 Weights: [-0.40876529  2.21990067] , error: 0.541332414025048\n",
      "Step: 1759 Weights: [-0.40702093  2.21970118] , error: 0.5410245075120306\n",
      "Step: 1760 Weights: [-0.40528055  2.21950214] , error: 0.5407180037073326\n",
      "Step: 1761 Weights: [-0.40354414  2.21930356] , error: 0.5404128962207343\n",
      "Step: 1762 Weights: [-0.40181169  2.21910543] , error: 0.5401091786911241\n",
      "Step: 1763 Weights: [-0.40008319  2.21890775] , error: 0.5398068447863743\n",
      "Step: 1764 Weights: [-0.39835863  2.21871052] , error: 0.539505888203201\n",
      "Step: 1765 Weights: [-0.39663801  2.21851375] , error: 0.5392063026670328\n",
      "Step: 1766 Weights: [-0.3949213   2.21831742] , error: 0.5389080819318883\n",
      "Step: 1767 Weights: [-0.39320852  2.21812154] , error: 0.5386112197802391\n",
      "Step: 1768 Weights: [-0.39149963  2.2179261 ] , error: 0.5383157100228797\n",
      "Step: 1769 Weights: [-0.38979465  2.21773111] , error: 0.5380215464988003\n",
      "Step: 1770 Weights: [-0.38809355  2.21753657] , error: 0.5377287230750605\n",
      "Step: 1771 Weights: [-0.38639634  2.21734247] , error: 0.5374372336466587\n",
      "Step: 1772 Weights: [-0.38470299  2.21714881] , error: 0.5371470721364049\n",
      "Step: 1773 Weights: [-0.3830135   2.21695559] , error: 0.5368582324947933\n",
      "Step: 1774 Weights: [-0.38132787  2.21676281] , error: 0.5365707086998801\n",
      "Step: 1775 Weights: [-0.37964608  2.21657048] , error: 0.5362844947571533\n",
      "Step: 1776 Weights: [-0.37796813  2.21637858] , error: 0.5359995846994099\n",
      "Step: 1777 Weights: [-0.376294    2.21618712] , error: 0.5357159725866316\n",
      "Step: 1778 Weights: [-0.37462369  2.2159961 ] , error: 0.5354336525058626\n",
      "Step: 1779 Weights: [-0.37295719  2.21580551] , error: 0.5351526185710797\n",
      "Step: 1780 Weights: [-0.37129449  2.21561536] , error: 0.5348728649230778\n",
      "Step: 1781 Weights: [-0.36963558  2.21542564] , error: 0.5345943857293449\n",
      "Step: 1782 Weights: [-0.36798046  2.21523635] , error: 0.5343171751839368\n",
      "Step: 1783 Weights: [-0.36632911  2.21504749] , error: 0.5340412275073595\n",
      "Step: 1784 Weights: [-0.36468152  2.21485907] , error: 0.5337665369464514\n",
      "Step: 1785 Weights: [-0.36303769  2.21467107] , error: 0.5334930977742555\n",
      "Step: 1786 Weights: [-0.36139761  2.21448351] , error: 0.533220904289909\n",
      "Step: 1787 Weights: [-0.35976127  2.21429637] , error: 0.5329499508185177\n",
      "Step: 1788 Weights: [-0.35812867  2.21410966] , error: 0.5326802317110404\n",
      "Step: 1789 Weights: [-0.35649978  2.21392337] , error: 0.5324117413441709\n",
      "Step: 1790 Weights: [-0.35487461  2.21373751] , error: 0.5321444741202227\n",
      "Step: 1791 Weights: [-0.35325315  2.21355207] , error: 0.5318784244670063\n",
      "Step: 1792 Weights: [-0.35163538  2.21336706] , error: 0.531613586837721\n",
      "Step: 1793 Weights: [-0.3500213   2.21318246] , error: 0.5313499557108329\n",
      "Step: 1794 Weights: [-0.34841091  2.21299829] , error: 0.5310875255899608\n",
      "Step: 1795 Weights: [-0.34680418  2.21281454] , error: 0.5308262910037687\n",
      "Step: 1796 Weights: [-0.34520112  2.21263121] , error: 0.5305662465058392\n",
      "Step: 1797 Weights: [-0.34360172  2.21244829] , error: 0.5303073866745721\n",
      "Step: 1798 Weights: [-0.34200596  2.2122658 ] , error: 0.5300497061130622\n",
      "Step: 1799 Weights: [-0.34041384  2.21208371] , error: 0.5297931994489928\n",
      "Step: 1800 Weights: [-0.33882535  2.21190205] , error: 0.5295378613345197\n",
      "Step: 1801 Weights: [-0.33724049  2.2117208 ] , error: 0.5292836864461666\n",
      "Step: 1802 Weights: [-0.33565924  2.21153996] , error: 0.5290306694846996\n",
      "Step: 1803 Weights: [-0.33408159  2.21135953] , error: 0.5287788051750348\n",
      "Step: 1804 Weights: [-0.33250754  2.21117952] , error: 0.5285280882661161\n",
      "Step: 1805 Weights: [-0.33093709  2.21099991] , error: 0.5282785135308091\n",
      "Step: 1806 Weights: [-0.32937021  2.21082072] , error: 0.5280300757657921\n",
      "Step: 1807 Weights: [-0.3278069   2.21064193] , error: 0.5277827697914499\n",
      "Step: 1808 Weights: [-0.32624717  2.21046355] , error: 0.527536590451762\n",
      "Step: 1809 Weights: [-0.32469098  2.21028558] , error: 0.5272915326141969\n",
      "Step: 1810 Weights: [-0.32313835  2.21010802] , error: 0.5270475911696043\n",
      "Step: 1811 Weights: [-0.32158926  2.20993086] , error: 0.5268047610321125\n",
      "Step: 1812 Weights: [-0.3200437  2.2097541] , error: 0.5265630371390152\n",
      "Step: 1813 Weights: [-0.31850166  2.20957774] , error: 0.5263224144506711\n",
      "Step: 1814 Weights: [-0.31696314  2.20940179] , error: 0.5260828879503999\n",
      "Step: 1815 Weights: [-0.31542813  2.20922624] , error: 0.5258444526443736\n",
      "Step: 1816 Weights: [-0.31389662  2.20905109] , error: 0.5256071035615124\n",
      "Step: 1817 Weights: [-0.31236861  2.20887634] , error: 0.5253708357533868\n",
      "Step: 1818 Weights: [-0.31084407  2.20870199] , error: 0.525135644294108\n",
      "Step: 1819 Weights: [-0.30932302  2.20852804] , error: 0.5249015242802284\n",
      "Step: 1820 Weights: [-0.30780543  2.20835448] , error: 0.524668470830638\n",
      "Step: 1821 Weights: [-0.3062913   2.20818132] , error: 0.5244364790864646\n",
      "Step: 1822 Weights: [-0.30478063  2.20800855] , error: 0.5242055442109701\n",
      "Step: 1823 Weights: [-0.3032734   2.20783618] , error: 0.5239756613894522\n",
      "Step: 1824 Weights: [-0.30176961  2.2076642 ] , error: 0.52374682582914\n",
      "Step: 1825 Weights: [-0.30026924  2.20749261] , error: 0.523519032759099\n",
      "Step: 1826 Weights: [-0.2987723   2.20732141] , error: 0.52329227743013\n",
      "Step: 1827 Weights: [-0.29727878  2.20715061] , error: 0.5230665551146667\n",
      "Step: 1828 Weights: [-0.29578865  2.20698019] , error: 0.5228418611066811\n",
      "Step: 1829 Weights: [-0.29430193  2.20681016] , error: 0.5226181907215847\n",
      "Step: 1830 Weights: [-0.2928186   2.20664052] , error: 0.5223955392961301\n",
      "Step: 1831 Weights: [-0.29133865  2.20647127] , error: 0.5221739021883124\n",
      "Step: 1832 Weights: [-0.28986207  2.2063024 ] , error: 0.5219532747772768\n",
      "Step: 1833 Weights: [-0.28838886  2.20613392] , error: 0.5217336524632166\n",
      "Step: 1834 Weights: [-0.28691901  2.20596582] , error: 0.5215150306672826\n",
      "Step: 1835 Weights: [-0.28545251  2.2057981 ] , error: 0.5212974048314822\n",
      "Step: 1836 Weights: [-0.28398936  2.20563077] , error: 0.5210807704185892\n",
      "Step: 1837 Weights: [-0.28252955  2.20546382] , error: 0.5208651229120473\n",
      "Step: 1838 Weights: [-0.28107306  2.20529725] , error: 0.5206504578158772\n",
      "Step: 1839 Weights: [-0.27961989  2.20513106] , error: 0.5204367706545795\n",
      "Step: 1840 Weights: [-0.27817004  2.20496525] , error: 0.520224056973043\n",
      "Step: 1841 Weights: [-0.27672349  2.20479982] , error: 0.520012312336455\n",
      "Step: 1842 Weights: [-0.27528025  2.20463476] , error: 0.5198015323302031\n",
      "Step: 1843 Weights: [-0.27384029  2.20447008] , error: 0.5195917125597893\n",
      "Step: 1844 Weights: [-0.27240362  2.20430578] , error: 0.519382848650733\n",
      "Step: 1845 Weights: [-0.27097022  2.20414185] , error: 0.5191749362484839\n",
      "Step: 1846 Weights: [-0.26954009  2.20397829] , error: 0.5189679710183278\n",
      "Step: 1847 Weights: [-0.26811323  2.20381511] , error: 0.5187619486452987\n",
      "Step: 1848 Weights: [-0.26668962  2.2036523 ] , error: 0.5185568648340884\n",
      "Step: 1849 Weights: [-0.26526925  2.20348986] , error: 0.5183527153089553\n",
      "Step: 1850 Weights: [-0.26385212  2.20332779] , error: 0.5181494958136367\n",
      "Step: 1851 Weights: [-0.26243823  2.20316609] , error: 0.517947202111263\n",
      "Step: 1852 Weights: [-0.26102756  2.20300476] , error: 0.5177458299842604\n",
      "Step: 1853 Weights: [-0.2596201  2.2028438] , error: 0.5175453752342721\n",
      "Step: 1854 Weights: [-0.25821586  2.20268321] , error: 0.5173458336820695\n",
      "Step: 1855 Weights: [-0.25681482  2.20252298] , error: 0.5171472011674603\n",
      "Step: 1856 Weights: [-0.25541697  2.20236311] , error: 0.5169494735492046\n",
      "Step: 1857 Weights: [-0.25402231  2.20220361] , error: 0.5167526467049279\n",
      "Step: 1858 Weights: [-0.25263083  2.20204448] , error: 0.5165567165310396\n",
      "Step: 1859 Weights: [-0.25124252  2.20188571] , error: 0.5163616789426374\n",
      "Step: 1860 Weights: [-0.24985738  2.2017273 ] , error: 0.5161675298734334\n",
      "Step: 1861 Weights: [-0.2484754   2.20156925] , error: 0.515974265275662\n",
      "Step: 1862 Weights: [-0.24709657  2.20141156] , error: 0.5157818811199982\n",
      "Step: 1863 Weights: [-0.24572089  2.20125423] , error: 0.5155903733954721\n",
      "Step: 1864 Weights: [-0.24434834  2.20109726] , error: 0.5153997381093885\n",
      "Step: 1865 Weights: [-0.24297892  2.20094065] , error: 0.5152099712872397\n",
      "Step: 1866 Weights: [-0.24161262  2.20078439] , error: 0.5150210689726256\n",
      "Step: 1867 Weights: [-0.24024944  2.20062849] , error: 0.5148330272271684\n",
      "Step: 1868 Weights: [-0.23888937  2.20047295] , error: 0.5146458421304326\n",
      "Step: 1869 Weights: [-0.2375324   2.20031776] , error: 0.5144595097798439\n",
      "Step: 1870 Weights: [-0.23617853  2.20016292] , error: 0.5142740262906054\n",
      "Step: 1871 Weights: [-0.23482774  2.20000844] , error: 0.5140893877956185\n",
      "Step: 1872 Weights: [-0.23348003  2.19985431] , error: 0.5139055904454014\n",
      "Step: 1873 Weights: [-0.2321354   2.19970053] , error: 0.5137226304080106\n",
      "Step: 1874 Weights: [-0.23079383  2.19954711] , error: 0.5135405038689562\n",
      "Step: 1875 Weights: [-0.22945532  2.19939403] , error: 0.5133592070311299\n",
      "Step: 1876 Weights: [-0.22811987  2.1992413 ] , error: 0.5131787361147162\n",
      "Step: 1877 Weights: [-0.22678746  2.19908892] , error: 0.5129990873571266\n",
      "Step: 1878 Weights: [-0.22545808  2.19893689] , error: 0.5128202570129048\n",
      "Step: 1879 Weights: [-0.22413174  2.1987852 ] , error: 0.5126422413536658\n",
      "Step: 1880 Weights: [-0.22280843  2.19863386] , error: 0.5124650366680028\n",
      "Step: 1881 Weights: [-0.22148813  2.19848287] , error: 0.5122886392614203\n",
      "Step: 1882 Weights: [-0.22017084  2.19833222] , error: 0.5121130454562546\n",
      "Step: 1883 Weights: [-0.21885656  2.19818191] , error: 0.511938251591594\n",
      "Step: 1884 Weights: [-0.21754527  2.19803195] , error: 0.5117642540232041\n",
      "Step: 1885 Weights: [-0.21623697  2.19788232] , error: 0.5115910491234541\n",
      "Step: 1886 Weights: [-0.21493166  2.19773304] , error: 0.5114186332812377\n",
      "Step: 1887 Weights: [-0.21362932  2.1975841 ] , error: 0.5112470029019023\n",
      "Step: 1888 Weights: [-0.21232996  2.1974355 ] , error: 0.5110761544071664\n",
      "Step: 1889 Weights: [-0.21103355  2.19728724] , error: 0.5109060842350548\n",
      "Step: 1890 Weights: [-0.20974011  2.19713931] , error: 0.5107367888398158\n",
      "Step: 1891 Weights: [-0.20844961  2.19699173] , error: 0.5105682646918539\n",
      "Step: 1892 Weights: [-0.20716206  2.19684448] , error: 0.510400508277649\n",
      "Step: 1893 Weights: [-0.20587744  2.19669756] , error: 0.5102335160996915\n",
      "Step: 1894 Weights: [-0.20459575  2.19655098] , error: 0.5100672846764034\n",
      "Step: 1895 Weights: [-0.20331698  2.19640474] , error: 0.509901810542067\n",
      "Step: 1896 Weights: [-0.20204113  2.19625883] , error: 0.5097370902467531\n",
      "Step: 1897 Weights: [-0.20076819  2.19611325] , error: 0.5095731203562506\n",
      "Step: 1898 Weights: [-0.19949815  2.195968  ] , error: 0.5094098974519923\n",
      "Step: 1899 Weights: [-0.19823101  2.19582309] , error: 0.5092474181309836\n",
      "Step: 1900 Weights: [-0.19696676  2.1956785 ] , error: 0.5090856790057354\n",
      "Step: 1901 Weights: [-0.19570539  2.19553425] , error: 0.5089246767041878\n",
      "Step: 1902 Weights: [-0.1944469   2.19539032] , error: 0.5087644078696466\n",
      "Step: 1903 Weights: [-0.19319128  2.19524672] , error: 0.5086048691607056\n",
      "Step: 1904 Weights: [-0.19193852  2.19510345] , error: 0.5084460572511814\n",
      "Step: 1905 Weights: [-0.19068862  2.19496051] , error: 0.5082879688300451\n",
      "Step: 1906 Weights: [-0.18944156  2.19481789] , error: 0.5081306006013523\n",
      "Step: 1907 Weights: [-0.18819736  2.19467559] , error: 0.5079739492841697\n",
      "Step: 1908 Weights: [-0.18695598  2.19453363] , error: 0.5078180116125156\n",
      "Step: 1909 Weights: [-0.18571744  2.19439198] , error: 0.5076627843352828\n",
      "Step: 1910 Weights: [-0.18448173  2.19425066] , error: 0.5075082642161786\n",
      "Step: 1911 Weights: [-0.18324883  2.19410966] , error: 0.5073544480336518\n",
      "Step: 1912 Weights: [-0.18201874  2.19396898] , error: 0.5072013325808251\n",
      "Step: 1913 Weights: [-0.18079146  2.19382863] , error: 0.5070489146654348\n",
      "Step: 1914 Weights: [-0.17956698  2.19368859] , error: 0.5068971911097572\n",
      "Step: 1915 Weights: [-0.17834529  2.19354887] , error: 0.5067461587505466\n",
      "Step: 1916 Weights: [-0.17712639  2.19340947] , error: 0.5065958144389673\n",
      "Step: 1917 Weights: [-0.17591026  2.19327039] , error: 0.5064461550405275\n",
      "Step: 1918 Weights: [-0.17469691  2.19313163] , error: 0.5062971774350165\n",
      "Step: 1919 Weights: [-0.17348633  2.19299318] , error: 0.5061488785164376\n",
      "Step: 1920 Weights: [-0.1722785   2.19285505] , error: 0.506001255192945\n",
      "Step: 1921 Weights: [-0.17107343  2.19271723] , error: 0.5058543043867759\n",
      "Step: 1922 Weights: [-0.16987111  2.19257973] , error: 0.5057080230341898\n",
      "Step: 1923 Weights: [-0.16867153  2.19244254] , error: 0.5055624080854039\n",
      "Step: 1924 Weights: [-0.16747469  2.19230566] , error: 0.5054174565045276\n",
      "Step: 1925 Weights: [-0.16628058  2.1921691 ] , error: 0.5052731652695032\n",
      "Step: 1926 Weights: [-0.16508918  2.19203285] , error: 0.505129531372039\n",
      "Step: 1927 Weights: [-0.16390051  2.1918969 ] , error: 0.5049865518175454\n",
      "Step: 1928 Weights: [-0.16271454  2.19176127] , error: 0.5048442236250816\n",
      "Step: 1929 Weights: [-0.16153129  2.19162595] , error: 0.5047025438272796\n",
      "Step: 1930 Weights: [-0.16035072  2.19149094] , error: 0.5045615094702943\n",
      "Step: 1931 Weights: [-0.15917286  2.19135623] , error: 0.5044211176137355\n",
      "Step: 1932 Weights: [-0.15799767  2.19122183] , error: 0.5042813653306099\n",
      "Step: 1933 Weights: [-0.15682517  2.19108774] , error: 0.5041422497072543\n",
      "Step: 1934 Weights: [-0.15565534  2.19095395] , error: 0.5040037678432845\n",
      "Step: 1935 Weights: [-0.15448818  2.19082047] , error: 0.5038659168515252\n",
      "Step: 1936 Weights: [-0.15332368  2.19068729] , error: 0.5037286938579575\n",
      "Step: 1937 Weights: [-0.15216183  2.19055442] , error: 0.5035920960016523\n",
      "Step: 1938 Weights: [-0.15100264  2.19042185] , error: 0.5034561204347145\n",
      "Step: 1939 Weights: [-0.14984609  2.19028958] , error: 0.5033207643222258\n",
      "Step: 1940 Weights: [-0.14869217  2.19015762] , error: 0.5031860248421801\n",
      "Step: 1941 Weights: [-0.14754089  2.19002595] , error: 0.5030518991854263\n",
      "Step: 1942 Weights: [-0.14639223  2.18989458] , error: 0.5029183845556129\n",
      "Step: 1943 Weights: [-0.1452462   2.18976352] , error: 0.5027854781691262\n",
      "Step: 1944 Weights: [-0.14410277  2.18963275] , error: 0.5026531772550376\n",
      "Step: 1945 Weights: [-0.14296195  2.18950228] , error: 0.5025214790550343\n",
      "Step: 1946 Weights: [-0.14182374  2.18937211] , error: 0.5023903808233765\n",
      "Step: 1947 Weights: [-0.14068812  2.18924224] , error: 0.5022598798268278\n",
      "Step: 1948 Weights: [-0.13955509  2.18911266] , error: 0.502129973344608\n",
      "Step: 1949 Weights: [-0.13842464  2.18898338] , error: 0.5020006586683283\n",
      "Step: 1950 Weights: [-0.13729677  2.18885439] , error: 0.5018719331019391\n",
      "Step: 1951 Weights: [-0.13617148  2.1887257 ] , error: 0.5017437939616736\n",
      "Step: 1952 Weights: [-0.13504875  2.1885973 ] , error: 0.5016162385759919\n",
      "Step: 1953 Weights: [-0.13392858  2.18846919] , error: 0.5014892642855227\n",
      "Step: 1954 Weights: [-0.13281096  2.18834137] , error: 0.5013628684430111\n",
      "Step: 1955 Weights: [-0.13169589  2.18821385] , error: 0.5012370484132629\n",
      "Step: 1956 Weights: [-0.13058337  2.18808662] , error: 0.5011118015730861\n",
      "Step: 1957 Weights: [-0.12947338  2.18795967] , error: 0.5009871253112423\n",
      "Step: 1958 Weights: [-0.12836593  2.18783302] , error: 0.5008630170283878\n",
      "Step: 1959 Weights: [-0.127261    2.18770666] , error: 0.5007394741370177\n",
      "Step: 1960 Weights: [-0.12615859  2.18758058] , error: 0.5006164940614197\n",
      "Step: 1961 Weights: [-0.12505869  2.18745479] , error: 0.5004940742376127\n",
      "Step: 1962 Weights: [-0.1239613   2.18732929] , error: 0.5003722121132952\n",
      "Step: 1963 Weights: [-0.12286642  2.18720407] , error: 0.5002509051477952\n",
      "Step: 1964 Weights: [-0.12177403  2.18707914] , error: 0.5001301508120155\n",
      "Step: 1965 Weights: [-0.12068413  2.1869545 ] , error: 0.5000099465883763\n",
      "Step: 1966 Weights: [-0.11959672  2.18683014] , error: 0.49989028997077223\n",
      "Step: 1967 Weights: [-0.11851178  2.18670606] , error: 0.4997711784645115\n",
      "Step: 1968 Weights: [-0.11742932  2.18658226] , error: 0.4996526095862685\n",
      "Step: 1969 Weights: [-0.11634933  2.18645875] , error: 0.49953458086403146\n",
      "Step: 1970 Weights: [-0.11527181  2.18633552] , error: 0.49941708983704747\n",
      "Step: 1971 Weights: [-0.11419674  2.18621257] , error: 0.4993001340557765\n",
      "Step: 1972 Weights: [-0.11312412  2.1860899 ] , error: 0.49918371108183646\n",
      "Step: 1973 Weights: [-0.11205394  2.18596751] , error: 0.4990678184879557\n",
      "Step: 1974 Weights: [-0.11098621  2.1858454 ] , error: 0.4989524538579153\n",
      "Step: 1975 Weights: [-0.10992091  2.18572357] , error: 0.49883761478650923\n",
      "Step: 1976 Weights: [-0.10885805  2.18560202] , error: 0.4987232988794868\n",
      "Step: 1977 Weights: [-0.1077976   2.18548074] , error: 0.49860950375350355\n",
      "Step: 1978 Weights: [-0.10673958  2.18535974] , error: 0.49849622703607416\n",
      "Step: 1979 Weights: [-0.10568396  2.18523902] , error: 0.49838346636551945\n",
      "Step: 1980 Weights: [-0.10463076  2.18511857] , error: 0.4982712193909214\n",
      "Step: 1981 Weights: [-0.10357995  2.18499839] , error: 0.49815948377207087\n",
      "Step: 1982 Weights: [-0.10253154  2.18487849] , error: 0.4980482571794206\n",
      "Step: 1983 Weights: [-0.10148553  2.18475886] , error: 0.49793753729403434\n",
      "Step: 1984 Weights: [-0.10044189  2.18463951] , error: 0.4978273218075425\n",
      "Step: 1985 Weights: [-0.09940064  2.18452043] , error: 0.4977176084220875\n",
      "Step: 1986 Weights: [-0.09836176  2.18440162] , error: 0.4976083948502844\n",
      "Step: 1987 Weights: [-0.09732526  2.18428308] , error: 0.49749967881516566\n",
      "Step: 1988 Weights: [-0.09629111  2.18416481] , error: 0.497391458050141\n",
      "Step: 1989 Weights: [-0.09525933  2.18404681] , error: 0.49728373029893835\n",
      "Step: 1990 Weights: [-0.09422989  2.18392908] , error: 0.49717649331557245\n",
      "Step: 1991 Weights: [-0.09320281  2.18381162] , error: 0.49706974486428457\n",
      "Step: 1992 Weights: [-0.09217806  2.18369442] , error: 0.4969634827195028\n",
      "Step: 1993 Weights: [-0.09115565  2.1835775 ] , error: 0.4968577046657956\n",
      "Step: 1994 Weights: [-0.09013558  2.18346084] , error: 0.4967524084978219\n",
      "Step: 1995 Weights: [-0.08911783  2.18334444] , error: 0.49664759202028896\n",
      "Step: 1996 Weights: [-0.0881024   2.18322831] , error: 0.4965432530479045\n",
      "Step: 1997 Weights: [-0.08708929  2.18311245] , error: 0.4964393894053315\n",
      "Step: 1998 Weights: [-0.08607849  2.18299685] , error: 0.4963359989271412\n",
      "Step: 1999 Weights: [-0.08506999  2.18288151] , error: 0.4962330794577733\n",
      "Step: 2000 Weights: [-0.08406379  2.18276644] , error: 0.49613062885148557\n",
      "Step: 2001 Weights: [-0.08305989  2.18265163] , error: 0.4960286449723097\n",
      "Step: 2002 Weights: [-0.08205827  2.18253708] , error: 0.4959271256940109\n",
      "Step: 2003 Weights: [-0.08105894  2.18242279] , error: 0.49582606890003844\n",
      "Step: 2004 Weights: [-0.08006189  2.18230877] , error: 0.49572547248348553\n",
      "Step: 2005 Weights: [-0.07906712  2.182195  ] , error: 0.495625334347042\n",
      "Step: 2006 Weights: [-0.07807461  2.18208149] , error: 0.4955256524029525\n",
      "Step: 2007 Weights: [-0.07708436  2.18196824] , error: 0.4954264245729731\n",
      "Step: 2008 Weights: [-0.07609638  2.18185525] , error: 0.49532764878832825\n",
      "Step: 2009 Weights: [-0.07511064  2.18174252] , error: 0.49522932298966604\n",
      "Step: 2010 Weights: [-0.07412715  2.18163005] , error: 0.4951314451270176\n",
      "Step: 2011 Weights: [-0.07314591  2.18151783] , error: 0.4950340131597515\n",
      "Step: 2012 Weights: [-0.07216691  2.18140586] , error: 0.4949370250565333\n",
      "Step: 2013 Weights: [-0.07119013  2.18129416] , error: 0.4948404787952809\n",
      "Step: 2014 Weights: [-0.07021559  2.1811827 ] , error: 0.4947443723631272\n",
      "Step: 2015 Weights: [-0.06924326  2.1810715 ] , error: 0.49464870375637243\n",
      "Step: 2016 Weights: [-0.06827316  2.18096056] , error: 0.4945534709804459\n",
      "Step: 2017 Weights: [-0.06730526  2.18084987] , error: 0.49445867204986393\n",
      "Step: 2018 Weights: [-0.06633958  2.18073943] , error: 0.4943643049881874\n",
      "Step: 2019 Weights: [-0.06537609  2.18062924] , error: 0.4942703678279793\n",
      "Step: 2020 Weights: [-0.0644148  2.1805193] , error: 0.49417685861077043\n",
      "Step: 2021 Weights: [-0.06345571  2.18040961] , error: 0.49408377538700804\n",
      "Step: 2022 Weights: [-0.0624988   2.18030018] , error: 0.4939911162160243\n",
      "Step: 2023 Weights: [-0.06154407  2.18019099] , error: 0.4938988791659923\n",
      "Step: 2024 Weights: [-0.06059153  2.18008205] , error: 0.4938070623138838\n",
      "Step: 2025 Weights: [-0.05964115  2.17997337] , error: 0.4937156637454317\n",
      "Step: 2026 Weights: [-0.05869294  2.17986492] , error: 0.4936246815550922\n",
      "Step: 2027 Weights: [-0.05774689  2.17975673] , error: 0.49353411384599866\n",
      "Step: 2028 Weights: [-0.056803    2.17964878] , error: 0.4934439587299282\n",
      "Step: 2029 Weights: [-0.05586127  2.17954108] , error: 0.4933542143272598\n",
      "Step: 2030 Weights: [-0.05492168  2.17943363] , error: 0.4932648787669357\n",
      "Step: 2031 Weights: [-0.05398423  2.17932642] , error: 0.4931759501864178\n",
      "Step: 2032 Weights: [-0.05304892  2.17921945] , error: 0.4930874267316615\n",
      "Step: 2033 Weights: [-0.05211574  2.17911273] , error: 0.4929993065570587\n",
      "Step: 2034 Weights: [-0.0511847   2.17900625] , error: 0.4929115878254169\n",
      "Step: 2035 Weights: [-0.05025577  2.17890001] , error: 0.49282426870790996\n",
      "Step: 2036 Weights: [-0.04932896  2.17879402] , error: 0.49273734738404223\n",
      "Step: 2037 Weights: [-0.04840427  2.17868827] , error: 0.4926508220416138\n",
      "Step: 2038 Weights: [-0.04748169  2.17858276] , error: 0.4925646908766804\n",
      "Step: 2039 Weights: [-0.04656121  2.17847749] , error: 0.4924789520935138\n",
      "Step: 2040 Weights: [-0.04564282  2.17837246] , error: 0.49239360390456705\n",
      "Step: 2041 Weights: [-0.04472654  2.17826767] , error: 0.49230864453043854\n",
      "Step: 2042 Weights: [-0.04381234  2.17816312] , error: 0.4922240721998313\n",
      "Step: 2043 Weights: [-0.04290023  2.1780588 ] , error: 0.49213988514951734\n",
      "Step: 2044 Weights: [-0.04199019  2.17795473] , error: 0.49205608162430237\n",
      "Step: 2045 Weights: [-0.04108223  2.17785089] , error: 0.4919726598769879\n",
      "Step: 2046 Weights: [-0.04017635  2.17774729] , error: 0.49188961816833426\n",
      "Step: 2047 Weights: [-0.03927253  2.17764392] , error: 0.49180695476702807\n",
      "Step: 2048 Weights: [-0.03837077  2.17754079] , error: 0.491724667949637\n",
      "Step: 2049 Weights: [-0.03747106  2.1774379 ] , error: 0.49164275600058716\n",
      "Step: 2050 Weights: [-0.03657341  2.17733524] , error: 0.491561217212114\n",
      "Step: 2051 Weights: [-0.0356778   2.17723282] , error: 0.4914800498842379\n",
      "Step: 2052 Weights: [-0.03478424  2.17713062] , error: 0.4913992523247217\n",
      "Step: 2053 Weights: [-0.03389272  2.17702867] , error: 0.49131882284903616\n",
      "Step: 2054 Weights: [-0.03300322  2.17692694] , error: 0.49123875978032766\n",
      "Step: 2055 Weights: [-0.03211576  2.17682545] , error: 0.49115906144938204\n",
      "Step: 2056 Weights: [-0.03123032  2.17672418] , error: 0.4910797261945887\n",
      "Step: 2057 Weights: [-0.0303469   2.17662315] , error: 0.491000752361906\n",
      "Step: 2058 Weights: [-0.02946549  2.17652235] , error: 0.49092213830482834\n",
      "Step: 2059 Weights: [-0.0285861   2.17642178] , error: 0.4908438823843529\n",
      "Step: 2060 Weights: [-0.0277087   2.17632144] , error: 0.490765982968939\n",
      "Step: 2061 Weights: [-0.02683331  2.17622132] , error: 0.49068843843448223\n",
      "Step: 2062 Weights: [-0.02595992  2.17612144] , error: 0.4906112471642762\n",
      "Step: 2063 Weights: [-0.02508852  2.17602178] , error: 0.4905344075489801\n",
      "Step: 2064 Weights: [-0.0242191   2.17592235] , error: 0.49045791798658445\n",
      "Step: 2065 Weights: [-0.02335167  2.17582315] , error: 0.4903817768823758\n",
      "Step: 2066 Weights: [-0.02248622  2.17572417] , error: 0.4903059826489077\n",
      "Step: 2067 Weights: [-0.02162274  2.17562542] , error: 0.49023053370596636\n",
      "Step: 2068 Weights: [-0.02076122  2.17552689] , error: 0.49015542848053484\n",
      "Step: 2069 Weights: [-0.01990168  2.17542859] , error: 0.4900806654067642\n",
      "Step: 2070 Weights: [-0.01904409  2.17533051] , error: 0.49000624292593586\n",
      "Step: 2071 Weights: [-0.01818846  2.17523266] , error: 0.4899321594864366\n",
      "Step: 2072 Weights: [-0.01733478  2.17513503] , error: 0.48985841354371795\n",
      "Step: 2073 Weights: [-0.01648305  2.17503762] , error: 0.4897850035602685\n",
      "Step: 2074 Weights: [-0.01563326  2.17494044] , error: 0.4897119280055839\n",
      "Step: 2075 Weights: [-0.0147854   2.17484347] , error: 0.4896391853561294\n",
      "Step: 2076 Weights: [-0.01393948  2.17474673] , error: 0.48956677409531046\n",
      "Step: 2077 Weights: [-0.01309549  2.17465021] , error: 0.48949469271344564\n",
      "Step: 2078 Weights: [-0.01225343  2.17455391] , error: 0.4894229397077259\n",
      "Step: 2079 Weights: [-0.01141328  2.17445782] , error: 0.4893515135821922\n",
      "Step: 2080 Weights: [-0.01057505  2.17436196] , error: 0.48928041284769863\n",
      "Step: 2081 Weights: [-0.00973873  2.17426631] , error: 0.4892096360218833\n",
      "Step: 2082 Weights: [-0.00890432  2.17417089] , error: 0.4891391816291388\n",
      "Step: 2083 Weights: [-0.00807181  2.17407568] , error: 0.4890690482005785\n",
      "Step: 2084 Weights: [-0.0072412   2.17398069] , error: 0.4889992342740092\n",
      "Step: 2085 Weights: [-0.00641249  2.17388591] , error: 0.48892973839389636\n",
      "Step: 2086 Weights: [-0.00558566  2.17379135] , error: 0.4888605591113393\n",
      "Step: 2087 Weights: [-0.00476072  2.17369701] , error: 0.488791694984037\n",
      "Step: 2088 Weights: [-0.00393766  2.17360288] , error: 0.48872314457625554\n",
      "Step: 2089 Weights: [-0.00311648  2.17350897] , error: 0.4886549064588074\n",
      "Step: 2090 Weights: [-0.00229717  2.17341527] , error: 0.4885869792090124\n",
      "Step: 2091 Weights: [-1.47972911e-03  2.17332178e+00] , error: 0.48851936141067276\n",
      "Step: 2092 Weights: [-6.64151957e-04  2.17322851e+00] , error: 0.4884520516540398\n",
      "Step: 2093 Weights: [1.49565340e-04 2.17313545e+00] , error: 0.48838504853579223\n",
      "Step: 2094 Weights: [9.61427024e-04 2.17304260e+00] , error: 0.48831835065899865\n",
      "Step: 2095 Weights: [1.77143733e-03 2.17294996e+00] , error: 0.48825195663309007\n",
      "Step: 2096 Weights: [0.0025796  2.17285754] , error: 0.4881858650738341\n",
      "Step: 2097 Weights: [0.00338592 2.17276532] , error: 0.48812007460330487\n",
      "Step: 2098 Weights: [0.0041904  2.17267332] , error: 0.4880545838498543\n",
      "Step: 2099 Weights: [0.00499305 2.17258153] , error: 0.4879893914480822\n",
      "Step: 2100 Weights: [0.00579387 2.17248994] , error: 0.48792449603880694\n",
      "Step: 2101 Weights: [0.00659286 2.17239856] , error: 0.48785989626904186\n",
      "Step: 2102 Weights: [0.00739002 2.1723074 ] , error: 0.48779559079196144\n",
      "Step: 2103 Weights: [0.00818537 2.17221644] , error: 0.4877315782668781\n",
      "Step: 2104 Weights: [0.00897891 2.17212569] , error: 0.4876678573592098\n",
      "Step: 2105 Weights: [0.00977064 2.17203514] , error: 0.4876044267404547\n",
      "Step: 2106 Weights: [0.01056056 2.1719448 ] , error: 0.48754128508816685\n",
      "Step: 2107 Weights: [0.01134868 2.17185467] , error: 0.48747843108591793\n",
      "Step: 2108 Weights: [0.012135   2.17176474] , error: 0.48741586342328275\n",
      "Step: 2109 Weights: [0.01291953 2.17167502] , error: 0.48735358079580426\n",
      "Step: 2110 Weights: [0.01370227 2.1715855 ] , error: 0.48729158190496585\n",
      "Step: 2111 Weights: [0.01448323 2.17149619] , error: 0.4872298654581695\n",
      "Step: 2112 Weights: [0.0152624  2.17140708] , error: 0.4871684301687046\n",
      "Step: 2113 Weights: [0.0160398  2.17131817] , error: 0.48710727475572085\n",
      "Step: 2114 Weights: [0.01681543 2.17122947] , error: 0.4870463979442061\n",
      "Step: 2115 Weights: [0.01758929 2.17114097] , error: 0.4869857984649546\n",
      "Step: 2116 Weights: [0.01836138 2.17105267] , error: 0.4869254750545415\n",
      "Step: 2117 Weights: [0.01913171 2.17096457] , error: 0.4868654264553004\n",
      "Step: 2118 Weights: [0.01990028 2.17087667] , error: 0.48680565141529375\n",
      "Step: 2119 Weights: [0.0206671  2.17078897] , error: 0.4867461486882859\n",
      "Step: 2120 Weights: [0.02143218 2.17070148] , error: 0.48668691703371814\n",
      "Step: 2121 Weights: [0.02219551 2.17061418] , error: 0.48662795521668833\n",
      "Step: 2122 Weights: [0.02295709 2.17052708] , error: 0.4865692620079116\n",
      "Step: 2123 Weights: [0.02371694 2.17044018] , error: 0.4865108361837118\n",
      "Step: 2124 Weights: [0.02447506 2.17035348] , error: 0.4864526765259819\n",
      "Step: 2125 Weights: [0.02523145 2.17026698] , error: 0.4863947818221659\n",
      "Step: 2126 Weights: [0.02598612 2.17018067] , error: 0.4863371508652312\n",
      "Step: 2127 Weights: [0.02673906 2.17009456] , error: 0.4862797824536461\n",
      "Step: 2128 Weights: [0.02749029 2.17000865] , error: 0.486222675391349\n",
      "Step: 2129 Weights: [0.0282398  2.16992293] , error: 0.4861658284877308\n",
      "Step: 2130 Weights: [0.02898761 2.16983741] , error: 0.48610924055760335\n",
      "Step: 2131 Weights: [0.0297337  2.16975208] , error: 0.48605291042118015\n",
      "Step: 2132 Weights: [0.0304781  2.16966695] , error: 0.4859968369040476\n",
      "Step: 2133 Weights: [0.0312208  2.16958201] , error: 0.4859410188371428\n",
      "Step: 2134 Weights: [0.03196181 2.16949726] , error: 0.48588545505673086\n",
      "Step: 2135 Weights: [0.03270112 2.16941271] , error: 0.4858301444043731\n",
      "Step: 2136 Weights: [0.03343876 2.16932835] , error: 0.48577508572691364\n",
      "Step: 2137 Weights: [0.0341747  2.16924419] , error: 0.4857202778764483\n",
      "Step: 2138 Weights: [0.03490897 2.16916021] , error: 0.4856657197103018\n",
      "Step: 2139 Weights: [0.03564157 2.16907643] , error: 0.48561141009100306\n",
      "Step: 2140 Weights: [0.03637249 2.16899284] , error: 0.48555734788626653\n",
      "Step: 2141 Weights: [0.03710175 2.16890944] , error: 0.48550353196896134\n",
      "Step: 2142 Weights: [0.03782935 2.16882623] , error: 0.48544996121709433\n",
      "Step: 2143 Weights: [0.03855528 2.16874321] , error: 0.48539663451378046\n",
      "Step: 2144 Weights: [0.03927957 2.16866038] , error: 0.4853435507472278\n",
      "Step: 2145 Weights: [0.04000219 2.16857773] , error: 0.4852907088107023\n",
      "Step: 2146 Weights: [0.04072318 2.16849528] , error: 0.48523810760251773\n",
      "Step: 2147 Weights: [0.04144251 2.16841301] , error: 0.48518574602600534\n",
      "Step: 2148 Weights: [0.04216021 2.16833093] , error: 0.48513362298949014\n",
      "Step: 2149 Weights: [0.04287627 2.16824904] , error: 0.4850817374062739\n",
      "Step: 2150 Weights: [0.0435907  2.16816734] , error: 0.48503008819460636\n",
      "Step: 2151 Weights: [0.04430349 2.16808582] , error: 0.48497867427766506\n",
      "Step: 2152 Weights: [0.04501467 2.16800448] , error: 0.48492749458353474\n",
      "Step: 2153 Weights: [0.04572422 2.16792334] , error: 0.48487654804518326\n",
      "Step: 2154 Weights: [0.04643215 2.16784238] , error: 0.4848258336004392\n",
      "Step: 2155 Weights: [0.04713847 2.1677616 ] , error: 0.48477535019196805\n",
      "Step: 2156 Weights: [0.04784318 2.167681  ] , error: 0.4847250967672561\n",
      "Step: 2157 Weights: [0.04854628 2.1676006 ] , error: 0.4846750722785821\n",
      "Step: 2158 Weights: [0.04924777 2.16752037] , error: 0.4846252756829968\n",
      "Step: 2159 Weights: [0.04994767 2.16744033] , error: 0.48457570594230365\n",
      "Step: 2160 Weights: [0.05064597 2.16736046] , error: 0.48452636202303645\n",
      "Step: 2161 Weights: [0.05134268 2.16728079] , error: 0.48447724289643535\n",
      "Step: 2162 Weights: [0.0520378  2.16720129] , error: 0.4844283475384292\n",
      "Step: 2163 Weights: [0.05273134 2.16712197] , error: 0.48437967492960965\n",
      "Step: 2164 Weights: [0.05342329 2.16704284] , error: 0.4843312240552138\n",
      "Step: 2165 Weights: [0.05411366 2.16696388] , error: 0.48428299390510227\n",
      "Step: 2166 Weights: [0.05480247 2.16688511] , error: 0.4842349834737367\n",
      "Step: 2167 Weights: [0.0554897  2.16680652] , error: 0.4841871917601592\n",
      "Step: 2168 Weights: [0.05617536 2.1667281 ] , error: 0.484139617767973\n",
      "Step: 2169 Weights: [0.05685946 2.16664986] , error: 0.4840922605053197\n",
      "Step: 2170 Weights: [0.057542   2.16657181] , error: 0.48404511898485775\n",
      "Step: 2171 Weights: [0.05822298 2.16649393] , error: 0.4839981922237486\n",
      "Step: 2172 Weights: [0.05890241 2.16641622] , error: 0.4839514792436249\n",
      "Step: 2173 Weights: [0.05958029 2.1663387 ] , error: 0.48390497907058183\n",
      "Step: 2174 Weights: [0.06025663 2.16626135] , error: 0.4838586907351481\n",
      "Step: 2175 Weights: [0.06093142 2.16618418] , error: 0.48381261327226943\n",
      "Step: 2176 Weights: [0.06160467 2.16610718] , error: 0.4837667457212886\n",
      "Step: 2177 Weights: [0.06227639 2.16603036] , error: 0.483721087125925\n",
      "Step: 2178 Weights: [0.06294658 2.16595372] , error: 0.4836756365342538\n",
      "Step: 2179 Weights: [0.06361524 2.16587725] , error: 0.483630392998686\n",
      "Step: 2180 Weights: [0.06428237 2.16580095] , error: 0.48358535557595317\n",
      "Step: 2181 Weights: [0.06494798 2.16572483] , error: 0.48354052332707825\n",
      "Step: 2182 Weights: [0.06561208 2.16564888] , error: 0.4834958953173663\n",
      "Step: 2183 Weights: [0.06627466 2.1655731 ] , error: 0.4834514706163804\n",
      "Step: 2184 Weights: [0.06693573 2.1654975 ] , error: 0.48340724829791915\n",
      "Step: 2185 Weights: [0.06759529 2.16542207] , error: 0.48336322744000226\n",
      "Step: 2186 Weights: [0.06825335 2.16534681] , error: 0.48331940712485205\n",
      "Step: 2187 Weights: [0.0689099  2.16527172] , error: 0.48327578643886904\n",
      "Step: 2188 Weights: [0.06956496 2.16519681] , error: 0.4832323644726148\n",
      "Step: 2189 Weights: [0.07021853 2.16512206] , error: 0.4831891403207974\n",
      "Step: 2190 Weights: [0.0708706  2.16504749] , error: 0.4831461130822476\n",
      "Step: 2191 Weights: [0.07152119 2.16497309] , error: 0.4831032818598996\n",
      "Step: 2192 Weights: [0.0721703  2.16489885] , error: 0.4830606457607776\n",
      "Step: 2193 Weights: [0.07281792 2.16482479] , error: 0.4830182038959714\n",
      "Step: 2194 Weights: [0.07346407 2.16475089] , error: 0.4829759553806208\n",
      "Step: 2195 Weights: [0.07410874 2.16467716] , error: 0.48293389933389896\n",
      "Step: 2196 Weights: [0.07475195 2.1646036 ] , error: 0.48289203487898846\n",
      "Step: 2197 Weights: [0.07539368 2.16453021] , error: 0.482850361143068\n",
      "Step: 2198 Weights: [0.07603396 2.16445699] , error: 0.4828088772572925\n",
      "Step: 2199 Weights: [0.07667277 2.16438393] , error: 0.48276758235677436\n",
      "Step: 2200 Weights: [0.07731013 2.16431104] , error: 0.48272647558056647\n",
      "Step: 2201 Weights: [0.07794603 2.16423832] , error: 0.48268555607164576\n",
      "Step: 2202 Weights: [0.07858048 2.16416576] , error: 0.48264482297688915\n",
      "Step: 2203 Weights: [0.07921349 2.16409336] , error: 0.48260427544706486\n",
      "Step: 2204 Weights: [0.07984505 2.16402113] , error: 0.4825639126368054\n",
      "Step: 2205 Weights: [0.08047518 2.16394907] , error: 0.48252373370459856\n",
      "Step: 2206 Weights: [0.08110386 2.16387717] , error: 0.4824837378127629\n",
      "Step: 2207 Weights: [0.08173112 2.16380544] , error: 0.48244392412743403\n",
      "Step: 2208 Weights: [0.08235694 2.16373387] , error: 0.4824042918185477\n",
      "Step: 2209 Weights: [0.08298133 2.16366246] , error: 0.482364840059818\n",
      "Step: 2210 Weights: [0.0836043  2.16359121] , error: 0.4823255680287257\n",
      "Step: 2211 Weights: [0.08422585 2.16352013] , error: 0.48228647490649923\n",
      "Step: 2212 Weights: [0.08484599 2.16344921] , error: 0.4822475598780945\n",
      "Step: 2213 Weights: [0.0854647  2.16337845] , error: 0.48220882213218125\n",
      "Step: 2214 Weights: [0.08608201 2.16330785] , error: 0.48217026086112946\n",
      "Step: 2215 Weights: [0.08669791 2.16323741] , error: 0.4821318752609804\n",
      "Step: 2216 Weights: [0.08731241 2.16316714] , error: 0.482093664531445\n",
      "Step: 2217 Weights: [0.0879255  2.16309702] , error: 0.4820556278758773\n",
      "Step: 2218 Weights: [0.0885372  2.16302706] , error: 0.48201776450125977\n",
      "Step: 2219 Weights: [0.0891475  2.16295727] , error: 0.48198007361818795\n",
      "Step: 2220 Weights: [0.08975641 2.16288763] , error: 0.4819425544408559\n",
      "Step: 2221 Weights: [0.09036393 2.16281815] , error: 0.4819052061870344\n",
      "Step: 2222 Weights: [0.09097007 2.16274883] , error: 0.48186802807805873\n",
      "Step: 2223 Weights: [0.09157482 2.16267967] , error: 0.48183101933881267\n",
      "Step: 2224 Weights: [0.09217819 2.16261067] , error: 0.48179417919771017\n",
      "Step: 2225 Weights: [0.09278019 2.16254182] , error: 0.48175750688668073\n",
      "Step: 2226 Weights: [0.09338082 2.16247313] , error: 0.4817210016411513\n",
      "Step: 2227 Weights: [0.09398007 2.16240459] , error: 0.4816846627000344\n",
      "Step: 2228 Weights: [0.09457796 2.16233622] , error: 0.481648489305708\n",
      "Step: 2229 Weights: [0.09517449 2.162268  ] , error: 0.4816124807040013\n",
      "Step: 2230 Weights: [0.09576965 2.16219993] , error: 0.48157663614418206\n",
      "Step: 2231 Weights: [0.09636346 2.16213202] , error: 0.48154095487893583\n",
      "Step: 2232 Weights: [0.09695591 2.16206426] , error: 0.48150543616435004\n",
      "Step: 2233 Weights: [0.09754702 2.16199666] , error: 0.4814700792599066\n",
      "Step: 2234 Weights: [0.09813677 2.16192922] , error: 0.4814348834284579\n",
      "Step: 2235 Weights: [0.09872518 2.16186192] , error: 0.48139984793621327\n",
      "Step: 2236 Weights: [0.09931225 2.16179478] , error: 0.4813649720527292\n",
      "Step: 2237 Weights: [0.09989798 2.1617278 ] , error: 0.4813302550508843\n",
      "Step: 2238 Weights: [0.10048237 2.16166096] , error: 0.48129569620687507\n",
      "Step: 2239 Weights: [0.10106544 2.16159428] , error: 0.48126129480019053\n",
      "Step: 2240 Weights: [0.10164717 2.16152775] , error: 0.4812270501136071\n",
      "Step: 2241 Weights: [0.10222757 2.16146138] , error: 0.4811929614331627\n",
      "Step: 2242 Weights: [0.10280665 2.16139515] , error: 0.481159028048153\n",
      "Step: 2243 Weights: [0.10338441 2.16132907] , error: 0.4811252492511099\n",
      "Step: 2244 Weights: [0.10396086 2.16126315] , error: 0.4810916243377863\n",
      "Step: 2245 Weights: [0.10453599 2.16119738] , error: 0.4810581526071448\n",
      "Step: 2246 Weights: [0.1051098  2.16113175] , error: 0.48102483336134316\n",
      "Step: 2247 Weights: [0.10568231 2.16106628] , error: 0.48099166590571574\n",
      "Step: 2248 Weights: [0.10625352 2.16100095] , error: 0.48095864954876266\n",
      "Step: 2249 Weights: [0.10682342 2.16093578] , error: 0.48092578360213445\n",
      "Step: 2250 Weights: [0.10739202 2.16087075] , error: 0.4808930673806163\n",
      "Step: 2251 Weights: [0.10795932 2.16080587] , error: 0.48086050020211735\n",
      "Step: 2252 Weights: [0.10852533 2.16074114] , error: 0.480828081387651\n",
      "Step: 2253 Weights: [0.10909005 2.16067655] , error: 0.480795810261328\n",
      "Step: 2254 Weights: [0.10965348 2.16061212] , error: 0.48076368615033344\n",
      "Step: 2255 Weights: [0.11021563 2.16054783] , error: 0.4807317083849214\n",
      "Step: 2256 Weights: [0.1107765  2.16048368] , error: 0.4806998762983928\n",
      "Step: 2257 Weights: [0.11133608 2.16041969] , error: 0.480668189227092\n",
      "Step: 2258 Weights: [0.11189439 2.16035584] , error: 0.48063664651038157\n",
      "Step: 2259 Weights: [0.11245143 2.16029213] , error: 0.48060524749063327\n",
      "Step: 2260 Weights: [0.1130072  2.16022857] , error: 0.48057399151322044\n",
      "Step: 2261 Weights: [0.1135617  2.16016516] , error: 0.480542877926494\n",
      "Step: 2262 Weights: [0.11411493 2.16010189] , error: 0.48051190608177263\n",
      "Step: 2263 Weights: [0.1146669  2.16003876] , error: 0.4804810753333344\n",
      "Step: 2264 Weights: [0.11521762 2.15997578] , error: 0.48045038503839577\n",
      "Step: 2265 Weights: [0.11576708 2.15991294] , error: 0.48041983455710285\n",
      "Step: 2266 Weights: [0.11631528 2.15985025] , error: 0.48038942325251627\n",
      "Step: 2267 Weights: [0.11686224 2.15978769] , error: 0.4803591504905973\n",
      "Step: 2268 Weights: [0.11740795 2.15972528] , error: 0.4803290156401985\n",
      "Step: 2269 Weights: [0.11795241 2.15966302] , error: 0.48029901807304465\n",
      "Step: 2270 Weights: [0.11849563 2.15960089] , error: 0.48026915716372376\n",
      "Step: 2271 Weights: [0.11903762 2.15953891] , error: 0.48023943228967547\n",
      "Step: 2272 Weights: [0.11957836 2.15947707] , error: 0.4802098428311708\n",
      "Step: 2273 Weights: [0.12011788 2.15941536] , error: 0.4801803881713065\n",
      "Step: 2274 Weights: [0.12065616 2.1593538 ] , error: 0.48015106769599164\n",
      "Step: 2275 Weights: [0.12119322 2.15929238] , error: 0.4801218807939307\n",
      "Step: 2276 Weights: [0.12172905 2.1592311 ] , error: 0.48009282685661236\n",
      "Step: 2277 Weights: [0.12226366 2.15916996] , error: 0.4800639052782987\n",
      "Step: 2278 Weights: [0.12279705 2.15910896] , error: 0.480035115456011\n",
      "Step: 2279 Weights: [0.12332923 2.1590481 ] , error: 0.48000645678951764\n",
      "Step: 2280 Weights: [0.12386019 2.15898738] , error: 0.4799779286813196\n",
      "Step: 2281 Weights: [0.12438994 2.15892679] , error: 0.47994953053664535\n",
      "Step: 2282 Weights: [0.12491848 2.15886635] , error: 0.47992126176342575\n",
      "Step: 2283 Weights: [0.12544582 2.15880604] , error: 0.4798931217722923\n",
      "Step: 2284 Weights: [0.12597195 2.15874587] , error: 0.47986510997656406\n",
      "Step: 2285 Weights: [0.12649689 2.15868583] , error: 0.47983722579222765\n",
      "Step: 2286 Weights: [0.12702062 2.15862594] , error: 0.4798094686379344\n",
      "Step: 2287 Weights: [0.12754317 2.15856618] , error: 0.47978183793498075\n",
      "Step: 2288 Weights: [0.12806452 2.15850655] , error: 0.47975433310730087\n",
      "Step: 2289 Weights: [0.12858468 2.15844707] , error: 0.47972695358145634\n",
      "Step: 2290 Weights: [0.12910366 2.15838771] , error: 0.479699698786615\n",
      "Step: 2291 Weights: [0.12962145 2.1583285 ] , error: 0.47967256815455017\n",
      "Step: 2292 Weights: [0.13013806 2.15826941] , error: 0.4796455611196222\n",
      "Step: 2293 Weights: [0.13065349 2.15821047] , error: 0.4796186771187678\n",
      "Step: 2294 Weights: [0.13116775 2.15815165] , error: 0.47959191559148956\n",
      "Step: 2295 Weights: [0.13168084 2.15809298] , error: 0.479565275979842\n",
      "Step: 2296 Weights: [0.13219275 2.15803443] , error: 0.4795387577284239\n",
      "Step: 2297 Weights: [0.1327035  2.15797602] , error: 0.47951236028436184\n",
      "Step: 2298 Weights: [0.13321309 2.15791774] , error: 0.479486083097303\n",
      "Step: 2299 Weights: [0.13372151 2.1578596 ] , error: 0.4794599256194003\n",
      "Step: 2300 Weights: [0.13422877 2.15780158] , error: 0.47943388730530345\n",
      "Step: 2301 Weights: [0.13473488 2.1577437 ] , error: 0.4794079676121452\n",
      "Step: 2302 Weights: [0.13523983 2.15768596] , error: 0.4793821659995343\n",
      "Step: 2303 Weights: [0.13574363 2.15762834] , error: 0.47935648192953795\n",
      "Step: 2304 Weights: [0.13624628 2.15757085] , error: 0.47933091486667656\n",
      "Step: 2305 Weights: [0.13674778 2.1575135 ] , error: 0.4793054642779063\n",
      "Step: 2306 Weights: [0.13724814 2.15745628] , error: 0.479280129632617\n",
      "Step: 2307 Weights: [0.13774736 2.15739918] , error: 0.47925491040261237\n",
      "Step: 2308 Weights: [0.13824544 2.15734222] , error: 0.4792298060621015\n",
      "Step: 2309 Weights: [0.13874239 2.15728539] , error: 0.4792048160876925\n",
      "Step: 2310 Weights: [0.1392382  2.15722868] , error: 0.4791799399583734\n",
      "Step: 2311 Weights: [0.13973288 2.15717211] , error: 0.47915517715551026\n",
      "Step: 2312 Weights: [0.14022644 2.15711567] , error: 0.4791305271628285\n",
      "Step: 2313 Weights: [0.14071887 2.15705935] , error: 0.4791059894664058\n",
      "Step: 2314 Weights: [0.14121017 2.15700316] , error: 0.4790815635546639\n",
      "Step: 2315 Weights: [0.14170036 2.1569471 ] , error: 0.4790572489183509\n",
      "Step: 2316 Weights: [0.14218942 2.15689117] , error: 0.4790330450505381\n",
      "Step: 2317 Weights: [0.14267738 2.15683537] , error: 0.4790089514466057\n",
      "Step: 2318 Weights: [0.14316421 2.15677969] , error: 0.4789849676042309\n",
      "Step: 2319 Weights: [0.14364994 2.15672414] , error: 0.4789610930233834\n",
      "Step: 2320 Weights: [0.14413456 2.15666872] , error: 0.4789373272063038\n",
      "Step: 2321 Weights: [0.14461808 2.15661342] , error: 0.4789136696575078\n",
      "Step: 2322 Weights: [0.14510049 2.15655825] , error: 0.4788901198837636\n",
      "Step: 2323 Weights: [0.14558181 2.1565032 ] , error: 0.4788666773940877\n",
      "Step: 2324 Weights: [0.14606202 2.15644828] , error: 0.47884334169973525\n",
      "Step: 2325 Weights: [0.14654114 2.15639349] , error: 0.478820112314185\n",
      "Step: 2326 Weights: [0.14701917 2.15633882] , error: 0.4787969887531338\n",
      "Step: 2327 Weights: [0.14749611 2.15628427] , error: 0.47877397053448234\n",
      "Step: 2328 Weights: [0.14797196 2.15622985] , error: 0.47875105717833194\n",
      "Step: 2329 Weights: [0.14844673 2.15617556] , error: 0.47872824820696797\n",
      "Step: 2330 Weights: [0.14892041 2.15612139] , error: 0.4787055431448499\n",
      "Step: 2331 Weights: [0.14939301 2.15606734] , error: 0.4786829415186077\n",
      "Step: 2332 Weights: [0.14986454 2.15601341] , error: 0.478660442857025\n",
      "Step: 2333 Weights: [0.15033498 2.15595961] , error: 0.4786380466910303\n",
      "Step: 2334 Weights: [0.15080436 2.15590593] , error: 0.47861575255369426\n",
      "Step: 2335 Weights: [0.15127267 2.15585237] , error: 0.478593559980212\n",
      "Step: 2336 Weights: [0.15173991 2.15579894] , error: 0.4785714685078968\n",
      "Step: 2337 Weights: [0.15220608 2.15574562] , error: 0.47854947767616685\n",
      "Step: 2338 Weights: [0.15267119 2.15569243] , error: 0.4785275870265424\n",
      "Step: 2339 Weights: [0.15313524 2.15563936] , error: 0.47850579610263044\n",
      "Step: 2340 Weights: [0.15359823 2.15558641] , error: 0.4784841044501168\n",
      "Step: 2341 Weights: [0.15406016 2.15553358] , error: 0.478462511616758\n",
      "Step: 2342 Weights: [0.15452104 2.15548087] , error: 0.47844101715237075\n",
      "Step: 2343 Weights: [0.15498087 2.15542829] , error: 0.4784196206088239\n",
      "Step: 2344 Weights: [0.15543966 2.15537582] , error: 0.4783983215400231\n",
      "Step: 2345 Weights: [0.15589739 2.15532347] , error: 0.47837711950191186\n",
      "Step: 2346 Weights: [0.15635408 2.15527124] , error: 0.47835601405245254\n",
      "Step: 2347 Weights: [0.15680973 2.15521913] , error: 0.47833500475162355\n",
      "Step: 2348 Weights: [0.15726435 2.15516714] , error: 0.4783140911614081\n",
      "Step: 2349 Weights: [0.15771792 2.15511527] , error: 0.47829327284578294\n",
      "Step: 2350 Weights: [0.15817046 2.15506351] , error: 0.47827254937071295\n",
      "Step: 2351 Weights: [0.15862197 2.15501187] , error: 0.47825192030413993\n",
      "Step: 2352 Weights: [0.15907245 2.15496036] , error: 0.47823138521597164\n",
      "Step: 2353 Weights: [0.1595219  2.15490895] , error: 0.4782109436780787\n",
      "Step: 2354 Weights: [0.15997033 2.15485767] , error: 0.4781905952642819\n",
      "Step: 2355 Weights: [0.16041773 2.1548065 ] , error: 0.47817033955033916\n",
      "Step: 2356 Weights: [0.16086411 2.15475545] , error: 0.4781501761139465\n",
      "Step: 2357 Weights: [0.16130948 2.15470452] , error: 0.4781301045347212\n",
      "Step: 2358 Weights: [0.16175383 2.1546537 ] , error: 0.4781101243941956\n",
      "Step: 2359 Weights: [0.16219717 2.154603  ] , error: 0.47809023527580763\n",
      "Step: 2360 Weights: [0.16263949 2.15455241] , error: 0.47807043676489613\n",
      "Step: 2361 Weights: [0.16308081 2.15450194] , error: 0.47805072844868546\n",
      "Step: 2362 Weights: [0.16352112 2.15445159] , error: 0.47803110991628217\n",
      "Step: 2363 Weights: [0.16396043 2.15440135] , error: 0.4780115807586658\n",
      "Step: 2364 Weights: [0.16439873 2.15435122] , error: 0.47799214056867645\n",
      "Step: 2365 Weights: [0.16483604 2.15430121] , error: 0.47797278894100936\n",
      "Step: 2366 Weights: [0.16527235 2.15425131] , error: 0.4779535254722092\n",
      "Step: 2367 Weights: [0.16570766 2.15420153] , error: 0.47793434976065663\n",
      "Step: 2368 Weights: [0.16614198 2.15415185] , error: 0.4779152614065616\n",
      "Step: 2369 Weights: [0.16657531 2.1541023 ] , error: 0.47789626001195545\n",
      "Step: 2370 Weights: [0.16700765 2.15405285] , error: 0.4778773451806836\n",
      "Step: 2371 Weights: [0.16743901 2.15400352] , error: 0.477858516518394\n",
      "Step: 2372 Weights: [0.16786938 2.1539543 ] , error: 0.4778397736325358\n",
      "Step: 2373 Weights: [0.16829877 2.15390519] , error: 0.47782111613233924\n",
      "Step: 2374 Weights: [0.16872718 2.1538562 ] , error: 0.4778025436288209\n",
      "Step: 2375 Weights: [0.16915462 2.15380732] , error: 0.47778405573476834\n",
      "Step: 2376 Weights: [0.16958108 2.15375854] , error: 0.4777656520647305\n",
      "Step: 2377 Weights: [0.17000656 2.15370988] , error: 0.4777473322350142\n",
      "Step: 2378 Weights: [0.17043108 2.15366133] , error: 0.47772909586367246\n",
      "Step: 2379 Weights: [0.17085463 2.1536129 ] , error: 0.47771094257050295\n",
      "Step: 2380 Weights: [0.17127721 2.15356457] , error: 0.47769287197703064\n",
      "Step: 2381 Weights: [0.17169883 2.15351635] , error: 0.4776748837065057\n",
      "Step: 2382 Weights: [0.17211949 2.15346824] , error: 0.47765697738389545\n",
      "Step: 2383 Weights: [0.17253919 2.15342024] , error: 0.4776391526358752\n",
      "Step: 2384 Weights: [0.17295793 2.15337235] , error: 0.4776214090908232\n",
      "Step: 2385 Weights: [0.17337572 2.15332457] , error: 0.47760374637880576\n",
      "Step: 2386 Weights: [0.17379255 2.1532769 ] , error: 0.4775861641315805\n",
      "Step: 2387 Weights: [0.17420844 2.15322934] , error: 0.4775686619825765\n",
      "Step: 2388 Weights: [0.17462337 2.15318189] , error: 0.4775512395668986\n",
      "Step: 2389 Weights: [0.17503736 2.15313454] , error: 0.4775338965213096\n",
      "Step: 2390 Weights: [0.1754504 2.1530873] , error: 0.47751663248422843\n",
      "Step: 2391 Weights: [0.17586251 2.15304017] , error: 0.47749944709572234\n",
      "Step: 2392 Weights: [0.17627367 2.15299315] , error: 0.47748233999749795\n",
      "Step: 2393 Weights: [0.1766839  2.15294624] , error: 0.4774653108328919\n",
      "Step: 2394 Weights: [0.17709319 2.15289943] , error: 0.4774483592468699\n",
      "Step: 2395 Weights: [0.17750154 2.15285273] , error: 0.4774314848860096\n",
      "Step: 2396 Weights: [0.17790897 2.15280613] , error: 0.4774146873985046\n",
      "Step: 2397 Weights: [0.17831547 2.15275964] , error: 0.47739796643414645\n",
      "Step: 2398 Weights: [0.17872103 2.15271326] , error: 0.4773813216443251\n",
      "Step: 2399 Weights: [0.17912568 2.15266698] , error: 0.4773647526820163\n",
      "Step: 2400 Weights: [0.1795294  2.15262081] , error: 0.4773482592017778\n",
      "Step: 2401 Weights: [0.1799322  2.15257475] , error: 0.47733184085974256\n",
      "Step: 2402 Weights: [0.18033408 2.15252879] , error: 0.47731549731360867\n",
      "Step: 2403 Weights: [0.18073505 2.15248293] , error: 0.47729922822263227\n",
      "Step: 2404 Weights: [0.1811351  2.15243718] , error: 0.4772830332476241\n",
      "Step: 2405 Weights: [0.18153424 2.15239153] , error: 0.47726691205093896\n",
      "Step: 2406 Weights: [0.18193247 2.15234599] , error: 0.4772508642964699\n",
      "Step: 2407 Weights: [0.18232979 2.15230055] , error: 0.4772348896496419\n",
      "Step: 2408 Weights: [0.18272621 2.15225521] , error: 0.4772189877774031\n",
      "Step: 2409 Weights: [0.18312172 2.15220998] , error: 0.4772031583482194\n",
      "Step: 2410 Weights: [0.18351633 2.15216485] , error: 0.477187401032066\n",
      "Step: 2411 Weights: [0.18391004 2.15211982] , error: 0.47717171550042436\n",
      "Step: 2412 Weights: [0.18430285 2.1520749 ] , error: 0.47715610142627046\n",
      "Step: 2413 Weights: [0.18469476 2.15203008] , error: 0.47714055848406983\n",
      "Step: 2414 Weights: [0.18508579 2.15198536] , error: 0.47712508634977113\n",
      "Step: 2415 Weights: [0.18547592 2.15194074] , error: 0.47710968470080095\n",
      "Step: 2416 Weights: [0.18586516 2.15189623] , error: 0.477094353216053\n",
      "Step: 2417 Weights: [0.18625351 2.15185182] , error: 0.47707909157588546\n",
      "Step: 2418 Weights: [0.18664098 2.1518075 ] , error: 0.4770638994621124\n",
      "Step: 2419 Weights: [0.18702756 2.15176329] , error: 0.47704877655799627\n",
      "Step: 2420 Weights: [0.18741326 2.15171918] , error: 0.4770337225482454\n",
      "Step: 2421 Weights: [0.18779809 2.15167517] , error: 0.4770187371190008\n",
      "Step: 2422 Weights: [0.18818203 2.15163126] , error: 0.47700381995783603\n",
      "Step: 2423 Weights: [0.1885651  2.15158745] , error: 0.4769889707537458\n",
      "Step: 2424 Weights: [0.1889473  2.15154374] , error: 0.47697418919714424\n",
      "Step: 2425 Weights: [0.18932862 2.15150013] , error: 0.47695947497985314\n",
      "Step: 2426 Weights: [0.18970908 2.15145662] , error: 0.476944827795101\n",
      "Step: 2427 Weights: [0.19008866 2.15141321] , error: 0.4769302473375096\n",
      "Step: 2428 Weights: [0.19046739 2.1513699 ] , error: 0.4769157333030973\n",
      "Step: 2429 Weights: [0.19084524 2.15132669] , error: 0.4769012853892639\n",
      "Step: 2430 Weights: [0.19122224 2.15128357] , error: 0.4768869032947878\n",
      "Step: 2431 Weights: [0.19159838 2.15124055] , error: 0.4768725867198207\n",
      "Step: 2432 Weights: [0.19197365 2.15119764] , error: 0.4768583353658814\n",
      "Step: 2433 Weights: [0.19234808 2.15115481] , error: 0.47684414893584376\n",
      "Step: 2434 Weights: [0.19272165 2.15111209] , error: 0.4768300271339412\n",
      "Step: 2435 Weights: [0.19309436 2.15106947] , error: 0.47681596966575\n",
      "Step: 2436 Weights: [0.19346623 2.15102694] , error: 0.47680197623819176\n",
      "Step: 2437 Weights: [0.19383725 2.15098451] , error: 0.476788046559519\n",
      "Step: 2438 Weights: [0.19420742 2.15094217] , error: 0.47677418033931623\n",
      "Step: 2439 Weights: [0.19457675 2.15089993] , error: 0.47676037728849086\n",
      "Step: 2440 Weights: [0.19494524 2.15085779] , error: 0.47674663711926385\n",
      "Step: 2441 Weights: [0.19531289 2.15081575] , error: 0.4767329595451739\n",
      "Step: 2442 Weights: [0.1956797 2.1507738] , error: 0.476719344281056\n",
      "Step: 2443 Weights: [0.19604567 2.15073194] , error: 0.4767057910430533\n",
      "Step: 2444 Weights: [0.1964108  2.15069018] , error: 0.47669229954859516\n",
      "Step: 2445 Weights: [0.19677511 2.15064852] , error: 0.4766788695164016\n",
      "Step: 2446 Weights: [0.19713858 2.15060695] , error: 0.47666550066647206\n",
      "Step: 2447 Weights: [0.19750123 2.15056548] , error: 0.47665219272008524\n",
      "Step: 2448 Weights: [0.19786305 2.1505241 ] , error: 0.476638945399784\n",
      "Step: 2449 Weights: [0.19822404 2.15048282] , error: 0.4766257584293815\n",
      "Step: 2450 Weights: [0.19858421 2.15044162] , error: 0.4766126315339432\n",
      "Step: 2451 Weights: [0.19894356 2.15040053] , error: 0.4765995644397923\n",
      "Step: 2452 Weights: [0.19930208 2.15035953] , error: 0.4765865568744938\n",
      "Step: 2453 Weights: [0.1996598  2.15031862] , error: 0.4765736085668577\n",
      "Step: 2454 Weights: [0.20001669 2.1502778 ] , error: 0.476560719246927\n",
      "Step: 2455 Weights: [0.20037277 2.15023708] , error: 0.4765478886459761\n",
      "Step: 2456 Weights: [0.20072804 2.15019645] , error: 0.4765351164965032\n",
      "Step: 2457 Weights: [0.2010825  2.15015591] , error: 0.4765224025322249\n",
      "Step: 2458 Weights: [0.20143615 2.15011546] , error: 0.47650974648807065\n",
      "Step: 2459 Weights: [0.201789   2.15007511] , error: 0.4764971481001784\n",
      "Step: 2460 Weights: [0.20214104 2.15003485] , error: 0.4764846071058869\n",
      "Step: 2461 Weights: [0.20249228 2.14999468] , error: 0.47647212324373134\n",
      "Step: 2462 Weights: [0.20284271 2.1499546 ] , error: 0.4764596962534402\n",
      "Step: 2463 Weights: [0.20319235 2.14991462] , error: 0.47644732587592586\n",
      "Step: 2464 Weights: [0.20354119 2.14987472] , error: 0.47643501185328113\n",
      "Step: 2465 Weights: [0.20388923 2.14983492] , error: 0.4764227539287747\n",
      "Step: 2466 Weights: [0.20423648 2.14979521] , error: 0.4764105518468432\n",
      "Step: 2467 Weights: [0.20458294 2.14975558] , error: 0.47639840535308986\n",
      "Step: 2468 Weights: [0.20492861 2.14971605] , error: 0.47638631419427335\n",
      "Step: 2469 Weights: [0.20527349 2.14967661] , error: 0.47637427811831007\n",
      "Step: 2470 Weights: [0.20561758 2.14963726] , error: 0.47636229687426335\n",
      "Step: 2471 Weights: [0.20596089 2.149598  ] , error: 0.4763503702123366\n",
      "Step: 2472 Weights: [0.20630342 2.14955882] , error: 0.4763384978838761\n",
      "Step: 2473 Weights: [0.20664517 2.14951974] , error: 0.47632667964135844\n",
      "Step: 2474 Weights: [0.20698613 2.14948075] , error: 0.47631491523838554\n",
      "Step: 2475 Weights: [0.20732632 2.14944184] , error: 0.4763032044296882\n",
      "Step: 2476 Weights: [0.20766573 2.14940302] , error: 0.47629154697110904\n",
      "Step: 2477 Weights: [0.20800437 2.14936429] , error: 0.47627994261960294\n",
      "Step: 2478 Weights: [0.20834224 2.14932566] , error: 0.4762683911332354\n",
      "Step: 2479 Weights: [0.20867933 2.1492871 ] , error: 0.4762568922711732\n",
      "Step: 2480 Weights: [0.20901566 2.14924864] , error: 0.4762454457936782\n",
      "Step: 2481 Weights: [0.20935122 2.14921026] , error: 0.47623405146210546\n",
      "Step: 2482 Weights: [0.20968602 2.14917197] , error: 0.47622270903889763\n",
      "Step: 2483 Weights: [0.21002005 2.14913377] , error: 0.4762114182875797\n",
      "Step: 2484 Weights: [0.21035332 2.14909566] , error: 0.47620017897275435\n",
      "Step: 2485 Weights: [0.21068583 2.14905763] , error: 0.4761889908600942\n",
      "Step: 2486 Weights: [0.21101758 2.14901969] , error: 0.4761778537163413\n",
      "Step: 2487 Weights: [0.21134857 2.14898184] , error: 0.4761667673093026\n",
      "Step: 2488 Weights: [0.21167881 2.14894407] , error: 0.47615573140783773\n",
      "Step: 2489 Weights: [0.2120083  2.14890639] , error: 0.4761447457818625\n",
      "Step: 2490 Weights: [0.21233704 2.14886879] , error: 0.47613381020234\n",
      "Step: 2491 Weights: [0.21266502 2.14883128] , error: 0.4761229244412791\n",
      "Step: 2492 Weights: [0.21299226 2.14879386] , error: 0.4761120882717239\n",
      "Step: 2493 Weights: [0.21331875 2.14875652] , error: 0.47610130146775337\n",
      "Step: 2494 Weights: [0.2136445  2.14871927] , error: 0.4760905638044765\n",
      "Step: 2495 Weights: [0.2139695 2.1486821] , error: 0.4760798750580268\n",
      "Step: 2496 Weights: [0.21429377 2.14864501] , error: 0.47606923500555753\n",
      "Step: 2497 Weights: [0.21461729 2.14860801] , error: 0.47605864342523607\n",
      "Step: 2498 Weights: [0.21494008 2.1485711 ] , error: 0.47604810009624127\n",
      "Step: 2499 Weights: [0.21526213 2.14853427] , error: 0.4760376047987579\n",
      "Step: 2500 Weights: [0.21558344 2.14849752] , error: 0.4760271573139728\n",
      "Step: 2501 Weights: [0.21590403 2.14846086] , error: 0.4760167574240696\n",
      "Step: 2502 Weights: [0.21622388 2.14842428] , error: 0.47600640491222135\n",
      "Step: 2503 Weights: [0.216543   2.14838778] , error: 0.47599609956259414\n",
      "Step: 2504 Weights: [0.2168614  2.14835137] , error: 0.4759858411603311\n",
      "Step: 2505 Weights: [0.21717906 2.14831504] , error: 0.47597562949155936\n",
      "Step: 2506 Weights: [0.21749601 2.14827879] , error: 0.47596546434337794\n",
      "Step: 2507 Weights: [0.21781223 2.14824263] , error: 0.4759553455038552\n",
      "Step: 2508 Weights: [0.21812773 2.14820654] , error: 0.47594527276202786\n",
      "Step: 2509 Weights: [0.21844251 2.14817055] , error: 0.4759352459078922\n",
      "Step: 2510 Weights: [0.21875658 2.14813463] , error: 0.47592526473239755\n",
      "Step: 2511 Weights: [0.21906992 2.14809879] , error: 0.4759153290274527\n",
      "Step: 2512 Weights: [0.21938255 2.14806304] , error: 0.4759054385859084\n",
      "Step: 2513 Weights: [0.21969447 2.14802737] , error: 0.47589559320156166\n",
      "Step: 2514 Weights: [0.22000568 2.14799177] , error: 0.47588579266914793\n",
      "Step: 2515 Weights: [0.22031618 2.14795626] , error: 0.47587603678433976\n",
      "Step: 2516 Weights: [0.22062597 2.14792084] , error: 0.47586632534373907\n",
      "Step: 2517 Weights: [0.22093505 2.14788549] , error: 0.4758566581448733\n",
      "Step: 2518 Weights: [0.22124343 2.14785022] , error: 0.47584703498619424\n",
      "Step: 2519 Weights: [0.22155111 2.14781503] , error: 0.4758374556670713\n",
      "Step: 2520 Weights: [0.22185808 2.14777993] , error: 0.47582791998778695\n",
      "Step: 2521 Weights: [0.22216436 2.1477449 ] , error: 0.47581842774953453\n",
      "Step: 2522 Weights: [0.22246993 2.14770995] , error: 0.4758089787544135\n",
      "Step: 2523 Weights: [0.22277481 2.14767509] , error: 0.475799572805422\n",
      "Step: 2524 Weights: [0.223079  2.1476403] , error: 0.47579020970646035\n",
      "Step: 2525 Weights: [0.22338249 2.14760559] , error: 0.47578088926231743\n",
      "Step: 2526 Weights: [0.22368528 2.14757096] , error: 0.4757716112786755\n",
      "Step: 2527 Weights: [0.22398739 2.14753641] , error: 0.4757623755620991\n",
      "Step: 2528 Weights: [0.22428881 2.14750194] , error: 0.47575318192003546\n",
      "Step: 2529 Weights: [0.22458954 2.14746755] , error: 0.47574403016080863\n",
      "Step: 2530 Weights: [0.22488959 2.14743323] , error: 0.47573492009361545\n",
      "Step: 2531 Weights: [0.22518895 2.14739899] , error: 0.4757258515285231\n",
      "Step: 2532 Weights: [0.22548763 2.14736484] , error: 0.4757168242764628\n",
      "Step: 2533 Weights: [0.22578562 2.14733076] , error: 0.4757078381492281\n",
      "Step: 2534 Weights: [0.22608294 2.14729675] , error: 0.475698892959469\n",
      "Step: 2535 Weights: [0.22637958 2.14726283] , error: 0.47568998852069\n",
      "Step: 2536 Weights: [0.22667554 2.14722898] , error: 0.4756811246472444\n",
      "Step: 2537 Weights: [0.22697083 2.14719521] , error: 0.4756723011543308\n",
      "Step: 2538 Weights: [0.22726545 2.14716152] , error: 0.4756635178579919\n",
      "Step: 2539 Weights: [0.22755939 2.1471279 ] , error: 0.47565477457510563\n",
      "Step: 2540 Weights: [0.22785266 2.14709436] , error: 0.4756460711233864\n",
      "Step: 2541 Weights: [0.22814527 2.1470609 ] , error: 0.47563740732137794\n",
      "Step: 2542 Weights: [0.2284372  2.14702751] , error: 0.4756287829884503\n",
      "Step: 2543 Weights: [0.22872847 2.1469942 ] , error: 0.47562019794479815\n",
      "Step: 2544 Weights: [0.22901908 2.14696096] , error: 0.47561165201143263\n",
      "Step: 2545 Weights: [0.22930903 2.1469278 ] , error: 0.47560314501018164\n",
      "Step: 2546 Weights: [0.22959831 2.14689472] , error: 0.4755946767636864\n",
      "Step: 2547 Weights: [0.22988693 2.14686171] , error: 0.4755862470953937\n",
      "Step: 2548 Weights: [0.2301749  2.14682878] , error: 0.4755778558295553\n",
      "Step: 2549 Weights: [0.2304622  2.14679592] , error: 0.4755695027912235\n",
      "Step: 2550 Weights: [0.23074886 2.14676314] , error: 0.475561187806248\n",
      "Step: 2551 Weights: [0.23103486 2.14673043] , error: 0.4755529107012732\n",
      "Step: 2552 Weights: [0.2313202 2.1466978] , error: 0.47554467130372896\n",
      "Step: 2553 Weights: [0.2316049  2.14666524] , error: 0.47553646944183875\n",
      "Step: 2554 Weights: [0.23188895 2.14663275] , error: 0.47552830494460047\n",
      "Step: 2555 Weights: [0.23217235 2.14660034] , error: 0.47552017764179455\n",
      "Step: 2556 Weights: [0.2324551  2.14656801] , error: 0.4755120873639778\n",
      "Step: 2557 Weights: [0.23273721 2.14653574] , error: 0.4755040339424784\n",
      "Step: 2558 Weights: [0.23301868 2.14650355] , error: 0.47549601720939044\n",
      "Step: 2559 Weights: [0.2332995  2.14647144] , error: 0.47548803699757836\n",
      "Step: 2560 Weights: [0.23357968 2.14643939] , error: 0.47548009314066253\n",
      "Step: 2561 Weights: [0.23385923 2.14640742] , error: 0.47547218547302394\n",
      "Step: 2562 Weights: [0.23413813 2.14637553] , error: 0.4754643138297977\n",
      "Step: 2563 Weights: [0.2344164 2.1463437] , error: 0.4754564780468707\n",
      "Step: 2564 Weights: [0.23469404 2.14631195] , error: 0.4754486779608749\n",
      "Step: 2565 Weights: [0.23497104 2.14628027] , error: 0.47544091340918954\n",
      "Step: 2566 Weights: [0.23524741 2.14624867] , error: 0.47543318422993364\n",
      "Step: 2567 Weights: [0.23552315 2.14621713] , error: 0.47542549026196124\n",
      "Step: 2568 Weights: [0.23579827 2.14618567] , error: 0.47541783134486615\n",
      "Step: 2569 Weights: [0.23607275 2.14615428] , error: 0.475410207318967\n",
      "Step: 2570 Weights: [0.23634661 2.14612296] , error: 0.475402618025314\n",
      "Step: 2571 Weights: [0.23661984 2.14609171] , error: 0.47539506330567854\n",
      "Step: 2572 Weights: [0.23689246 2.14606053] , error: 0.4753875430025542\n",
      "Step: 2573 Weights: [0.23716444 2.14602943] , error: 0.47538005695915403\n",
      "Step: 2574 Weights: [0.23743581 2.14599839] , error: 0.4753726050194008\n",
      "Step: 2575 Weights: [0.23770656 2.14596743] , error: 0.47536518702793223\n",
      "Step: 2576 Weights: [0.2379767  2.14593653] , error: 0.47535780283009194\n",
      "Step: 2577 Weights: [0.23824621 2.14590571] , error: 0.4753504522719292\n",
      "Step: 2578 Weights: [0.23851512 2.14587496] , error: 0.4753431352001941\n",
      "Step: 2579 Weights: [0.23878341 2.14584427] , error: 0.47533585146233437\n",
      "Step: 2580 Weights: [0.23905108 2.14581366] , error: 0.4753286009064941\n",
      "Step: 2581 Weights: [0.23931815 2.14578312] , error: 0.4753213833815065\n",
      "Step: 2582 Weights: [0.23958461 2.14575265] , error: 0.47531419873689634\n",
      "Step: 2583 Weights: [0.23985046 2.14572224] , error: 0.47530704682287395\n",
      "Step: 2584 Weights: [0.2401157  2.14569191] , error: 0.4752999274903283\n",
      "Step: 2585 Weights: [0.24038034 2.14566164] , error: 0.4752928405908329\n",
      "Step: 2586 Weights: [0.24064438 2.14563145] , error: 0.47528578597663307\n",
      "Step: 2587 Weights: [0.24090781 2.14560132] , error: 0.4752787635006481\n",
      "Step: 2588 Weights: [0.24117064 2.14557126] , error: 0.47527177301647033\n",
      "Step: 2589 Weights: [0.24143288 2.14554127] , error: 0.4752648143783552\n",
      "Step: 2590 Weights: [0.24169451 2.14551135] , error: 0.47525788744122466\n",
      "Step: 2591 Weights: [0.24195555 2.14548149] , error: 0.47525099206066207\n",
      "Step: 2592 Weights: [0.242216   2.14545171] , error: 0.4752441280929045\n",
      "Step: 2593 Weights: [0.24247585 2.14542199] , error: 0.4752372953948479\n",
      "Step: 2594 Weights: [0.2427351  2.14539234] , error: 0.4752304938240397\n",
      "Step: 2595 Weights: [0.24299377 2.14536276] , error: 0.4752237232386759\n",
      "Step: 2596 Weights: [0.24325184 2.14533325] , error: 0.4752169834975966\n",
      "Step: 2597 Weights: [0.24350933 2.1453038 ] , error: 0.47521027446028874\n",
      "Step: 2598 Weights: [0.24376623 2.14527442] , error: 0.47520359598687556\n",
      "Step: 2599 Weights: [0.24402255 2.1452451 ] , error: 0.47519694793812034\n",
      "Step: 2600 Weights: [0.24427828 2.14521586] , error: 0.47519033017541884\n",
      "Step: 2601 Weights: [0.24453342 2.14518668] , error: 0.47518374256080087\n",
      "Step: 2602 Weights: [0.24478799 2.14515757] , error: 0.47517718495691985\n",
      "Step: 2603 Weights: [0.24504197 2.14512852] , error: 0.47517065722705965\n",
      "Step: 2604 Weights: [0.24529538 2.14509954] , error: 0.47516415923512484\n",
      "Step: 2605 Weights: [0.24554821 2.14507062] , error: 0.47515769084564136\n",
      "Step: 2606 Weights: [0.24580046 2.14504178] , error: 0.47515125192374946\n",
      "Step: 2607 Weights: [0.24605213 2.14501299] , error: 0.4751448423352083\n",
      "Step: 2608 Weights: [0.24630323 2.14498428] , error: 0.47513846194638454\n",
      "Step: 2609 Weights: [0.24655376 2.14495562] , error: 0.4751321106242543\n",
      "Step: 2610 Weights: [0.24680372 2.14492704] , error: 0.4751257882364014\n",
      "Step: 2611 Weights: [0.24705311 2.14489852] , error: 0.47511949465101155\n",
      "Step: 2612 Weights: [0.24730193 2.14487006] , error: 0.475113229736872\n",
      "Step: 2613 Weights: [0.24755018 2.14484167] , error: 0.4751069933633665\n",
      "Step: 2614 Weights: [0.24779786 2.14481334] , error: 0.47510078540047507\n",
      "Step: 2615 Weights: [0.24804499 2.14478508] , error: 0.4750946057187686\n",
      "Step: 2616 Weights: [0.24829154 2.14475688] , error: 0.4750884541894099\n",
      "Step: 2617 Weights: [0.24853754 2.14472875] , error: 0.4750823306841455\n",
      "Step: 2618 Weights: [0.24878297 2.14470068] , error: 0.4750762350753088\n",
      "Step: 2619 Weights: [0.24902785 2.14467268] , error: 0.4750701672358142\n",
      "Step: 2620 Weights: [0.24927216 2.14464474] , error: 0.47506412703915557\n",
      "Step: 2621 Weights: [0.24951592 2.14461686] , error: 0.4750581143593994\n",
      "Step: 2622 Weights: [0.24975912 2.14458905] , error: 0.4750521290711929\n",
      "Step: 2623 Weights: [0.25000177 2.1445613 ] , error: 0.4750461710497472\n",
      "Step: 2624 Weights: [0.25024387 2.14453361] , error: 0.4750402401708458\n",
      "Step: 2625 Weights: [0.25048541 2.14450598] , error: 0.475034336310838\n",
      "Step: 2626 Weights: [0.2507264  2.14447842] , error: 0.4750284593466359\n",
      "Step: 2627 Weights: [0.25096684 2.14445093] , error: 0.4750226091557106\n",
      "Step: 2628 Weights: [0.25120674 2.14442349] , error: 0.47501678561609406\n",
      "Step: 2629 Weights: [0.25144608 2.14439612] , error: 0.4750109886063731\n",
      "Step: 2630 Weights: [0.25168489 2.14436881] , error: 0.47500521800568574\n",
      "Step: 2631 Weights: [0.25192314 2.14434156] , error: 0.4749994736937236\n",
      "Step: 2632 Weights: [0.25216086 2.14431437] , error: 0.4749937555507242\n",
      "Step: 2633 Weights: [0.25239803 2.14428725] , error: 0.4749880634574725\n",
      "Step: 2634 Weights: [0.25263466 2.14426019] , error: 0.474982397295295\n",
      "Step: 2635 Weights: [0.25287075 2.14423319] , error: 0.4749767569460588\n",
      "Step: 2636 Weights: [0.2531063  2.14420625] , error: 0.47497114229216925\n",
      "Step: 2637 Weights: [0.25334132 2.14417937] , error: 0.47496555321656925\n",
      "Step: 2638 Weights: [0.25357579 2.14415255] , error: 0.47495998960273283\n",
      "Step: 2639 Weights: [0.25380974 2.1441258 ] , error: 0.4749544513346652\n",
      "Step: 2640 Weights: [0.25404315 2.14409911] , error: 0.47494893829690105\n",
      "Step: 2641 Weights: [0.25427603 2.14407247] , error: 0.4749434503745002\n",
      "Step: 2642 Weights: [0.25450838 2.1440459 ] , error: 0.4749379874530468\n",
      "Step: 2643 Weights: [0.25474019 2.14401939] , error: 0.4749325494186446\n",
      "Step: 2644 Weights: [0.25497148 2.14399294] , error: 0.47492713615791793\n",
      "Step: 2645 Weights: [0.25520225 2.14396655] , error: 0.4749217475580084\n",
      "Step: 2646 Weights: [0.25543248 2.14394022] , error: 0.4749163835065686\n",
      "Step: 2647 Weights: [0.25566219 2.14391395] , error: 0.4749110438917653\n",
      "Step: 2648 Weights: [0.25589138 2.14388773] , error: 0.47490572860227453\n",
      "Step: 2649 Weights: [0.25612004 2.14386158] , error: 0.4749004375272782\n",
      "Step: 2650 Weights: [0.25634819 2.14383549] , error: 0.474895170556466\n",
      "Step: 2651 Weights: [0.25657581 2.14380946] , error: 0.4748899275800263\n",
      "Step: 2652 Weights: [0.25680291 2.14378349] , error: 0.47488470848865166\n",
      "Step: 2653 Weights: [0.2570295  2.14375757] , error: 0.47487951317352683\n",
      "Step: 2654 Weights: [0.25725557 2.14373172] , error: 0.4748743415263397\n",
      "Step: 2655 Weights: [0.25748112 2.14370593] , error: 0.47486919343926715\n",
      "Step: 2656 Weights: [0.25770616 2.14368019] , error: 0.47486406880497667\n",
      "Step: 2657 Weights: [0.25793068 2.14365451] , error: 0.4748589675166259\n",
      "Step: 2658 Weights: [0.2581547  2.14362889] , error: 0.47485388946786206\n",
      "Step: 2659 Weights: [0.2583782  2.14360333] , error: 0.47484883455281124\n",
      "Step: 2660 Weights: [0.25860119 2.14357783] , error: 0.4748438026660856\n",
      "Step: 2661 Weights: [0.25882368 2.14355238] , error: 0.4748387937027773\n",
      "Step: 2662 Weights: [0.25904565 2.143527  ] , error: 0.47483380755845583\n",
      "Step: 2663 Weights: [0.25926713 2.14350167] , error: 0.47482884412916443\n",
      "Step: 2664 Weights: [0.25948809 2.1434764 ] , error: 0.47482390331142443\n",
      "Step: 2665 Weights: [0.25970855 2.14345119] , error: 0.4748189850022251\n",
      "Step: 2666 Weights: [0.25992851 2.14342603] , error: 0.47481408909902395\n",
      "Step: 2667 Weights: [0.26014797 2.14340093] , error: 0.47480921549974875\n",
      "Step: 2668 Weights: [0.26036693 2.14337589] , error: 0.47480436410279286\n",
      "Step: 2669 Weights: [0.26058539 2.14335091] , error: 0.4747995348070098\n",
      "Step: 2670 Weights: [0.26080335 2.14332598] , error: 0.4747947275117125\n",
      "Step: 2671 Weights: [0.26102081 2.14330111] , error: 0.47478994211667674\n",
      "Step: 2672 Weights: [0.26123778 2.1432763 ] , error: 0.4747851785221343\n",
      "Step: 2673 Weights: [0.26145425 2.14325154] , error: 0.47478043662876745\n",
      "Step: 2674 Weights: [0.26167023 2.14322684] , error: 0.4747757163377146\n",
      "Step: 2675 Weights: [0.26188571 2.1432022 ] , error: 0.4747710175505645\n",
      "Step: 2676 Weights: [0.26210071 2.14317761] , error: 0.4747663401693531\n",
      "Step: 2677 Weights: [0.26231521 2.14315308] , error: 0.4747616840965624\n",
      "Step: 2678 Weights: [0.26252923 2.1431286 ] , error: 0.4747570492351185\n",
      "Step: 2679 Weights: [0.26274275 2.14310418] , error: 0.4747524354883911\n",
      "Step: 2680 Weights: [0.26295579 2.14307982] , error: 0.47474784276018983\n",
      "Step: 2681 Weights: [0.26316835 2.14305551] , error: 0.47474327095476143\n",
      "Step: 2682 Weights: [0.26338042 2.14303126] , error: 0.4747387199767894\n",
      "Step: 2683 Weights: [0.263592   2.14300706] , error: 0.4747341897313913\n",
      "Step: 2684 Weights: [0.26380311 2.14298292] , error: 0.47472968012411826\n",
      "Step: 2685 Weights: [0.26401373 2.14295883] , error: 0.47472519106094896\n",
      "Step: 2686 Weights: [0.26422387 2.1429348 ] , error: 0.4747207224482941\n",
      "Step: 2687 Weights: [0.26443353 2.14291082] , error: 0.47471627419298745\n",
      "Step: 2688 Weights: [0.26464272 2.14288689] , error: 0.4747118462022882\n",
      "Step: 2689 Weights: [0.26485142 2.14286303] , error: 0.4747074383838788\n",
      "Step: 2690 Weights: [0.26505966 2.14283921] , error: 0.47470305064586116\n",
      "Step: 2691 Weights: [0.26526741 2.14281545] , error: 0.47469868289675765\n",
      "Step: 2692 Weights: [0.2654747  2.14279175] , error: 0.47469433504550507\n",
      "Step: 2693 Weights: [0.26568151 2.14276809] , error: 0.47469000700145697\n",
      "Step: 2694 Weights: [0.26588784 2.1427445 ] , error: 0.47468569867437793\n",
      "Step: 2695 Weights: [0.26609371 2.14272095] , error: 0.47468140997444574\n",
      "Step: 2696 Weights: [0.26629911 2.14269746] , error: 0.47467714081224566\n",
      "Step: 2697 Weights: [0.26650404 2.14267403] , error: 0.47467289109877286\n",
      "Step: 2698 Weights: [0.2667085  2.14265064] , error: 0.4746686607454222\n",
      "Step: 2699 Weights: [0.2669125  2.14262731] , error: 0.4746644496639999\n",
      "Step: 2700 Weights: [0.26711603 2.14260404] , error: 0.4746602577667093\n",
      "Step: 2701 Weights: [0.2673191  2.14258081] , error: 0.47465608496615364\n",
      "Step: 2702 Weights: [0.2675217  2.14255764] , error: 0.47465193117533516\n",
      "Step: 2703 Weights: [0.26772385 2.14253452] , error: 0.4746477963076534\n",
      "Step: 2704 Weights: [0.26792553 2.14251146] , error: 0.4746436802769018\n",
      "Step: 2705 Weights: [0.26812675 2.14248845] , error: 0.474639582997265\n",
      "Step: 2706 Weights: [0.26832751 2.14246549] , error: 0.47463550438332014\n",
      "Step: 2707 Weights: [0.26852781 2.14244258] , error: 0.4746314443500338\n",
      "Step: 2708 Weights: [0.26872766 2.14241972] , error: 0.47462740281275967\n",
      "Step: 2709 Weights: [0.26892705 2.14239692] , error: 0.4746233796872368\n",
      "Step: 2710 Weights: [0.26912599 2.14237417] , error: 0.47461937488958633\n",
      "Step: 2711 Weights: [0.26932448 2.14235147] , error: 0.474615388336315\n",
      "Step: 2712 Weights: [0.26952251 2.14232882] , error: 0.47461141994430833\n",
      "Step: 2713 Weights: [0.26972009 2.14230623] , error: 0.47460746963082745\n",
      "Step: 2714 Weights: [0.26991722 2.14228368] , error: 0.47460353731351757\n",
      "Step: 2715 Weights: [0.27011389 2.14226119] , error: 0.4745996229103906\n",
      "Step: 2716 Weights: [0.27031013 2.14223875] , error: 0.47459572633983993\n",
      "Step: 2717 Weights: [0.27050591 2.14221636] , error: 0.47459184752062533\n",
      "Step: 2718 Weights: [0.27070125 2.14219402] , error: 0.474587986371876\n",
      "Step: 2719 Weights: [0.27089614 2.14217173] , error: 0.47458414281309513\n",
      "Step: 2720 Weights: [0.27109058 2.14214949] , error: 0.4745803167641479\n",
      "Step: 2721 Weights: [0.27128459 2.1421273 ] , error: 0.4745765081452661\n",
      "Step: 2722 Weights: [0.27147815 2.14210517] , error: 0.4745727168770453\n",
      "Step: 2723 Weights: [0.27167127 2.14208308] , error: 0.474568942880441\n",
      "Step: 2724 Weights: [0.27186395 2.14206104] , error: 0.47456518607677234\n",
      "Step: 2725 Weights: [0.27205619 2.14203906] , error: 0.47456144638771214\n",
      "Step: 2726 Weights: [0.27224799 2.14201712] , error: 0.474557723735294\n",
      "Step: 2727 Weights: [0.27243935 2.14199524] , error: 0.4745540180419053\n",
      "Step: 2728 Weights: [0.27263028 2.1419734 ] , error: 0.4745503292302863\n",
      "Step: 2729 Weights: [0.27282077 2.14195162] , error: 0.47454665722353023\n",
      "Step: 2730 Weights: [0.27301083 2.14192988] , error: 0.4745430019450797\n",
      "Step: 2731 Weights: [0.27320046 2.1419082 ] , error: 0.4745393633187285\n",
      "Step: 2732 Weights: [0.27338965 2.14188656] , error: 0.47453574126861475\n",
      "Step: 2733 Weights: [0.27357841 2.14186497] , error: 0.47453213571922276\n",
      "Step: 2734 Weights: [0.27376674 2.14184343] , error: 0.4745285465953816\n",
      "Step: 2735 Weights: [0.27395464 2.14182194] , error: 0.47452497382226216\n",
      "Step: 2736 Weights: [0.27414211 2.1418005 ] , error: 0.47452141732537767\n",
      "Step: 2737 Weights: [0.27432916 2.14177911] , error: 0.4745178770305792\n",
      "Step: 2738 Weights: [0.27451578 2.14175777] , error: 0.47451435286405574\n",
      "Step: 2739 Weights: [0.27470197 2.14173648] , error: 0.4745108447523335\n",
      "Step: 2740 Weights: [0.27488774 2.14171523] , error: 0.4745073526222723\n",
      "Step: 2741 Weights: [0.27507308 2.14169403] , error: 0.4745038764010655\n",
      "Step: 2742 Weights: [0.275258   2.14167289] , error: 0.47450041601623694\n",
      "Step: 2743 Weights: [0.2754425  2.14165179] , error: 0.4744969713956448\n",
      "Step: 2744 Weights: [0.27562658 2.14163073] , error: 0.4744935424674708\n",
      "Step: 2745 Weights: [0.27581024 2.14160973] , error: 0.4744901291602265\n",
      "Step: 2746 Weights: [0.27599348 2.14158877] , error: 0.4744867314027495\n",
      "Step: 2747 Weights: [0.27617631 2.14156786] , error: 0.47448334912419965\n",
      "Step: 2748 Weights: [0.27635871 2.141547  ] , error: 0.4744799822540616\n",
      "Step: 2749 Weights: [0.2765407  2.14152619] , error: 0.4744766307221413\n",
      "Step: 2750 Weights: [0.27672228 2.14150543] , error: 0.47447329445856\n",
      "Step: 2751 Weights: [0.27690344 2.14148471] , error: 0.4744699733937652\n",
      "Step: 2752 Weights: [0.27708419 2.14146404] , error: 0.47446666745851324\n",
      "Step: 2753 Weights: [0.27726452 2.14144341] , error: 0.4744633765838806\n",
      "Step: 2754 Weights: [0.27744445 2.14142284] , error: 0.4744601007012575\n",
      "Step: 2755 Weights: [0.27762396 2.14140231] , error: 0.4744568397423466\n",
      "Step: 2756 Weights: [0.27780307 2.14138182] , error: 0.4744535936391578\n",
      "Step: 2757 Weights: [0.27798176 2.14136139] , error: 0.4744503623240178\n",
      "Step: 2758 Weights: [0.27816005 2.141341  ] , error: 0.4744471457295548\n",
      "Step: 2759 Weights: [0.27833793 2.14132065] , error: 0.4744439437887075\n",
      "Step: 2760 Weights: [0.27851541 2.14130036] , error: 0.4744407564347214\n",
      "Step: 2761 Weights: [0.27869248 2.1412801 ] , error: 0.47443758360114024\n",
      "Step: 2762 Weights: [0.27886915 2.1412599 ] , error: 0.47443442522181795\n",
      "Step: 2763 Weights: [0.27904542 2.14123974] , error: 0.47443128123090467\n",
      "Step: 2764 Weights: [0.27922128 2.14121963] , error: 0.47442815156285234\n",
      "Step: 2765 Weights: [0.27939674 2.14119956] , error: 0.4744250361524112\n",
      "Step: 2766 Weights: [0.2795718  2.14117954] , error: 0.47442193493463\n",
      "Step: 2767 Weights: [0.27974647 2.14115957] , error: 0.474418847844851\n",
      "Step: 2768 Weights: [0.27992073 2.14113964] , error: 0.47441577481871194\n",
      "Step: 2769 Weights: [0.2800946  2.14111975] , error: 0.4744127157921452\n",
      "Step: 2770 Weights: [0.28026807 2.14109991] , error: 0.4744096707013733\n",
      "Step: 2771 Weights: [0.28044114 2.14108012] , error: 0.47440663948290984\n",
      "Step: 2772 Weights: [0.28061382 2.14106037] , error: 0.4744036220735585\n",
      "Step: 2773 Weights: [0.28078611 2.14104067] , error: 0.47440061841040876\n",
      "Step: 2774 Weights: [0.280958   2.14102101] , error: 0.47439762843083866\n",
      "Step: 2775 Weights: [0.28112951 2.1410014 ] , error: 0.4743946520725113\n",
      "Step: 2776 Weights: [0.28130062 2.14098183] , error: 0.47439168927337166\n",
      "Step: 2777 Weights: [0.28147134 2.1409623 ] , error: 0.47438873997165176\n",
      "Step: 2778 Weights: [0.28164167 2.14094282] , error: 0.4743858041058605\n",
      "Step: 2779 Weights: [0.28181161 2.14092339] , error: 0.47438288161478853\n",
      "Step: 2780 Weights: [0.28198117 2.140904  ] , error: 0.47437997243750674\n",
      "Step: 2781 Weights: [0.28215034 2.14088465] , error: 0.47437707651336236\n",
      "Step: 2782 Weights: [0.28231912 2.14086535] , error: 0.47437419378197754\n",
      "Step: 2783 Weights: [0.28248752 2.14084609] , error: 0.47437132418325223\n",
      "Step: 2784 Weights: [0.28265553 2.14082687] , error: 0.47436846765735874\n",
      "Step: 2785 Weights: [0.28282316 2.1408077 ] , error: 0.4743656241447413\n",
      "Step: 2786 Weights: [0.28299041 2.14078858] , error: 0.47436279358611744\n",
      "Step: 2787 Weights: [0.28315728 2.14076949] , error: 0.47435997592247336\n",
      "Step: 2788 Weights: [0.28332376 2.14075045] , error: 0.4743571710950638\n",
      "Step: 2789 Weights: [0.28348987 2.14073146] , error: 0.4743543790454107\n",
      "Step: 2790 Weights: [0.2836556 2.1407125] , error: 0.4743515997153056\n",
      "Step: 2791 Weights: [0.28382095 2.14069359] , error: 0.47434883304680037\n",
      "Step: 2792 Weights: [0.28398592 2.14067472] , error: 0.4743460789822156\n",
      "Step: 2793 Weights: [0.28415052 2.1406559 ] , error: 0.4743433374641313\n",
      "Step: 2794 Weights: [0.28431474 2.14063712] , error: 0.47434060843539044\n",
      "Step: 2795 Weights: [0.28447859 2.14061838] , error: 0.47433789183909664\n",
      "Step: 2796 Weights: [0.28464206 2.14059969] , error: 0.4743351876186119\n",
      "Step: 2797 Weights: [0.28480516 2.14058103] , error: 0.4743324957175557\n",
      "Step: 2798 Weights: [0.28496789 2.14056242] , error: 0.4743298160798076\n",
      "Step: 2799 Weights: [0.28513025 2.14054385] , error: 0.47432714864949876\n",
      "Step: 2800 Weights: [0.28529223 2.14052533] , error: 0.4743244933710159\n",
      "Step: 2801 Weights: [0.28545385 2.14050685] , error: 0.4743218501890022\n",
      "Step: 2802 Weights: [0.2856151 2.1404884] , error: 0.4743192190483481\n",
      "Step: 2803 Weights: [0.28577598 2.14047001] , error: 0.4743165998941995\n",
      "Step: 2804 Weights: [0.2859365  2.14045165] , error: 0.4743139926719493\n",
      "Step: 2805 Weights: [0.28609665 2.14043333] , error: 0.47431139732724137\n",
      "Step: 2806 Weights: [0.28625643 2.14041506] , error: 0.4743088138059636\n",
      "Step: 2807 Weights: [0.28641585 2.14039683] , error: 0.4743062420542555\n",
      "Step: 2808 Weights: [0.2865749  2.14037864] , error: 0.4743036820184967\n",
      "Step: 2809 Weights: [0.2867336  2.14036049] , error: 0.47430113364531656\n",
      "Step: 2810 Weights: [0.28689193 2.14034238] , error: 0.47429859688158277\n",
      "Step: 2811 Weights: [0.2870499  2.14032432] , error: 0.47429607167440657\n",
      "Step: 2812 Weights: [0.28720751 2.14030629] , error: 0.47429355797114214\n",
      "Step: 2813 Weights: [0.28736476 2.14028831] , error: 0.47429105571938074\n",
      "Step: 2814 Weights: [0.28752165 2.14027036] , error: 0.4742885648669547\n",
      "Step: 2815 Weights: [0.28767818 2.14025246] , error: 0.4742860853619321\n",
      "Step: 2816 Weights: [0.28783436 2.1402346 ] , error: 0.474283617152616\n",
      "Step: 2817 Weights: [0.28799018 2.14021678] , error: 0.4742811601875522\n",
      "Step: 2818 Weights: [0.28814565 2.140199  ] , error: 0.47427871441551195\n",
      "Step: 2819 Weights: [0.28830076 2.14018126] , error: 0.47427627978550696\n",
      "Step: 2820 Weights: [0.28845552 2.14016356] , error: 0.4742738562467761\n",
      "Step: 2821 Weights: [0.28860992 2.1401459 ] , error: 0.4742714437487923\n",
      "Step: 2822 Weights: [0.28876397 2.14012829] , error: 0.47426904224125843\n",
      "Step: 2823 Weights: [0.28891767 2.14011071] , error: 0.47426665167410553\n",
      "Step: 2824 Weights: [0.28907102 2.14009317] , error: 0.47426427199749327\n",
      "Step: 2825 Weights: [0.28922402 2.14007567] , error: 0.4742619031618084\n",
      "Step: 2826 Weights: [0.28937668 2.14005822] , error: 0.47425954511766366\n",
      "Step: 2827 Weights: [0.28952898 2.1400408 ] , error: 0.47425719781589676\n",
      "Step: 2828 Weights: [0.28968094 2.14002342] , error: 0.47425486120756993\n",
      "Step: 2829 Weights: [0.28983255 2.14000608] , error: 0.47425253524396704\n",
      "Step: 2830 Weights: [0.28998381 2.13998878] , error: 0.4742502198765956\n",
      "Step: 2831 Weights: [0.29013473 2.13997152] , error: 0.474247915057183\n",
      "Step: 2832 Weights: [0.2902853 2.1399543] , error: 0.47424562073767423\n",
      "Step: 2833 Weights: [0.29043554 2.13993712] , error: 0.4742433368702399\n",
      "Step: 2834 Weights: [0.29058543 2.13991998] , error: 0.4742410634072594\n",
      "Step: 2835 Weights: [0.29073497 2.13990287] , error: 0.4742388003013375\n",
      "Step: 2836 Weights: [0.29088418 2.13988581] , error: 0.47423654750529076\n",
      "Step: 2837 Weights: [0.29103305 2.13986879] , error: 0.4742343049721493\n",
      "Step: 2838 Weights: [0.29118157 2.1398518 ] , error: 0.47423207265516154\n",
      "Step: 2839 Weights: [0.29132976 2.13983485] , error: 0.4742298505077841\n",
      "Step: 2840 Weights: [0.29147761 2.13981794] , error: 0.4742276384836909\n",
      "Step: 2841 Weights: [0.29162512 2.13980107] , error: 0.47422543653676\n",
      "Step: 2842 Weights: [0.2917723  2.13978424] , error: 0.4742232446210873\n",
      "Step: 2843 Weights: [0.29191914 2.13976745] , error: 0.47422106269097253\n",
      "Step: 2844 Weights: [0.29206565 2.13975069] , error: 0.47421889070092427\n",
      "Step: 2845 Weights: [0.29221182 2.13973398] , error: 0.47421672860566166\n",
      "Step: 2846 Weights: [0.29235766 2.1397173 ] , error: 0.47421457636010567\n",
      "Step: 2847 Weights: [0.29250316 2.13970066] , error: 0.4742124339193846\n",
      "Step: 2848 Weights: [0.29264834 2.13968405] , error: 0.4742103012388327\n",
      "Step: 2849 Weights: [0.29279318 2.13966749] , error: 0.4742081782739849\n",
      "Step: 2850 Weights: [0.29293769 2.13965096] , error: 0.47420606498058177\n",
      "Step: 2851 Weights: [0.29308187 2.13963447] , error: 0.4742039613145613\n",
      "Step: 2852 Weights: [0.29322573 2.13961802] , error: 0.47420186723206714\n",
      "Step: 2853 Weights: [0.29336925 2.13960161] , error: 0.4741997826894389\n",
      "Step: 2854 Weights: [0.29351245 2.13958523] , error: 0.4741977076432169\n",
      "Step: 2855 Weights: [0.29365533 2.13956889] , error: 0.47419564205013887\n",
      "Step: 2856 Weights: [0.29379787 2.13955259] , error: 0.4741935858671391\n",
      "Step: 2857 Weights: [0.29394009 2.13953632] , error: 0.47419153905134936\n",
      "Step: 2858 Weights: [0.29408199 2.1395201 ] , error: 0.47418950156009687\n",
      "Step: 2859 Weights: [0.29422356 2.1395039 ] , error: 0.4741874733509017\n",
      "Step: 2860 Weights: [0.29436482 2.13948775] , error: 0.47418545438147797\n",
      "Step: 2861 Weights: [0.29450574 2.13947163] , error: 0.4741834446097335\n",
      "Step: 2862 Weights: [0.29464635 2.13945555] , error: 0.47418144399376627\n",
      "Step: 2863 Weights: [0.29478664 2.13943951] , error: 0.4741794524918661\n",
      "Step: 2864 Weights: [0.29492661 2.1394235 ] , error: 0.4741774700625137\n",
      "Step: 2865 Weights: [0.29506625 2.13940753] , error: 0.47417549666437664\n",
      "Step: 2866 Weights: [0.29520558 2.1393916 ] , error: 0.47417353225631215\n",
      "Step: 2867 Weights: [0.29534459 2.1393757 ] , error: 0.4741715767973656\n",
      "Step: 2868 Weights: [0.29548329 2.13935984] , error: 0.47416963024676617\n",
      "Step: 2869 Weights: [0.29562167 2.13934401] , error: 0.47416769256393376\n",
      "Step: 2870 Weights: [0.29575973 2.13932822] , error: 0.4741657637084678\n",
      "Step: 2871 Weights: [0.29589748 2.13931247] , error: 0.4741638436401544\n",
      "Step: 2872 Weights: [0.29603491 2.13929675] , error: 0.4741619323189634\n",
      "Step: 2873 Weights: [0.29617203 2.13928107] , error: 0.47416002970504584\n",
      "Step: 2874 Weights: [0.29630884 2.13926542] , error: 0.4741581357587333\n",
      "Step: 2875 Weights: [0.29644533 2.13924981] , error: 0.47415625044054194\n",
      "Step: 2876 Weights: [0.29658152 2.13923424] , error: 0.4741543737111613\n",
      "Step: 2877 Weights: [0.29671739 2.1392187 ] , error: 0.47415250553146937\n",
      "Step: 2878 Weights: [0.29685295 2.1392032 ] , error: 0.4741506458625136\n",
      "Step: 2879 Weights: [0.29698821 2.13918773] , error: 0.4741487946655206\n",
      "Step: 2880 Weights: [0.29712316 2.1391723 ] , error: 0.47414695190189793\n",
      "Step: 2881 Weights: [0.29725779 2.1391569 ] , error: 0.47414511753322697\n",
      "Step: 2882 Weights: [0.29739213 2.13914153] , error: 0.47414329152125984\n",
      "Step: 2883 Weights: [0.29752615 2.13912621] , error: 0.4741414738279297\n",
      "Step: 2884 Weights: [0.29765987 2.13911091] , error: 0.4741396644153392\n",
      "Step: 2885 Weights: [0.29779328 2.13909566] , error: 0.47413786324576324\n",
      "Step: 2886 Weights: [0.2979264  2.13908043] , error: 0.4741360702816503\n",
      "Step: 2887 Weights: [0.2980592  2.13906524] , error: 0.47413428548562075\n",
      "Step: 2888 Weights: [0.29819171 2.13905009] , error: 0.47413250882046126\n",
      "Step: 2889 Weights: [0.29832391 2.13903497] , error: 0.47413074024913227\n",
      "Step: 2890 Weights: [0.29845581 2.13901989] , error: 0.4741289797347612\n",
      "Step: 2891 Weights: [0.29858741 2.13900484] , error: 0.47412722724064266\n",
      "Step: 2892 Weights: [0.29871871 2.13898982] , error: 0.47412548273024047\n",
      "Step: 2893 Weights: [0.29884971 2.13897484] , error: 0.47412374616718234\n",
      "Step: 2894 Weights: [0.29898041 2.13895989] , error: 0.474122017515264\n",
      "Step: 2895 Weights: [0.29911081 2.13894498] , error: 0.4741202967384461\n",
      "Step: 2896 Weights: [0.29924092 2.1389301 ] , error: 0.4741185838008508\n",
      "Step: 2897 Weights: [0.29937073 2.13891525] , error: 0.47411687866676694\n",
      "Step: 2898 Weights: [0.29950024 2.13890044] , error: 0.4741151813006438\n",
      "Step: 2899 Weights: [0.29962946 2.13888566] , error: 0.47411349166709366\n",
      "Step: 2900 Weights: [0.29975838 2.13887092] , error: 0.4741118097308896\n",
      "Step: 2901 Weights: [0.29988701 2.13885621] , error: 0.47411013545696556\n",
      "Step: 2902 Weights: [0.30001535 2.13884153] , error: 0.474108468810415\n",
      "Step: 2903 Weights: [0.30014339 2.13882689] , error: 0.4741068097564911\n",
      "Step: 2904 Weights: [0.30027114 2.13881228] , error: 0.4741051582606033\n",
      "Step: 2905 Weights: [0.3003986 2.1387977] , error: 0.4741035142883201\n",
      "Step: 2906 Weights: [0.30052577 2.13878316] , error: 0.4741018778053681\n",
      "Step: 2907 Weights: [0.30065265 2.13876865] , error: 0.4741002487776268\n",
      "Step: 2908 Weights: [0.30077924 2.13875417] , error: 0.47409862717113527\n",
      "Step: 2909 Weights: [0.30090554 2.13873973] , error: 0.4740970129520826\n",
      "Step: 2910 Weights: [0.30103155 2.13872531] , error: 0.4740954060868175\n",
      "Step: 2911 Weights: [0.30115728 2.13871094] , error: 0.47409380654183475\n",
      "Step: 2912 Weights: [0.30128272 2.13869659] , error: 0.47409221428378895\n",
      "Step: 2913 Weights: [0.30140787 2.13868228] , error: 0.4740906292794834\n",
      "Step: 2914 Weights: [0.30153274 2.138668  ] , error: 0.4740890514958707\n",
      "Step: 2915 Weights: [0.30165732 2.13865375] , error: 0.47408748090005765\n",
      "Step: 2916 Weights: [0.30178162 2.13863953] , error: 0.47408591745929896\n",
      "Step: 2917 Weights: [0.30190563 2.13862535] , error: 0.47408436114099894\n",
      "Step: 2918 Weights: [0.30202937 2.1386112 ] , error: 0.47408281191270946\n",
      "Step: 2919 Weights: [0.30215282 2.13859708] , error: 0.4740812697421324\n",
      "Step: 2920 Weights: [0.30227599 2.138583  ] , error: 0.474079734597114\n",
      "Step: 2921 Weights: [0.30239887 2.13856894] , error: 0.47407820644564963\n",
      "Step: 2922 Weights: [0.30252148 2.13855492] , error: 0.47407668525587865\n",
      "Step: 2923 Weights: [0.30264381 2.13854093] , error: 0.4740751709960873\n",
      "Step: 2924 Weights: [0.30276586 2.13852697] , error: 0.4740736636347042\n",
      "Step: 2925 Weights: [0.30288763 2.13851305] , error: 0.47407216314030004\n",
      "Step: 2926 Weights: [0.30300912 2.13849915] , error: 0.4740706694815958\n",
      "Step: 2927 Weights: [0.30313034 2.13848529] , error: 0.47406918262744935\n",
      "Step: 2928 Weights: [0.30325128 2.13847146] , error: 0.47406770254685926\n",
      "Step: 2929 Weights: [0.30337194 2.13845766] , error: 0.4740662292089711\n",
      "Step: 2930 Weights: [0.30349233 2.13844389] , error: 0.47406476258306623\n",
      "Step: 2931 Weights: [0.30361245 2.13843015] , error: 0.4740633026385659\n",
      "Step: 2932 Weights: [0.30373229 2.13841645] , error: 0.4740618493450337\n",
      "Step: 2933 Weights: [0.30385185 2.13840277] , error: 0.47406040267217064\n",
      "Step: 2934 Weights: [0.30397115 2.13838913] , error: 0.47405896258981417\n",
      "Step: 2935 Weights: [0.30409017 2.13837552] , error: 0.4740575290679414\n",
      "Step: 2936 Weights: [0.30420892 2.13836194] , error: 0.47405610207666427\n",
      "Step: 2937 Weights: [0.3043274  2.13834839] , error: 0.47405468158623165\n",
      "Step: 2938 Weights: [0.30444561 2.13833487] , error: 0.47405326756703015\n",
      "Step: 2939 Weights: [0.30456355 2.13832138] , error: 0.4740518599895767\n",
      "Step: 2940 Weights: [0.30468122 2.13830792] , error: 0.47405045882452584\n",
      "Step: 2941 Weights: [0.30479862 2.1382945 ] , error: 0.4740490640426654\n",
      "Step: 2942 Weights: [0.30491576 2.1382811 ] , error: 0.4740476756149162\n",
      "Step: 2943 Weights: [0.30503263 2.13826773] , error: 0.4740462935123306\n",
      "Step: 2944 Weights: [0.30514923 2.1382544 ] , error: 0.474044917706095\n",
      "Step: 2945 Weights: [0.30526557 2.13824109] , error: 0.4740435481675228\n",
      "Step: 2946 Weights: [0.30538164 2.13822782] , error: 0.47404218486806293\n",
      "Step: 2947 Weights: [0.30549744 2.13821458] , error: 0.47404082777929124\n",
      "Step: 2948 Weights: [0.30561298 2.13820136] , error: 0.4740394768729137\n",
      "Step: 2949 Weights: [0.30572826 2.13818818] , error: 0.4740381321207701\n",
      "Step: 2950 Weights: [0.30584328 2.13817503] , error: 0.4740367934948177\n",
      "Step: 2951 Weights: [0.30595803 2.1381619 ] , error: 0.47403546096715127\n",
      "Step: 2952 Weights: [0.30607252 2.13814881] , error: 0.47403413450998855\n",
      "Step: 2953 Weights: [0.30618675 2.13813574] , error: 0.4740328140956742\n",
      "Step: 2954 Weights: [0.30630072 2.13812271] , error: 0.47403149969668074\n",
      "Step: 2955 Weights: [0.30641443 2.13810971] , error: 0.47403019128560175\n",
      "Step: 2956 Weights: [0.30652788 2.13809673] , error: 0.47402888883516214\n",
      "Step: 2957 Weights: [0.30664107 2.13808379] , error: 0.47402759231820496\n",
      "Step: 2958 Weights: [0.30675401 2.13807087] , error: 0.47402630170769877\n",
      "Step: 2959 Weights: [0.30686668 2.13805798] , error: 0.4740250169767384\n",
      "Step: 2960 Weights: [0.3069791  2.13804513] , error: 0.47402373809853804\n",
      "Step: 2961 Weights: [0.30709127 2.1380323 ] , error: 0.4740224650464335\n",
      "Step: 2962 Weights: [0.30720317 2.1380195 ] , error: 0.47402119779388413\n",
      "Step: 2963 Weights: [0.30731482 2.13800673] , error: 0.4740199363144688\n",
      "Step: 2964 Weights: [0.30742622 2.13799399] , error: 0.47401868058188945\n",
      "Step: 2965 Weights: [0.30753736 2.13798128] , error: 0.4740174305699612\n",
      "Step: 2966 Weights: [0.30764825 2.1379686 ] , error: 0.47401618625262737\n",
      "Step: 2967 Weights: [0.30775889 2.13795595] , error: 0.4740149476039432\n",
      "Step: 2968 Weights: [0.30786928 2.13794332] , error: 0.47401371459808483\n",
      "Step: 2969 Weights: [0.30797941 2.13793073] , error: 0.47401248720934563\n",
      "Step: 2970 Weights: [0.30808929 2.13791816] , error: 0.47401126541213495\n",
      "Step: 2971 Weights: [0.30819892 2.13790562] , error: 0.4740100491809828\n",
      "Step: 2972 Weights: [0.3083083  2.13789311] , error: 0.47400883849052944\n",
      "Step: 2973 Weights: [0.30841743 2.13788063] , error: 0.4740076333155354\n",
      "Step: 2974 Weights: [0.30852632 2.13786818] , error: 0.4740064336308727\n",
      "Step: 2975 Weights: [0.30863495 2.13785576] , error: 0.4740052394115301\n",
      "Step: 2976 Weights: [0.30874334 2.13784336] , error: 0.4740040506326095\n",
      "Step: 2977 Weights: [0.30885148 2.13783099] , error: 0.47400286726932594\n",
      "Step: 2978 Weights: [0.30895937 2.13781866] , error: 0.474001689297009\n",
      "Step: 2979 Weights: [0.30906702 2.13780634] , error: 0.47400051669109877\n",
      "Step: 2980 Weights: [0.30917442 2.13779406] , error: 0.473999349427148\n",
      "Step: 2981 Weights: [0.30928158 2.13778181] , error: 0.47399818748082034\n",
      "Step: 2982 Weights: [0.30938849 2.13776958] , error: 0.4739970308278908\n",
      "Step: 2983 Weights: [0.30949516 2.13775738] , error: 0.4739958794442451\n",
      "Step: 2984 Weights: [0.30960158 2.13774521] , error: 0.47399473330587777\n",
      "Step: 2985 Weights: [0.30970777 2.13773307] , error: 0.4739935923888927\n",
      "Step: 2986 Weights: [0.30981371 2.13772095] , error: 0.47399245666950507\n",
      "Step: 2987 Weights: [0.3099194  2.13770886] , error: 0.4739913261240349\n",
      "Step: 2988 Weights: [0.31002486 2.1376968 ] , error: 0.4739902007289114\n",
      "Step: 2989 Weights: [0.31013008 2.13768477] , error: 0.4739890804606736\n",
      "Step: 2990 Weights: [0.31023506 2.13767276] , error: 0.4739879652959629\n",
      "Step: 2991 Weights: [0.3103398  2.13766078] , error: 0.4739868552115317\n",
      "Step: 2992 Weights: [0.31044429 2.13764883] , error: 0.4739857501842337\n",
      "Step: 2993 Weights: [0.31054855 2.13763691] , error: 0.47398465019103325\n",
      "Step: 2994 Weights: [0.31065258 2.13762501] , error: 0.47398355520899516\n",
      "Step: 2995 Weights: [0.31075636 2.13761314] , error: 0.47398246521529014\n",
      "Step: 2996 Weights: [0.31085991 2.1376013 ] , error: 0.47398138018719405\n",
      "Step: 2997 Weights: [0.31096323 2.13758949] , error: 0.4739803001020845\n",
      "Step: 2998 Weights: [0.3110663 2.1375777] , error: 0.4739792249374452\n",
      "Step: 2999 Weights: [0.31116915 2.13756594] , error: 0.47397815467085797\n",
      "Step: 3000 Weights: [0.31127175 2.1375542 ] , error: 0.4739770892800094\n",
      "Step: 3001 Weights: [0.31137413 2.13754249] , error: 0.4739760287426884\n",
      "Step: 3002 Weights: [0.31147627 2.13753081] , error: 0.47397497303678304\n",
      "Step: 3003 Weights: [0.31157818 2.13751916] , error: 0.47397392214028455\n",
      "Step: 3004 Weights: [0.31167985 2.13750753] , error: 0.47397287603128185\n",
      "Step: 3005 Weights: [0.31178129 2.13749593] , error: 0.4739718346879658\n",
      "Step: 3006 Weights: [0.31188251 2.13748435] , error: 0.47397079808862475\n",
      "Step: 3007 Weights: [0.31198349 2.1374728 ] , error: 0.4739697662116469\n",
      "Step: 3008 Weights: [0.31208424 2.13746128] , error: 0.4739687390355197\n",
      "Step: 3009 Weights: [0.31218476 2.13744979] , error: 0.47396771653882747\n",
      "Step: 3010 Weights: [0.31228505 2.13743832] , error: 0.4739666987002531\n",
      "Step: 3011 Weights: [0.31238511 2.13742687] , error: 0.4739656854985747\n",
      "Step: 3012 Weights: [0.31248495 2.13741546] , error: 0.47396467691266864\n",
      "Step: 3013 Weights: [0.31258456 2.13740406] , error: 0.4739636729215082\n",
      "Step: 3014 Weights: [0.31268394 2.1373927 ] , error: 0.47396267350415966\n",
      "Step: 3015 Weights: [0.31278309 2.13738136] , error: 0.4739616786397877\n",
      "Step: 3016 Weights: [0.31288202 2.13737005] , error: 0.4739606883076497\n",
      "Step: 3017 Weights: [0.31298072 2.13735876] , error: 0.47395970248709923\n",
      "Step: 3018 Weights: [0.31307919 2.1373475 ] , error: 0.4739587211575832\n",
      "Step: 3019 Weights: [0.31317745 2.13733626] , error: 0.47395774429864257\n",
      "Step: 3020 Weights: [0.31327548 2.13732505] , error: 0.4739567718899089\n",
      "Step: 3021 Weights: [0.31337328 2.13731386] , error: 0.47395580391111214\n",
      "Step: 3022 Weights: [0.31347086 2.1373027 ] , error: 0.4739548403420669\n",
      "Step: 3023 Weights: [0.31356822 2.13729157] , error: 0.4739538811626886\n",
      "Step: 3024 Weights: [0.31366536 2.13728046] , error: 0.4739529263529757\n",
      "Step: 3025 Weights: [0.31376227 2.13726938] , error: 0.47395197589302296\n",
      "Step: 3026 Weights: [0.31385897 2.13725832] , error: 0.4739510297630147\n",
      "Step: 3027 Weights: [0.31395544 2.13724728] , error: 0.47395008794322613\n",
      "Step: 3028 Weights: [0.31405169 2.13723628] , error: 0.47394915041402\n",
      "Step: 3029 Weights: [0.31414773 2.13722529] , error: 0.47394821715585017\n",
      "Step: 3030 Weights: [0.31424354 2.13721434] , error: 0.4739472881492606\n",
      "Step: 3031 Weights: [0.31433914 2.1372034 ] , error: 0.47394636337488116\n",
      "Step: 3032 Weights: [0.31443452 2.13719249] , error: 0.47394544281343287\n",
      "Step: 3033 Weights: [0.31452968 2.13718161] , error: 0.473944526445722\n",
      "Step: 3034 Weights: [0.31462463 2.13717075] , error: 0.47394361425264425\n",
      "Step: 3035 Weights: [0.31471935 2.13715992] , error: 0.47394270621518025\n",
      "Step: 3036 Weights: [0.31481387 2.13714911] , error: 0.4739418023144004\n",
      "Step: 3037 Weights: [0.31490816 2.13713833] , error: 0.47394090253145826\n",
      "Step: 3038 Weights: [0.31500224 2.13712757] , error: 0.4739400068475946\n",
      "Step: 3039 Weights: [0.31509611 2.13711683] , error: 0.4739391152441357\n",
      "Step: 3040 Weights: [0.31518976 2.13710612] , error: 0.47393822770249294\n",
      "Step: 3041 Weights: [0.3152832  2.13709544] , error: 0.4739373442041611\n",
      "Step: 3042 Weights: [0.31537643 2.13708477] , error: 0.4739364647307226\n",
      "Step: 3043 Weights: [0.31546944 2.13707414] , error: 0.47393558926383994\n",
      "Step: 3044 Weights: [0.31556224 2.13706352] , error: 0.47393471778526025\n",
      "Step: 3045 Weights: [0.31565483 2.13705293] , error: 0.47393385027681634\n",
      "Step: 3046 Weights: [0.31574721 2.13704237] , error: 0.4739329867204191\n",
      "Step: 3047 Weights: [0.31583938 2.13703183] , error: 0.4739321270980663\n",
      "Step: 3048 Weights: [0.31593134 2.13702131] , error: 0.4739312713918347\n",
      "Step: 3049 Weights: [0.31602309 2.13701082] , error: 0.47393041958388554\n",
      "Step: 3050 Weights: [0.31611462 2.13700035] , error: 0.47392957165645816\n",
      "Step: 3051 Weights: [0.31620595 2.13698991] , error: 0.4739287275918749\n",
      "Step: 3052 Weights: [0.31629708 2.13697948] , error: 0.47392788737253844\n",
      "Step: 3053 Weights: [0.31638799 2.13696909] , error: 0.4739270509809306\n",
      "Step: 3054 Weights: [0.3164787  2.13695871] , error: 0.47392621839961346\n",
      "Step: 3055 Weights: [0.3165692  2.13694836] , error: 0.47392538961122965\n",
      "Step: 3056 Weights: [0.31665949 2.13693804] , error: 0.4739245645985001\n",
      "Step: 3057 Weights: [0.31674958 2.13692773] , error: 0.47392374334422305\n",
      "Step: 3058 Weights: [0.31683946 2.13691746] , error: 0.4739229258312774\n",
      "Step: 3059 Weights: [0.31692914 2.1369072 ] , error: 0.4739221120426176\n",
      "Step: 3060 Weights: [0.31701861 2.13689697] , error: 0.47392130196127924\n",
      "Step: 3061 Weights: [0.31710788 2.13688676] , error: 0.47392049557037214\n",
      "Step: 3062 Weights: [0.31719694 2.13687657] , error: 0.4739196928530851\n",
      "Step: 3063 Weights: [0.31728581 2.13686641] , error: 0.47391889379268015\n",
      "Step: 3064 Weights: [0.31737446 2.13685627] , error: 0.4739180983724989\n",
      "Step: 3065 Weights: [0.31746292 2.13684615] , error: 0.4739173065759593\n",
      "Step: 3066 Weights: [0.31755118 2.13683606] , error: 0.4739165183865509\n",
      "Step: 3067 Weights: [0.31763923 2.13682599] , error: 0.47391573378784435\n",
      "Step: 3068 Weights: [0.31772708 2.13681594] , error: 0.47391495276347767\n",
      "Step: 3069 Weights: [0.31781474 2.13680592] , error: 0.47391417529717084\n",
      "Step: 3070 Weights: [0.31790219 2.13679592] , error: 0.47391340137271193\n",
      "Step: 3071 Weights: [0.31798944 2.13678594] , error: 0.4739126309739681\n",
      "Step: 3072 Weights: [0.3180765  2.13677598] , error: 0.47391186408487507\n",
      "Step: 3073 Weights: [0.31816336 2.13676605] , error: 0.473911100689446\n",
      "Step: 3074 Weights: [0.31825001 2.13675614] , error: 0.4739103407717647\n",
      "Step: 3075 Weights: [0.31833647 2.13674625] , error: 0.4739095843159875\n",
      "Step: 3076 Weights: [0.31842274 2.13673639] , error: 0.47390883130634376\n",
      "Step: 3077 Weights: [0.3185088  2.13672654] , error: 0.47390808172713317\n",
      "Step: 3078 Weights: [0.31859467 2.13671672] , error: 0.47390733556272846\n",
      "Step: 3079 Weights: [0.31868035 2.13670692] , error: 0.4739065927975741\n",
      "Step: 3080 Weights: [0.31876583 2.13669715] , error: 0.47390585341618197\n",
      "Step: 3081 Weights: [0.31885111 2.13668739] , error: 0.4739051174031399\n",
      "Step: 3082 Weights: [0.3189362  2.13667766] , error: 0.47390438474309987\n",
      "Step: 3083 Weights: [0.3190211  2.13666795] , error: 0.4739036554207884\n",
      "Step: 3084 Weights: [0.3191058  2.13665827] , error: 0.47390292942100065\n",
      "Step: 3085 Weights: [0.31919031 2.1366486 ] , error: 0.47390220672859973\n",
      "Step: 3086 Weights: [0.31927463 2.13663896] , error: 0.4739014873285182\n",
      "Step: 3087 Weights: [0.31935875 2.13662934] , error: 0.47390077120575747\n",
      "Step: 3088 Weights: [0.31944268 2.13661974] , error: 0.4739000583453876\n",
      "Step: 3089 Weights: [0.31952642 2.13661016] , error: 0.47389934873254624\n",
      "Step: 3090 Weights: [0.31960997 2.13660061] , error: 0.4738986423524387\n",
      "Step: 3091 Weights: [0.31969333 2.13659107] , error: 0.47389793919033785\n",
      "Step: 3092 Weights: [0.3197765  2.13658156] , error: 0.47389723923158467\n",
      "Step: 3093 Weights: [0.31985948 2.13657207] , error: 0.4738965424615845\n",
      "Step: 3094 Weights: [0.31994227 2.1365626 ] , error: 0.4738958488658104\n",
      "Step: 3095 Weights: [0.32002487 2.13655316] , error: 0.47389515842980284\n",
      "Step: 3096 Weights: [0.32010728 2.13654373] , error: 0.47389447113916705\n",
      "Step: 3097 Weights: [0.32018951 2.13653433] , error: 0.47389378697957285\n",
      "Step: 3098 Weights: [0.32027155 2.13652495] , error: 0.473893105936757\n",
      "Step: 3099 Weights: [0.3203534  2.13651559] , error: 0.473892427996521\n",
      "Step: 3100 Weights: [0.32043506 2.13650625] , error: 0.4738917531447295\n",
      "Step: 3101 Weights: [0.32051654 2.13649693] , error: 0.47389108136731506\n",
      "Step: 3102 Weights: [0.32059783 2.13648763] , error: 0.4738904126502689\n",
      "Step: 3103 Weights: [0.32067894 2.13647836] , error: 0.47388974697965136\n",
      "Step: 3104 Weights: [0.32075986 2.1364691 ] , error: 0.4738890843415827\n",
      "Step: 3105 Weights: [0.3208406  2.13645987] , error: 0.47388842472224824\n",
      "Step: 3106 Weights: [0.32092115 2.13645066] , error: 0.4738877681078955\n",
      "Step: 3107 Weights: [0.32100152 2.13644146] , error: 0.4738871144848358\n",
      "Step: 3108 Weights: [0.3210817  2.13643229] , error: 0.47388646383944166\n",
      "Step: 3109 Weights: [0.32116171 2.13642314] , error: 0.47388581615814673\n",
      "Step: 3110 Weights: [0.32124153 2.13641402] , error: 0.4738851714274497\n",
      "Step: 3111 Weights: [0.32132117 2.13640491] , error: 0.47388452963390615\n",
      "Step: 3112 Weights: [0.32140062 2.13639582] , error: 0.4738838907641376\n",
      "Step: 3113 Weights: [0.3214799  2.13638676] , error: 0.47388325480482335\n",
      "Step: 3114 Weights: [0.32155899 2.13637771] , error: 0.4738826217427048\n",
      "Step: 3115 Weights: [0.32163791 2.13636868] , error: 0.4738819915645839\n",
      "Step: 3116 Weights: [0.32171664 2.13635968] , error: 0.47388136425732036\n",
      "Step: 3117 Weights: [0.3217952 2.1363507] , error: 0.47388073980783807\n",
      "Step: 3118 Weights: [0.32187358 2.13634173] , error: 0.47388011820311665\n",
      "Step: 3119 Weights: [0.32195177 2.13633279] , error: 0.47387949943019747\n",
      "Step: 3120 Weights: [0.32202979 2.13632387] , error: 0.4738788834761779\n",
      "Step: 3121 Weights: [0.32210763 2.13631496] , error: 0.4738782703282175\n",
      "Step: 3122 Weights: [0.3221853  2.13630608] , error: 0.4738776599735335\n",
      "Step: 3123 Weights: [0.32226278 2.13629722] , error: 0.4738770523993987\n",
      "Step: 3124 Weights: [0.32234009 2.13628838] , error: 0.47387644759314795\n",
      "Step: 3125 Weights: [0.32241723 2.13627956] , error: 0.47387584554217105\n",
      "Step: 3126 Weights: [0.32249418 2.13627076] , error: 0.47387524623391664\n",
      "Step: 3127 Weights: [0.32257097 2.13626198] , error: 0.4738746496558881\n",
      "Step: 3128 Weights: [0.32264757 2.13625322] , error: 0.47387405579564906\n",
      "Step: 3129 Weights: [0.322724   2.13624447] , error: 0.4738734646408175\n",
      "Step: 3130 Weights: [0.32280026 2.13623575] , error: 0.4738728761790696\n",
      "Step: 3131 Weights: [0.32287635 2.13622705] , error: 0.4738722903981355\n",
      "Step: 3132 Weights: [0.32295226 2.13621837] , error: 0.47387170728580297\n",
      "Step: 3133 Weights: [0.32302799 2.13620971] , error: 0.47387112682991556\n",
      "Step: 3134 Weights: [0.32310356 2.13620107] , error: 0.4738705490183702\n",
      "Step: 3135 Weights: [0.32317895 2.13619244] , error: 0.47386997383912105\n",
      "Step: 3136 Weights: [0.32325417 2.13618384] , error: 0.4738694012801758\n",
      "Step: 3137 Weights: [0.32332922 2.13617526] , error: 0.47386883132959756\n",
      "Step: 3138 Weights: [0.3234041 2.1361667] , error: 0.4738682639755034\n",
      "Step: 3139 Weights: [0.32347881 2.13615815] , error: 0.4738676992060648\n",
      "Step: 3140 Weights: [0.32355334 2.13614963] , error: 0.4738671370095083\n",
      "Step: 3141 Weights: [0.32362771 2.13614112] , error: 0.4738665773741107\n",
      "Step: 3142 Weights: [0.32370191 2.13613264] , error: 0.4738660202882048\n",
      "Step: 3143 Weights: [0.32377593 2.13612417] , error: 0.4738654657401772\n",
      "Step: 3144 Weights: [0.32384979 2.13611572] , error: 0.4738649137184645\n",
      "Step: 3145 Weights: [0.32392348 2.1361073 ] , error: 0.47386436421155964\n",
      "Step: 3146 Weights: [0.32399701 2.13609889] , error: 0.47386381720800574\n",
      "Step: 3147 Weights: [0.32407036 2.1360905 ] , error: 0.4738632726963969\n",
      "Step: 3148 Weights: [0.32414355 2.13608213] , error: 0.4738627306653823\n",
      "Step: 3149 Weights: [0.32421657 2.13607378] , error: 0.4738621911036608\n",
      "Step: 3150 Weights: [0.32428942 2.13606545] , error: 0.47386165399998337\n",
      "Step: 3151 Weights: [0.32436211 2.13605713] , error: 0.4738611193431505\n",
      "Step: 3152 Weights: [0.32443464 2.13604884] , error: 0.473860587122017\n",
      "Step: 3153 Weights: [0.32450699 2.13604056] , error: 0.47386005732548814\n",
      "Step: 3154 Weights: [0.32457918 2.13603231] , error: 0.4738595299425148\n",
      "Step: 3155 Weights: [0.32465121 2.13602407] , error: 0.4738590049621048\n",
      "Step: 3156 Weights: [0.32472307 2.13601585] , error: 0.47385848237331046\n",
      "Step: 3157 Weights: [0.32479477 2.13600765] , error: 0.47385796216523796\n",
      "Step: 3158 Weights: [0.32486631 2.13599947] , error: 0.47385744432704113\n",
      "Step: 3159 Weights: [0.32493768 2.13599131] , error: 0.47385692884792396\n",
      "Step: 3160 Weights: [0.32500889 2.13598316] , error: 0.473856415717139\n",
      "Step: 3161 Weights: [0.32507994 2.13597504] , error: 0.47385590492398866\n",
      "Step: 3162 Weights: [0.32515083 2.13596693] , error: 0.4738553964578234\n",
      "Step: 3163 Weights: [0.32522155 2.13595884] , error: 0.47385489030804157\n",
      "Step: 3164 Weights: [0.32529211 2.13595077] , error: 0.47385438646409256\n",
      "Step: 3165 Weights: [0.32536251 2.13594272] , error: 0.4738538849154686\n",
      "Step: 3166 Weights: [0.32543275 2.13593469] , error: 0.47385338565171586\n",
      "Step: 3167 Weights: [0.32550284 2.13592668] , error: 0.4738528886624239\n",
      "Step: 3168 Weights: [0.32557276 2.13591868] , error: 0.47385239393723194\n",
      "Step: 3169 Weights: [0.32564252 2.1359107 ] , error: 0.4738519014658244\n",
      "Step: 3170 Weights: [0.32571212 2.13590274] , error: 0.4738514112379354\n",
      "Step: 3171 Weights: [0.32578156 2.1358948 ] , error: 0.473850923243344\n",
      "Step: 3172 Weights: [0.32585085 2.13588687] , error: 0.47385043747187405\n",
      "Step: 3173 Weights: [0.32591998 2.13587897] , error: 0.47384995391340107\n",
      "Step: 3174 Weights: [0.32598895 2.13587108] , error: 0.47384947255784154\n",
      "Step: 3175 Weights: [0.32605776 2.13586321] , error: 0.4738489933951593\n",
      "Step: 3176 Weights: [0.32612642 2.13585536] , error: 0.4738485164153654\n",
      "Step: 3177 Weights: [0.32619491 2.13584753] , error: 0.47384804160851546\n",
      "Step: 3178 Weights: [0.32626326 2.13583971] , error: 0.4738475689647098\n",
      "Step: 3179 Weights: [0.32633144 2.13583191] , error: 0.4738470984740958\n",
      "Step: 3180 Weights: [0.32639948 2.13582413] , error: 0.47384663012686173\n",
      "Step: 3181 Weights: [0.32646735 2.13581637] , error: 0.47384616391324597\n",
      "Step: 3182 Weights: [0.32653507 2.13580862] , error: 0.47384569982352676\n",
      "Step: 3183 Weights: [0.32660264 2.1358009 ] , error: 0.47384523784802834\n",
      "Step: 3184 Weights: [0.32667005 2.13579319] , error: 0.4738447779771205\n",
      "Step: 3185 Weights: [0.32673731 2.1357855 ] , error: 0.4738443202012141\n",
      "Step: 3186 Weights: [0.32680442 2.13577782] , error: 0.47384386451076566\n",
      "Step: 3187 Weights: [0.32687137 2.13577016] , error: 0.47384341089627424\n",
      "Step: 3188 Weights: [0.32693817 2.13576252] , error: 0.4738429593482838\n",
      "Step: 3189 Weights: [0.32700482 2.1357549 ] , error: 0.47384250985737814\n",
      "Step: 3190 Weights: [0.32707132 2.1357473 ] , error: 0.4738420624141871\n",
      "Step: 3191 Weights: [0.32713766 2.13573971] , error: 0.4738416170093819\n",
      "Step: 3192 Weights: [0.32720385 2.13573214] , error: 0.4738411736336759\n",
      "Step: 3193 Weights: [0.3272699  2.13572459] , error: 0.47384073227782747\n",
      "Step: 3194 Weights: [0.32733579 2.13571705] , error: 0.4738402929326326\n",
      "Step: 3195 Weights: [0.32740153 2.13570953] , error: 0.47383985558893205\n",
      "Step: 3196 Weights: [0.32746712 2.13570203] , error: 0.47383942023760783\n",
      "Step: 3197 Weights: [0.32753256 2.13569455] , error: 0.4738389868695829\n",
      "Step: 3198 Weights: [0.32759785 2.13568708] , error: 0.473838555475823\n",
      "Step: 3199 Weights: [0.327663   2.13567963] , error: 0.4738381260473346\n",
      "Step: 3200 Weights: [0.32772799 2.1356722 ] , error: 0.47383769857516256\n",
      "Step: 3201 Weights: [0.32779284 2.13566478] , error: 0.4738372730503958\n",
      "Step: 3202 Weights: [0.32785754 2.13565738] , error: 0.4738368494641627\n",
      "Step: 3203 Weights: [0.32792209 2.13565   ] , error: 0.4738364278076321\n",
      "Step: 3204 Weights: [0.32798649 2.13564263] , error: 0.4738360080720128\n",
      "Step: 3205 Weights: [0.32805075 2.13563528] , error: 0.4738355902485547\n",
      "Step: 3206 Weights: [0.32811486 2.13562795] , error: 0.4738351743285449\n",
      "Step: 3207 Weights: [0.32817883 2.13562064] , error: 0.47383476030331373\n",
      "Step: 3208 Weights: [0.32824264 2.13561334] , error: 0.47383434816422854\n",
      "Step: 3209 Weights: [0.32830632 2.13560606] , error: 0.47383393790269623\n",
      "Step: 3210 Weights: [0.32836985 2.13559879] , error: 0.4738335295101636\n",
      "Step: 3211 Weights: [0.32843323 2.13559154] , error: 0.4738331229781174\n",
      "Step: 3212 Weights: [0.32849647 2.13558431] , error: 0.4738327182980805\n",
      "Step: 3213 Weights: [0.32855956 2.1355771 ] , error: 0.47383231546161736\n",
      "Step: 3214 Weights: [0.32862251 2.1355699 ] , error: 0.473831914460327\n",
      "Step: 3215 Weights: [0.32868532 2.13556271] , error: 0.4738315152858512\n",
      "Step: 3216 Weights: [0.32874798 2.13555555] , error: 0.47383111792986593\n",
      "Step: 3217 Weights: [0.3288105 2.1355484] , error: 0.47383072238408824\n",
      "Step: 3218 Weights: [0.32887288 2.13554126] , error: 0.4738303286402703\n",
      "Step: 3219 Weights: [0.32893512 2.13553415] , error: 0.47382993669020496\n",
      "Step: 3220 Weights: [0.32899721 2.13552704] , error: 0.47382954652571885\n",
      "Step: 3221 Weights: [0.32905916 2.13551996] , error: 0.4738291581386783\n",
      "Step: 3222 Weights: [0.32912097 2.13551289] , error: 0.47382877152098485\n",
      "Step: 3223 Weights: [0.32918265 2.13550584] , error: 0.47382838666457944\n",
      "Step: 3224 Weights: [0.32924417 2.1354988 ] , error: 0.47382800356143695\n",
      "Step: 3225 Weights: [0.32930556 2.13549178] , error: 0.4738276222035712\n",
      "Step: 3226 Weights: [0.32936681 2.13548477] , error: 0.47382724258303105\n",
      "Step: 3227 Weights: [0.32942792 2.13547779] , error: 0.47382686469190205\n",
      "Step: 3228 Weights: [0.32948889 2.13547081] , error: 0.4738264885223058\n",
      "Step: 3229 Weights: [0.32954972 2.13546386] , error: 0.4738261140663983\n",
      "Step: 3230 Weights: [0.32961042 2.13545691] , error: 0.4738257413163738\n",
      "Step: 3231 Weights: [0.32967097 2.13544999] , error: 0.4738253702644603\n",
      "Step: 3232 Weights: [0.32973139 2.13544308] , error: 0.47382500090292334\n",
      "Step: 3233 Weights: [0.32979167 2.13543619] , error: 0.47382463322406043\n",
      "Step: 3234 Weights: [0.32985181 2.13542931] , error: 0.47382426722020654\n",
      "Step: 3235 Weights: [0.32991181 2.13542245] , error: 0.4738239028837311\n",
      "Step: 3236 Weights: [0.32997168 2.1354156 ] , error: 0.47382354020703893\n",
      "Step: 3237 Weights: [0.33003141 2.13540877] , error: 0.4738231791825661\n",
      "Step: 3238 Weights: [0.330091   2.13540195] , error: 0.4738228198027882\n",
      "Step: 3239 Weights: [0.33015046 2.13539515] , error: 0.47382246206021195\n",
      "Step: 3240 Weights: [0.33020978 2.13538837] , error: 0.47382210594737845\n",
      "Step: 3241 Weights: [0.33026897 2.1353816 ] , error: 0.473821751456864\n",
      "Step: 3242 Weights: [0.33032802 2.13537485] , error: 0.4738213985812771\n",
      "Step: 3243 Weights: [0.33038694 2.13536811] , error: 0.4738210473132606\n",
      "Step: 3244 Weights: [0.33044572 2.13536139] , error: 0.4738206976454914\n",
      "Step: 3245 Weights: [0.33050437 2.13535468] , error: 0.4738203495706799\n",
      "Step: 3246 Weights: [0.33056289 2.13534799] , error: 0.473820003081568\n",
      "Step: 3247 Weights: [0.33062127 2.13534131] , error: 0.4738196581709333\n",
      "Step: 3248 Weights: [0.33067952 2.13533465] , error: 0.47381931483158374\n",
      "Step: 3249 Weights: [0.33073763 2.135328  ] , error: 0.4738189730563611\n",
      "Step: 3250 Weights: [0.33079562 2.13532137] , error: 0.47381863283814046\n",
      "Step: 3251 Weights: [0.33085347 2.13531475] , error: 0.4738182941698278\n",
      "Step: 3252 Weights: [0.33091119 2.13530815] , error: 0.4738179570443632\n",
      "Step: 3253 Weights: [0.33096878 2.13530157] , error: 0.4738176214547181\n",
      "Step: 3254 Weights: [0.33102623 2.135295  ] , error: 0.47381728739389534\n",
      "Step: 3255 Weights: [0.33108356 2.13528844] , error: 0.47381695485493\n",
      "Step: 3256 Weights: [0.33114075 2.1352819 ] , error: 0.47381662383088885\n",
      "Step: 3257 Weights: [0.33119782 2.13527537] , error: 0.4738162943148714\n",
      "Step: 3258 Weights: [0.33125475 2.13526886] , error: 0.47381596630000716\n",
      "Step: 3259 Weights: [0.33131155 2.13526237] , error: 0.47381563977945695\n",
      "Step: 3260 Weights: [0.33136823 2.13525588] , error: 0.4738153147464148\n",
      "Step: 3261 Weights: [0.33142478 2.13524942] , error: 0.4738149911941026\n",
      "Step: 3262 Weights: [0.33148119 2.13524297] , error: 0.47381466911577513\n",
      "Step: 3263 Weights: [0.33153748 2.13523653] , error: 0.4738143485047182\n",
      "Step: 3264 Weights: [0.33159364 2.13523011] , error: 0.4738140293542456\n",
      "Step: 3265 Weights: [0.33164967 2.1352237 ] , error: 0.4738137116577051\n",
      "Step: 3266 Weights: [0.33170557 2.1352173 ] , error: 0.4738133954084726\n",
      "Step: 3267 Weights: [0.33176135 2.13521093] , error: 0.4738130805999551\n",
      "Step: 3268 Weights: [0.331817   2.13520456] , error: 0.4738127672255895\n",
      "Step: 3269 Weights: [0.33187252 2.13519821] , error: 0.47381245527884\n",
      "Step: 3270 Weights: [0.33192792 2.13519188] , error: 0.4738121447532059\n",
      "Step: 3271 Weights: [0.33198319 2.13518555] , error: 0.47381183564221196\n",
      "Step: 3272 Weights: [0.33203833 2.13517925] , error: 0.4738115279394124\n",
      "Step: 3273 Weights: [0.33209335 2.13517296] , error: 0.4738112216383944\n",
      "Step: 3274 Weights: [0.33214824 2.13516668] , error: 0.47381091673277065\n",
      "Step: 3275 Weights: [0.33220301 2.13516042] , error: 0.47381061321618345\n",
      "Step: 3276 Weights: [0.33225765 2.13515417] , error: 0.47381031108230603\n",
      "Step: 3277 Weights: [0.33231217 2.13514793] , error: 0.4738100103248388\n",
      "Step: 3278 Weights: [0.33236656 2.13514171] , error: 0.473809710937512\n",
      "Step: 3279 Weights: [0.33242083 2.1351355 ] , error: 0.4738094129140824\n",
      "Step: 3280 Weights: [0.33247497 2.13512931] , error: 0.473809116248338\n",
      "Step: 3281 Weights: [0.33252899 2.13512313] , error: 0.47380882093409354\n",
      "Step: 3282 Weights: [0.33258289 2.13511697] , error: 0.4738085269651905\n",
      "Step: 3283 Weights: [0.33263667 2.13511082] , error: 0.47380823433550207\n",
      "Step: 3284 Weights: [0.33269032 2.13510468] , error: 0.47380794303892576\n",
      "Step: 3285 Weights: [0.33274385 2.13509856] , error: 0.4738076530693893\n",
      "Step: 3286 Weights: [0.33279726 2.13509245] , error: 0.47380736442084714\n",
      "Step: 3287 Weights: [0.33285055 2.13508636] , error: 0.47380707708728126\n",
      "Step: 3288 Weights: [0.33290371 2.13508028] , error: 0.47380679106270096\n",
      "Step: 3289 Weights: [0.33295676 2.13507421] , error: 0.47380650634114246\n",
      "Step: 3290 Weights: [0.33300968 2.13506816] , error: 0.4738062229166706\n",
      "Step: 3291 Weights: [0.33306248 2.13506212] , error: 0.4738059407833754\n",
      "Step: 3292 Weights: [0.33311516 2.1350561 ] , error: 0.4738056599353766\n",
      "Step: 3293 Weights: [0.33316773 2.13505009] , error: 0.47380538036681574\n",
      "Step: 3294 Weights: [0.33322017 2.13504409] , error: 0.47380510207186755\n",
      "Step: 3295 Weights: [0.33327249 2.1350381 ] , error: 0.47380482504472743\n",
      "Step: 3296 Weights: [0.33332469 2.13503213] , error: 0.47380454927962035\n",
      "Step: 3297 Weights: [0.33337678 2.13502618] , error: 0.4738042747707975\n",
      "Step: 3298 Weights: [0.33342874 2.13502024] , error: 0.47380400151253566\n",
      "Step: 3299 Weights: [0.33348059 2.13501431] , error: 0.4738037294991373\n",
      "Step: 3300 Weights: [0.33353232 2.13500839] , error: 0.4738034587249321\n",
      "Step: 3301 Weights: [0.33358393 2.13500249] , error: 0.4738031891842731\n",
      "Step: 3302 Weights: [0.33363542 2.1349966 ] , error: 0.47380292087154235\n",
      "Step: 3303 Weights: [0.3336868  2.13499072] , error: 0.4738026537811455\n",
      "Step: 3304 Weights: [0.33373805 2.13498486] , error: 0.4738023879075141\n",
      "Step: 3305 Weights: [0.3337892  2.13497901] , error: 0.4738021232451035\n",
      "Step: 3306 Weights: [0.33384022 2.13497318] , error: 0.4738018597883982\n",
      "Step: 3307 Weights: [0.33389113 2.13496735] , error: 0.47380159753190343\n",
      "Step: 3308 Weights: [0.33394192 2.13496155] , error: 0.47380133647015266\n",
      "Step: 3309 Weights: [0.3339926  2.13495575] , error: 0.47380107659770365\n",
      "Step: 3310 Weights: [0.33404316 2.13494997] , error: 0.47380081790913653\n",
      "Step: 3311 Weights: [0.3340936 2.1349442] , error: 0.4738005603990592\n",
      "Step: 3312 Weights: [0.33414393 2.13493844] , error: 0.4738003040621023\n",
      "Step: 3313 Weights: [0.33419415 2.1349327 ] , error: 0.4738000488929227\n",
      "Step: 3314 Weights: [0.33424425 2.13492697] , error: 0.4737997948861995\n",
      "Step: 3315 Weights: [0.33429424 2.13492125] , error: 0.4737995420366359\n",
      "Step: 3316 Weights: [0.33434411 2.13491555] , error: 0.47379929033896273\n",
      "Step: 3317 Weights: [0.33439387 2.13490986] , error: 0.4737990397879304\n",
      "Step: 3318 Weights: [0.33444352 2.13490418] , error: 0.47379879037831624\n",
      "Step: 3319 Weights: [0.33449305 2.13489852] , error: 0.47379854210492045\n",
      "Step: 3320 Weights: [0.33454247 2.13489286] , error: 0.4737982949625672\n",
      "Step: 3321 Weights: [0.33459178 2.13488723] , error: 0.4737980489461011\n",
      "Step: 3322 Weights: [0.33464097 2.1348816 ] , error: 0.4737978040503964\n",
      "Step: 3323 Weights: [0.33469005 2.13487599] , error: 0.4737975602703465\n",
      "Step: 3324 Weights: [0.33473902 2.13487039] , error: 0.47379731760086796\n",
      "Step: 3325 Weights: [0.33478788 2.1348648 ] , error: 0.47379707603690235\n",
      "Step: 3326 Weights: [0.33483663 2.13485922] , error: 0.47379683557341173\n",
      "Step: 3327 Weights: [0.33488526 2.13485366] , error: 0.4737965962053854\n",
      "Step: 3328 Weights: [0.33493379 2.13484811] , error: 0.4737963579278308\n",
      "Step: 3329 Weights: [0.3349822  2.13484257] , error: 0.4737961207357807\n",
      "Step: 3330 Weights: [0.33503051 2.13483705] , error: 0.4737958846242897\n",
      "Step: 3331 Weights: [0.3350787  2.13483154] , error: 0.47379564958843545\n",
      "Step: 3332 Weights: [0.33512679 2.13482604] , error: 0.47379541562331795\n",
      "Step: 3333 Weights: [0.33517476 2.13482055] , error: 0.47379518272405907\n",
      "Step: 3334 Weights: [0.33522263 2.13481508] , error: 0.47379495088580337\n",
      "Step: 3335 Weights: [0.33527038 2.13480962] , error: 0.47379472010371654\n",
      "Step: 3336 Weights: [0.33531803 2.13480417] , error: 0.4737944903729877\n",
      "Step: 3337 Weights: [0.33536557 2.13479873] , error: 0.47379426168882766\n",
      "Step: 3338 Weights: [0.335413   2.13479331] , error: 0.4737940340464685\n",
      "Step: 3339 Weights: [0.33546032 2.1347879 ] , error: 0.4737938074411624\n",
      "Step: 3340 Weights: [0.33550753 2.1347825 ] , error: 0.4737935818681881\n",
      "Step: 3341 Weights: [0.33555464 2.13477711] , error: 0.4737933573228399\n",
      "Step: 3342 Weights: [0.33560164 2.13477173] , error: 0.47379313380043697\n",
      "Step: 3343 Weights: [0.33564853 2.13476637] , error: 0.4737929112963195\n",
      "Step: 3344 Weights: [0.33569531 2.13476102] , error: 0.4737926898058492\n",
      "Step: 3345 Weights: [0.33574199 2.13475568] , error: 0.4737924693244082\n",
      "Step: 3346 Weights: [0.33578856 2.13475036] , error: 0.4737922498473985\n",
      "Step: 3347 Weights: [0.33583503 2.13474504] , error: 0.473792031370245\n",
      "Step: 3348 Weights: [0.33588139 2.13473974] , error: 0.47379181388839264\n",
      "Step: 3349 Weights: [0.33592764 2.13473445] , error: 0.47379159739730714\n",
      "Step: 3350 Weights: [0.33597379 2.13472917] , error: 0.47379138189247566\n",
      "Step: 3351 Weights: [0.33601983 2.13472391] , error: 0.47379116736940435\n",
      "Step: 3352 Weights: [0.33606577 2.13471865] , error: 0.47379095382362096\n",
      "Step: 3353 Weights: [0.3361116  2.13471341] , error: 0.4737907412506733\n",
      "Step: 3354 Weights: [0.33615733 2.13470818] , error: 0.4737905296461289\n",
      "Step: 3355 Weights: [0.33620296 2.13470296] , error: 0.4737903190055766\n",
      "Step: 3356 Weights: [0.33624848 2.13469776] , error: 0.47379010932462473\n",
      "Step: 3357 Weights: [0.33629389 2.13469256] , error: 0.47378990059890347\n",
      "Step: 3358 Weights: [0.33633921 2.13468738] , error: 0.4737896928240577\n",
      "Step: 3359 Weights: [0.33638442 2.13468221] , error: 0.47378948599575754\n",
      "Step: 3360 Weights: [0.33642952 2.13467705] , error: 0.47378928010969135\n",
      "Step: 3361 Weights: [0.33647453 2.13467191] , error: 0.4737890751615658\n",
      "Step: 3362 Weights: [0.33651943 2.13466677] , error: 0.47378887114710866\n",
      "Step: 3363 Weights: [0.33656423 2.13466165] , error: 0.47378866806206493\n",
      "Step: 3364 Weights: [0.33660892 2.13465654] , error: 0.47378846590220225\n",
      "Step: 3365 Weights: [0.33665352 2.13465144] , error: 0.4737882646633055\n",
      "Step: 3366 Weights: [0.33669801 2.13464635] , error: 0.4737880643411788\n",
      "Step: 3367 Weights: [0.3367424  2.13464127] , error: 0.4737878649316447\n",
      "Step: 3368 Weights: [0.33678669 2.13463621] , error: 0.4737876664305474\n",
      "Step: 3369 Weights: [0.33683088 2.13463115] , error: 0.47378746883374784\n",
      "Step: 3370 Weights: [0.33687497 2.13462611] , error: 0.4737872721371269\n",
      "Step: 3371 Weights: [0.33691896 2.13462108] , error: 0.4737870763365816\n",
      "Step: 3372 Weights: [0.33696285 2.13461606] , error: 0.473786881428033\n",
      "Step: 3373 Weights: [0.33700663 2.13461105] , error: 0.4737866874074146\n",
      "Step: 3374 Weights: [0.33705032 2.13460606] , error: 0.47378649427068265\n",
      "Step: 3375 Weights: [0.33709391 2.13460107] , error: 0.4737863020138108\n",
      "Step: 3376 Weights: [0.3371374 2.1345961] , error: 0.47378611063278925\n",
      "Step: 3377 Weights: [0.33718079 2.13459114] , error: 0.47378592012363047\n",
      "Step: 3378 Weights: [0.33722408 2.13458618] , error: 0.47378573048236045\n",
      "Step: 3379 Weights: [0.33726727 2.13458124] , error: 0.47378554170502424\n",
      "Step: 3380 Weights: [0.33731036 2.13457632] , error: 0.47378535378768943\n",
      "Step: 3381 Weights: [0.33735336 2.1345714 ] , error: 0.47378516672643606\n",
      "Step: 3382 Weights: [0.33739625 2.13456649] , error: 0.47378498051736495\n",
      "Step: 3383 Weights: [0.33743905 2.1345616 ] , error: 0.47378479515659444\n",
      "Step: 3384 Weights: [0.33748176 2.13455672] , error: 0.4737846106402569\n",
      "Step: 3385 Weights: [0.33752436 2.13455184] , error: 0.4737844269645097\n",
      "Step: 3386 Weights: [0.33756687 2.13454698] , error: 0.47378424412552017\n",
      "Step: 3387 Weights: [0.33760928 2.13454213] , error: 0.47378406211947827\n",
      "Step: 3388 Weights: [0.33765159 2.13453729] , error: 0.4737838809425882\n",
      "Step: 3389 Weights: [0.33769381 2.13453246] , error: 0.4737837005910741\n",
      "Step: 3390 Weights: [0.33773593 2.13452765] , error: 0.4737835210611728\n",
      "Step: 3391 Weights: [0.33777795 2.13452284] , error: 0.473783342349146\n",
      "Step: 3392 Weights: [0.33781988 2.13451805] , error: 0.4737831644512626\n",
      "Step: 3393 Weights: [0.33786171 2.13451326] , error: 0.4737829873638186\n",
      "Step: 3394 Weights: [0.33790345 2.13450849] , error: 0.4737828110831175\n",
      "Step: 3395 Weights: [0.33794509 2.13450373] , error: 0.47378263560548717\n",
      "Step: 3396 Weights: [0.33798664 2.13449897] , error: 0.4737824609272676\n",
      "Step: 3397 Weights: [0.33802809 2.13449423] , error: 0.47378228704481856\n",
      "Step: 3398 Weights: [0.33806945 2.1344895 ] , error: 0.4737821139545124\n",
      "Step: 3399 Weights: [0.33811072 2.13448478] , error: 0.47378194165274257\n",
      "Step: 3400 Weights: [0.33815189 2.13448008] , error: 0.4737817701359152\n",
      "Step: 3401 Weights: [0.33819296 2.13447538] , error: 0.47378159940045683\n",
      "Step: 3402 Weights: [0.33823394 2.13447069] , error: 0.4737814294428042\n",
      "Step: 3403 Weights: [0.33827483 2.13446602] , error: 0.47378126025941747\n",
      "Step: 3404 Weights: [0.33831563 2.13446135] , error: 0.4737810918467666\n",
      "Step: 3405 Weights: [0.33835633 2.1344567 ] , error: 0.4737809242013422\n",
      "Step: 3406 Weights: [0.33839694 2.13445205] , error: 0.4737807573196472\n",
      "Step: 3407 Weights: [0.33843746 2.13444742] , error: 0.47378059119820454\n",
      "Step: 3408 Weights: [0.33847788 2.13444279] , error: 0.4737804258335496\n",
      "Step: 3409 Weights: [0.33851822 2.13443818] , error: 0.473780261222235\n",
      "Step: 3410 Weights: [0.33855846 2.13443358] , error: 0.4737800973608286\n",
      "Step: 3411 Weights: [0.33859861 2.13442899] , error: 0.4737799342459149\n",
      "Step: 3412 Weights: [0.33863866 2.13442441] , error: 0.47377977187409154\n",
      "Step: 3413 Weights: [0.33867863 2.13441984] , error: 0.47377961024197457\n",
      "Step: 3414 Weights: [0.3387185  2.13441528] , error: 0.4737794493461933\n",
      "Step: 3415 Weights: [0.33875829 2.13441073] , error: 0.4737792891833947\n",
      "Step: 3416 Weights: [0.33879798 2.13440619] , error: 0.47377912975023845\n",
      "Step: 3417 Weights: [0.33883758 2.13440166] , error: 0.4737789710434006\n",
      "Step: 3418 Weights: [0.33887709 2.13439714] , error: 0.47377881305957226\n",
      "Step: 3419 Weights: [0.33891652 2.13439263] , error: 0.47377865579546036\n",
      "Step: 3420 Weights: [0.33895585 2.13438813] , error: 0.47377849924778487\n",
      "Step: 3421 Weights: [0.33899509 2.13438364] , error: 0.4737783434132838\n",
      "Step: 3422 Weights: [0.33903425 2.13437917] , error: 0.47377818828870594\n",
      "Step: 3423 Weights: [0.33907331 2.1343747 ] , error: 0.4737780338708191\n",
      "Step: 3424 Weights: [0.33911228 2.13437024] , error: 0.4737778801564033\n",
      "Step: 3425 Weights: [0.33915117 2.13436579] , error: 0.4737777271422535\n",
      "Step: 3426 Weights: [0.33918997 2.13436136] , error: 0.47377757482517924\n",
      "Step: 3427 Weights: [0.33922868 2.13435693] , error: 0.47377742320200494\n",
      "Step: 3428 Weights: [0.3392673  2.13435251] , error: 0.47377727226957045\n",
      "Step: 3429 Weights: [0.33930583 2.13434811] , error: 0.47377712202472977\n",
      "Step: 3430 Weights: [0.33934427 2.13434371] , error: 0.47377697246434647\n",
      "Step: 3431 Weights: [0.33938263 2.13433932] , error: 0.4737768235853068\n",
      "Step: 3432 Weights: [0.3394209  2.13433495] , error: 0.47377667538450413\n",
      "Step: 3433 Weights: [0.33945908 2.13433058] , error: 0.4737765278588492\n",
      "Step: 3434 Weights: [0.33949718 2.13432622] , error: 0.4737763810052667\n",
      "Step: 3435 Weights: [0.33953518 2.13432188] , error: 0.4737762348206968\n",
      "Step: 3436 Weights: [0.33957311 2.13431754] , error: 0.47377608930208787\n",
      "Step: 3437 Weights: [0.33961094 2.13431321] , error: 0.4737759444464082\n",
      "Step: 3438 Weights: [0.33964869 2.1343089 ] , error: 0.47377580025063776\n",
      "Step: 3439 Weights: [0.33968635 2.13430459] , error: 0.47377565671177035\n",
      "Step: 3440 Weights: [0.33972393 2.13430029] , error: 0.4737755138268123\n",
      "Step: 3441 Weights: [0.33976142 2.134296  ] , error: 0.4737753715927859\n",
      "Step: 3442 Weights: [0.33979883 2.13429173] , error: 0.4737752300067255\n",
      "Step: 3443 Weights: [0.33983615 2.13428746] , error: 0.4737750890656777\n",
      "Step: 3444 Weights: [0.33987338 2.1342832 ] , error: 0.47377494876670584\n",
      "Step: 3445 Weights: [0.33991053 2.13427895] , error: 0.4737748091068844\n",
      "Step: 3446 Weights: [0.3399476  2.13427471] , error: 0.4737746700833011\n",
      "Step: 3447 Weights: [0.33998458 2.13427048] , error: 0.47377453169305894\n",
      "Step: 3448 Weights: [0.34002147 2.13426626] , error: 0.47377439393327087\n",
      "Step: 3449 Weights: [0.34005829 2.13426205] , error: 0.4737742568010649\n",
      "Step: 3450 Weights: [0.34009502 2.13425785] , error: 0.47377412029358335\n",
      "Step: 3451 Weights: [0.34013166 2.13425366] , error: 0.4737739844079792\n",
      "Step: 3452 Weights: [0.34016822 2.13424948] , error: 0.47377384914141973\n",
      "Step: 3453 Weights: [0.3402047  2.13424531] , error: 0.47377371449108474\n",
      "Step: 3454 Weights: [0.34024109 2.13424115] , error: 0.47377358045416723\n",
      "Step: 3455 Weights: [0.34027741 2.13423699] , error: 0.4737734470278721\n",
      "Step: 3456 Weights: [0.34031363 2.13423285] , error: 0.4737733142094183\n",
      "Step: 3457 Weights: [0.34034978 2.13422872] , error: 0.47377318199603535\n",
      "Step: 3458 Weights: [0.34038585 2.13422459] , error: 0.47377305038496836\n",
      "Step: 3459 Weights: [0.34042183 2.13422048] , error: 0.47377291937347277\n",
      "Step: 3460 Weights: [0.34045773 2.13421637] , error: 0.4737727889588169\n",
      "Step: 3461 Weights: [0.34049354 2.13421227] , error: 0.4737726591382825\n",
      "Step: 3462 Weights: [0.34052928 2.13420819] , error: 0.4737725299091613\n",
      "Step: 3463 Weights: [0.34056493 2.13420411] , error: 0.4737724012687617\n",
      "Step: 3464 Weights: [0.34060051 2.13420004] , error: 0.4737722732144\n",
      "Step: 3465 Weights: [0.340636   2.13419598] , error: 0.47377214574340654\n",
      "Step: 3466 Weights: [0.34067141 2.13419193] , error: 0.4737720188531234\n",
      "Step: 3467 Weights: [0.34070674 2.13418789] , error: 0.47377189254090574\n",
      "Step: 3468 Weights: [0.34074199 2.13418386] , error: 0.4737717668041197\n",
      "Step: 3469 Weights: [0.34077716 2.13417984] , error: 0.4737716416401442\n",
      "Step: 3470 Weights: [0.34081225 2.13417583] , error: 0.47377151704636944\n",
      "Step: 3471 Weights: [0.34084726 2.13417182] , error: 0.4737713930201979\n",
      "Step: 3472 Weights: [0.34088219 2.13416783] , error: 0.4737712695590438\n",
      "Step: 3473 Weights: [0.34091704 2.13416384] , error: 0.47377114666033315\n",
      "Step: 3474 Weights: [0.34095181 2.13415987] , error: 0.4737710243215038\n",
      "Step: 3475 Weights: [0.3409865 2.1341559] , error: 0.47377090254000437\n",
      "Step: 3476 Weights: [0.34102111 2.13415194] , error: 0.4737707813132974\n",
      "Step: 3477 Weights: [0.34105564 2.13414799] , error: 0.4737706606388538\n",
      "Step: 3478 Weights: [0.3410901  2.13414405] , error: 0.4737705405141583\n",
      "Step: 3479 Weights: [0.34112447 2.13414012] , error: 0.47377042093670646\n",
      "Step: 3480 Weights: [0.34115877 2.1341362 ] , error: 0.47377030190400526\n",
      "Step: 3481 Weights: [0.34119299 2.13413228] , error: 0.4737701834135746\n",
      "Step: 3482 Weights: [0.34122713 2.13412838] , error: 0.4737700654629409\n",
      "Step: 3483 Weights: [0.34126119 2.13412448] , error: 0.47376994804964784\n",
      "Step: 3484 Weights: [0.34129518 2.1341206 ] , error: 0.4737698311712452\n",
      "Step: 3485 Weights: [0.34132909 2.13411672] , error: 0.4737697148252976\n",
      "Step: 3486 Weights: [0.34136292 2.13411285] , error: 0.47376959900937976\n",
      "Step: 3487 Weights: [0.34139667 2.13410899] , error: 0.47376948372107563\n",
      "Step: 3488 Weights: [0.34143035 2.13410514] , error: 0.47376936895798377\n",
      "Step: 3489 Weights: [0.34146395 2.1341013 ] , error: 0.4737692547177085\n",
      "Step: 3490 Weights: [0.34149747 2.13409746] , error: 0.4737691409978708\n",
      "Step: 3491 Weights: [0.34153092 2.13409364] , error: 0.47376902779609875\n",
      "Step: 3492 Weights: [0.34156429 2.13408982] , error: 0.4737689151100324\n",
      "Step: 3493 Weights: [0.34159758 2.13408601] , error: 0.4737688029373212\n",
      "Step: 3494 Weights: [0.3416308  2.13408221] , error: 0.4737686912756274\n",
      "Step: 3495 Weights: [0.34166394 2.13407842] , error: 0.4737685801226238\n",
      "Step: 3496 Weights: [0.34169701 2.13407464] , error: 0.4737684694759921\n",
      "Step: 3497 Weights: [0.34173    2.13407087] , error: 0.47376835933342454\n",
      "Step: 3498 Weights: [0.34176292 2.1340671 ] , error: 0.47376824969262676\n",
      "Step: 3499 Weights: [0.34179576 2.13406335] , error: 0.47376814055131217\n",
      "Step: 3500 Weights: [0.34182853 2.1340596 ] , error: 0.47376803190720507\n",
      "Step: 3501 Weights: [0.34186122 2.13405586] , error: 0.47376792375803956\n",
      "Step: 3502 Weights: [0.34189384 2.13405213] , error: 0.47376781610156266\n",
      "Step: 3503 Weights: [0.34192638 2.13404841] , error: 0.4737677089355281\n",
      "Step: 3504 Weights: [0.34195885 2.1340447 ] , error: 0.4737676022577029\n",
      "Step: 3505 Weights: [0.34199124 2.13404099] , error: 0.4737674960658618\n",
      "Step: 3506 Weights: [0.34202356 2.1340373 ] , error: 0.4737673903577928\n",
      "Step: 3507 Weights: [0.34205581 2.13403361] , error: 0.47376728513128963\n",
      "Step: 3508 Weights: [0.34208798 2.13402993] , error: 0.4737671803841592\n",
      "Step: 3509 Weights: [0.34212008 2.13402626] , error: 0.4737670761142195\n",
      "Step: 3510 Weights: [0.34215211 2.13402259] , error: 0.4737669723192935\n",
      "Step: 3511 Weights: [0.34218406 2.13401894] , error: 0.4737668689972194\n",
      "Step: 3512 Weights: [0.34221594 2.13401529] , error: 0.4737667661458435\n",
      "Step: 3513 Weights: [0.34224775 2.13401166] , error: 0.4737666637630189\n",
      "Step: 3514 Weights: [0.34227949 2.13400803] , error: 0.4737665618466138\n",
      "Step: 3515 Weights: [0.34231115 2.13400441] , error: 0.4737664603945017\n",
      "Step: 3516 Weights: [0.34234274 2.13400079] , error: 0.4737663594045677\n",
      "Step: 3517 Weights: [0.34237426 2.13399719] , error: 0.4737662588747071\n",
      "Step: 3518 Weights: [0.34240571 2.13399359] , error: 0.4737661588028229\n",
      "Step: 3519 Weights: [0.34243708 2.13399   ] , error: 0.4737660591868294\n",
      "Step: 3520 Weights: [0.34246839 2.13398642] , error: 0.47376596002465\n",
      "Step: 3521 Weights: [0.34249962 2.13398285] , error: 0.47376586131421616\n",
      "Step: 3522 Weights: [0.34253078 2.13397929] , error: 0.47376576305347073\n",
      "Step: 3523 Weights: [0.34256187 2.13397573] , error: 0.473765665240365\n",
      "Step: 3524 Weights: [0.34259289 2.13397218] , error: 0.4737655678728597\n",
      "Step: 3525 Weights: [0.34262384 2.13396864] , error: 0.4737654709489255\n",
      "Step: 3526 Weights: [0.34265472 2.13396511] , error: 0.47376537446653955\n",
      "Step: 3527 Weights: [0.34268553 2.13396159] , error: 0.47376527842369254\n",
      "Step: 3528 Weights: [0.34271626 2.13395808] , error: 0.4737651828183816\n",
      "Step: 3529 Weights: [0.34274693 2.13395457] , error: 0.4737650876486127\n",
      "Step: 3530 Weights: [0.34277753 2.13395107] , error: 0.4737649929124015\n",
      "Step: 3531 Weights: [0.34280806 2.13394758] , error: 0.47376489860777465\n",
      "Step: 3532 Weights: [0.34283851 2.13394409] , error: 0.47376480473276383\n",
      "Step: 3533 Weights: [0.3428689  2.13394062] , error: 0.47376471128541364\n",
      "Step: 3534 Weights: [0.34289922 2.13393715] , error: 0.47376461826377425\n",
      "Step: 3535 Weights: [0.34292947 2.13393369] , error: 0.473764525665908\n",
      "Step: 3536 Weights: [0.34295965 2.13393024] , error: 0.47376443348988295\n",
      "Step: 3537 Weights: [0.34298976 2.1339268 ] , error: 0.47376434173377774\n",
      "Step: 3538 Weights: [0.34301981 2.13392336] , error: 0.47376425039567915\n",
      "Step: 3539 Weights: [0.34304978 2.13391993] , error: 0.4737641594736837\n",
      "Step: 3540 Weights: [0.34307969 2.13391651] , error: 0.47376406896589496\n",
      "Step: 3541 Weights: [0.34310953 2.1339131 ] , error: 0.473763978870427\n",
      "Step: 3542 Weights: [0.3431393  2.13390969] , error: 0.47376388918540074\n",
      "Step: 3543 Weights: [0.343169  2.1339063] , error: 0.4737637999089446\n",
      "Step: 3544 Weights: [0.34319864 2.13390291] , error: 0.47376371103920073\n",
      "Step: 3545 Weights: [0.3432282  2.13389953] , error: 0.4737636225743146\n",
      "Step: 3546 Weights: [0.3432577  2.13389615] , error: 0.4737635345124407\n",
      "Step: 3547 Weights: [0.34328714 2.13389279] , error: 0.47376344685174426\n",
      "Step: 3548 Weights: [0.3433165  2.13388943] , error: 0.4737633595903989\n",
      "Step: 3549 Weights: [0.3433458  2.13388608] , error: 0.4737632727265827\n",
      "Step: 3550 Weights: [0.34337503 2.13388274] , error: 0.4737631862584858\n",
      "Step: 3551 Weights: [0.3434042 2.1338794] , error: 0.4737631001843066\n",
      "Step: 3552 Weights: [0.3434333  2.13387607] , error: 0.47376301450224945\n",
      "Step: 3553 Weights: [0.34346233 2.13387275] , error: 0.4737629292105268\n",
      "Step: 3554 Weights: [0.34349129 2.13386944] , error: 0.47376284430736393\n",
      "Step: 3555 Weights: [0.34352019 2.13386613] , error: 0.47376275979098637\n",
      "Step: 3556 Weights: [0.34354903 2.13386284] , error: 0.4737626756596353\n",
      "Step: 3557 Weights: [0.3435778  2.13385955] , error: 0.4737625919115557\n",
      "Step: 3558 Weights: [0.3436065  2.13385626] , error: 0.473762508545001\n",
      "Step: 3559 Weights: [0.34363514 2.13385299] , error: 0.4737624255582333\n",
      "Step: 3560 Weights: [0.34366371 2.13384972] , error: 0.4737623429495234\n",
      "Step: 3561 Weights: [0.34369221 2.13384646] , error: 0.4737622607171473\n",
      "Step: 3562 Weights: [0.34372066 2.13384321] , error: 0.4737621788593924\n",
      "Step: 3563 Weights: [0.34374903 2.13383996] , error: 0.47376209737455066\n",
      "Step: 3564 Weights: [0.34377735 2.13383673] , error: 0.47376201626092423\n",
      "Step: 3565 Weights: [0.34380559 2.13383349] , error: 0.4737619355168208\n",
      "Step: 3566 Weights: [0.34383378 2.13383027] , error: 0.473761855140558\n",
      "Step: 3567 Weights: [0.3438619  2.13382706] , error: 0.47376177513046003\n",
      "Step: 3568 Weights: [0.34388995 2.13382385] , error: 0.4737616954848584\n",
      "Step: 3569 Weights: [0.34391794 2.13382065] , error: 0.4737616162020933\n",
      "Step: 3570 Weights: [0.34394587 2.13381745] , error: 0.47376153728051007\n",
      "Step: 3571 Weights: [0.34397373 2.13381427] , error: 0.4737614587184651\n",
      "Step: 3572 Weights: [0.34400153 2.13381109] , error: 0.4737613805143194\n",
      "Step: 3573 Weights: [0.34402927 2.13380791] , error: 0.473761302666443\n",
      "Step: 3574 Weights: [0.34405694 2.13380475] , error: 0.47376122517321295\n",
      "Step: 3575 Weights: [0.34408455 2.13380159] , error: 0.47376114803301317\n",
      "Step: 3576 Weights: [0.3441121  2.13379844] , error: 0.4737610712442362\n",
      "Step: 3577 Weights: [0.34413958 2.1337953 ] , error: 0.4737609948052804\n",
      "Step: 3578 Weights: [0.344167   2.13379216] , error: 0.4737609187145513\n",
      "Step: 3579 Weights: [0.34419436 2.13378903] , error: 0.47376084297046384\n",
      "Step: 3580 Weights: [0.34422166 2.13378591] , error: 0.47376076757143926\n",
      "Step: 3581 Weights: [0.34424889 2.1337828 ] , error: 0.4737606925159037\n",
      "Step: 3582 Weights: [0.34427607 2.13377969] , error: 0.47376061780229395\n",
      "Step: 3583 Weights: [0.34430318 2.13377659] , error: 0.4737605434290525\n",
      "Step: 3584 Weights: [0.34433022 2.1337735 ] , error: 0.47376046939462696\n",
      "Step: 3585 Weights: [0.34435721 2.13377041] , error: 0.4737603956974758\n",
      "Step: 3586 Weights: [0.34438414 2.13376733] , error: 0.47376032233606047\n",
      "Step: 3587 Weights: [0.344411   2.13376426] , error: 0.47376024930885374\n",
      "Step: 3588 Weights: [0.3444378  2.13376119] , error: 0.4737601766143321\n",
      "Step: 3589 Weights: [0.34446454 2.13375813] , error: 0.4737601042509789\n",
      "Step: 3590 Weights: [0.34449122 2.13375508] , error: 0.47376003221728663\n",
      "Step: 3591 Weights: [0.34451784 2.13375204] , error: 0.4737599605117535\n",
      "Step: 3592 Weights: [0.3445444 2.133749 ] , error: 0.47375988913288436\n",
      "Step: 3593 Weights: [0.3445709  2.13374597] , error: 0.47375981807919104\n",
      "Step: 3594 Weights: [0.34459734 2.13374295] , error: 0.4737597473491916\n",
      "Step: 3595 Weights: [0.34462372 2.13373993] , error: 0.4737596769414121\n",
      "Step: 3596 Weights: [0.34465003 2.13373692] , error: 0.473759606854385\n",
      "Step: 3597 Weights: [0.34467629 2.13373392] , error: 0.4737595370866482\n",
      "Step: 3598 Weights: [0.34470249 2.13373092] , error: 0.47375946763674714\n",
      "Step: 3599 Weights: [0.34472863 2.13372793] , error: 0.47375939850323395\n",
      "Step: 3600 Weights: [0.34475471 2.13372495] , error: 0.4737593296846683\n",
      "Step: 3601 Weights: [0.34478072 2.13372197] , error: 0.4737592611796133\n",
      "Step: 3602 Weights: [0.34480668 2.13371901] , error: 0.4737591929866434\n",
      "Step: 3603 Weights: [0.34483258 2.13371604] , error: 0.47375912510433493\n",
      "Step: 3604 Weights: [0.34485843 2.13371309] , error: 0.47375905753127345\n",
      "Step: 3605 Weights: [0.34488421 2.13371014] , error: 0.4737589902660497\n",
      "Step: 3606 Weights: [0.34490993 2.1337072 ] , error: 0.4737589233072621\n",
      "Step: 3607 Weights: [0.3449356  2.13370426] , error: 0.4737588566535126\n",
      "Step: 3608 Weights: [0.3449612  2.13370133] , error: 0.4737587903034134\n",
      "Step: 3609 Weights: [0.34498675 2.13369841] , error: 0.4737587242555813\n",
      "Step: 3610 Weights: [0.34501224 2.1336955 ] , error: 0.47375865850863913\n",
      "Step: 3611 Weights: [0.34503767 2.13369259] , error: 0.47375859306121454\n",
      "Step: 3612 Weights: [0.34506305 2.13368969] , error: 0.47375852791194517\n",
      "Step: 3613 Weights: [0.34508836 2.13368679] , error: 0.47375846305947067\n",
      "Step: 3614 Weights: [0.34511362 2.1336839 ] , error: 0.47375839850244167\n",
      "Step: 3615 Weights: [0.34513882 2.13368102] , error: 0.47375833423950897\n",
      "Step: 3616 Weights: [0.34516396 2.13367815] , error: 0.47375827026933576\n",
      "Step: 3617 Weights: [0.34518905 2.13367528] , error: 0.47375820659058687\n",
      "Step: 3618 Weights: [0.34521408 2.13367241] , error: 0.47375814320193443\n",
      "Step: 3619 Weights: [0.34523905 2.13366956] , error: 0.473758080102057\n",
      "Step: 3620 Weights: [0.34526396 2.13366671] , error: 0.47375801728963973\n",
      "Step: 3621 Weights: [0.34528882 2.13366387] , error: 0.47375795476337257\n",
      "Step: 3622 Weights: [0.34531362 2.13366103] , error: 0.4737578925219518\n",
      "Step: 3623 Weights: [0.34533836 2.1336582 ] , error: 0.4737578305640802\n",
      "Step: 3624 Weights: [0.34536305 2.13365538] , error: 0.4737577688884641\n",
      "Step: 3625 Weights: [0.34538768 2.13365256] , error: 0.47375770749382146\n",
      "Step: 3626 Weights: [0.34541226 2.13364975] , error: 0.47375764637887025\n",
      "Step: 3627 Weights: [0.34543678 2.13364695] , error: 0.4737575855423348\n",
      "Step: 3628 Weights: [0.34546124 2.13364415] , error: 0.4737575249829495\n",
      "Step: 3629 Weights: [0.34548565 2.13364136] , error: 0.4737574646994498\n",
      "Step: 3630 Weights: [0.34551    2.13363857] , error: 0.4737574046905798\n",
      "Step: 3631 Weights: [0.3455343  2.13363579] , error: 0.47375734495508637\n",
      "Step: 3632 Weights: [0.34555854 2.13363302] , error: 0.47375728549172696\n",
      "Step: 3633 Weights: [0.34558272 2.13363025] , error: 0.4737572262992614\n",
      "Step: 3634 Weights: [0.34560685 2.13362749] , error: 0.47375716737645457\n",
      "Step: 3635 Weights: [0.34563093 2.13362474] , error: 0.47375710872207755\n",
      "Step: 3636 Weights: [0.34565495 2.13362199] , error: 0.47375705033490767\n",
      "Step: 3637 Weights: [0.34567892 2.13361925] , error: 0.4737569922137297\n",
      "Step: 3638 Weights: [0.34570283 2.13361652] , error: 0.4737569343573296\n",
      "Step: 3639 Weights: [0.34572668 2.13361379] , error: 0.4737568767645017\n",
      "Step: 3640 Weights: [0.34575049 2.13361107] , error: 0.4737568194340459\n",
      "Step: 3641 Weights: [0.34577423 2.13360835] , error: 0.47375676236476555\n",
      "Step: 3642 Weights: [0.34579793 2.13360564] , error: 0.473756705555473\n",
      "Step: 3643 Weights: [0.34582157 2.13360294] , error: 0.47375664900498177\n",
      "Step: 3644 Weights: [0.34584515 2.13360024] , error: 0.47375659271211396\n",
      "Step: 3645 Weights: [0.34586869 2.13359755] , error: 0.4737565366756956\n",
      "Step: 3646 Weights: [0.34589217 2.13359487] , error: 0.47375648089455935\n",
      "Step: 3647 Weights: [0.34591559 2.13359219] , error: 0.4737564253675404\n",
      "Step: 3648 Weights: [0.34593896 2.13358951] , error: 0.47375637009348237\n",
      "Step: 3649 Weights: [0.34596228 2.13358685] , error: 0.4737563150712316\n",
      "Step: 3650 Weights: [0.34598554 2.13358419] , error: 0.47375626029964213\n",
      "Step: 3651 Weights: [0.34600876 2.13358153] , error: 0.4737562057775732\n",
      "Step: 3652 Weights: [0.34603192 2.13357888] , error: 0.4737561515038854\n",
      "Step: 3653 Weights: [0.34605502 2.13357624] , error: 0.4737560974774482\n",
      "Step: 3654 Weights: [0.34607808 2.1335736 ] , error: 0.4737560436971359\n",
      "Step: 3655 Weights: [0.34610108 2.13357097] , error: 0.47375599016182746\n",
      "Step: 3656 Weights: [0.34612403 2.13356835] , error: 0.4737559368704058\n",
      "Step: 3657 Weights: [0.34614692 2.13356573] , error: 0.4737558838217604\n",
      "Step: 3658 Weights: [0.34616977 2.13356312] , error: 0.4737558310147842\n",
      "Step: 3659 Weights: [0.34619256 2.13356051] , error: 0.47375577844837835\n",
      "Step: 3660 Weights: [0.3462153  2.13355791] , error: 0.473755726121444\n",
      "Step: 3661 Weights: [0.34623799 2.13355532] , error: 0.4737556740328931\n",
      "Step: 3662 Weights: [0.34626062 2.13355273] , error: 0.47375562218163814\n",
      "Step: 3663 Weights: [0.34628321 2.13355014] , error: 0.47375557056659773\n",
      "Step: 3664 Weights: [0.34630574 2.13354757] , error: 0.47375551918669623\n",
      "Step: 3665 Weights: [0.34632822 2.133545  ] , error: 0.47375546804086394\n",
      "Step: 3666 Weights: [0.34635065 2.13354243] , error: 0.47375541712803165\n",
      "Step: 3667 Weights: [0.34637303 2.13353987] , error: 0.4737553664471412\n",
      "Step: 3668 Weights: [0.34639536 2.13353732] , error: 0.4737553159971326\n",
      "Step: 3669 Weights: [0.34641764 2.13353477] , error: 0.47375526577695626\n",
      "Step: 3670 Weights: [0.34643986 2.13353223] , error: 0.4737552157855638\n",
      "Step: 3671 Weights: [0.34646204 2.13352969] , error: 0.4737551660219139\n",
      "Step: 3672 Weights: [0.34648416 2.13352716] , error: 0.473755116484969\n",
      "Step: 3673 Weights: [0.34650624 2.13352464] , error: 0.4737550671736964\n",
      "Step: 3674 Weights: [0.34652826 2.13352212] , error: 0.47375501808706805\n",
      "Step: 3675 Weights: [0.34655024 2.13351961] , error: 0.47375496922405896\n",
      "Step: 3676 Weights: [0.34657216 2.1335171 ] , error: 0.47375492058365287\n",
      "Step: 3677 Weights: [0.34659404 2.1335146 ] , error: 0.47375487216483364\n",
      "Step: 3678 Weights: [0.34661586 2.1335121 ] , error: 0.47375482396659363\n",
      "Step: 3679 Weights: [0.34663764 2.13350961] , error: 0.47375477598792665\n",
      "Step: 3680 Weights: [0.34665936 2.13350713] , error: 0.4737547282278322\n",
      "Step: 3681 Weights: [0.34668104 2.13350465] , error: 0.4737546806853156\n",
      "Step: 3682 Weights: [0.34670266 2.13350217] , error: 0.4737546333593854\n",
      "Step: 3683 Weights: [0.34672424 2.13349971] , error: 0.4737545862490539\n",
      "Step: 3684 Weights: [0.34674577 2.13349724] , error: 0.4737545393533402\n",
      "Step: 3685 Weights: [0.34676724 2.13349479] , error: 0.47375449267126557\n",
      "Step: 3686 Weights: [0.34678867 2.13349234] , error: 0.47375444620185736\n",
      "Step: 3687 Weights: [0.34681005 2.13348989] , error: 0.4737543999441465\n",
      "Step: 3688 Weights: [0.34683139 2.13348745] , error: 0.4737543538971695\n",
      "Step: 3689 Weights: [0.34685267 2.13348502] , error: 0.4737543080599649\n",
      "Step: 3690 Weights: [0.3468739  2.13348259] , error: 0.4737542624315775\n",
      "Step: 3691 Weights: [0.34689509 2.13348017] , error: 0.47375421701105697\n",
      "Step: 3692 Weights: [0.34691623 2.13347775] , error: 0.47375417179745516\n",
      "Step: 3693 Weights: [0.34693732 2.13347534] , error: 0.4737541267898292\n",
      "Step: 3694 Weights: [0.34695836 2.13347293] , error: 0.4737540819872415\n",
      "Step: 3695 Weights: [0.34697935 2.13347053] , error: 0.47375403738875843\n",
      "Step: 3696 Weights: [0.3470003  2.13346813] , error: 0.47375399299345\n",
      "Step: 3697 Weights: [0.3470212  2.13346574] , error: 0.4737539488003887\n",
      "Step: 3698 Weights: [0.34704205 2.13346336] , error: 0.4737539048086564\n",
      "Step: 3699 Weights: [0.34706285 2.13346098] , error: 0.47375386101733225\n",
      "Step: 3700 Weights: [0.3470836  2.13345861] , error: 0.47375381742550604\n",
      "Step: 3701 Weights: [0.34710431 2.13345624] , error: 0.47375377403226865\n",
      "Step: 3702 Weights: [0.34712497 2.13345388] , error: 0.47375373083671485\n",
      "Step: 3703 Weights: [0.34714559 2.13345152] , error: 0.4737536878379438\n",
      "Step: 3704 Weights: [0.34716615 2.13344917] , error: 0.4737536450350586\n",
      "Step: 3705 Weights: [0.34718667 2.13344682] , error: 0.4737536024271673\n",
      "Step: 3706 Weights: [0.34720715 2.13344448] , error: 0.47375356001338276\n",
      "Step: 3707 Weights: [0.34722757 2.13344214] , error: 0.4737535177928205\n",
      "Step: 3708 Weights: [0.34724795 2.13343981] , error: 0.47375347576459814\n",
      "Step: 3709 Weights: [0.34726829 2.13343749] , error: 0.4737534339278407\n",
      "Step: 3710 Weights: [0.34728857 2.13343517] , error: 0.4737533922816773\n",
      "Step: 3711 Weights: [0.34730881 2.13343285] , error: 0.4737533508252373\n",
      "Step: 3712 Weights: [0.34732901 2.13343054] , error: 0.473753309557658\n",
      "Step: 3713 Weights: [0.34734916 2.13342824] , error: 0.47375326847807836\n",
      "Step: 3714 Weights: [0.34736926 2.13342594] , error: 0.4737532275856419\n",
      "Step: 3715 Weights: [0.34738931 2.13342365] , error: 0.4737531868794965\n",
      "Step: 3716 Weights: [0.34740933 2.13342136] , error: 0.47375314635879434\n",
      "Step: 3717 Weights: [0.34742929 2.13341907] , error: 0.47375310602268794\n",
      "Step: 3718 Weights: [0.34744921 2.1334168 ] , error: 0.4737530658703383\n",
      "Step: 3719 Weights: [0.34746908 2.13341452] , error: 0.47375302590090834\n",
      "Step: 3720 Weights: [0.34748891 2.13341225] , error: 0.4737529861135634\n",
      "Step: 3721 Weights: [0.3475087  2.13340999] , error: 0.4737529465074765\n",
      "Step: 3722 Weights: [0.34752844 2.13340773] , error: 0.4737529070818194\n",
      "Step: 3723 Weights: [0.34754813 2.13340548] , error: 0.4737528678357705\n",
      "Step: 3724 Weights: [0.34756778 2.13340324] , error: 0.47375282876851366\n",
      "Step: 3725 Weights: [0.34758738 2.13340099] , error: 0.47375278987923175\n",
      "Step: 3726 Weights: [0.34760694 2.13339876] , error: 0.4737527511671143\n",
      "Step: 3727 Weights: [0.34762645 2.13339652] , error: 0.4737527126313563\n",
      "Step: 3728 Weights: [0.34764592 2.1333943 ] , error: 0.4737526742711529\n",
      "Step: 3729 Weights: [0.34766535 2.13339208] , error: 0.47375263608570356\n",
      "Step: 3730 Weights: [0.34768473 2.13338986] , error: 0.47375259807421277\n",
      "Step: 3731 Weights: [0.34770407 2.13338765] , error: 0.47375256023588924\n",
      "Step: 3732 Weights: [0.34772336 2.13338544] , error: 0.4737525225699436\n",
      "Step: 3733 Weights: [0.34774261 2.13338324] , error: 0.47375248507558904\n",
      "Step: 3734 Weights: [0.34776182 2.13338104] , error: 0.47375244775204484\n",
      "Step: 3735 Weights: [0.34778098 2.13337885] , error: 0.4737524105985335\n",
      "Step: 3736 Weights: [0.3478001  2.13337667] , error: 0.47375237361428046\n",
      "Step: 3737 Weights: [0.34781917 2.13337449] , error: 0.47375233679851303\n",
      "Step: 3738 Weights: [0.3478382  2.13337231] , error: 0.4737523001504641\n",
      "Step: 3739 Weights: [0.34785719 2.13337014] , error: 0.47375226366937073\n",
      "Step: 3740 Weights: [0.34787613 2.13336797] , error: 0.47375222735447187\n",
      "Step: 3741 Weights: [0.34789503 2.13336581] , error: 0.47375219120501055\n",
      "Step: 3742 Weights: [0.34791389 2.13336365] , error: 0.4737521552202325\n",
      "Step: 3743 Weights: [0.3479327 2.1333615] , error: 0.47375211939938766\n",
      "Step: 3744 Weights: [0.34795148 2.13335935] , error: 0.4737520837417302\n",
      "Step: 3745 Weights: [0.3479702  2.13335721] , error: 0.4737520482465152\n",
      "Step: 3746 Weights: [0.34798889 2.13335508] , error: 0.47375201291300256\n",
      "Step: 3747 Weights: [0.34800753 2.13335294] , error: 0.4737519777404573\n",
      "Step: 3748 Weights: [0.34802613 2.13335082] , error: 0.4737519427281447\n",
      "Step: 3749 Weights: [0.34804469 2.13334869] , error: 0.4737519078753354\n",
      "Step: 3750 Weights: [0.34806321 2.13334658] , error: 0.473751873181303\n",
      "Step: 3751 Weights: [0.34808168 2.13334446] , error: 0.4737518386453236\n",
      "Step: 3752 Weights: [0.34810012 2.13334236] , error: 0.47375180426667696\n",
      "Step: 3753 Weights: [0.34811851 2.13334025] , error: 0.4737517700446473\n",
      "Step: 3754 Weights: [0.34813685 2.13333815] , error: 0.47375173597852044\n",
      "Step: 3755 Weights: [0.34815516 2.13333606] , error: 0.4737517020675856\n",
      "Step: 3756 Weights: [0.34817342 2.13333397] , error: 0.4737516683111366\n",
      "Step: 3757 Weights: [0.34819165 2.13333189] , error: 0.47375163470847037\n",
      "Step: 3758 Weights: [0.34820983 2.13332981] , error: 0.47375160125888566\n",
      "Step: 3759 Weights: [0.34822797 2.13332773] , error: 0.47375156796168355\n",
      "Step: 3760 Weights: [0.34824607 2.13332566] , error: 0.47375153481617205\n",
      "Step: 3761 Weights: [0.34826412 2.1333236 ] , error: 0.4737515018216591\n",
      "Step: 3762 Weights: [0.34828214 2.13332154] , error: 0.4737514689774562\n",
      "Step: 3763 Weights: [0.34830011 2.13331948] , error: 0.4737514362828812\n",
      "Step: 3764 Weights: [0.34831805 2.13331743] , error: 0.4737514037372489\n",
      "Step: 3765 Weights: [0.34833594 2.13331539] , error: 0.4737513713398833\n",
      "Step: 3766 Weights: [0.34835379 2.13331334] , error: 0.47375133909010775\n",
      "Step: 3767 Weights: [0.3483716  2.13331131] , error: 0.4737513069872508\n",
      "Step: 3768 Weights: [0.34838937 2.13330927] , error: 0.47375127503064096\n",
      "Step: 3769 Weights: [0.3484071  2.13330725] , error: 0.47375124321961676\n",
      "Step: 3770 Weights: [0.34842479 2.13330522] , error: 0.47375121155350897\n",
      "Step: 3771 Weights: [0.34844244 2.1333032 ] , error: 0.4737511800316618\n",
      "Step: 3772 Weights: [0.34846005 2.13330119] , error: 0.4737511486534154\n",
      "Step: 3773 Weights: [0.34847762 2.13329918] , error: 0.47375111741811726\n",
      "Step: 3774 Weights: [0.34849515 2.13329718] , error: 0.47375108632511587\n",
      "Step: 3775 Weights: [0.34851264 2.13329518] , error: 0.4737510553737623\n",
      "Step: 3776 Weights: [0.34853009 2.13329318] , error: 0.4737510245634131\n",
      "Step: 3777 Weights: [0.3485475  2.13329119] , error: 0.4737509938934214\n",
      "Step: 3778 Weights: [0.34856487 2.1332892 ] , error: 0.4737509633631529\n",
      "Step: 3779 Weights: [0.3485822  2.13328722] , error: 0.473750932971969\n",
      "Step: 3780 Weights: [0.34859949 2.13328524] , error: 0.47375090271923537\n",
      "Step: 3781 Weights: [0.34861674 2.13328327] , error: 0.4737508726043229\n",
      "Step: 3782 Weights: [0.34863395 2.1332813 ] , error: 0.4737508426266022\n",
      "Step: 3783 Weights: [0.34865112 2.13327934] , error: 0.4737508127854499\n",
      "Step: 3784 Weights: [0.34866826 2.13327738] , error: 0.47375078308024127\n",
      "Step: 3785 Weights: [0.34868535 2.13327542] , error: 0.47375075351035967\n",
      "Step: 3786 Weights: [0.34870241 2.13327347] , error: 0.47375072407518737\n",
      "Step: 3787 Weights: [0.34871942 2.13327153] , error: 0.473750694774111\n",
      "Step: 3788 Weights: [0.3487364  2.13326959] , error: 0.47375066560651913\n",
      "Step: 3789 Weights: [0.34875334 2.13326765] , error: 0.4737506365718045\n",
      "Step: 3790 Weights: [0.34877024 2.13326572] , error: 0.4737506076693607\n",
      "Step: 3791 Weights: [0.3487871  2.13326379] , error: 0.47375057889858635\n",
      "Step: 3792 Weights: [0.34880393 2.13326186] , error: 0.4737505502588807\n",
      "Step: 3793 Weights: [0.34882071 2.13325994] , error: 0.4737505217496466\n",
      "Step: 3794 Weights: [0.34883746 2.13325803] , error: 0.47375049337029057\n",
      "Step: 3795 Weights: [0.34885417 2.13325612] , error: 0.47375046512022023\n",
      "Step: 3796 Weights: [0.34887084 2.13325421] , error: 0.4737504369988466\n",
      "Step: 3797 Weights: [0.34888747 2.13325231] , error: 0.47375040900558374\n",
      "Step: 3798 Weights: [0.34890406 2.13325041] , error: 0.4737503811398489\n",
      "Step: 3799 Weights: [0.34892062 2.13324852] , error: 0.4737503534010576\n",
      "Step: 3800 Weights: [0.34893714 2.13324663] , error: 0.47375032578863685\n",
      "Step: 3801 Weights: [0.34895362 2.13324474] , error: 0.4737502983020055\n",
      "Step: 3802 Weights: [0.34897006 2.13324286] , error: 0.47375027094059396\n",
      "Step: 3803 Weights: [0.34898647 2.13324099] , error: 0.4737502437038326\n",
      "Step: 3804 Weights: [0.34900284 2.13323912] , error: 0.47375021659114935\n",
      "Step: 3805 Weights: [0.34901917 2.13323725] , error: 0.47375018960198306\n",
      "Step: 3806 Weights: [0.34903546 2.13323538] , error: 0.4737501627357694\n",
      "Step: 3807 Weights: [0.34905172 2.13323353] , error: 0.4737501359919467\n",
      "Step: 3808 Weights: [0.34906794 2.13323167] , error: 0.47375010936996\n",
      "Step: 3809 Weights: [0.34908412 2.13322982] , error: 0.47375008286925374\n",
      "Step: 3810 Weights: [0.34910027 2.13322797] , error: 0.4737500564892744\n",
      "Step: 3811 Weights: [0.34911638 2.13322613] , error: 0.4737500302294733\n",
      "Step: 3812 Weights: [0.34913245 2.13322429] , error: 0.4737500040893012\n",
      "Step: 3813 Weights: [0.34914849 2.13322246] , error: 0.47374997806821456\n",
      "Step: 3814 Weights: [0.34916448 2.13322063] , error: 0.4737499521656692\n",
      "Step: 3815 Weights: [0.34918045 2.1332188 ] , error: 0.4737499263811278\n",
      "Step: 3816 Weights: [0.34919637 2.13321698] , error: 0.4737499007140503\n",
      "Step: 3817 Weights: [0.34921226 2.13321517] , error: 0.47374987516390343\n",
      "Step: 3818 Weights: [0.34922812 2.13321335] , error: 0.4737498497301534\n",
      "Step: 3819 Weights: [0.34924393 2.13321154] , error: 0.4737498244122692\n",
      "Step: 3820 Weights: [0.34925972 2.13320974] , error: 0.4737497992097249\n",
      "Step: 3821 Weights: [0.34927546 2.13320794] , error: 0.47374977412199315\n",
      "Step: 3822 Weights: [0.34929117 2.13320614] , error: 0.4737497491485528\n",
      "Step: 3823 Weights: [0.34930685 2.13320435] , error: 0.4737497242888814\n",
      "Step: 3824 Weights: [0.34932248 2.13320256] , error: 0.4737496995424618\n",
      "Step: 3825 Weights: [0.34933809 2.13320078] , error: 0.47374967490877795\n",
      "Step: 3826 Weights: [0.34935365 2.133199  ] , error: 0.47374965038731665\n",
      "Step: 3827 Weights: [0.34936918 2.13319722] , error: 0.4737496259775649\n",
      "Step: 3828 Weights: [0.34938468 2.13319545] , error: 0.47374960167901586\n",
      "Step: 3829 Weights: [0.34940014 2.13319368] , error: 0.47374957749116076\n",
      "Step: 3830 Weights: [0.34941557 2.13319191] , error: 0.47374955341349745\n",
      "Step: 3831 Weights: [0.34943096 2.13319015] , error: 0.473749529445523\n",
      "Step: 3832 Weights: [0.34944631 2.1331884 ] , error: 0.47374950558673845\n",
      "Step: 3833 Weights: [0.34946163 2.13318665] , error: 0.4737494818366449\n",
      "Step: 3834 Weights: [0.34947692 2.1331849 ] , error: 0.473749458194748\n",
      "Step: 3835 Weights: [0.34949217 2.13318315] , error: 0.47374943466055525\n",
      "Step: 3836 Weights: [0.34950738 2.13318141] , error: 0.4737494112335749\n",
      "Step: 3837 Weights: [0.34952256 2.13317968] , error: 0.47374938791331966\n",
      "Step: 3838 Weights: [0.34953771 2.13317795] , error: 0.47374936469930284\n",
      "Step: 3839 Weights: [0.34955282 2.13317622] , error: 0.4737493415910408\n",
      "Step: 3840 Weights: [0.3495679  2.13317449] , error: 0.4737493185880508\n",
      "Step: 3841 Weights: [0.34958294 2.13317277] , error: 0.47374929568985513\n",
      "Step: 3842 Weights: [0.34959795 2.13317106] , error: 0.4737492728959741\n",
      "Step: 3843 Weights: [0.34961292 2.13316934] , error: 0.47374925020593395\n",
      "Step: 3844 Weights: [0.34962786 2.13316764] , error: 0.47374922761926186\n",
      "Step: 3845 Weights: [0.34964277 2.13316593] , error: 0.47374920513548496\n",
      "Step: 3846 Weights: [0.34965764 2.13316423] , error: 0.47374918275413674\n",
      "Step: 3847 Weights: [0.34967248 2.13316253] , error: 0.47374916047474963\n",
      "Step: 3848 Weights: [0.34968728 2.13316084] , error: 0.47374913829685894\n",
      "Step: 3849 Weights: [0.34970205 2.13315915] , error: 0.47374911622000204\n",
      "Step: 3850 Weights: [0.34971679 2.13315747] , error: 0.47374909424371997\n",
      "Step: 3851 Weights: [0.34973149 2.13315578] , error: 0.47374907236755354\n",
      "Step: 3852 Weights: [0.34974616 2.13315411] , error: 0.47374905059104633\n",
      "Step: 3853 Weights: [0.3497608  2.13315243] , error: 0.47374902891374554\n",
      "Step: 3854 Weights: [0.3497754  2.13315076] , error: 0.47374900733519876\n",
      "Step: 3855 Weights: [0.34978997 2.1331491 ] , error: 0.47374898585495495\n",
      "Step: 3856 Weights: [0.34980451 2.13314743] , error: 0.473748964472568\n",
      "Step: 3857 Weights: [0.34981901 2.13314577] , error: 0.4737489431875903\n",
      "Step: 3858 Weights: [0.34983348 2.13314412] , error: 0.47374892199958024\n",
      "Step: 3859 Weights: [0.34984792 2.13314247] , error: 0.47374890090809385\n",
      "Step: 3860 Weights: [0.34986232 2.13314082] , error: 0.473748879912693\n",
      "Step: 3861 Weights: [0.34987669 2.13313918] , error: 0.47374885901293906\n",
      "Step: 3862 Weights: [0.34989103 2.13313754] , error: 0.47374883820839725\n",
      "Step: 3863 Weights: [0.34990534 2.1331359 ] , error: 0.4737488174986329\n",
      "Step: 3864 Weights: [0.34991961 2.13313427] , error: 0.4737487968832154\n",
      "Step: 3865 Weights: [0.34993385 2.13313264] , error: 0.47374877636171253\n",
      "Step: 3866 Weights: [0.34994806 2.13313102] , error: 0.4737487559336995\n",
      "Step: 3867 Weights: [0.34996224 2.1331294 ] , error: 0.47374873559874864\n",
      "Step: 3868 Weights: [0.34997638 2.13312778] , error: 0.4737487153564361\n",
      "Step: 3869 Weights: [0.34999049 2.13312616] , error: 0.47374869520633933\n",
      "Step: 3870 Weights: [0.35000457 2.13312455] , error: 0.4737486751480404\n",
      "Step: 3871 Weights: [0.35001862 2.13312295] , error: 0.47374865518111875\n",
      "Step: 3872 Weights: [0.35003263 2.13312134] , error: 0.47374863530516\n",
      "Step: 3873 Weights: [0.35004661 2.13311975] , error: 0.4737486155197471\n",
      "Step: 3874 Weights: [0.35006057 2.13311815] , error: 0.4737485958244704\n",
      "Step: 3875 Weights: [0.35007448 2.13311656] , error: 0.4737485762189179\n",
      "Step: 3876 Weights: [0.35008837 2.13311497] , error: 0.4737485567026805\n",
      "Step: 3877 Weights: [0.35010223 2.13311339] , error: 0.4737485372753523\n",
      "Step: 3878 Weights: [0.35011605 2.1331118 ] , error: 0.4737485179365278\n",
      "Step: 3879 Weights: [0.35012984 2.13311023] , error: 0.4737484986858043\n",
      "Step: 3880 Weights: [0.35014361 2.13310865] , error: 0.47374847952277993\n",
      "Step: 3881 Weights: [0.35015734 2.13310708] , error: 0.4737484604470551\n",
      "Step: 3882 Weights: [0.35017103 2.13310552] , error: 0.4737484414582316\n",
      "Step: 3883 Weights: [0.3501847  2.13310395] , error: 0.4737484225559139\n",
      "Step: 3884 Weights: [0.35019834 2.13310239] , error: 0.47374840373970994\n",
      "Step: 3885 Weights: [0.35021194 2.13310084] , error: 0.4737483850092243\n",
      "Step: 3886 Weights: [0.35022552 2.13309929] , error: 0.4737483663640674\n",
      "Step: 3887 Weights: [0.35023906 2.13309774] , error: 0.4737483478038524\n",
      "Step: 3888 Weights: [0.35025257 2.13309619] , error: 0.47374832932818994\n",
      "Step: 3889 Weights: [0.35026605 2.13309465] , error: 0.4737483109366959\n",
      "Step: 3890 Weights: [0.3502795  2.13309311] , error: 0.47374829262898666\n",
      "Step: 3891 Weights: [0.35029292 2.13309158] , error: 0.47374827440468065\n",
      "Step: 3892 Weights: [0.35030631 2.13309004] , error: 0.4737482562633978\n",
      "Step: 3893 Weights: [0.35031967 2.13308852] , error: 0.4737482382047604\n",
      "Step: 3894 Weights: [0.350333   2.13308699] , error: 0.4737482202283917\n",
      "Step: 3895 Weights: [0.3503463  2.13308547] , error: 0.47374820233391607\n",
      "Step: 3896 Weights: [0.35035957 2.13308395] , error: 0.47374818452096107\n",
      "Step: 3897 Weights: [0.3503728  2.13308244] , error: 0.4737481667891543\n",
      "Step: 3898 Weights: [0.35038601 2.13308093] , error: 0.47374814913812857\n",
      "Step: 3899 Weights: [0.35039919 2.13307942] , error: 0.4737481315675137\n",
      "Step: 3900 Weights: [0.35041234 2.13307792] , error: 0.47374811407694495\n",
      "Step: 3901 Weights: [0.35042545 2.13307642] , error: 0.473748096666055\n",
      "Step: 3902 Weights: [0.35043854 2.13307492] , error: 0.4737480793344845\n",
      "Step: 3903 Weights: [0.3504516  2.13307343] , error: 0.47374806208186937\n",
      "Step: 3904 Weights: [0.35046462 2.13307194] , error: 0.4737480449078513\n",
      "Step: 3905 Weights: [0.35047762 2.13307045] , error: 0.47374802781207065\n",
      "Step: 3906 Weights: [0.35049059 2.13306897] , error: 0.47374801079417284\n",
      "Step: 3907 Weights: [0.35050353 2.13306749] , error: 0.4737479938538023\n",
      "Step: 3908 Weights: [0.35051644 2.13306601] , error: 0.47374797699060583\n",
      "Step: 3909 Weights: [0.35052932 2.13306454] , error: 0.47374796020423215\n",
      "Step: 3910 Weights: [0.35054217 2.13306307] , error: 0.47374794349433014\n",
      "Step: 3911 Weights: [0.35055499 2.13306161] , error: 0.4737479268605531\n",
      "Step: 3912 Weights: [0.35056778 2.13306014] , error: 0.47374791030255214\n",
      "Step: 3913 Weights: [0.35058054 2.13305868] , error: 0.4737478938199846\n",
      "Step: 3914 Weights: [0.35059328 2.13305723] , error: 0.473747877412505\n",
      "Step: 3915 Weights: [0.35060598 2.13305577] , error: 0.4737478610797716\n",
      "Step: 3916 Weights: [0.35061866 2.13305432] , error: 0.47374784482144494\n",
      "Step: 3917 Weights: [0.3506313  2.13305288] , error: 0.4737478286371846\n",
      "Step: 3918 Weights: [0.35064392 2.13305143] , error: 0.4737478125266531\n",
      "Step: 3919 Weights: [0.35065651 2.13305   ] , error: 0.4737477964895169\n",
      "Step: 3920 Weights: [0.35066907 2.13304856] , error: 0.473747780525439\n",
      "Step: 3921 Weights: [0.3506816  2.13304713] , error: 0.47374776463408785\n",
      "Step: 3922 Weights: [0.3506941 2.1330457] , error: 0.4737477488151312\n",
      "Step: 3923 Weights: [0.35070658 2.13304427] , error: 0.47374773306824014\n",
      "Step: 3924 Weights: [0.35071903 2.13304285] , error: 0.47374771739308646\n",
      "Step: 3925 Weights: [0.35073144 2.13304143] , error: 0.4737477017893423\n",
      "Step: 3926 Weights: [0.35074383 2.13304001] , error: 0.4737476862566834\n",
      "Step: 3927 Weights: [0.35075619 2.13303859] , error: 0.4737476707947854\n",
      "Step: 3928 Weights: [0.35076853 2.13303718] , error: 0.47374765540332636\n",
      "Step: 3929 Weights: [0.35078083 2.13303578] , error: 0.47374764008198617\n",
      "Step: 3930 Weights: [0.35079311 2.13303437] , error: 0.47374762483044247\n",
      "Step: 3931 Weights: [0.35080536 2.13303297] , error: 0.47374760964838036\n",
      "Step: 3932 Weights: [0.35081758 2.13303157] , error: 0.4737475945354823\n",
      "Step: 3933 Weights: [0.35082977 2.13303018] , error: 0.47374757949143154\n",
      "Step: 3934 Weights: [0.35084194 2.13302879] , error: 0.47374756451591715\n",
      "Step: 3935 Weights: [0.35085407 2.1330274 ] , error: 0.47374754960862503\n",
      "Step: 3936 Weights: [0.35086618 2.13302602] , error: 0.4737475347692459\n",
      "Step: 3937 Weights: [0.35087826 2.13302463] , error: 0.4737475199974684\n",
      "Step: 3938 Weights: [0.35089032 2.13302326] , error: 0.47374750529298626\n",
      "Step: 3939 Weights: [0.35090235 2.13302188] , error: 0.47374749065549226\n",
      "Step: 3940 Weights: [0.35091435 2.13302051] , error: 0.4737474760846819\n",
      "Step: 3941 Weights: [0.35092632 2.13301914] , error: 0.4737474615802493\n",
      "Step: 3942 Weights: [0.35093826 2.13301777] , error: 0.4737474471418949\n",
      "Step: 3943 Weights: [0.35095018 2.13301641] , error: 0.4737474327693157\n",
      "Step: 3944 Weights: [0.35096207 2.13301505] , error: 0.47374741846221247\n",
      "Step: 3945 Weights: [0.35097393 2.13301369] , error: 0.4737474042202875\n",
      "Step: 3946 Weights: [0.35098577 2.13301234] , error: 0.4737473900432437\n",
      "Step: 3947 Weights: [0.35099758 2.13301099] , error: 0.4737473759307843\n",
      "Step: 3948 Weights: [0.35100936 2.13300964] , error: 0.4737473618826168\n",
      "Step: 3949 Weights: [0.35102112 2.1330083 ] , error: 0.4737473478984469\n",
      "Step: 3950 Weights: [0.35103285 2.13300696] , error: 0.4737473339779847\n",
      "Step: 3951 Weights: [0.35104455 2.13300562] , error: 0.4737473201209394\n",
      "Step: 3952 Weights: [0.35105622 2.13300428] , error: 0.4737473063270212\n",
      "Step: 3953 Weights: [0.35106787 2.13300295] , error: 0.47374729259594106\n",
      "Step: 3954 Weights: [0.3510795  2.13300162] , error: 0.47374727892741697\n",
      "Step: 3955 Weights: [0.35109109 2.13300029] , error: 0.4737472653211599\n",
      "Step: 3956 Weights: [0.35110266 2.13299897] , error: 0.4737472517768898\n",
      "Step: 3957 Weights: [0.3511142  2.13299765] , error: 0.47374723829432075\n",
      "Step: 3958 Weights: [0.35112572 2.13299633] , error: 0.4737472248731743\n",
      "Step: 3959 Weights: [0.35113721 2.13299502] , error: 0.47374721151317\n",
      "Step: 3960 Weights: [0.35114867 2.13299371] , error: 0.47374719821402766\n",
      "Step: 3961 Weights: [0.35116011 2.1329924 ] , error: 0.47374718497547197\n",
      "Step: 3962 Weights: [0.35117152 2.1329911 ] , error: 0.47374717179722614\n",
      "Step: 3963 Weights: [0.35118291 2.13298979] , error: 0.4737471586790164\n",
      "Step: 3964 Weights: [0.35119427 2.13298849] , error: 0.47374714562056686\n",
      "Step: 3965 Weights: [0.3512056 2.1329872] , error: 0.47374713262160784\n",
      "Step: 3966 Weights: [0.35121691 2.13298591] , error: 0.4737471196818672\n",
      "Step: 3967 Weights: [0.35122819 2.13298461] , error: 0.47374710680107396\n",
      "Step: 3968 Weights: [0.35123945 2.13298333] , error: 0.47374709397896286\n",
      "Step: 3969 Weights: [0.35125068 2.13298204] , error: 0.47374708121526354\n",
      "Step: 3970 Weights: [0.35126189 2.13298076] , error: 0.47374706850971104\n",
      "Step: 3971 Weights: [0.35127307 2.13297948] , error: 0.47374705586204013\n",
      "Step: 3972 Weights: [0.35128422 2.13297821] , error: 0.4737470432719873\n",
      "Step: 3973 Weights: [0.35129535 2.13297693] , error: 0.4737470307392899\n",
      "Step: 3974 Weights: [0.35130645 2.13297566] , error: 0.473747018263687\n",
      "Step: 3975 Weights: [0.35131753 2.1329744 ] , error: 0.4737470058449181\n",
      "Step: 3976 Weights: [0.35132858 2.13297313] , error: 0.4737469934827258\n",
      "Step: 3977 Weights: [0.35133961 2.13297187] , error: 0.47374698117685\n",
      "Step: 3978 Weights: [0.35135061 2.13297061] , error: 0.4737469689270356\n",
      "Step: 3979 Weights: [0.35136159 2.13296936] , error: 0.4737469567330266\n",
      "Step: 3980 Weights: [0.35137254 2.13296811] , error: 0.4737469445945703\n",
      "Step: 3981 Weights: [0.35138347 2.13296686] , error: 0.47374693251141053\n",
      "Step: 3982 Weights: [0.35139437 2.13296561] , error: 0.4737469204832972\n",
      "Step: 3983 Weights: [0.35140525 2.13296437] , error: 0.4737469085099807\n",
      "Step: 3984 Weights: [0.3514161  2.13296312] , error: 0.4737468965912084\n",
      "Step: 3985 Weights: [0.35142693 2.13296189] , error: 0.4737468847267352\n",
      "Step: 3986 Weights: [0.35143774 2.13296065] , error: 0.47374687291631223\n",
      "Step: 3987 Weights: [0.35144851 2.13295942] , error: 0.47374686115969256\n",
      "Step: 3988 Weights: [0.35145927 2.13295819] , error: 0.47374684945663137\n",
      "Step: 3989 Weights: [0.35147    2.13295696] , error: 0.47374683780688553\n",
      "Step: 3990 Weights: [0.3514807  2.13295574] , error: 0.47374682621021175\n",
      "Step: 3991 Weights: [0.35149138 2.13295452] , error: 0.47374681466636814\n",
      "Step: 3992 Weights: [0.35150204 2.1329533 ] , error: 0.47374680317511436\n",
      "Step: 3993 Weights: [0.35151267 2.13295208] , error: 0.47374679173620926\n",
      "Step: 3994 Weights: [0.35152328 2.13295087] , error: 0.4737467803494167\n",
      "Step: 3995 Weights: [0.35153386 2.13294966] , error: 0.47374676901449775\n",
      "Step: 3996 Weights: [0.35154442 2.13294845] , error: 0.473746757731217\n",
      "Step: 3997 Weights: [0.35155496 2.13294724] , error: 0.4737467464993378\n",
      "Step: 3998 Weights: [0.35156547 2.13294604] , error: 0.47374673531862654\n",
      "Step: 3999 Weights: [0.35157596 2.13294484] , error: 0.4737467241888518\n",
      "Step: 4000 Weights: [0.35158642 2.13294365] , error: 0.47374671310977984\n",
      "Step: 4001 Weights: [0.35159686 2.13294245] , error: 0.47374670208117914\n",
      "Step: 4002 Weights: [0.35160728 2.13294126] , error: 0.47374669110282197\n",
      "Step: 4003 Weights: [0.35161767 2.13294007] , error: 0.47374668017447724\n",
      "Step: 4004 Weights: [0.35162804 2.13293889] , error: 0.47374666929591824\n",
      "Step: 4005 Weights: [0.35163838 2.1329377 ] , error: 0.47374665846691805\n",
      "Step: 4006 Weights: [0.3516487  2.13293652] , error: 0.4737466476872516\n",
      "Step: 4007 Weights: [0.351659   2.13293535] , error: 0.4737466369566917\n",
      "Step: 4008 Weights: [0.35166927 2.13293417] , error: 0.47374662627501773\n",
      "Step: 4009 Weights: [0.35167953 2.132933  ] , error: 0.47374661564200465\n",
      "Step: 4010 Weights: [0.35168975 2.13293183] , error: 0.47374660505743194\n",
      "Step: 4011 Weights: [0.35169996 2.13293066] , error: 0.47374659452107826\n",
      "Step: 4012 Weights: [0.35171014 2.1329295 ] , error: 0.4737465840327249\n",
      "Step: 4013 Weights: [0.35172029 2.13292834] , error: 0.47374657359215244\n",
      "Step: 4014 Weights: [0.35173043 2.13292718] , error: 0.47374656319914304\n",
      "Step: 4015 Weights: [0.35174054 2.13292602] , error: 0.4737465528534798\n",
      "Step: 4016 Weights: [0.35175063 2.13292487] , error: 0.4737465425549484\n",
      "Step: 4017 Weights: [0.35176069 2.13292372] , error: 0.47374653230333313\n",
      "Step: 4018 Weights: [0.35177074 2.13292257] , error: 0.4737465220984208\n",
      "Step: 4019 Weights: [0.35178076 2.13292142] , error: 0.4737465119399971\n",
      "Step: 4020 Weights: [0.35179075 2.13292028] , error: 0.4737465018278536\n",
      "Step: 4021 Weights: [0.35180073 2.13291914] , error: 0.473746491761775\n",
      "Step: 4022 Weights: [0.35181068 2.132918  ] , error: 0.47374648174155576\n",
      "Step: 4023 Weights: [0.3518206  2.13291686] , error: 0.4737464717669829\n",
      "Step: 4024 Weights: [0.35183051 2.13291573] , error: 0.47374646183785185\n",
      "Step: 4025 Weights: [0.35184039 2.1329146 ] , error: 0.47374645195395376\n",
      "Step: 4026 Weights: [0.35185025 2.13291347] , error: 0.47374644211508404\n",
      "Step: 4027 Weights: [0.35186009 2.13291235] , error: 0.47374643232103536\n",
      "Step: 4028 Weights: [0.35186991 2.13291123] , error: 0.4737464225716044\n",
      "Step: 4029 Weights: [0.3518797  2.13291011] , error: 0.47374641286658986\n",
      "Step: 4030 Weights: [0.35188947 2.13290899] , error: 0.4737464032057865\n",
      "Step: 4031 Weights: [0.35189922 2.13290787] , error: 0.4737463935889949\n",
      "Step: 4032 Weights: [0.35190895 2.13290676] , error: 0.47374638401601354\n",
      "Step: 4033 Weights: [0.35191865 2.13290565] , error: 0.47374637448664303\n",
      "Step: 4034 Weights: [0.35192833 2.13290454] , error: 0.4737463650006847\n",
      "Step: 4035 Weights: [0.35193799 2.13290344] , error: 0.47374635555794126\n",
      "Step: 4036 Weights: [0.35194763 2.13290234] , error: 0.4737463461582149\n",
      "Step: 4037 Weights: [0.35195725 2.13290124] , error: 0.47374633680131173\n",
      "Step: 4038 Weights: [0.35196684 2.13290014] , error: 0.47374632748703344\n",
      "Step: 4039 Weights: [0.35197641 2.13289905] , error: 0.4737463182151882\n",
      "Step: 4040 Weights: [0.35198596 2.13289795] , error: 0.473746308985582\n",
      "Step: 4041 Weights: [0.35199549 2.13289686] , error: 0.4737462997980229\n",
      "Step: 4042 Weights: [0.352005   2.13289578] , error: 0.4737462906523186\n",
      "Step: 4043 Weights: [0.35201448 2.13289469] , error: 0.473746281548279\n",
      "Step: 4044 Weights: [0.35202395 2.13289361] , error: 0.4737462724857133\n",
      "Step: 4045 Weights: [0.35203339 2.13289253] , error: 0.4737462634644342\n",
      "Step: 4046 Weights: [0.35204281 2.13289145] , error: 0.4737462544842518\n",
      "Step: 4047 Weights: [0.35205221 2.13289038] , error: 0.4737462455449809\n",
      "Step: 4048 Weights: [0.35206159 2.1328893 ] , error: 0.47374623664643284\n",
      "Step: 4049 Weights: [0.35207094 2.13288823] , error: 0.4737462277884233\n",
      "Step: 4050 Weights: [0.35208028 2.13288717] , error: 0.47374621897076885\n",
      "Step: 4051 Weights: [0.35208959 2.1328861 ] , error: 0.473746210193284\n",
      "Step: 4052 Weights: [0.35209888 2.13288504] , error: 0.4737462014557848\n",
      "Step: 4053 Weights: [0.35210815 2.13288398] , error: 0.4737461927580913\n",
      "Step: 4054 Weights: [0.3521174  2.13288292] , error: 0.47374618410002195\n",
      "Step: 4055 Weights: [0.35212663 2.13288187] , error: 0.4737461754813947\n",
      "Step: 4056 Weights: [0.35213584 2.13288081] , error: 0.4737461669020304\n",
      "Step: 4057 Weights: [0.35214503 2.13287976] , error: 0.4737461583617519\n",
      "Step: 4058 Weights: [0.35215419 2.13287871] , error: 0.47374614986037833\n",
      "Step: 4059 Weights: [0.35216334 2.13287767] , error: 0.4737461413977344\n",
      "Step: 4060 Weights: [0.35217246 2.13287662] , error: 0.47374613297364465\n",
      "Step: 4061 Weights: [0.35218156 2.13287558] , error: 0.4737461245879302\n",
      "Step: 4062 Weights: [0.35219065 2.13287454] , error: 0.4737461162404175\n",
      "Step: 4063 Weights: [0.35219971 2.13287351] , error: 0.4737461079309336\n",
      "Step: 4064 Weights: [0.35220875 2.13287247] , error: 0.47374609965930603\n",
      "Step: 4065 Weights: [0.35221777 2.13287144] , error: 0.47374609142535956\n",
      "Step: 4066 Weights: [0.35222677 2.13287041] , error: 0.473746083228924\n",
      "Step: 4067 Weights: [0.35223575 2.13286939] , error: 0.4737460750698286\n",
      "Step: 4068 Weights: [0.35224471 2.13286836] , error: 0.47374606694790306\n",
      "Step: 4069 Weights: [0.35225365 2.13286734] , error: 0.47374605886297727\n",
      "Step: 4070 Weights: [0.35226257 2.13286632] , error: 0.47374605081488463\n",
      "Step: 4071 Weights: [0.35227146 2.1328653 ] , error: 0.47374604280345445\n",
      "Step: 4072 Weights: [0.35228034 2.13286429] , error: 0.4737460348285231\n",
      "Step: 4073 Weights: [0.3522892  2.13286327] , error: 0.47374602688992185\n",
      "Step: 4074 Weights: [0.35229803 2.13286226] , error: 0.4737460189874856\n",
      "Step: 4075 Weights: [0.35230685 2.13286125] , error: 0.47374601112105075\n",
      "Step: 4076 Weights: [0.35231565 2.13286025] , error: 0.4737460032904518\n",
      "Step: 4077 Weights: [0.35232442 2.13285925] , error: 0.47374599549552693\n",
      "Step: 4078 Weights: [0.35233318 2.13285824] , error: 0.47374598773611254\n",
      "Step: 4079 Weights: [0.35234192 2.13285724] , error: 0.4737459800120461\n",
      "Step: 4080 Weights: [0.35235064 2.13285625] , error: 0.4737459723231683\n",
      "Step: 4081 Weights: [0.35235933 2.13285525] , error: 0.47374596466931956\n",
      "Step: 4082 Weights: [0.35236801 2.13285426] , error: 0.47374595705033684\n",
      "Step: 4083 Weights: [0.35237667 2.13285327] , error: 0.47374594946606413\n",
      "Step: 4084 Weights: [0.3523853  2.13285228] , error: 0.47374594191634356\n",
      "Step: 4085 Weights: [0.35239392 2.1328513 ] , error: 0.4737459344010163\n",
      "Step: 4086 Weights: [0.35240252 2.13285031] , error: 0.4737459269199256\n",
      "Step: 4087 Weights: [0.3524111  2.13284933] , error: 0.47374591947291544\n",
      "Step: 4088 Weights: [0.35241966 2.13284835] , error: 0.4737459120598322\n",
      "Step: 4089 Weights: [0.3524282  2.13284738] , error: 0.47374590468051997\n",
      "Step: 4090 Weights: [0.35243672 2.1328464 ] , error: 0.47374589733482597\n",
      "Step: 4091 Weights: [0.35244522 2.13284543] , error: 0.4737458900225946\n",
      "Step: 4092 Weights: [0.3524537  2.13284446] , error: 0.473745882743675\n",
      "Step: 4093 Weights: [0.35246216 2.13284349] , error: 0.4737458754979167\n",
      "Step: 4094 Weights: [0.3524706  2.13284253] , error: 0.4737458682851661\n",
      "Step: 4095 Weights: [0.35247903 2.13284156] , error: 0.47374586110527495\n",
      "Step: 4096 Weights: [0.35248743 2.1328406 ] , error: 0.4737458539580939\n",
      "Step: 4097 Weights: [0.35249582 2.13283964] , error: 0.473745846843471\n",
      "Step: 4098 Weights: [0.35250418 2.13283869] , error: 0.47374583976126056\n",
      "Step: 4099 Weights: [0.35251253 2.13283773] , error: 0.47374583271131304\n",
      "Step: 4100 Weights: [0.35252086 2.13283678] , error: 0.4737458256934836\n",
      "Step: 4101 Weights: [0.35252917 2.13283583] , error: 0.47374581870762417\n",
      "Step: 4102 Weights: [0.35253746 2.13283488] , error: 0.4737458117535904\n",
      "Step: 4103 Weights: [0.35254573 2.13283394] , error: 0.47374580483123635\n",
      "Step: 4104 Weights: [0.35255398 2.13283299] , error: 0.47374579794041727\n",
      "Step: 4105 Weights: [0.35256221 2.13283205] , error: 0.4737457910809909\n",
      "Step: 4106 Weights: [0.35257043 2.13283111] , error: 0.4737457842528141\n",
      "Step: 4107 Weights: [0.35257862 2.13283017] , error: 0.47374577745574203\n",
      "Step: 4108 Weights: [0.3525868  2.13282924] , error: 0.473745770689637\n",
      "Step: 4109 Weights: [0.35259496 2.13282831] , error: 0.47374576395435475\n",
      "Step: 4110 Weights: [0.3526031  2.13282738] , error: 0.4737457572497569\n",
      "Step: 4111 Weights: [0.35261122 2.13282645] , error: 0.4737457505757018\n",
      "Step: 4112 Weights: [0.35261932 2.13282552] , error: 0.4737457439320518\n",
      "Step: 4113 Weights: [0.3526274 2.1328246] , error: 0.4737457373186666\n",
      "Step: 4114 Weights: [0.35263547 2.13282367] , error: 0.47374573073541043\n",
      "Step: 4115 Weights: [0.35264352 2.13282275] , error: 0.4737457241821449\n",
      "Step: 4116 Weights: [0.35265155 2.13282183] , error: 0.4737457176587349\n",
      "Step: 4117 Weights: [0.35265956 2.13282092] , error: 0.47374571116504194\n",
      "Step: 4118 Weights: [0.35266755 2.13282   ] , error: 0.4737457047009313\n",
      "Step: 4119 Weights: [0.35267552 2.13281909] , error: 0.4737456982662691\n",
      "Step: 4120 Weights: [0.35268348 2.13281818] , error: 0.47374569186092147\n",
      "Step: 4121 Weights: [0.35269142 2.13281727] , error: 0.47374568548475493\n",
      "Step: 4122 Weights: [0.35269934 2.13281637] , error: 0.4737456791376343\n",
      "Step: 4123 Weights: [0.35270724 2.13281546] , error: 0.47374567281942975\n",
      "Step: 4124 Weights: [0.35271512 2.13281456] , error: 0.47374566653000844\n",
      "Step: 4125 Weights: [0.35272299 2.13281366] , error: 0.47374566026923837\n",
      "Step: 4126 Weights: [0.35273084 2.13281277] , error: 0.47374565403699165\n",
      "Step: 4127 Weights: [0.35273867 2.13281187] , error: 0.47374564783313633\n",
      "Step: 4128 Weights: [0.35274648 2.13281098] , error: 0.4737456416575426\n",
      "Step: 4129 Weights: [0.35275427 2.13281009] , error: 0.4737456355100829\n",
      "Step: 4130 Weights: [0.35276205 2.1328092 ] , error: 0.47374562939062864\n",
      "Step: 4131 Weights: [0.35276981 2.13280831] , error: 0.47374562329905356\n",
      "Step: 4132 Weights: [0.35277755 2.13280742] , error: 0.47374561723522807\n",
      "Step: 4133 Weights: [0.35278527 2.13280654] , error: 0.47374561119902736\n",
      "Step: 4134 Weights: [0.35279298 2.13280566] , error: 0.4737456051903269\n",
      "Step: 4135 Weights: [0.35280067 2.13280478] , error: 0.4737455992089982\n",
      "Step: 4136 Weights: [0.35280834 2.1328039 ] , error: 0.4737455932549184\n",
      "Step: 4137 Weights: [0.35281599 2.13280303] , error: 0.47374558732796385\n",
      "Step: 4138 Weights: [0.35282363 2.13280215] , error: 0.4737455814280092\n",
      "Step: 4139 Weights: [0.35283124 2.13280128] , error: 0.4737455755549336\n",
      "Step: 4140 Weights: [0.35283885 2.13280041] , error: 0.4737455697086133\n",
      "Step: 4141 Weights: [0.35284643 2.13279955] , error: 0.4737455638889266\n",
      "Step: 4142 Weights: [0.352854   2.13279868] , error: 0.47374555809575236\n",
      "Step: 4143 Weights: [0.35286154 2.13279782] , error: 0.473745552328969\n",
      "Step: 4144 Weights: [0.35286908 2.13279696] , error: 0.4737455465884575\n",
      "Step: 4145 Weights: [0.35287659 2.1327961 ] , error: 0.47374554087409815\n",
      "Step: 4146 Weights: [0.35288409 2.13279524] , error: 0.4737455351857711\n",
      "Step: 4147 Weights: [0.35289157 2.13279438] , error: 0.473745529523357\n",
      "Step: 4148 Weights: [0.35289903 2.13279353] , error: 0.47374552388673974\n",
      "Step: 4149 Weights: [0.35290648 2.13279268] , error: 0.4737455182758012\n",
      "Step: 4150 Weights: [0.35291391 2.13279183] , error: 0.47374551269042253\n",
      "Step: 4151 Weights: [0.35292132 2.13279098] , error: 0.47374550713048963\n",
      "Step: 4152 Weights: [0.35292872 2.13279014] , error: 0.4737455015958859\n",
      "Step: 4153 Weights: [0.3529361  2.13278929] , error: 0.4737454960864953\n",
      "Step: 4154 Weights: [0.35294346 2.13278845] , error: 0.47374549060220394\n",
      "Step: 4155 Weights: [0.3529508  2.13278761] , error: 0.47374548514289694\n",
      "Step: 4156 Weights: [0.35295813 2.13278677] , error: 0.47374547970846037\n",
      "Step: 4157 Weights: [0.35296544 2.13278594] , error: 0.4737454742987811\n",
      "Step: 4158 Weights: [0.35297274 2.1327851 ] , error: 0.47374546891374725\n",
      "Step: 4159 Weights: [0.35298002 2.13278427] , error: 0.4737454635532447\n",
      "Step: 4160 Weights: [0.35298728 2.13278344] , error: 0.4737454582171617\n",
      "Step: 4161 Weights: [0.35299452 2.13278261] , error: 0.47374545290538983\n",
      "Step: 4162 Weights: [0.35300175 2.13278178] , error: 0.47374544761781545\n",
      "Step: 4163 Weights: [0.35300896 2.13278096] , error: 0.47374544235432836\n",
      "Step: 4164 Weights: [0.35301616 2.13278014] , error: 0.4737454371148211\n",
      "Step: 4165 Weights: [0.35302334 2.13277931] , error: 0.47374543189918333\n",
      "Step: 4166 Weights: [0.3530305 2.1327785] , error: 0.4737454267073051\n",
      "Step: 4167 Weights: [0.35303765 2.13277768] , error: 0.47374542153907984\n",
      "Step: 4168 Weights: [0.35304478 2.13277686] , error: 0.47374541639439827\n",
      "Step: 4169 Weights: [0.35305189 2.13277605] , error: 0.47374541127315467\n",
      "Step: 4170 Weights: [0.35305899 2.13277524] , error: 0.4737454061752406\n",
      "Step: 4171 Weights: [0.35306607 2.13277443] , error: 0.47374540110055247\n",
      "Step: 4172 Weights: [0.35307314 2.13277362] , error: 0.4737453960489811\n",
      "Step: 4173 Weights: [0.35308019 2.13277281] , error: 0.47374539102042384\n",
      "Step: 4174 Weights: [0.35308722 2.13277201] , error: 0.4737453860147745\n",
      "Step: 4175 Weights: [0.35309424 2.13277121] , error: 0.47374538103192865\n",
      "Step: 4176 Weights: [0.35310124 2.13277041] , error: 0.47374537607178335\n",
      "Step: 4177 Weights: [0.35310822 2.13276961] , error: 0.47374537113423487\n",
      "Step: 4178 Weights: [0.35311519 2.13276881] , error: 0.4737453662191802\n",
      "Step: 4179 Weights: [0.35312215 2.13276801] , error: 0.47374536132651607\n",
      "Step: 4180 Weights: [0.35312908 2.13276722] , error: 0.47374535645614124\n",
      "Step: 4181 Weights: [0.353136   2.13276643] , error: 0.47374535160795356\n",
      "Step: 4182 Weights: [0.35314291 2.13276564] , error: 0.4737453467818532\n",
      "Step: 4183 Weights: [0.3531498  2.13276485] , error: 0.4737453419777381\n",
      "Step: 4184 Weights: [0.35315668 2.13276407] , error: 0.4737453371955088\n",
      "Step: 4185 Weights: [0.35316353 2.13276328] , error: 0.47374533243506595\n",
      "Step: 4186 Weights: [0.35317038 2.1327625 ] , error: 0.47374532769631045\n",
      "Step: 4187 Weights: [0.3531772  2.13276172] , error: 0.4737453229791432\n",
      "Step: 4188 Weights: [0.35318402 2.13276094] , error: 0.47374531828346345\n",
      "Step: 4189 Weights: [0.35319081 2.13276016] , error: 0.47374531360917765\n",
      "Step: 4190 Weights: [0.35319759 2.13275939] , error: 0.4737453089561852\n",
      "Step: 4191 Weights: [0.35320436 2.13275861] , error: 0.4737453043243901\n",
      "Step: 4192 Weights: [0.35321111 2.13275784] , error: 0.4737452997136958\n",
      "Step: 4193 Weights: [0.35321784 2.13275707] , error: 0.4737452951240066\n",
      "Step: 4194 Weights: [0.35322456 2.1327563 ] , error: 0.47374529055522546\n",
      "Step: 4195 Weights: [0.35323127 2.13275553] , error: 0.4737452860072582\n",
      "Step: 4196 Weights: [0.35323796 2.13275477] , error: 0.4737452814800099\n",
      "Step: 4197 Weights: [0.35324463 2.13275401] , error: 0.47374527697338664\n",
      "Step: 4198 Weights: [0.35325129 2.13275325] , error: 0.4737452724872931\n",
      "Step: 4199 Weights: [0.35325793 2.13275249] , error: 0.47374526802163736\n",
      "Step: 4200 Weights: [0.35326456 2.13275173] , error: 0.47374526357632557\n",
      "Step: 4201 Weights: [0.35327117 2.13275097] , error: 0.47374525915126336\n",
      "Step: 4202 Weights: [0.35327777 2.13275022] , error: 0.4737452547463618\n",
      "Step: 4203 Weights: [0.35328435 2.13274946] , error: 0.4737452503615263\n",
      "Step: 4204 Weights: [0.35329092 2.13274871] , error: 0.47374524599666723\n",
      "Step: 4205 Weights: [0.35329747 2.13274796] , error: 0.47374524165169246\n",
      "Step: 4206 Weights: [0.35330401 2.13274722] , error: 0.47374523732651175\n",
      "Step: 4207 Weights: [0.35331053 2.13274647] , error: 0.47374523302103505\n",
      "Step: 4208 Weights: [0.35331704 2.13274573] , error: 0.47374522873517305\n",
      "Step: 4209 Weights: [0.35332353 2.13274498] , error: 0.4737452244688356\n",
      "Step: 4210 Weights: [0.35333001 2.13274424] , error: 0.473745220221934\n",
      "Step: 4211 Weights: [0.35333648 2.1327435 ] , error: 0.4737452159943783\n",
      "Step: 4212 Weights: [0.35334293 2.13274277] , error: 0.4737452117860834\n",
      "Step: 4213 Weights: [0.35334936 2.13274203] , error: 0.4737452075969595\n",
      "Step: 4214 Weights: [0.35335578 2.1327413 ] , error: 0.4737452034269199\n",
      "Step: 4215 Weights: [0.35336218 2.13274056] , error: 0.4737451992758774\n",
      "Step: 4216 Weights: [0.35336857 2.13273983] , error: 0.473745195143745\n",
      "Step: 4217 Weights: [0.35337495 2.1327391 ] , error: 0.47374519103043755\n",
      "Step: 4218 Weights: [0.35338131 2.13273838] , error: 0.47374518693586853\n",
      "Step: 4219 Weights: [0.35338766 2.13273765] , error: 0.4737451828599534\n",
      "Step: 4220 Weights: [0.35339399 2.13273693] , error: 0.4737451788026058\n",
      "Step: 4221 Weights: [0.35340031 2.1327362 ] , error: 0.47374517476374217\n",
      "Step: 4222 Weights: [0.35340661 2.13273548] , error: 0.47374517074327915\n",
      "Step: 4223 Weights: [0.3534129  2.13273476] , error: 0.4737451667411311\n",
      "Step: 4224 Weights: [0.35341917 2.13273405] , error: 0.4737451627572154\n",
      "Step: 4225 Weights: [0.35342543 2.13273333] , error: 0.4737451587914486\n",
      "Step: 4226 Weights: [0.35343168 2.13273261] , error: 0.47374515484374935\n",
      "Step: 4227 Weights: [0.35343791 2.1327319 ] , error: 0.4737451509140338\n",
      "Step: 4228 Weights: [0.35344413 2.13273119] , error: 0.47374514700221976\n",
      "Step: 4229 Weights: [0.35345033 2.13273048] , error: 0.47374514310822746\n",
      "Step: 4230 Weights: [0.35345652 2.13272977] , error: 0.47374513923197437\n",
      "Step: 4231 Weights: [0.3534627  2.13272907] , error: 0.4737451353733806\n",
      "Step: 4232 Weights: [0.35346886 2.13272836] , error: 0.47374513153236464\n",
      "Step: 4233 Weights: [0.353475   2.13272766] , error: 0.4737451277088469\n",
      "Step: 4234 Weights: [0.35348114 2.13272696] , error: 0.4737451239027477\n",
      "Step: 4235 Weights: [0.35348726 2.13272626] , error: 0.4737451201139876\n",
      "Step: 4236 Weights: [0.35349336 2.13272556] , error: 0.4737451163424876\n",
      "Step: 4237 Weights: [0.35349945 2.13272486] , error: 0.4737451125881705\n",
      "Step: 4238 Weights: [0.35350553 2.13272417] , error: 0.4737451088509558\n",
      "Step: 4239 Weights: [0.35351159 2.13272348] , error: 0.4737451051307662\n",
      "Step: 4240 Weights: [0.35351764 2.13272278] , error: 0.473745101427524\n",
      "Step: 4241 Weights: [0.35352368 2.13272209] , error: 0.4737450977411534\n",
      "Step: 4242 Weights: [0.3535297 2.1327214] , error: 0.47374509407157595\n",
      "Step: 4243 Weights: [0.35353571 2.13272072] , error: 0.47374509041871604\n",
      "Step: 4244 Weights: [0.3535417  2.13272003] , error: 0.4737450867824969\n",
      "Step: 4245 Weights: [0.35354768 2.13271935] , error: 0.47374508316284325\n",
      "Step: 4246 Weights: [0.35355365 2.13271867] , error: 0.47374507955967865\n",
      "Step: 4247 Weights: [0.3535596  2.13271798] , error: 0.47374507597292925\n",
      "Step: 4248 Weights: [0.35356554 2.13271731] , error: 0.47374507240252095\n",
      "Step: 4249 Weights: [0.35357147 2.13271663] , error: 0.4737450688483762\n",
      "Step: 4250 Weights: [0.35357738 2.13271595] , error: 0.4737450653104239\n",
      "Step: 4251 Weights: [0.35358328 2.13271528] , error: 0.473745061788589\n",
      "Step: 4252 Weights: [0.35358917 2.1327146 ] , error: 0.4737450582827992\n",
      "Step: 4253 Weights: [0.35359504 2.13271393] , error: 0.47374505479297946\n",
      "Step: 4254 Weights: [0.3536009  2.13271326] , error: 0.47374505131905814\n",
      "Step: 4255 Weights: [0.35360675 2.13271259] , error: 0.47374504786096205\n",
      "Step: 4256 Weights: [0.35361258 2.13271193] , error: 0.4737450444186201\n",
      "Step: 4257 Weights: [0.3536184  2.13271126] , error: 0.47374504099196074\n",
      "Step: 4258 Weights: [0.3536242 2.1327106] , error: 0.4737450375809118\n",
      "Step: 4259 Weights: [0.35363    2.13270993] , error: 0.47374503418540226\n",
      "Step: 4260 Weights: [0.35363578 2.13270927] , error: 0.47374503080536207\n",
      "Step: 4261 Weights: [0.35364154 2.13270861] , error: 0.47374502744071945\n",
      "Step: 4262 Weights: [0.35364729 2.13270796] , error: 0.4737450240914044\n",
      "Step: 4263 Weights: [0.35365303 2.1327073 ] , error: 0.47374502075734815\n",
      "Step: 4264 Weights: [0.35365876 2.13270664] , error: 0.4737450174384806\n",
      "Step: 4265 Weights: [0.35366448 2.13270599] , error: 0.4737450141347328\n",
      "Step: 4266 Weights: [0.35367018 2.13270534] , error: 0.47374501084603565\n",
      "Step: 4267 Weights: [0.35367586 2.13270469] , error: 0.47374500757231996\n",
      "Step: 4268 Weights: [0.35368154 2.13270404] , error: 0.4737450043135194\n",
      "Step: 4269 Weights: [0.3536872  2.13270339] , error: 0.4737450010695632\n",
      "Step: 4270 Weights: [0.35369285 2.13270275] , error: 0.4737449978403855\n",
      "Step: 4271 Weights: [0.35369849 2.1327021 ] , error: 0.47374499462592\n",
      "Step: 4272 Weights: [0.35370411 2.13270146] , error: 0.47374499142609683\n",
      "Step: 4273 Weights: [0.35370972 2.13270082] , error: 0.473744988240852\n",
      "Step: 4274 Weights: [0.35371532 2.13270018] , error: 0.473744985070117\n",
      "Step: 4275 Weights: [0.3537209  2.13269954] , error: 0.4737449819138283\n",
      "Step: 4276 Weights: [0.35372647 2.1326989 ] , error: 0.4737449787719172\n",
      "Step: 4277 Weights: [0.35373203 2.13269827] , error: 0.47374497564432033\n",
      "Step: 4278 Weights: [0.35373758 2.13269763] , error: 0.47374497253097025\n",
      "Step: 4279 Weights: [0.35374311 2.132697  ] , error: 0.4737449694318042\n",
      "Step: 4280 Weights: [0.35374864 2.13269637] , error: 0.4737449663467566\n",
      "Step: 4281 Weights: [0.35375415 2.13269574] , error: 0.4737449632757643\n",
      "Step: 4282 Weights: [0.35375964 2.13269511] , error: 0.47374496021876167\n",
      "Step: 4283 Weights: [0.35376513 2.13269448] , error: 0.47374495717568554\n",
      "Step: 4284 Weights: [0.3537706  2.13269385] , error: 0.4737449541464727\n",
      "Step: 4285 Weights: [0.35377606 2.13269323] , error: 0.4737449511310594\n",
      "Step: 4286 Weights: [0.3537815  2.13269261] , error: 0.47374494812938417\n",
      "Step: 4287 Weights: [0.35378694 2.13269199] , error: 0.4737449451413822\n",
      "Step: 4288 Weights: [0.35379236 2.13269137] , error: 0.47374494216699276\n",
      "Step: 4289 Weights: [0.35379777 2.13269075] , error: 0.473744939206154\n",
      "Step: 4290 Weights: [0.35380316 2.13269013] , error: 0.473744936258804\n",
      "Step: 4291 Weights: [0.35380855 2.13268951] , error: 0.4737449333248809\n",
      "Step: 4292 Weights: [0.35381392 2.1326889 ] , error: 0.4737449304043224\n",
      "Step: 4293 Weights: [0.35381928 2.13268829] , error: 0.47374492749707\n",
      "Step: 4294 Weights: [0.35382463 2.13268768] , error: 0.4737449246030615\n",
      "Step: 4295 Weights: [0.35382996 2.13268707] , error: 0.47374492172223803\n",
      "Step: 4296 Weights: [0.35383529 2.13268646] , error: 0.47374491885453757\n",
      "Step: 4297 Weights: [0.3538406  2.13268585] , error: 0.47374491599990187\n",
      "Step: 4298 Weights: [0.3538459  2.13268524] , error: 0.4737449131582707\n",
      "Step: 4299 Weights: [0.35385118 2.13268464] , error: 0.473744910329584\n",
      "Step: 4300 Weights: [0.35385646 2.13268404] , error: 0.47374490751378495\n",
      "Step: 4301 Weights: [0.35386172 2.13268343] , error: 0.47374490471081365\n",
      "Step: 4302 Weights: [0.35386697 2.13268283] , error: 0.4737449019206107\n",
      "Step: 4303 Weights: [0.35387221 2.13268223] , error: 0.4737448991431201\n",
      "Step: 4304 Weights: [0.35387744 2.13268164] , error: 0.47374489637828127\n",
      "Step: 4305 Weights: [0.35388266 2.13268104] , error: 0.4737448936260392\n",
      "Step: 4306 Weights: [0.35388786 2.13268044] , error: 0.47374489088633526\n",
      "Step: 4307 Weights: [0.35389305 2.13267985] , error: 0.47374488815911164\n",
      "Step: 4308 Weights: [0.35389823 2.13267926] , error: 0.47374488544431265\n",
      "Step: 4309 Weights: [0.3539034  2.13267867] , error: 0.47374488274188115\n",
      "Step: 4310 Weights: [0.35390855 2.13267808] , error: 0.47374488005176196\n",
      "Step: 4311 Weights: [0.3539137  2.13267749] , error: 0.47374487737389703\n",
      "Step: 4312 Weights: [0.35391883 2.1326769 ] , error: 0.4737448747082311\n",
      "Step: 4313 Weights: [0.35392395 2.13267632] , error: 0.47374487205470983\n",
      "Step: 4314 Weights: [0.35392906 2.13267573] , error: 0.4737448694132754\n",
      "Step: 4315 Weights: [0.35393416 2.13267515] , error: 0.4737448667838764\n",
      "Step: 4316 Weights: [0.35393924 2.13267457] , error: 0.4737448641664551\n",
      "Step: 4317 Weights: [0.35394432 2.13267399] , error: 0.47374486156095813\n",
      "Step: 4318 Weights: [0.35394938 2.13267341] , error: 0.47374485896733026\n",
      "Step: 4319 Weights: [0.35395443 2.13267283] , error: 0.4737448563855176\n",
      "Step: 4320 Weights: [0.35395947 2.13267225] , error: 0.4737448538154679\n",
      "Step: 4321 Weights: [0.3539645  2.13267168] , error: 0.4737448512571262\n",
      "Step: 4322 Weights: [0.35396952 2.13267111] , error: 0.47374484871043804\n",
      "Step: 4323 Weights: [0.35397452 2.13267053] , error: 0.47374484617535256\n",
      "Step: 4324 Weights: [0.35397951 2.13266996] , error: 0.47374484365181646\n",
      "Step: 4325 Weights: [0.3539845  2.13266939] , error: 0.4737448411397766\n",
      "Step: 4326 Weights: [0.35398947 2.13266882] , error: 0.47374483863917993\n",
      "Step: 4327 Weights: [0.35399443 2.13266826] , error: 0.4737448361499759\n",
      "Step: 4328 Weights: [0.35399938 2.13266769] , error: 0.4737448336721112\n",
      "Step: 4329 Weights: [0.35400431 2.13266713] , error: 0.47374483120553484\n",
      "Step: 4330 Weights: [0.35400924 2.13266656] , error: 0.47374482875019486\n",
      "Step: 4331 Weights: [0.35401415 2.132666  ] , error: 0.4737448263060414\n",
      "Step: 4332 Weights: [0.35401906 2.13266544] , error: 0.47374482387302264\n",
      "Step: 4333 Weights: [0.35402395 2.13266488] , error: 0.473744821451087\n",
      "Step: 4334 Weights: [0.35402883 2.13266432] , error: 0.4737448190401851\n",
      "Step: 4335 Weights: [0.3540337  2.13266377] , error: 0.47374481664026624\n",
      "Step: 4336 Weights: [0.35403856 2.13266321] , error: 0.47374481425128045\n",
      "Step: 4337 Weights: [0.35404341 2.13266266] , error: 0.4737448118731788\n",
      "Step: 4338 Weights: [0.35404824 2.1326621 ] , error: 0.4737448095059111\n",
      "Step: 4339 Weights: [0.35405307 2.13266155] , error: 0.4737448071494258\n",
      "Step: 4340 Weights: [0.35405788 2.132661  ] , error: 0.47374480480367703\n",
      "Step: 4341 Weights: [0.35406269 2.13266045] , error: 0.4737448024686149\n",
      "Step: 4342 Weights: [0.35406748 2.1326599 ] , error: 0.47374480014419074\n",
      "Step: 4343 Weights: [0.35407226 2.13265936] , error: 0.47374479783035484\n",
      "Step: 4344 Weights: [0.35407703 2.13265881] , error: 0.47374479552706045\n",
      "Step: 4345 Weights: [0.35408179 2.13265827] , error: 0.4737447932342589\n",
      "Step: 4346 Weights: [0.35408654 2.13265772] , error: 0.4737447909519032\n",
      "Step: 4347 Weights: [0.35409128 2.13265718] , error: 0.47374478867994363\n",
      "Step: 4348 Weights: [0.35409601 2.13265664] , error: 0.47374478641833506\n",
      "Step: 4349 Weights: [0.35410073 2.1326561 ] , error: 0.4737447841670296\n",
      "Step: 4350 Weights: [0.35410543 2.13265556] , error: 0.47374478192597996\n",
      "Step: 4351 Weights: [0.35411013 2.13265502] , error: 0.47374477969513984\n",
      "Step: 4352 Weights: [0.35411481 2.13265449] , error: 0.473744777474463\n",
      "Step: 4353 Weights: [0.35411948 2.13265395] , error: 0.4737447752639022\n",
      "Step: 4354 Weights: [0.35412415 2.13265342] , error: 0.4737447730634121\n",
      "Step: 4355 Weights: [0.3541288  2.13265289] , error: 0.47374477087294653\n",
      "Step: 4356 Weights: [0.35413344 2.13265236] , error: 0.4737447686924598\n",
      "Step: 4357 Weights: [0.35413807 2.13265183] , error: 0.47374476652190717\n",
      "Step: 4358 Weights: [0.35414269 2.1326513 ] , error: 0.47374476436124163\n",
      "Step: 4359 Weights: [0.35414731 2.13265077] , error: 0.4737447622104203\n",
      "Step: 4360 Weights: [0.35415191 2.13265025] , error: 0.47374476006939736\n",
      "Step: 4361 Weights: [0.35415649 2.13264972] , error: 0.47374475793812754\n",
      "Step: 4362 Weights: [0.35416107 2.1326492 ] , error: 0.4737447558165675\n",
      "Step: 4363 Weights: [0.35416564 2.13264868] , error: 0.47374475370467206\n",
      "Step: 4364 Weights: [0.3541702  2.13264815] , error: 0.47374475160239793\n",
      "Step: 4365 Weights: [0.35417475 2.13264763] , error: 0.4737447495097009\n",
      "Step: 4366 Weights: [0.35417928 2.13264712] , error: 0.4737447474265373\n",
      "Step: 4367 Weights: [0.35418381 2.1326466 ] , error: 0.4737447453528641\n",
      "Step: 4368 Weights: [0.35418833 2.13264608] , error: 0.4737447432886379\n",
      "Step: 4369 Weights: [0.35419283 2.13264557] , error: 0.4737447412338156\n",
      "Step: 4370 Weights: [0.35419733 2.13264505] , error: 0.47374473918835314\n",
      "Step: 4371 Weights: [0.35420182 2.13264454] , error: 0.4737447371522102\n",
      "Step: 4372 Weights: [0.35420629 2.13264403] , error: 0.47374473512534276\n",
      "Step: 4373 Weights: [0.35421076 2.13264352] , error: 0.4737447331077095\n",
      "Step: 4374 Weights: [0.35421521 2.13264301] , error: 0.4737447310992667\n",
      "Step: 4375 Weights: [0.35421966 2.1326425 ] , error: 0.4737447290999756\n",
      "Step: 4376 Weights: [0.35422409 2.13264199] , error: 0.4737447271097901\n",
      "Step: 4377 Weights: [0.35422852 2.13264149] , error: 0.47374472512867294\n",
      "Step: 4378 Weights: [0.35423293 2.13264098] , error: 0.47374472315658\n",
      "Step: 4379 Weights: [0.35423733 2.13264048] , error: 0.4737447211934723\n",
      "Step: 4380 Weights: [0.35424173 2.13263997] , error: 0.47374471923930717\n",
      "Step: 4381 Weights: [0.35424611 2.13263947] , error: 0.4737447172940441\n",
      "Step: 4382 Weights: [0.35425049 2.13263897] , error: 0.4737447153576434\n",
      "Step: 4383 Weights: [0.35425485 2.13263847] , error: 0.47374471343006364\n",
      "Step: 4384 Weights: [0.35425921 2.13263798] , error: 0.473744711511266\n",
      "Step: 4385 Weights: [0.35426355 2.13263748] , error: 0.4737447096012086\n",
      "Step: 4386 Weights: [0.35426789 2.13263698] , error: 0.4737447076998541\n",
      "Step: 4387 Weights: [0.35427221 2.13263649] , error: 0.47374470580716094\n",
      "Step: 4388 Weights: [0.35427653 2.13263599] , error: 0.47374470392309065\n",
      "Step: 4389 Weights: [0.35428083 2.1326355 ] , error: 0.4737447020476021\n",
      "Step: 4390 Weights: [0.35428513 2.13263501] , error: 0.4737447001806585\n",
      "Step: 4391 Weights: [0.35428941 2.13263452] , error: 0.47374469832222027\n",
      "Step: 4392 Weights: [0.35429369 2.13263403] , error: 0.47374469647224793\n",
      "Step: 4393 Weights: [0.35429795 2.13263354] , error: 0.47374469463070323\n",
      "Step: 4394 Weights: [0.35430221 2.13263306] , error: 0.47374469279754805\n",
      "Step: 4395 Weights: [0.35430646 2.13263257] , error: 0.4737446909727443\n",
      "Step: 4396 Weights: [0.35431069 2.13263209] , error: 0.4737446891562541\n",
      "Step: 4397 Weights: [0.35431492 2.1326316 ] , error: 0.4737446873480378\n",
      "Step: 4398 Weights: [0.35431914 2.13263112] , error: 0.47374468554806093\n",
      "Step: 4399 Weights: [0.35432335 2.13263064] , error: 0.4737446837562825\n",
      "Step: 4400 Weights: [0.35432754 2.13263016] , error: 0.47374468197266684\n",
      "Step: 4401 Weights: [0.35433173 2.13262968] , error: 0.47374468019717786\n",
      "Step: 4402 Weights: [0.35433591 2.1326292 ] , error: 0.47374467842977613\n",
      "Step: 4403 Weights: [0.35434008 2.13262873] , error: 0.47374467667042636\n",
      "Step: 4404 Weights: [0.35434424 2.13262825] , error: 0.4737446749190929\n",
      "Step: 4405 Weights: [0.35434839 2.13262778] , error: 0.47374467317573626\n",
      "Step: 4406 Weights: [0.35435253 2.1326273 ] , error: 0.4737446714403222\n",
      "Step: 4407 Weights: [0.35435667 2.13262683] , error: 0.47374466971281426\n",
      "Step: 4408 Weights: [0.35436079 2.13262636] , error: 0.47374466799317533\n",
      "Step: 4409 Weights: [0.3543649  2.13262589] , error: 0.4737446662813711\n",
      "Step: 4410 Weights: [0.354369   2.13262542] , error: 0.4737446645773651\n",
      "Step: 4411 Weights: [0.3543731  2.13262495] , error: 0.4737446628811227\n",
      "Step: 4412 Weights: [0.35437718 2.13262448] , error: 0.4737446611926059\n",
      "Step: 4413 Weights: [0.35438126 2.13262402] , error: 0.47374465951178235\n",
      "Step: 4414 Weights: [0.35438533 2.13262355] , error: 0.4737446578386165\n",
      "Step: 4415 Weights: [0.35438938 2.13262309] , error: 0.4737446561730725\n",
      "Step: 4416 Weights: [0.35439343 2.13262263] , error: 0.47374465451511666\n",
      "Step: 4417 Weights: [0.35439747 2.13262216] , error: 0.47374465286471357\n",
      "Step: 4418 Weights: [0.3544015 2.1326217] , error: 0.47374465122182813\n",
      "Step: 4419 Weights: [0.35440552 2.13262124] , error: 0.47374464958642876\n",
      "Step: 4420 Weights: [0.35440953 2.13262078] , error: 0.4737446479584789\n",
      "Step: 4421 Weights: [0.35441353 2.13262033] , error: 0.47374464633794455\n",
      "Step: 4422 Weights: [0.35441752 2.13261987] , error: 0.4737446447247933\n",
      "Step: 4423 Weights: [0.35442151 2.13261941] , error: 0.4737446431189914\n",
      "Step: 4424 Weights: [0.35442548 2.13261896] , error: 0.47374464152050566\n",
      "Step: 4425 Weights: [0.35442945 2.13261851] , error: 0.47374463992930077\n",
      "Step: 4426 Weights: [0.3544334  2.13261805] , error: 0.47374463834534447\n",
      "Step: 4427 Weights: [0.35443735 2.1326176 ] , error: 0.47374463676860507\n",
      "Step: 4428 Weights: [0.35444129 2.13261715] , error: 0.473744635199048\n",
      "Step: 4429 Weights: [0.35444522 2.1326167 ] , error: 0.4737446336366422\n",
      "Step: 4430 Weights: [0.35444914 2.13261625] , error: 0.4737446320813536\n",
      "Step: 4431 Weights: [0.35445305 2.13261581] , error: 0.47374463053314997\n",
      "Step: 4432 Weights: [0.35445695 2.13261536] , error: 0.47374462899199987\n",
      "Step: 4433 Weights: [0.35446085 2.13261491] , error: 0.4737446274578703\n",
      "Step: 4434 Weights: [0.35446473 2.13261447] , error: 0.4737446259307297\n",
      "Step: 4435 Weights: [0.35446861 2.13261403] , error: 0.4737446244105465\n",
      "Step: 4436 Weights: [0.35447247 2.13261359] , error: 0.47374462289728836\n",
      "Step: 4437 Weights: [0.35447633 2.13261314] , error: 0.47374462139092466\n",
      "Step: 4438 Weights: [0.35448018 2.1326127 ] , error: 0.4737446198914229\n",
      "Step: 4439 Weights: [0.35448402 2.13261226] , error: 0.47374461839875226\n",
      "Step: 4440 Weights: [0.35448785 2.13261183] , error: 0.4737446169128823\n",
      "Step: 4441 Weights: [0.35449168 2.13261139] , error: 0.47374461543378066\n",
      "Step: 4442 Weights: [0.35449549 2.13261095] , error: 0.47374461396141776\n",
      "Step: 4443 Weights: [0.3544993  2.13261052] , error: 0.47374461249576205\n",
      "Step: 4444 Weights: [0.3545031  2.13261008] , error: 0.47374461103678295\n",
      "Step: 4445 Weights: [0.35450688 2.13260965] , error: 0.4737446095844511\n",
      "Step: 4446 Weights: [0.35451066 2.13260922] , error: 0.47374460813873603\n",
      "Step: 4447 Weights: [0.35451443 2.13260879] , error: 0.4737446066996054\n",
      "Step: 4448 Weights: [0.3545182  2.13260836] , error: 0.47374460526703205\n",
      "Step: 4449 Weights: [0.35452195 2.13260793] , error: 0.4737446038409857\n",
      "Step: 4450 Weights: [0.3545257 2.1326075] , error: 0.47374460242143496\n",
      "Step: 4451 Weights: [0.35452943 2.13260707] , error: 0.47374460100835103\n",
      "Step: 4452 Weights: [0.35453316 2.13260664] , error: 0.47374459960170456\n",
      "Step: 4453 Weights: [0.35453688 2.13260622] , error: 0.4737445982014671\n",
      "Step: 4454 Weights: [0.35454059 2.13260579] , error: 0.47374459680760783\n",
      "Step: 4455 Weights: [0.3545443  2.13260537] , error: 0.473744595420099\n",
      "Step: 4456 Weights: [0.35454799 2.13260495] , error: 0.4737445940389103\n",
      "Step: 4457 Weights: [0.35455168 2.13260453] , error: 0.4737445926640147\n",
      "Step: 4458 Weights: [0.35455535 2.13260411] , error: 0.47374459129538227\n",
      "Step: 4459 Weights: [0.35455902 2.13260369] , error: 0.47374458993298485\n",
      "Step: 4460 Weights: [0.35456268 2.13260327] , error: 0.4737445885767941\n",
      "Step: 4461 Weights: [0.35456634 2.13260285] , error: 0.4737445872267807\n",
      "Step: 4462 Weights: [0.35456998 2.13260243] , error: 0.4737445858829191\n",
      "Step: 4463 Weights: [0.35457362 2.13260202] , error: 0.47374458454517776\n",
      "Step: 4464 Weights: [0.35457724 2.1326016 ] , error: 0.47374458321353285\n",
      "Step: 4465 Weights: [0.35458086 2.13260119] , error: 0.47374458188795265\n",
      "Step: 4466 Weights: [0.35458447 2.13260078] , error: 0.4737445805684116\n",
      "Step: 4467 Weights: [0.35458808 2.13260036] , error: 0.4737445792548826\n",
      "Step: 4468 Weights: [0.35459167 2.13259995] , error: 0.4737445779473375\n",
      "Step: 4469 Weights: [0.35459526 2.13259954] , error: 0.47374457664574854\n",
      "Step: 4470 Weights: [0.35459884 2.13259913] , error: 0.47374457535008974\n",
      "Step: 4471 Weights: [0.35460241 2.13259873] , error: 0.47374457406033244\n",
      "Step: 4472 Weights: [0.35460597 2.13259832] , error: 0.47374457277645193\n",
      "Step: 4473 Weights: [0.35460952 2.13259791] , error: 0.473744571498419\n",
      "Step: 4474 Weights: [0.35461307 2.13259751] , error: 0.4737445702262095\n",
      "Step: 4475 Weights: [0.35461661 2.1325971 ] , error: 0.4737445689597963\n",
      "Step: 4476 Weights: [0.35462014 2.1325967 ] , error: 0.4737445676991506\n",
      "Step: 4477 Weights: [0.35462366 2.1325963 ] , error: 0.47374456644424967\n",
      "Step: 4478 Weights: [0.35462717 2.13259589] , error: 0.4737445651950639\n",
      "Step: 4479 Weights: [0.35463068 2.13259549] , error: 0.4737445639515696\n",
      "Step: 4480 Weights: [0.35463417 2.13259509] , error: 0.4737445627137404\n",
      "Step: 4481 Weights: [0.35463766 2.13259469] , error: 0.47374456148155036\n",
      "Step: 4482 Weights: [0.35464115 2.1325943 ] , error: 0.4737445602549739\n",
      "Step: 4483 Weights: [0.35464462 2.1325939 ] , error: 0.4737445590339854\n",
      "Step: 4484 Weights: [0.35464808 2.1325935 ] , error: 0.4737445578185592\n",
      "Step: 4485 Weights: [0.35465154 2.13259311] , error: 0.4737445566086697\n",
      "Step: 4486 Weights: [0.35465499 2.13259271] , error: 0.4737445554042919\n",
      "Step: 4487 Weights: [0.35465843 2.13259232] , error: 0.47374455420540085\n",
      "Step: 4488 Weights: [0.35466187 2.13259193] , error: 0.4737445530119718\n",
      "Step: 4489 Weights: [0.35466529 2.13259153] , error: 0.47374455182397907\n",
      "Step: 4490 Weights: [0.35466871 2.13259114] , error: 0.47374455064139825\n",
      "Step: 4491 Weights: [0.35467212 2.13259075] , error: 0.47374454946420647\n",
      "Step: 4492 Weights: [0.35467553 2.13259036] , error: 0.4737445482923762\n",
      "Step: 4493 Weights: [0.35467892 2.13258997] , error: 0.47374454712588426\n",
      "Step: 4494 Weights: [0.35468231 2.13258959] , error: 0.4737445459647065\n",
      "Step: 4495 Weights: [0.35468569 2.1325892 ] , error: 0.4737445448088189\n",
      "Step: 4496 Weights: [0.35468906 2.13258882] , error: 0.47374454365819707\n",
      "Step: 4497 Weights: [0.35469243 2.13258843] , error: 0.47374454251281617\n",
      "Step: 4498 Weights: [0.35469578 2.13258805] , error: 0.4737445413726543\n",
      "Step: 4499 Weights: [0.35469913 2.13258766] , error: 0.47374454023768675\n",
      "Step: 4500 Weights: [0.35470247 2.13258728] , error: 0.4737445391078891\n",
      "Step: 4501 Weights: [0.35470581 2.1325869 ] , error: 0.473744537983239\n",
      "Step: 4502 Weights: [0.35470913 2.13258652] , error: 0.473744536863712\n",
      "Step: 4503 Weights: [0.35471245 2.13258614] , error: 0.47374453574928466\n",
      "Step: 4504 Weights: [0.35471576 2.13258576] , error: 0.47374453463993504\n",
      "Step: 4505 Weights: [0.35471907 2.13258538] , error: 0.4737445335356387\n",
      "Step: 4506 Weights: [0.35472236 2.13258501] , error: 0.47374453243637316\n",
      "Step: 4507 Weights: [0.35472565 2.13258463] , error: 0.4737445313421161\n",
      "Step: 4508 Weights: [0.35472893 2.13258426] , error: 0.47374453025284274\n",
      "Step: 4509 Weights: [0.3547322  2.13258388] , error: 0.47374452916853277\n",
      "Step: 4510 Weights: [0.35473547 2.13258351] , error: 0.4737445280891624\n",
      "Step: 4511 Weights: [0.35473873 2.13258314] , error: 0.47374452701470937\n",
      "Step: 4512 Weights: [0.35474198 2.13258276] , error: 0.4737445259451503\n",
      "Step: 4513 Weights: [0.35474522 2.13258239] , error: 0.47374452488046437\n",
      "Step: 4514 Weights: [0.35474846 2.13258202] , error: 0.47374452382062904\n",
      "Step: 4515 Weights: [0.35475169 2.13258165] , error: 0.4737445227656212\n",
      "Step: 4516 Weights: [0.35475491 2.13258128] , error: 0.4737445217154204\n",
      "Step: 4517 Weights: [0.35475812 2.13258092] , error: 0.47374452067000344\n",
      "Step: 4518 Weights: [0.35476133 2.13258055] , error: 0.4737445196293491\n",
      "Step: 4519 Weights: [0.35476453 2.13258018] , error: 0.47374451859343525\n",
      "Step: 4520 Weights: [0.35476772 2.13257982] , error: 0.473744517562241\n",
      "Step: 4521 Weights: [0.35477091 2.13257946] , error: 0.47374451653574434\n",
      "Step: 4522 Weights: [0.35477409 2.13257909] , error: 0.4737445155139238\n",
      "Step: 4523 Weights: [0.35477726 2.13257873] , error: 0.4737445144967589\n",
      "Step: 4524 Weights: [0.35478042 2.13257837] , error: 0.47374451348422847\n",
      "Step: 4525 Weights: [0.35478358 2.13257801] , error: 0.473744512476309\n",
      "Step: 4526 Weights: [0.35478672 2.13257765] , error: 0.47374451147298213\n",
      "Step: 4527 Weights: [0.35478987 2.13257729] , error: 0.4737445104742263\n",
      "Step: 4528 Weights: [0.354793   2.13257693] , error: 0.4737445094800201\n",
      "Step: 4529 Weights: [0.35479613 2.13257657] , error: 0.47374450849034333\n",
      "Step: 4530 Weights: [0.35479925 2.13257621] , error: 0.4737445075051756\n",
      "Step: 4531 Weights: [0.35480236 2.13257586] , error: 0.4737445065244935\n",
      "Step: 4532 Weights: [0.35480547 2.1325755 ] , error: 0.4737445055482813\n",
      "Step: 4533 Weights: [0.35480857 2.13257515] , error: 0.47374450457651684\n",
      "Step: 4534 Weights: [0.35481166 2.13257479] , error: 0.47374450360917897\n",
      "Step: 4535 Weights: [0.35481474 2.13257444] , error: 0.4737445026462469\n",
      "Step: 4536 Weights: [0.35481782 2.13257409] , error: 0.4737445016877022\n",
      "Step: 4537 Weights: [0.35482089 2.13257374] , error: 0.4737445007335233\n",
      "Step: 4538 Weights: [0.35482395 2.13257339] , error: 0.4737444997836934\n",
      "Step: 4539 Weights: [0.35482701 2.13257304] , error: 0.4737444988381886\n",
      "Step: 4540 Weights: [0.35483006 2.13257269] , error: 0.4737444978969916\n",
      "Step: 4541 Weights: [0.3548331  2.13257234] , error: 0.47374449696008264\n",
      "Step: 4542 Weights: [0.35483614 2.13257199] , error: 0.4737444960274423\n",
      "Step: 4543 Weights: [0.35483917 2.13257165] , error: 0.47374449509905076\n",
      "Step: 4544 Weights: [0.35484219 2.1325713 ] , error: 0.47374449417488784\n",
      "Step: 4545 Weights: [0.35484521 2.13257096] , error: 0.4737444932549363\n",
      "Step: 4546 Weights: [0.35484821 2.13257061] , error: 0.4737444923391746\n",
      "Step: 4547 Weights: [0.35485122 2.13257027] , error: 0.4737444914275848\n",
      "Step: 4548 Weights: [0.35485421 2.13256993] , error: 0.4737444905201483\n",
      "Step: 4549 Weights: [0.3548572  2.13256959] , error: 0.4737444896168456\n",
      "Step: 4550 Weights: [0.35486018 2.13256925] , error: 0.4737444887176572\n",
      "Step: 4551 Weights: [0.35486315 2.13256891] , error: 0.4737444878225655\n",
      "Step: 4552 Weights: [0.35486612 2.13256857] , error: 0.47374448693155297\n",
      "Step: 4553 Weights: [0.35486908 2.13256823] , error: 0.4737444860445975\n",
      "Step: 4554 Weights: [0.35487203 2.13256789] , error: 0.47374448516168466\n",
      "Step: 4555 Weights: [0.35487498 2.13256755] , error: 0.4737444842827926\n",
      "Step: 4556 Weights: [0.35487792 2.13256722] , error: 0.4737444834079046\n",
      "Step: 4557 Weights: [0.35488086 2.13256688] , error: 0.4737444825370029\n",
      "Step: 4558 Weights: [0.35488378 2.13256655] , error: 0.4737444816700688\n",
      "Step: 4559 Weights: [0.3548867  2.13256621] , error: 0.4737444808070834\n",
      "Step: 4560 Weights: [0.35488962 2.13256588] , error: 0.47374447994803015\n",
      "Step: 4561 Weights: [0.35489252 2.13256555] , error: 0.4737444790928901\n",
      "Step: 4562 Weights: [0.35489542 2.13256521] , error: 0.47374447824164534\n",
      "Step: 4563 Weights: [0.35489832 2.13256488] , error: 0.4737444773942791\n",
      "Step: 4564 Weights: [0.35490121 2.13256455] , error: 0.47374447655077223\n",
      "Step: 4565 Weights: [0.35490409 2.13256422] , error: 0.4737444757111101\n",
      "Step: 4566 Weights: [0.35490696 2.1325639 ] , error: 0.4737444748752717\n",
      "Step: 4567 Weights: [0.35490983 2.13256357] , error: 0.47374447404324094\n",
      "Step: 4568 Weights: [0.35491269 2.13256324] , error: 0.4737444732150006\n",
      "Step: 4569 Weights: [0.35491554 2.13256291] , error: 0.4737444723905343\n",
      "Step: 4570 Weights: [0.35491839 2.13256259] , error: 0.4737444715698227\n",
      "Step: 4571 Weights: [0.35492123 2.13256226] , error: 0.47374447075285164\n",
      "Step: 4572 Weights: [0.35492407 2.13256194] , error: 0.4737444699396012\n",
      "Step: 4573 Weights: [0.3549269  2.13256162] , error: 0.4737444691300554\n",
      "Step: 4574 Weights: [0.35492972 2.13256129] , error: 0.4737444683241978\n",
      "Step: 4575 Weights: [0.35493253 2.13256097] , error: 0.4737444675220118\n",
      "Step: 4576 Weights: [0.35493534 2.13256065] , error: 0.47374446672348003\n",
      "Step: 4577 Weights: [0.35493814 2.13256033] , error: 0.4737444659285855\n",
      "Step: 4578 Weights: [0.35494094 2.13256001] , error: 0.47374446513731333\n",
      "Step: 4579 Weights: [0.35494373 2.13255969] , error: 0.4737444643496461\n",
      "Step: 4580 Weights: [0.35494651 2.13255937] , error: 0.47374446356556577\n",
      "Step: 4581 Weights: [0.35494929 2.13255905] , error: 0.47374446278505816\n",
      "Step: 4582 Weights: [0.35495206 2.13255874] , error: 0.4737444620081063\n",
      "Step: 4583 Weights: [0.35495483 2.13255842] , error: 0.47374446123469394\n",
      "Step: 4584 Weights: [0.35495759 2.13255811] , error: 0.47374446046480473\n",
      "Step: 4585 Weights: [0.35496034 2.13255779] , error: 0.47374445969842355\n",
      "Step: 4586 Weights: [0.35496308 2.13255748] , error: 0.47374445893553335\n",
      "Step: 4587 Weights: [0.35496582 2.13255716] , error: 0.47374445817611754\n",
      "Step: 4588 Weights: [0.35496856 2.13255685] , error: 0.47374445742016247\n",
      "Step: 4589 Weights: [0.35497128 2.13255654] , error: 0.4737444566676512\n",
      "Step: 4590 Weights: [0.354974   2.13255623] , error: 0.47374445591856623\n",
      "Step: 4591 Weights: [0.35497672 2.13255592] , error: 0.47374445517289715\n",
      "Step: 4592 Weights: [0.35497943 2.13255561] , error: 0.47374445443062274\n",
      "Step: 4593 Weights: [0.35498213 2.1325553 ] , error: 0.47374445369173107\n",
      "Step: 4594 Weights: [0.35498482 2.13255499] , error: 0.47374445295620526\n",
      "Step: 4595 Weights: [0.35498751 2.13255468] , error: 0.47374445222402956\n",
      "Step: 4596 Weights: [0.3549902  2.13255438] , error: 0.47374445149519046\n",
      "Step: 4597 Weights: [0.35499288 2.13255407] , error: 0.47374445076967014\n",
      "Step: 4598 Weights: [0.35499555 2.13255376] , error: 0.47374445004745613\n",
      "Step: 4599 Weights: [0.35499821 2.13255346] , error: 0.47374444932853166\n",
      "Step: 4600 Weights: [0.35500087 2.13255316] , error: 0.4737444486128827\n",
      "Step: 4601 Weights: [0.35500353 2.13255285] , error: 0.47374444790049464\n",
      "Step: 4602 Weights: [0.35500617 2.13255255] , error: 0.47374444719135117\n",
      "Step: 4603 Weights: [0.35500881 2.13255225] , error: 0.4737444464854381\n",
      "Step: 4604 Weights: [0.35501145 2.13255195] , error: 0.4737444457827414\n",
      "Step: 4605 Weights: [0.35501408 2.13255165] , error: 0.4737444450832464\n",
      "Step: 4606 Weights: [0.3550167  2.13255135] , error: 0.473744444386937\n",
      "Step: 4607 Weights: [0.35501932 2.13255105] , error: 0.47374444369379975\n",
      "Step: 4608 Weights: [0.35502193 2.13255075] , error: 0.47374444300382024\n",
      "Step: 4609 Weights: [0.35502454 2.13255045] , error: 0.4737444423169844\n",
      "Step: 4610 Weights: [0.35502713 2.13255015] , error: 0.47374444163327745\n",
      "Step: 4611 Weights: [0.35502973 2.13254986] , error: 0.4737444409526859\n",
      "Step: 4612 Weights: [0.35503232 2.13254956] , error: 0.47374444027519397\n",
      "Step: 4613 Weights: [0.3550349  2.13254926] , error: 0.4737444396007882\n",
      "Step: 4614 Weights: [0.35503747 2.13254897] , error: 0.4737444389294563\n",
      "Step: 4615 Weights: [0.35504004 2.13254868] , error: 0.47374443826118107\n",
      "Step: 4616 Weights: [0.35504261 2.13254838] , error: 0.4737444375959502\n",
      "Step: 4617 Weights: [0.35504516 2.13254809] , error: 0.47374443693375096\n",
      "Step: 4618 Weights: [0.35504772 2.1325478 ] , error: 0.4737444362745683\n",
      "Step: 4619 Weights: [0.35505026 2.13254751] , error: 0.47374443561838847\n",
      "Step: 4620 Weights: [0.3550528  2.13254722] , error: 0.4737444349651979\n",
      "Step: 4621 Weights: [0.35505534 2.13254693] , error: 0.4737444343149827\n",
      "Step: 4622 Weights: [0.35505787 2.13254664] , error: 0.4737444336677299\n",
      "Step: 4623 Weights: [0.35506039 2.13254635] , error: 0.47374443302342545\n",
      "Step: 4624 Weights: [0.35506291 2.13254606] , error: 0.47374443238205644\n",
      "Step: 4625 Weights: [0.35506542 2.13254577] , error: 0.4737444317436096\n",
      "Step: 4626 Weights: [0.35506793 2.13254549] , error: 0.4737444311080712\n",
      "Step: 4627 Weights: [0.35507043 2.1325452 ] , error: 0.4737444304754279\n",
      "Step: 4628 Weights: [0.35507292 2.13254492] , error: 0.47374442984566745\n",
      "Step: 4629 Weights: [0.35507541 2.13254463] , error: 0.47374442921877424\n",
      "Step: 4630 Weights: [0.35507789 2.13254435] , error: 0.47374442859473803\n",
      "Step: 4631 Weights: [0.35508037 2.13254406] , error: 0.4737444279735448\n",
      "Step: 4632 Weights: [0.35508284 2.13254378] , error: 0.4737444273551817\n",
      "Step: 4633 Weights: [0.35508531 2.1325435 ] , error: 0.47374442673963413\n",
      "Step: 4634 Weights: [0.35508777 2.13254322] , error: 0.47374442612689227\n",
      "Step: 4635 Weights: [0.35509023 2.13254294] , error: 0.4737444255169418\n",
      "Step: 4636 Weights: [0.35509268 2.13254266] , error: 0.47374442490976965\n",
      "Step: 4637 Weights: [0.35509512 2.13254238] , error: 0.4737444243053635\n",
      "Step: 4638 Weights: [0.35509756 2.1325421 ] , error: 0.47374442370371045\n",
      "Step: 4639 Weights: [0.35509999 2.13254182] , error: 0.4737444231047987\n",
      "Step: 4640 Weights: [0.35510242 2.13254154] , error: 0.47374442250861526\n",
      "Step: 4641 Weights: [0.35510484 2.13254127] , error: 0.4737444219151485\n",
      "Step: 4642 Weights: [0.35510726 2.13254099] , error: 0.4737444213243841\n",
      "Step: 4643 Weights: [0.35510967 2.13254071] , error: 0.4737444207363125\n",
      "Step: 4644 Weights: [0.35511207 2.13254044] , error: 0.4737444201509188\n",
      "Step: 4645 Weights: [0.35511447 2.13254016] , error: 0.4737444195681926\n",
      "Step: 4646 Weights: [0.35511687 2.13253989] , error: 0.4737444189881203\n",
      "Step: 4647 Weights: [0.35511925 2.13253962] , error: 0.4737444184106916\n",
      "Step: 4648 Weights: [0.35512164 2.13253934] , error: 0.47374441783589194\n",
      "Step: 4649 Weights: [0.35512402 2.13253907] , error: 0.47374441726371186\n",
      "Step: 4650 Weights: [0.35512639 2.1325388 ] , error: 0.47374441669413836\n",
      "Step: 4651 Weights: [0.35512876 2.13253853] , error: 0.47374441612715995\n",
      "Step: 4652 Weights: [0.35513112 2.13253826] , error: 0.47374441556276414\n",
      "Step: 4653 Weights: [0.35513347 2.13253799] , error: 0.47374441500093956\n",
      "Step: 4654 Weights: [0.35513582 2.13253772] , error: 0.47374441444167426\n",
      "Step: 4655 Weights: [0.35513817 2.13253745] , error: 0.47374441388495736\n",
      "Step: 4656 Weights: [0.35514051 2.13253719] , error: 0.4737444133307754\n",
      "Step: 4657 Weights: [0.35514284 2.13253692] , error: 0.4737444127791195\n",
      "Step: 4658 Weights: [0.35514517 2.13253665] , error: 0.47374441222997676\n",
      "Step: 4659 Weights: [0.3551475  2.13253639] , error: 0.4737444116833349\n",
      "Step: 4660 Weights: [0.35514982 2.13253612] , error: 0.4737444111391837\n",
      "Step: 4661 Weights: [0.35515213 2.13253586] , error: 0.4737444105975106\n",
      "Step: 4662 Weights: [0.35515444 2.13253559] , error: 0.4737444100583066\n",
      "Step: 4663 Weights: [0.35515674 2.13253533] , error: 0.4737444095215581\n",
      "Step: 4664 Weights: [0.35515904 2.13253507] , error: 0.47374440898725456\n",
      "Step: 4665 Weights: [0.35516133 2.1325348 ] , error: 0.4737444084553859\n",
      "Step: 4666 Weights: [0.35516362 2.13253454] , error: 0.47374440792593986\n",
      "Step: 4667 Weights: [0.3551659  2.13253428] , error: 0.4737444073989052\n",
      "Step: 4668 Weights: [0.35516818 2.13253402] , error: 0.4737444068742726\n",
      "Step: 4669 Weights: [0.35517045 2.13253376] , error: 0.4737444063520297\n",
      "Step: 4670 Weights: [0.35517272 2.1325335 ] , error: 0.47374440583216537\n",
      "Step: 4671 Weights: [0.35517498 2.13253324] , error: 0.47374440531467005\n",
      "Step: 4672 Weights: [0.35517724 2.13253299] , error: 0.4737444047995311\n",
      "Step: 4673 Weights: [0.35517949 2.13253273] , error: 0.47374440428674014\n",
      "Step: 4674 Weights: [0.35518173 2.13253247] , error: 0.473744403776285\n",
      "Step: 4675 Weights: [0.35518397 2.13253222] , error: 0.47374440326815587\n",
      "Step: 4676 Weights: [0.35518621 2.13253196] , error: 0.473744402762341\n",
      "Step: 4677 Weights: [0.35518844 2.1325317 ] , error: 0.4737444022588303\n",
      "Step: 4678 Weights: [0.35519067 2.13253145] , error: 0.47374440175761345\n",
      "Step: 4679 Weights: [0.35519289 2.1325312 ] , error: 0.47374440125868056\n",
      "Step: 4680 Weights: [0.3551951  2.13253094] , error: 0.4737444007620188\n",
      "Step: 4681 Weights: [0.35519731 2.13253069] , error: 0.47374440026762143\n",
      "Step: 4682 Weights: [0.35519952 2.13253044] , error: 0.4737443997754756\n",
      "Step: 4683 Weights: [0.35520172 2.13253019] , error: 0.4737443992855722\n",
      "Step: 4684 Weights: [0.35520391 2.13252993] , error: 0.47374439879790065\n",
      "Step: 4685 Weights: [0.3552061  2.13252968] , error: 0.47374439831245\n",
      "Step: 4686 Weights: [0.35520829 2.13252943] , error: 0.4737443978292124\n",
      "Step: 4687 Weights: [0.35521047 2.13252919] , error: 0.4737443973481744\n",
      "Step: 4688 Weights: [0.35521264 2.13252894] , error: 0.4737443968693294\n",
      "Step: 4689 Weights: [0.35521481 2.13252869] , error: 0.4737443963926646\n",
      "Step: 4690 Weights: [0.35521698 2.13252844] , error: 0.47374439591817236\n",
      "Step: 4691 Weights: [0.35521914 2.13252819] , error: 0.47374439544584146\n",
      "Step: 4692 Weights: [0.3552213  2.13252795] , error: 0.4737443949756616\n",
      "Step: 4693 Weights: [0.35522345 2.1325277 ] , error: 0.47374439450762407\n",
      "Step: 4694 Weights: [0.35522559 2.13252746] , error: 0.47374439404171825\n",
      "Step: 4695 Weights: [0.35522773 2.13252721] , error: 0.47374439357793663\n",
      "Step: 4696 Weights: [0.35522987 2.13252697] , error: 0.4737443931162666\n",
      "Step: 4697 Weights: [0.355232   2.13252672] , error: 0.4737443926567002\n",
      "Step: 4698 Weights: [0.35523413 2.13252648] , error: 0.4737443921992266\n",
      "Step: 4699 Weights: [0.35523625 2.13252624] , error: 0.47374439174383787\n",
      "Step: 4700 Weights: [0.35523836 2.13252599] , error: 0.4737443912905238\n",
      "Step: 4701 Weights: [0.35524048 2.13252575] , error: 0.4737443908392747\n",
      "Step: 4702 Weights: [0.35524258 2.13252551] , error: 0.4737443903900816\n",
      "Step: 4703 Weights: [0.35524468 2.13252527] , error: 0.47374438994293444\n",
      "Step: 4704 Weights: [0.35524678 2.13252503] , error: 0.4737443894978237\n",
      "Step: 4705 Weights: [0.35524887 2.13252479] , error: 0.4737443890547417\n",
      "Step: 4706 Weights: [0.35525096 2.13252455] , error: 0.4737443886136773\n",
      "Step: 4707 Weights: [0.35525304 2.13252432] , error: 0.4737443881746228\n",
      "Step: 4708 Weights: [0.35525512 2.13252408] , error: 0.47374438773756844\n",
      "Step: 4709 Weights: [0.3552572  2.13252384] , error: 0.47374438730250557\n",
      "Step: 4710 Weights: [0.35525927 2.1325236 ] , error: 0.47374438686942394\n",
      "Step: 4711 Weights: [0.35526133 2.13252337] , error: 0.47374438643831546\n",
      "Step: 4712 Weights: [0.35526339 2.13252313] , error: 0.47374438600917196\n",
      "Step: 4713 Weights: [0.35526544 2.1325229 ] , error: 0.47374438558198145\n",
      "Step: 4714 Weights: [0.35526749 2.13252266] , error: 0.4737443851567388\n",
      "Step: 4715 Weights: [0.35526954 2.13252243] , error: 0.4737443847334326\n",
      "Step: 4716 Weights: [0.35527158 2.1325222 ] , error: 0.47374438431205534\n",
      "Step: 4717 Weights: [0.35527362 2.13252196] , error: 0.47374438389259677\n",
      "Step: 4718 Weights: [0.35527565 2.13252173] , error: 0.47374438347504977\n",
      "Step: 4719 Weights: [0.35527767 2.1325215 ] , error: 0.47374438305940547\n",
      "Step: 4720 Weights: [0.3552797  2.13252127] , error: 0.47374438264565416\n",
      "Step: 4721 Weights: [0.35528171 2.13252104] , error: 0.47374438223378806\n",
      "Step: 4722 Weights: [0.35528373 2.13252081] , error: 0.47374438182379763\n",
      "Step: 4723 Weights: [0.35528573 2.13252058] , error: 0.47374438141567504\n",
      "Step: 4724 Weights: [0.35528774 2.13252035] , error: 0.47374438100941213\n",
      "Step: 4725 Weights: [0.35528974 2.13252012] , error: 0.4737443806049999\n",
      "Step: 4726 Weights: [0.35529173 2.13251989] , error: 0.4737443802024297\n",
      "Step: 4727 Weights: [0.35529372 2.13251966] , error: 0.47374437980169426\n",
      "Step: 4728 Weights: [0.35529571 2.13251944] , error: 0.47374437940278363\n",
      "Step: 4729 Weights: [0.35529769 2.13251921] , error: 0.47374437900569055\n",
      "Step: 4730 Weights: [0.35529966 2.13251898] , error: 0.47374437861040675\n",
      "Step: 4731 Weights: [0.35530164 2.13251876] , error: 0.4737443782169231\n",
      "Step: 4732 Weights: [0.3553036  2.13251853] , error: 0.4737443778252328\n",
      "Step: 4733 Weights: [0.35530557 2.13251831] , error: 0.47374437743532577\n",
      "Step: 4734 Weights: [0.35530752 2.13251809] , error: 0.4737443770471956\n",
      "Step: 4735 Weights: [0.35530948 2.13251786] , error: 0.47374437666083435\n",
      "Step: 4736 Weights: [0.35531143 2.13251764] , error: 0.47374437627623245\n",
      "Step: 4737 Weights: [0.35531337 2.13251742] , error: 0.4737443758933829\n",
      "Step: 4738 Weights: [0.35531531 2.13251719] , error: 0.4737443755122769\n",
      "Step: 4739 Weights: [0.35531725 2.13251697] , error: 0.4737443751329075\n",
      "Step: 4740 Weights: [0.35531918 2.13251675] , error: 0.47374437475526693\n",
      "Step: 4741 Weights: [0.35532111 2.13251653] , error: 0.4737443743793453\n",
      "Step: 4742 Weights: [0.35532303 2.13251631] , error: 0.4737443740051378\n",
      "Step: 4743 Weights: [0.35532495 2.13251609] , error: 0.47374437363263455\n",
      "Step: 4744 Weights: [0.35532687 2.13251587] , error: 0.4737443732618283\n",
      "Step: 4745 Weights: [0.35532878 2.13251565] , error: 0.47374437289271065\n",
      "Step: 4746 Weights: [0.35533068 2.13251544] , error: 0.4737443725252752\n",
      "Step: 4747 Weights: [0.35533258 2.13251522] , error: 0.47374437215951354\n",
      "Step: 4748 Weights: [0.35533448 2.132515  ] , error: 0.4737443717954186\n",
      "Step: 4749 Weights: [0.35533637 2.13251479] , error: 0.4737443714329812\n",
      "Step: 4750 Weights: [0.35533826 2.13251457] , error: 0.47374437107219564\n",
      "Step: 4751 Weights: [0.35534014 2.13251435] , error: 0.47374437071305386\n",
      "Step: 4752 Weights: [0.35534202 2.13251414] , error: 0.47374437035554784\n",
      "Step: 4753 Weights: [0.3553439  2.13251393] , error: 0.4737443699996705\n",
      "Step: 4754 Weights: [0.35534577 2.13251371] , error: 0.4737443696454144\n",
      "Step: 4755 Weights: [0.35534764 2.1325135 ] , error: 0.4737443692927725\n",
      "Step: 4756 Weights: [0.3553495  2.13251328] , error: 0.4737443689417373\n",
      "Step: 4757 Weights: [0.35535136 2.13251307] , error: 0.47374436859229985\n",
      "Step: 4758 Weights: [0.35535321 2.13251286] , error: 0.473744368244456\n",
      "Step: 4759 Weights: [0.35535506 2.13251265] , error: 0.47374436789819585\n",
      "Step: 4760 Weights: [0.35535691 2.13251244] , error: 0.47374436755351323\n",
      "Step: 4761 Weights: [0.35535875 2.13251223] , error: 0.4737443672104016\n",
      "Step: 4762 Weights: [0.35536059 2.13251202] , error: 0.4737443668688518\n",
      "Step: 4763 Weights: [0.35536242 2.13251181] , error: 0.4737443665288592\n",
      "Step: 4764 Weights: [0.35536425 2.1325116 ] , error: 0.47374436619041543\n",
      "Step: 4765 Weights: [0.35536607 2.13251139] , error: 0.47374436585351254\n",
      "Step: 4766 Weights: [0.35536789 2.13251118] , error: 0.4737443655181452\n",
      "Step: 4767 Weights: [0.35536971 2.13251097] , error: 0.47374436518430474\n",
      "Step: 4768 Weights: [0.35537152 2.13251077] , error: 0.4737443648519859\n",
      "Step: 4769 Weights: [0.35537333 2.13251056] , error: 0.4737443645211811\n",
      "Step: 4770 Weights: [0.35537513 2.13251035] , error: 0.473744364191883\n",
      "Step: 4771 Weights: [0.35537693 2.13251015] , error: 0.473744363864085\n",
      "Step: 4772 Weights: [0.35537873 2.13250994] , error: 0.4737443635377807\n",
      "Step: 4773 Weights: [0.35538052 2.13250974] , error: 0.47374436321296265\n",
      "Step: 4774 Weights: [0.35538231 2.13250953] , error: 0.47374436288962457\n",
      "Step: 4775 Weights: [0.35538409 2.13250933] , error: 0.4737443625677592\n",
      "Step: 4776 Weights: [0.35538587 2.13250913] , error: 0.4737443622473604\n",
      "Step: 4777 Weights: [0.35538765 2.13250892] , error: 0.47374436192842073\n",
      "Step: 4778 Weights: [0.35538942 2.13250872] , error: 0.47374436161093497\n",
      "Step: 4779 Weights: [0.35539118 2.13250852] , error: 0.47374436129489456\n",
      "Step: 4780 Weights: [0.35539295 2.13250832] , error: 0.4737443609802943\n",
      "Step: 4781 Weights: [0.35539471 2.13250811] , error: 0.47374436066712694\n",
      "Step: 4782 Weights: [0.35539646 2.13250791] , error: 0.47374436035538653\n",
      "Step: 4783 Weights: [0.35539821 2.13250771] , error: 0.473744360045067\n",
      "Step: 4784 Weights: [0.35539996 2.13250751] , error: 0.4737443597361606\n",
      "Step: 4785 Weights: [0.3554017  2.13250731] , error: 0.4737443594286608\n",
      "Step: 4786 Weights: [0.35540344 2.13250712] , error: 0.4737443591225625\n",
      "Step: 4787 Weights: [0.35540518 2.13250692] , error: 0.4737443588178585\n",
      "Step: 4788 Weights: [0.35540691 2.13250672] , error: 0.47374435851454316\n",
      "Step: 4789 Weights: [0.35540864 2.13250652] , error: 0.4737443582126089\n",
      "Step: 4790 Weights: [0.35541036 2.13250632] , error: 0.47374435791205055\n",
      "Step: 4791 Weights: [0.35541208 2.13250613] , error: 0.4737443576128611\n",
      "Step: 4792 Weights: [0.35541379 2.13250593] , error: 0.47374435731503506\n",
      "Step: 4793 Weights: [0.35541551 2.13250574] , error: 0.47374435701856404\n",
      "Step: 4794 Weights: [0.35541721 2.13250554] , error: 0.47374435672344695\n",
      "Step: 4795 Weights: [0.35541892 2.13250535] , error: 0.4737443564296723\n",
      "Step: 4796 Weights: [0.35542062 2.13250515] , error: 0.4737443561372362\n",
      "Step: 4797 Weights: [0.35542231 2.13250496] , error: 0.4737443558461323\n",
      "Step: 4798 Weights: [0.35542401 2.13250476] , error: 0.4737443555563551\n",
      "Step: 4799 Weights: [0.35542569 2.13250457] , error: 0.473744355267897\n",
      "Step: 4800 Weights: [0.35542738 2.13250438] , error: 0.47374435498075435\n",
      "Step: 4801 Weights: [0.35542906 2.13250419] , error: 0.47374435469491843\n",
      "Step: 4802 Weights: [0.35543074 2.13250399] , error: 0.4737443544103854\n",
      "Step: 4803 Weights: [0.35543241 2.1325038 ] , error: 0.47374435412714844\n",
      "Step: 4804 Weights: [0.35543408 2.13250361] , error: 0.47374435384520164\n",
      "Step: 4805 Weights: [0.35543574 2.13250342] , error: 0.4737443535645398\n",
      "Step: 4806 Weights: [0.35543741 2.13250323] , error: 0.4737443532851558\n",
      "Step: 4807 Weights: [0.35543906 2.13250304] , error: 0.4737443530070446\n",
      "Step: 4808 Weights: [0.35544072 2.13250285] , error: 0.47374435273020077\n",
      "Step: 4809 Weights: [0.35544237 2.13250266] , error: 0.4737443524546182\n",
      "Step: 4810 Weights: [0.35544401 2.13250248] , error: 0.47374435218029115\n",
      "Step: 4811 Weights: [0.35544566 2.13250229] , error: 0.47374435190721426\n",
      "Step: 4812 Weights: [0.3554473 2.1325021] , error: 0.47374435163537965\n",
      "Step: 4813 Weights: [0.35544893 2.13250191] , error: 0.47374435136478577\n",
      "Step: 4814 Weights: [0.35545056 2.13250173] , error: 0.473744351095423\n",
      "Step: 4815 Weights: [0.35545219 2.13250154] , error: 0.47374435082728794\n",
      "Step: 4816 Weights: [0.35545381 2.13250135] , error: 0.47374435056037417\n",
      "Step: 4817 Weights: [0.35545544 2.13250117] , error: 0.47374435029467665\n",
      "Step: 4818 Weights: [0.35545705 2.13250098] , error: 0.473744350030189\n",
      "Step: 4819 Weights: [0.35545867 2.1325008 ] , error: 0.4737443497669066\n",
      "Step: 4820 Weights: [0.35546027 2.13250062] , error: 0.4737443495048234\n",
      "Step: 4821 Weights: [0.35546188 2.13250043] , error: 0.47374434924393416\n",
      "Step: 4822 Weights: [0.35546348 2.13250025] , error: 0.47374434898423334\n",
      "Step: 4823 Weights: [0.35546508 2.13250007] , error: 0.4737443487257169\n",
      "Step: 4824 Weights: [0.35546668 2.13249988] , error: 0.47374434846837543\n",
      "Step: 4825 Weights: [0.35546827 2.1324997 ] , error: 0.4737443482122101\n",
      "Step: 4826 Weights: [0.35546985 2.13249952] , error: 0.4737443479572091\n",
      "Step: 4827 Weights: [0.35547144 2.13249934] , error: 0.47374434770337015\n",
      "Step: 4828 Weights: [0.35547302 2.13249916] , error: 0.473744347450688\n",
      "Step: 4829 Weights: [0.35547459 2.13249898] , error: 0.4737443471991574\n",
      "Step: 4830 Weights: [0.35547617 2.1324988 ] , error: 0.4737443469487721\n",
      "Step: 4831 Weights: [0.35547774 2.13249862] , error: 0.4737443466995279\n",
      "Step: 4832 Weights: [0.3554793  2.13249844] , error: 0.47374434645141844\n",
      "Step: 4833 Weights: [0.35548086 2.13249826] , error: 0.47374434620443917\n",
      "Step: 4834 Weights: [0.35548242 2.13249808] , error: 0.47374434595858583\n",
      "Step: 4835 Weights: [0.35548398 2.13249791] , error: 0.4737443457138517\n",
      "Step: 4836 Weights: [0.35548553 2.13249773] , error: 0.4737443454702331\n",
      "Step: 4837 Weights: [0.35548708 2.13249755] , error: 0.4737443452277241\n",
      "Step: 4838 Weights: [0.35548862 2.13249737] , error: 0.47374434498632023\n",
      "Step: 4839 Weights: [0.35549016 2.1324972 ] , error: 0.47374434474601523\n",
      "Step: 4840 Weights: [0.3554917  2.13249702] , error: 0.47374434450680625\n",
      "Step: 4841 Weights: [0.35549324 2.13249685] , error: 0.4737443442686864\n",
      "Step: 4842 Weights: [0.35549477 2.13249667] , error: 0.47374434403165044\n",
      "Step: 4843 Weights: [0.35549629 2.1324965 ] , error: 0.4737443437956955\n",
      "Step: 4844 Weights: [0.35549782 2.13249632] , error: 0.4737443435608158\n",
      "Step: 4845 Weights: [0.35549934 2.13249615] , error: 0.4737443433270043\n",
      "Step: 4846 Weights: [0.35550085 2.13249598] , error: 0.4737443430942597\n",
      "Step: 4847 Weights: [0.35550237 2.1324958 ] , error: 0.4737443428625751\n",
      "Step: 4848 Weights: [0.35550388 2.13249563] , error: 0.47374434263194615\n",
      "Step: 4849 Weights: [0.35550538 2.13249546] , error: 0.473744342402367\n",
      "Step: 4850 Weights: [0.35550688 2.13249529] , error: 0.4737443421738341\n",
      "Step: 4851 Weights: [0.35550838 2.13249511] , error: 0.4737443419463422\n",
      "Step: 4852 Weights: [0.35550988 2.13249494] , error: 0.4737443417198866\n",
      "Step: 4853 Weights: [0.35551137 2.13249477] , error: 0.47374434149446254\n",
      "Step: 4854 Weights: [0.35551286 2.1324946 ] , error: 0.473744341270066\n",
      "Step: 4855 Weights: [0.35551435 2.13249443] , error: 0.47374434104669183\n",
      "Step: 4856 Weights: [0.35551583 2.13249426] , error: 0.4737443408243349\n",
      "Step: 4857 Weights: [0.35551731 2.13249409] , error: 0.47374434060299153\n",
      "Step: 4858 Weights: [0.35551878 2.13249392] , error: 0.4737443403826557\n",
      "Step: 4859 Weights: [0.35552026 2.13249376] , error: 0.4737443401633238\n",
      "Step: 4860 Weights: [0.35552173 2.13249359] , error: 0.47374433994499127\n",
      "Step: 4861 Weights: [0.35552319 2.13249342] , error: 0.47374433972765245\n",
      "Step: 4862 Weights: [0.35552465 2.13249325] , error: 0.47374433951130546\n",
      "Step: 4863 Weights: [0.35552611 2.13249309] , error: 0.4737443392959425\n",
      "Step: 4864 Weights: [0.35552757 2.13249292] , error: 0.47374433908156105\n",
      "Step: 4865 Weights: [0.35552902 2.13249275] , error: 0.4737443388681576\n",
      "Step: 4866 Weights: [0.35553047 2.13249259] , error: 0.4737443386557245\n",
      "Step: 4867 Weights: [0.35553191 2.13249242] , error: 0.4737443384442609\n",
      "Step: 4868 Weights: [0.35553336 2.13249226] , error: 0.4737443382337591\n",
      "Step: 4869 Weights: [0.3555348  2.13249209] , error: 0.4737443380242173\n",
      "Step: 4870 Weights: [0.35553623 2.13249193] , error: 0.47374433781562997\n",
      "Step: 4871 Weights: [0.35553766 2.13249177] , error: 0.47374433760799195\n",
      "Step: 4872 Weights: [0.35553909 2.1324916 ] , error: 0.47374433740130073\n",
      "Step: 4873 Weights: [0.35554052 2.13249144] , error: 0.473744337195551\n",
      "Step: 4874 Weights: [0.35554194 2.13249128] , error: 0.4737443369907381\n",
      "Step: 4875 Weights: [0.35554336 2.13249111] , error: 0.47374433678685834\n",
      "Step: 4876 Weights: [0.35554478 2.13249095] , error: 0.47374433658390835\n",
      "Step: 4877 Weights: [0.35554619 2.13249079] , error: 0.47374433638188207\n",
      "Step: 4878 Weights: [0.3555476  2.13249063] , error: 0.473744336180776\n",
      "Step: 4879 Weights: [0.35554901 2.13249047] , error: 0.4737443359805865\n",
      "Step: 4880 Weights: [0.35555041 2.13249031] , error: 0.4737443357813088\n",
      "Step: 4881 Weights: [0.35555181 2.13249015] , error: 0.4737443355829393\n",
      "Step: 4882 Weights: [0.35555321 2.13248999] , error: 0.4737443353854733\n",
      "Step: 4883 Weights: [0.3555546  2.13248983] , error: 0.47374433518890596\n",
      "Step: 4884 Weights: [0.35555599 2.13248967] , error: 0.4737443349932359\n",
      "Step: 4885 Weights: [0.35555738 2.13248951] , error: 0.4737443347984559\n",
      "Step: 4886 Weights: [0.35555876 2.13248935] , error: 0.47374433460456333\n",
      "Step: 4887 Weights: [0.35556014 2.13248919] , error: 0.4737443344115547\n",
      "Step: 4888 Weights: [0.35556152 2.13248904] , error: 0.4737443342194249\n",
      "Step: 4889 Weights: [0.3555629  2.13248888] , error: 0.47374433402817023\n",
      "Step: 4890 Weights: [0.35556427 2.13248872] , error: 0.47374433383778763\n",
      "Step: 4891 Weights: [0.35556564 2.13248857] , error: 0.47374433364827195\n",
      "Step: 4892 Weights: [0.355567   2.13248841] , error: 0.4737443334596192\n",
      "Step: 4893 Weights: [0.35556836 2.13248825] , error: 0.47374433327182663\n",
      "Step: 4894 Weights: [0.35556972 2.1324881 ] , error: 0.47374433308488934\n",
      "Step: 4895 Weights: [0.35557108 2.13248794] , error: 0.47374433289880324\n",
      "Step: 4896 Weights: [0.35557243 2.13248779] , error: 0.47374433271356503\n",
      "Step: 4897 Weights: [0.35557378 2.13248763] , error: 0.4737443325291707\n",
      "Step: 4898 Weights: [0.35557513 2.13248748] , error: 0.4737443323456163\n",
      "Step: 4899 Weights: [0.35557647 2.13248733] , error: 0.4737443321628987\n",
      "Step: 4900 Weights: [0.35557781 2.13248717] , error: 0.4737443319810125\n",
      "Step: 4901 Weights: [0.35557915 2.13248702] , error: 0.4737443317999558\n",
      "Step: 4902 Weights: [0.35558049 2.13248687] , error: 0.473744331619724\n",
      "Step: 4903 Weights: [0.35558182 2.13248672] , error: 0.47374433144031275\n",
      "Step: 4904 Weights: [0.35558315 2.13248656] , error: 0.4737443312617189\n",
      "Step: 4905 Weights: [0.35558447 2.13248641] , error: 0.4737443310839383\n",
      "Step: 4906 Weights: [0.35558579 2.13248626] , error: 0.473744330906968\n",
      "Step: 4907 Weights: [0.35558711 2.13248611] , error: 0.4737443307308044\n",
      "Step: 4908 Weights: [0.35558843 2.13248596] , error: 0.4737443305554426\n",
      "Step: 4909 Weights: [0.35558974 2.13248581] , error: 0.47374433038088004\n",
      "Step: 4910 Weights: [0.35559105 2.13248566] , error: 0.4737443302071132\n",
      "Step: 4911 Weights: [0.35559236 2.13248551] , error: 0.47374433003413674\n",
      "Step: 4912 Weights: [0.35559367 2.13248536] , error: 0.4737443298619487\n",
      "Step: 4913 Weights: [0.35559497 2.13248521] , error: 0.4737443296905449\n",
      "Step: 4914 Weights: [0.35559627 2.13248506] , error: 0.4737443295199233\n",
      "Step: 4915 Weights: [0.35559756 2.13248492] , error: 0.4737443293500781\n",
      "Step: 4916 Weights: [0.35559885 2.13248477] , error: 0.4737443291810066\n",
      "Step: 4917 Weights: [0.35560014 2.13248462] , error: 0.47374432901270486\n",
      "Step: 4918 Weights: [0.35560143 2.13248447] , error: 0.47374432884517054\n",
      "Step: 4919 Weights: [0.35560271 2.13248433] , error: 0.4737443286783993\n",
      "Step: 4920 Weights: [0.35560399 2.13248418] , error: 0.47374432851238774\n",
      "Step: 4921 Weights: [0.35560527 2.13248403] , error: 0.47374432834713254\n",
      "Step: 4922 Weights: [0.35560655 2.13248389] , error: 0.4737443281826299\n",
      "Step: 4923 Weights: [0.35560782 2.13248374] , error: 0.4737443280188771\n",
      "Step: 4924 Weights: [0.35560909 2.1324836 ] , error: 0.47374432785587006\n",
      "Step: 4925 Weights: [0.35561035 2.13248345] , error: 0.473744327693606\n",
      "Step: 4926 Weights: [0.35561162 2.13248331] , error: 0.47374432753208096\n",
      "Step: 4927 Weights: [0.35561288 2.13248316] , error: 0.47374432737129146\n",
      "Step: 4928 Weights: [0.35561414 2.13248302] , error: 0.4737443272112341\n",
      "Step: 4929 Weights: [0.35561539 2.13248288] , error: 0.4737443270519074\n",
      "Step: 4930 Weights: [0.35561664 2.13248273] , error: 0.47374432689330503\n",
      "Step: 4931 Weights: [0.35561789 2.13248259] , error: 0.47374432673542605\n",
      "Step: 4932 Weights: [0.35561914 2.13248245] , error: 0.47374432657826593\n",
      "Step: 4933 Weights: [0.35562038 2.13248231] , error: 0.4737443264218215\n",
      "Step: 4934 Weights: [0.35562162 2.13248216] , error: 0.47374432626609\n",
      "Step: 4935 Weights: [0.35562286 2.13248202] , error: 0.47374432611106787\n",
      "Step: 4936 Weights: [0.3556241  2.13248188] , error: 0.4737443259567523\n",
      "Step: 4937 Weights: [0.35562533 2.13248174] , error: 0.47374432580313974\n",
      "Step: 4938 Weights: [0.35562656 2.1324816 ] , error: 0.4737443256502265\n",
      "Step: 4939 Weights: [0.35562778 2.13248146] , error: 0.4737443254980108\n",
      "Step: 4940 Weights: [0.35562901 2.13248132] , error: 0.47374432534648797\n",
      "Step: 4941 Weights: [0.35563023 2.13248118] , error: 0.4737443251956551\n",
      "Step: 4942 Weights: [0.35563145 2.13248104] , error: 0.4737443250455097\n",
      "Step: 4943 Weights: [0.35563266 2.1324809 ] , error: 0.4737443248960485\n",
      "Step: 4944 Weights: [0.35563387 2.13248076] , error: 0.473744324747267\n",
      "Step: 4945 Weights: [0.35563508 2.13248062] , error: 0.4737443245991651\n",
      "Step: 4946 Weights: [0.35563629 2.13248049] , error: 0.47374432445173703\n",
      "Step: 4947 Weights: [0.35563749 2.13248035] , error: 0.4737443243049812\n",
      "Step: 4948 Weights: [0.3556387  2.13248021] , error: 0.4737443241588929\n",
      "Step: 4949 Weights: [0.35563989 2.13248007] , error: 0.4737443240134701\n",
      "Step: 4950 Weights: [0.35564109 2.13247994] , error: 0.47374432386871057\n",
      "Step: 4951 Weights: [0.35564228 2.1324798 ] , error: 0.47374432372461023\n",
      "Step: 4952 Weights: [0.35564347 2.13247966] , error: 0.4737443235811662\n",
      "Step: 4953 Weights: [0.35564466 2.13247953] , error: 0.4737443234383759\n",
      "Step: 4954 Weights: [0.35564585 2.13247939] , error: 0.4737443232962364\n",
      "Step: 4955 Weights: [0.35564703 2.13247926] , error: 0.4737443231547437\n",
      "Step: 4956 Weights: [0.35564821 2.13247912] , error: 0.4737443230138954\n",
      "Step: 4957 Weights: [0.35564939 2.13247899] , error: 0.4737443228736892\n",
      "Step: 4958 Weights: [0.35565056 2.13247885] , error: 0.47374432273412226\n",
      "Step: 4959 Weights: [0.35565173 2.13247872] , error: 0.47374432259519006\n",
      "Step: 4960 Weights: [0.3556529  2.13247859] , error: 0.47374432245689196\n",
      "Step: 4961 Weights: [0.35565407 2.13247845] , error: 0.4737443223192229\n",
      "Step: 4962 Weights: [0.35565523 2.13247832] , error: 0.4737443221821821\n",
      "Step: 4963 Weights: [0.35565639 2.13247819] , error: 0.47374432204576433\n",
      "Step: 4964 Weights: [0.35565755 2.13247805] , error: 0.4737443219099691\n",
      "Step: 4965 Weights: [0.35565871 2.13247792] , error: 0.47374432177479187\n",
      "Step: 4966 Weights: [0.35565986 2.13247779] , error: 0.4737443216402306\n",
      "Step: 4967 Weights: [0.35566101 2.13247766] , error: 0.47374432150628293\n",
      "Step: 4968 Weights: [0.35566216 2.13247753] , error: 0.47374432137294425\n",
      "Step: 4969 Weights: [0.3556633 2.1324774] , error: 0.4737443212402135\n",
      "Step: 4970 Weights: [0.35566445 2.13247727] , error: 0.47374432110808773\n",
      "Step: 4971 Weights: [0.35566559 2.13247714] , error: 0.47374432097656405\n",
      "Step: 4972 Weights: [0.35566672 2.13247701] , error: 0.4737443208456384\n",
      "Step: 4973 Weights: [0.35566786 2.13247688] , error: 0.4737443207153108\n",
      "Step: 4974 Weights: [0.35566899 2.13247675] , error: 0.4737443205855759\n",
      "Step: 4975 Weights: [0.35567012 2.13247662] , error: 0.47374432045643217\n",
      "Step: 4976 Weights: [0.35567125 2.13247649] , error: 0.4737443203278776\n",
      "Step: 4977 Weights: [0.35567237 2.13247636] , error: 0.47374432019990736\n",
      "Step: 4978 Weights: [0.3556735  2.13247623] , error: 0.473744320072521\n",
      "Step: 4979 Weights: [0.35567461 2.1324761 ] , error: 0.4737443199457142\n",
      "Step: 4980 Weights: [0.35567573 2.13247598] , error: 0.47374431981948617\n",
      "Step: 4981 Weights: [0.35567685 2.13247585] , error: 0.47374431969383185\n",
      "Step: 4982 Weights: [0.35567796 2.13247572] , error: 0.47374431956875035\n",
      "Step: 4983 Weights: [0.35567907 2.13247559] , error: 0.47374431944423967\n",
      "Step: 4984 Weights: [0.35568017 2.13247547] , error: 0.47374431932029565\n",
      "Step: 4985 Weights: [0.35568128 2.13247534] , error: 0.473744319196916\n",
      "Step: 4986 Weights: [0.35568238 2.13247522] , error: 0.473744319074098\n",
      "Step: 4987 Weights: [0.35568348 2.13247509] , error: 0.47374431895184077\n",
      "Step: 4988 Weights: [0.35568458 2.13247496] , error: 0.47374431883014023\n",
      "Step: 4989 Weights: [0.35568567 2.13247484] , error: 0.4737443187089939\n",
      "Step: 4990 Weights: [0.35568676 2.13247471] , error: 0.473744318588399\n",
      "Step: 4991 Weights: [0.35568785 2.13247459] , error: 0.4737443184683534\n",
      "Step: 4992 Weights: [0.35568894 2.13247447] , error: 0.47374431834885533\n",
      "Step: 4993 Weights: [0.35569002 2.13247434] , error: 0.4737443182299014\n",
      "Step: 4994 Weights: [0.3556911  2.13247422] , error: 0.47374431811148887\n",
      "Step: 4995 Weights: [0.35569218 2.13247409] , error: 0.47374431799361727\n",
      "Step: 4996 Weights: [0.35569326 2.13247397] , error: 0.4737443178762811\n",
      "Step: 4997 Weights: [0.35569433 2.13247385] , error: 0.47374431775948\n",
      "Step: 4998 Weights: [0.35569541 2.13247373] , error: 0.47374431764321123\n",
      "Step: 4999 Weights: [0.35569648 2.1324736 ] , error: 0.47374431752747137\n",
      "Step: 5000 Weights: [0.35569754 2.13247348] , error: 0.47374431741225975\n",
      "Step: 5001 Weights: [0.35569861 2.13247336] , error: 0.4737443172975723\n",
      "Step: 5002 Weights: [0.35569967 2.13247324] , error: 0.47374431718340704\n",
      "Step: 5003 Weights: [0.35570073 2.13247312] , error: 0.47374431706976283\n",
      "Step: 5004 Weights: [0.35570179 2.132473  ] , error: 0.47374431695663644\n",
      "Step: 5005 Weights: [0.35570284 2.13247288] , error: 0.4737443168440246\n",
      "Step: 5006 Weights: [0.35570389 2.13247275] , error: 0.4737443167319267\n",
      "Step: 5007 Weights: [0.35570494 2.13247263] , error: 0.47374431662033917\n",
      "Step: 5008 Weights: [0.35570599 2.13247252] , error: 0.47374431650925897\n",
      "Step: 5009 Weights: [0.35570704 2.1324724 ] , error: 0.47374431639868536\n",
      "Step: 5010 Weights: [0.35570808 2.13247228] , error: 0.4737443162886164\n",
      "Step: 5011 Weights: [0.35570912 2.13247216] , error: 0.4737443161790475\n",
      "Step: 5012 Weights: [0.35571016 2.13247204] , error: 0.4737443160699788\n",
      "Step: 5013 Weights: [0.35571119 2.13247192] , error: 0.473744315961406\n",
      "Step: 5014 Weights: [0.35571223 2.1324718 ] , error: 0.47374431585332827\n",
      "Step: 5015 Weights: [0.35571326 2.13247168] , error: 0.47374431574574355\n",
      "Step: 5016 Weights: [0.35571429 2.13247157] , error: 0.47374431563864816\n",
      "Step: 5017 Weights: [0.35571531 2.13247145] , error: 0.4737443155320407\n",
      "Step: 5018 Weights: [0.35571634 2.13247133] , error: 0.47374431542591927\n",
      "Step: 5019 Weights: [0.35571736 2.13247121] , error: 0.47374431532028116\n",
      "Step: 5020 Weights: [0.35571838 2.1324711 ] , error: 0.47374431521512456\n",
      "Step: 5021 Weights: [0.3557194  2.13247098] , error: 0.4737443151104471\n",
      "Step: 5022 Weights: [0.35572041 2.13247087] , error: 0.473744315006246\n",
      "Step: 5023 Weights: [0.35572142 2.13247075] , error: 0.4737443149025192\n",
      "Step: 5024 Weights: [0.35572243 2.13247063] , error: 0.4737443147992656\n",
      "Step: 5025 Weights: [0.35572344 2.13247052] , error: 0.47374431469648276\n",
      "Step: 5026 Weights: [0.35572445 2.1324704 ] , error: 0.4737443145941684\n",
      "Step: 5027 Weights: [0.35572545 2.13247029] , error: 0.47374431449231835\n",
      "Step: 5028 Weights: [0.35572645 2.13247018] , error: 0.47374431439093373\n",
      "Step: 5029 Weights: [0.35572745 2.13247006] , error: 0.47374431429001085\n",
      "Step: 5030 Weights: [0.35572845 2.13246995] , error: 0.47374431418954654\n",
      "Step: 5031 Weights: [0.35572944 2.13246983] , error: 0.4737443140895415\n",
      "Step: 5032 Weights: [0.35573043 2.13246972] , error: 0.4737443139899912\n",
      "Step: 5033 Weights: [0.35573142 2.13246961] , error: 0.4737443138908941\n",
      "Step: 5034 Weights: [0.35573241 2.13246949] , error: 0.47374431379224935\n",
      "Step: 5035 Weights: [0.35573339 2.13246938] , error: 0.47374431369405334\n",
      "Step: 5036 Weights: [0.35573438 2.13246927] , error: 0.4737443135963051\n",
      "Step: 5037 Weights: [0.35573536 2.13246916] , error: 0.4737443134990014\n",
      "Step: 5038 Weights: [0.35573634 2.13246904] , error: 0.4737443134021426\n",
      "Step: 5039 Weights: [0.35573731 2.13246893] , error: 0.47374431330572453\n",
      "Step: 5040 Weights: [0.35573829 2.13246882] , error: 0.4737443132097441\n",
      "Step: 5041 Weights: [0.35573926 2.13246871] , error: 0.47374431311420245\n",
      "Step: 5042 Weights: [0.35574023 2.1324686 ] , error: 0.4737443130190952\n",
      "Step: 5043 Weights: [0.35574119 2.13246849] , error: 0.4737443129244222\n",
      "Step: 5044 Weights: [0.35574216 2.13246838] , error: 0.4737443128301795\n",
      "Step: 5045 Weights: [0.35574312 2.13246827] , error: 0.47374431273636736\n",
      "Step: 5046 Weights: [0.35574408 2.13246816] , error: 0.4737443126429813\n",
      "Step: 5047 Weights: [0.35574504 2.13246805] , error: 0.4737443125500212\n",
      "Step: 5048 Weights: [0.355746   2.13246794] , error: 0.47374431245748483\n",
      "Step: 5049 Weights: [0.35574695 2.13246783] , error: 0.4737443123653691\n",
      "Step: 5050 Weights: [0.3557479  2.13246772] , error: 0.473744312273674\n",
      "Step: 5051 Weights: [0.35574885 2.13246761] , error: 0.47374431218239704\n",
      "Step: 5052 Weights: [0.3557498 2.1324675] , error: 0.4737443120915353\n",
      "Step: 5053 Weights: [0.35575075 2.1324674 ] , error: 0.47374431200108635\n",
      "Step: 5054 Weights: [0.35575169 2.13246729] , error: 0.4737443119110512\n",
      "Step: 5055 Weights: [0.35575263 2.13246718] , error: 0.4737443118214249\n",
      "Step: 5056 Weights: [0.35575357 2.13246707] , error: 0.47374431173220727\n",
      "Step: 5057 Weights: [0.35575451 2.13246697] , error: 0.4737443116433977\n",
      "Step: 5058 Weights: [0.35575544 2.13246686] , error: 0.4737443115549911\n",
      "Step: 5059 Weights: [0.35575637 2.13246675] , error: 0.47374431146698626\n",
      "Step: 5060 Weights: [0.3557573  2.13246665] , error: 0.47374431137938505\n",
      "Step: 5061 Weights: [0.35575823 2.13246654] , error: 0.4737443112921814\n",
      "Step: 5062 Weights: [0.35575916 2.13246643] , error: 0.4737443112053741\n",
      "Step: 5063 Weights: [0.35576008 2.13246633] , error: 0.4737443111189633\n",
      "Step: 5064 Weights: [0.355761   2.13246622] , error: 0.4737443110329464\n",
      "Step: 5065 Weights: [0.35576192 2.13246612] , error: 0.47374431094732117\n",
      "Step: 5066 Weights: [0.35576284 2.13246601] , error: 0.4737443108620859\n",
      "Step: 5067 Weights: [0.35576376 2.13246591] , error: 0.473744310777239\n",
      "Step: 5068 Weights: [0.35576467 2.1324658 ] , error: 0.47374431069277856\n",
      "Step: 5069 Weights: [0.35576558 2.1324657 ] , error: 0.4737443106087025\n",
      "Step: 5070 Weights: [0.35576649 2.1324656 ] , error: 0.4737443105250099\n",
      "Step: 5071 Weights: [0.3557674  2.13246549] , error: 0.4737443104416981\n",
      "Step: 5072 Weights: [0.35576831 2.13246539] , error: 0.4737443103587664\n",
      "Step: 5073 Weights: [0.35576921 2.13246529] , error: 0.473744310276213\n",
      "Step: 5074 Weights: [0.35577011 2.13246518] , error: 0.47374431019403435\n",
      "Step: 5075 Weights: [0.35577101 2.13246508] , error: 0.473744310112231\n",
      "Step: 5076 Weights: [0.35577191 2.13246498] , error: 0.47374431003080025\n",
      "Step: 5077 Weights: [0.3557728  2.13246487] , error: 0.47374430994974026\n",
      "Step: 5078 Weights: [0.35577369 2.13246477] , error: 0.4737443098690493\n",
      "Step: 5079 Weights: [0.35577458 2.13246467] , error: 0.47374430978872595\n",
      "Step: 5080 Weights: [0.35577547 2.13246457] , error: 0.47374430970876935\n",
      "Step: 5081 Weights: [0.35577636 2.13246447] , error: 0.47374430962917646\n",
      "Step: 5082 Weights: [0.35577725 2.13246437] , error: 0.47374430954994573\n",
      "Step: 5083 Weights: [0.35577813 2.13246427] , error: 0.4737443094710765\n",
      "Step: 5084 Weights: [0.35577901 2.13246416] , error: 0.47374430939256673\n",
      "Step: 5085 Weights: [0.35577989 2.13246406] , error: 0.4737443093144135\n",
      "Step: 5086 Weights: [0.35578076 2.13246396] , error: 0.4737443092366175\n",
      "Step: 5087 Weights: [0.35578164 2.13246386] , error: 0.47374430915917565\n",
      "Step: 5088 Weights: [0.35578251 2.13246376] , error: 0.4737443090820859\n",
      "Step: 5089 Weights: [0.35578338 2.13246366] , error: 0.4737443090053483\n",
      "Step: 5090 Weights: [0.35578425 2.13246356] , error: 0.4737443089289602\n",
      "Step: 5091 Weights: [0.35578512 2.13246347] , error: 0.4737443088529205\n",
      "Step: 5092 Weights: [0.35578598 2.13246337] , error: 0.4737443087772258\n",
      "Step: 5093 Weights: [0.35578685 2.13246327] , error: 0.47374430870187817\n",
      "Step: 5094 Weights: [0.35578771 2.13246317] , error: 0.4737443086268706\n",
      "Step: 5095 Weights: [0.35578857 2.13246307] , error: 0.4737443085522066\n",
      "Step: 5096 Weights: [0.35578942 2.13246297] , error: 0.4737443084778831\n",
      "Step: 5097 Weights: [0.35579028 2.13246288] , error: 0.47374430840389714\n",
      "Step: 5098 Weights: [0.35579113 2.13246278] , error: 0.4737443083302486\n",
      "Step: 5099 Weights: [0.35579198 2.13246268] , error: 0.47374430825693614\n",
      "Step: 5100 Weights: [0.35579283 2.13246258] , error: 0.47374430818395713\n",
      "Step: 5101 Weights: [0.35579368 2.13246249] , error: 0.47374430811131096\n",
      "Step: 5102 Weights: [0.35579452 2.13246239] , error: 0.4737443080389949\n",
      "Step: 5103 Weights: [0.35579537 2.13246229] , error: 0.47374430796700917\n",
      "Step: 5104 Weights: [0.35579621 2.1324622 ] , error: 0.47374430789535105\n",
      "Step: 5105 Weights: [0.35579705 2.1324621 ] , error: 0.4737443078240193\n",
      "Step: 5106 Weights: [0.35579789 2.13246201] , error: 0.4737443077530129\n",
      "Step: 5107 Weights: [0.35579872 2.13246191] , error: 0.4737443076823297\n",
      "Step: 5108 Weights: [0.35579956 2.13246181] , error: 0.4737443076119686\n",
      "Step: 5109 Weights: [0.35580039 2.13246172] , error: 0.4737443075419279\n",
      "Step: 5110 Weights: [0.35580122 2.13246162] , error: 0.473744307472206\n",
      "Step: 5111 Weights: [0.35580205 2.13246153] , error: 0.47374430740280216\n",
      "Step: 5112 Weights: [0.35580287 2.13246144] , error: 0.4737443073337144\n",
      "Step: 5113 Weights: [0.3558037  2.13246134] , error: 0.4737443072649411\n",
      "Step: 5114 Weights: [0.35580452 2.13246125] , error: 0.47374430719648136\n",
      "Step: 5115 Weights: [0.35580534 2.13246115] , error: 0.4737443071283337\n",
      "Step: 5116 Weights: [0.35580616 2.13246106] , error: 0.47374430706049625\n",
      "Step: 5117 Weights: [0.35580698 2.13246097] , error: 0.47374430699296816\n",
      "Step: 5118 Weights: [0.35580779 2.13246087] , error: 0.47374430692574704\n",
      "Step: 5119 Weights: [0.3558086  2.13246078] , error: 0.47374430685883223\n",
      "Step: 5120 Weights: [0.35580942 2.13246069] , error: 0.47374430679222357\n",
      "Step: 5121 Weights: [0.35581023 2.13246059] , error: 0.47374430672591694\n",
      "Step: 5122 Weights: [0.35581103 2.1324605 ] , error: 0.4737443066599127\n",
      "Step: 5123 Weights: [0.35581184 2.13246041] , error: 0.4737443065942095\n",
      "Step: 5124 Weights: [0.35581264 2.13246032] , error: 0.47374430652880484\n",
      "Step: 5125 Weights: [0.35581344 2.13246023] , error: 0.4737443064636992\n",
      "Step: 5126 Weights: [0.35581424 2.13246013] , error: 0.47374430639888937\n",
      "Step: 5127 Weights: [0.35581504 2.13246004] , error: 0.47374430633437525\n",
      "Step: 5128 Weights: [0.35581584 2.13245995] , error: 0.4737443062701548\n",
      "Step: 5129 Weights: [0.35581663 2.13245986] , error: 0.4737443062062265\n",
      "Step: 5130 Weights: [0.35581743 2.13245977] , error: 0.47374430614258944\n",
      "Step: 5131 Weights: [0.35581822 2.13245968] , error: 0.47374430607924334\n",
      "Step: 5132 Weights: [0.35581901 2.13245959] , error: 0.4737443060161855\n",
      "Step: 5133 Weights: [0.3558198 2.1324595] , error: 0.4737443059534147\n",
      "Step: 5134 Weights: [0.35582058 2.13245941] , error: 0.47374430589093003\n",
      "Step: 5135 Weights: [0.35582137 2.13245932] , error: 0.47374430582872906\n",
      "Step: 5136 Weights: [0.35582215 2.13245923] , error: 0.4737443057668126\n",
      "Step: 5137 Weights: [0.35582293 2.13245914] , error: 0.47374430570517734\n",
      "Step: 5138 Weights: [0.35582371 2.13245905] , error: 0.47374430564382347\n",
      "Step: 5139 Weights: [0.35582448 2.13245896] , error: 0.4737443055827492\n",
      "Step: 5140 Weights: [0.35582526 2.13245888] , error: 0.473744305521953\n",
      "Step: 5141 Weights: [0.35582603 2.13245879] , error: 0.47374430546143387\n",
      "Step: 5142 Weights: [0.3558268 2.1324587] , error: 0.47374430540118945\n",
      "Step: 5143 Weights: [0.35582757 2.13245861] , error: 0.4737443053412206\n",
      "Step: 5144 Weights: [0.35582834 2.13245852] , error: 0.47374430528152545\n",
      "Step: 5145 Weights: [0.35582911 2.13245843] , error: 0.47374430522210115\n",
      "Step: 5146 Weights: [0.35582987 2.13245835] , error: 0.47374430516294724\n",
      "Step: 5147 Weights: [0.35583064 2.13245826] , error: 0.47374430510406385\n",
      "Step: 5148 Weights: [0.3558314  2.13245817] , error: 0.47374430504544807\n",
      "Step: 5149 Weights: [0.35583216 2.13245809] , error: 0.47374430498709924\n",
      "Step: 5150 Weights: [0.35583291 2.132458  ] , error: 0.47374430492901637\n",
      "Step: 5151 Weights: [0.35583367 2.13245791] , error: 0.47374430487119895\n",
      "Step: 5152 Weights: [0.35583442 2.13245783] , error: 0.47374430481364416\n",
      "Step: 5153 Weights: [0.35583518 2.13245774] , error: 0.47374430475635143\n",
      "Step: 5154 Weights: [0.35583593 2.13245766] , error: 0.4737443046993197\n",
      "Step: 5155 Weights: [0.35583668 2.13245757] , error: 0.4737443046425483\n",
      "Step: 5156 Weights: [0.35583742 2.13245748] , error: 0.4737443045860348\n",
      "Step: 5157 Weights: [0.35583817 2.1324574 ] , error: 0.47374430452977967\n",
      "Step: 5158 Weights: [0.35583891 2.13245731] , error: 0.4737443044737805\n",
      "Step: 5159 Weights: [0.35583965 2.13245723] , error: 0.47374430441803533\n",
      "Step: 5160 Weights: [0.3558404  2.13245714] , error: 0.4737443043625459\n",
      "Step: 5161 Weights: [0.35584113 2.13245706] , error: 0.47374430430730796\n",
      "Step: 5162 Weights: [0.35584187 2.13245698] , error: 0.47374430425232217\n",
      "Step: 5163 Weights: [0.35584261 2.13245689] , error: 0.4737443041975862\n",
      "Step: 5164 Weights: [0.35584334 2.13245681] , error: 0.4737443041431012\n",
      "Step: 5165 Weights: [0.35584407 2.13245672] , error: 0.47374430408886276\n",
      "Step: 5166 Weights: [0.3558448  2.13245664] , error: 0.47374430403487283\n",
      "Step: 5167 Weights: [0.35584553 2.13245656] , error: 0.4737443039811283\n",
      "Step: 5168 Weights: [0.35584626 2.13245647] , error: 0.4737443039276278\n",
      "Step: 5169 Weights: [0.35584698 2.13245639] , error: 0.47374430387437166\n",
      "Step: 5170 Weights: [0.35584771 2.13245631] , error: 0.4737443038213584\n",
      "Step: 5171 Weights: [0.35584843 2.13245623] , error: 0.4737443037685858\n",
      "Step: 5172 Weights: [0.35584915 2.13245614] , error: 0.47374430371605447\n",
      "Step: 5173 Weights: [0.35584987 2.13245606] , error: 0.473744303663762\n",
      "Step: 5174 Weights: [0.35585059 2.13245598] , error: 0.4737443036117078\n",
      "Step: 5175 Weights: [0.3558513 2.1324559] , error: 0.4737443035598914\n",
      "Step: 5176 Weights: [0.35585202 2.13245581] , error: 0.4737443035083098\n",
      "Step: 5177 Weights: [0.35585273 2.13245573] , error: 0.4737443034569646\n",
      "Step: 5178 Weights: [0.35585344 2.13245565] , error: 0.4737443034058527\n",
      "Step: 5179 Weights: [0.35585415 2.13245557] , error: 0.4737443033549734\n",
      "Step: 5180 Weights: [0.35585486 2.13245549] , error: 0.4737443033043258\n",
      "Step: 5181 Weights: [0.35585556 2.13245541] , error: 0.4737443032539095\n",
      "Step: 5182 Weights: [0.35585627 2.13245533] , error: 0.4737443032037221\n",
      "Step: 5183 Weights: [0.35585697 2.13245525] , error: 0.4737443031537645\n",
      "Step: 5184 Weights: [0.35585767 2.13245517] , error: 0.4737443031040331\n",
      "Step: 5185 Weights: [0.35585837 2.13245509] , error: 0.47374430305452886\n",
      "Step: 5186 Weights: [0.35585907 2.13245501] , error: 0.47374430300525094\n",
      "Step: 5187 Weights: [0.35585976 2.13245493] , error: 0.4737443029561965\n",
      "Step: 5188 Weights: [0.35586046 2.13245485] , error: 0.47374430290736536\n",
      "Step: 5189 Weights: [0.35586115 2.13245477] , error: 0.47374430285875785\n",
      "Step: 5190 Weights: [0.35586184 2.13245469] , error: 0.4737443028103702\n",
      "Step: 5191 Weights: [0.35586253 2.13245461] , error: 0.4737443027622046\n",
      "Step: 5192 Weights: [0.35586322 2.13245453] , error: 0.4737443027142568\n",
      "Step: 5193 Weights: [0.35586391 2.13245445] , error: 0.47374430266652867\n",
      "Step: 5194 Weights: [0.35586459 2.13245438] , error: 0.4737443026190178\n",
      "Step: 5195 Weights: [0.35586528 2.1324543 ] , error: 0.4737443025717232\n",
      "Step: 5196 Weights: [0.35586596 2.13245422] , error: 0.47374430252464433\n",
      "Step: 5197 Weights: [0.35586664 2.13245414] , error: 0.4737443024777791\n",
      "Step: 5198 Weights: [0.35586732 2.13245406] , error: 0.47374430243112775\n",
      "Step: 5199 Weights: [0.355868   2.13245399] , error: 0.4737443023846896\n",
      "Step: 5200 Weights: [0.35586867 2.13245391] , error: 0.47374430233846254\n",
      "Step: 5201 Weights: [0.35586935 2.13245383] , error: 0.4737443022924462\n",
      "Step: 5202 Weights: [0.35587002 2.13245376] , error: 0.47374430224663944\n",
      "Step: 5203 Weights: [0.35587069 2.13245368] , error: 0.4737443022010408\n",
      "Step: 5204 Weights: [0.35587136 2.1324536 ] , error: 0.4737443021556498\n",
      "Step: 5205 Weights: [0.35587203 2.13245353] , error: 0.47374430211046653\n",
      "Step: 5206 Weights: [0.35587269 2.13245345] , error: 0.47374430206548934\n",
      "Step: 5207 Weights: [0.35587336 2.13245337] , error: 0.4737443020207152\n",
      "Step: 5208 Weights: [0.35587402 2.1324533 ] , error: 0.4737443019761475\n",
      "Step: 5209 Weights: [0.35587469 2.13245322] , error: 0.47374430193178113\n",
      "Step: 5210 Weights: [0.35587535 2.13245315] , error: 0.47374430188761657\n",
      "Step: 5211 Weights: [0.35587601 2.13245307] , error: 0.4737443018436547\n",
      "Step: 5212 Weights: [0.35587666 2.132453  ] , error: 0.4737443017998923\n",
      "Step: 5213 Weights: [0.35587732 2.13245292] , error: 0.4737443017563293\n",
      "Step: 5214 Weights: [0.35587797 2.13245285] , error: 0.4737443017129645\n",
      "Step: 5215 Weights: [0.35587863 2.13245277] , error: 0.4737443016697969\n",
      "Step: 5216 Weights: [0.35587928 2.1324527 ] , error: 0.4737443016268279\n",
      "Step: 5217 Weights: [0.35587993 2.13245262] , error: 0.47374430158405223\n",
      "Step: 5218 Weights: [0.35588058 2.13245255] , error: 0.47374430154147307\n",
      "Step: 5219 Weights: [0.35588122 2.13245247] , error: 0.47374430149908764\n",
      "Step: 5220 Weights: [0.35588187 2.1324524 ] , error: 0.4737443014568947\n",
      "Step: 5221 Weights: [0.35588251 2.13245233] , error: 0.47374430141489443\n",
      "Step: 5222 Weights: [0.35588316 2.13245225] , error: 0.47374430137308454\n",
      "Step: 5223 Weights: [0.3558838  2.13245218] , error: 0.473744301331467\n",
      "Step: 5224 Weights: [0.35588444 2.13245211] , error: 0.4737443012900372\n",
      "Step: 5225 Weights: [0.35588508 2.13245203] , error: 0.4737443012487969\n",
      "Step: 5226 Weights: [0.35588571 2.13245196] , error: 0.4737443012077442\n",
      "Step: 5227 Weights: [0.35588635 2.13245189] , error: 0.47374430116688\n",
      "Step: 5228 Weights: [0.35588698 2.13245182] , error: 0.4737443011261999\n",
      "Step: 5229 Weights: [0.35588762 2.13245174] , error: 0.47374430108570614\n",
      "Step: 5230 Weights: [0.35588825 2.13245167] , error: 0.4737443010453969\n",
      "Step: 5231 Weights: [0.35588888 2.1324516 ] , error: 0.4737443010052708\n",
      "Step: 5232 Weights: [0.35588951 2.13245153] , error: 0.473744300965328\n",
      "Step: 5233 Weights: [0.35589013 2.13245146] , error: 0.4737443009255667\n",
      "Step: 5234 Weights: [0.35589076 2.13245138] , error: 0.4737443008859876\n",
      "Step: 5235 Weights: [0.35589138 2.13245131] , error: 0.4737443008465873\n",
      "Step: 5236 Weights: [0.355892   2.13245124] , error: 0.47374430080736785\n",
      "Step: 5237 Weights: [0.35589262 2.13245117] , error: 0.4737443007683254\n",
      "Step: 5238 Weights: [0.35589324 2.1324511 ] , error: 0.47374430072946233\n",
      "Step: 5239 Weights: [0.35589386 2.13245103] , error: 0.4737443006907766\n",
      "Step: 5240 Weights: [0.35589448 2.13245096] , error: 0.47374430065226597\n",
      "Step: 5241 Weights: [0.3558951  2.13245089] , error: 0.47374430061393086\n",
      "Step: 5242 Weights: [0.35589571 2.13245082] , error: 0.47374430057577044\n",
      "Step: 5243 Weights: [0.35589632 2.13245075] , error: 0.4737443005377849\n",
      "Step: 5244 Weights: [0.35589693 2.13245068] , error: 0.4737443004999714\n",
      "Step: 5245 Weights: [0.35589754 2.13245061] , error: 0.47374430046232985\n",
      "Step: 5246 Weights: [0.35589815 2.13245054] , error: 0.4737443004248599\n",
      "Step: 5247 Weights: [0.35589876 2.13245047] , error: 0.47374430038756105\n",
      "Step: 5248 Weights: [0.35589936 2.1324504 ] , error: 0.4737443003504328\n",
      "Step: 5249 Weights: [0.35589997 2.13245033] , error: 0.4737443003134729\n",
      "Step: 5250 Weights: [0.35590057 2.13245026] , error: 0.47374430027668313\n",
      "Step: 5251 Weights: [0.35590117 2.13245019] , error: 0.4737443002400573\n",
      "Step: 5252 Weights: [0.35590177 2.13245012] , error: 0.4737443002036009\n",
      "Step: 5253 Weights: [0.35590237 2.13245006] , error: 0.47374430016731006\n",
      "Step: 5254 Weights: [0.35590297 2.13244999] , error: 0.4737443001311852\n",
      "Step: 5255 Weights: [0.35590357 2.13244992] , error: 0.47374430009522295\n",
      "Step: 5256 Weights: [0.35590416 2.13244985] , error: 0.4737443000594262\n",
      "Step: 5257 Weights: [0.35590475 2.13244978] , error: 0.4737443000237924\n",
      "Step: 5258 Weights: [0.35590535 2.13244972] , error: 0.47374429998832035\n",
      "Step: 5259 Weights: [0.35590594 2.13244965] , error: 0.4737442999530101\n",
      "Step: 5260 Weights: [0.35590653 2.13244958] , error: 0.47374429991786127\n",
      "Step: 5261 Weights: [0.35590711 2.13244951] , error: 0.47374429988287187\n",
      "Step: 5262 Weights: [0.3559077  2.13244945] , error: 0.47374429984804206\n",
      "Step: 5263 Weights: [0.35590829 2.13244938] , error: 0.47374429981337174\n",
      "Step: 5264 Weights: [0.35590887 2.13244931] , error: 0.4737442997788579\n",
      "Step: 5265 Weights: [0.35590945 2.13244925] , error: 0.47374429974450266\n",
      "Step: 5266 Weights: [0.35591003 2.13244918] , error: 0.4737442997103024\n",
      "Step: 5267 Weights: [0.35591061 2.13244911] , error: 0.4737442996762598\n",
      "Step: 5268 Weights: [0.35591119 2.13244905] , error: 0.473744299642371\n",
      "Step: 5269 Weights: [0.35591177 2.13244898] , error: 0.4737442996086364\n",
      "Step: 5270 Weights: [0.35591235 2.13244892] , error: 0.47374429957505626\n",
      "Step: 5271 Weights: [0.35591292 2.13244885] , error: 0.47374429954162905\n",
      "Step: 5272 Weights: [0.3559135  2.13244878] , error: 0.47374429950835345\n",
      "Step: 5273 Weights: [0.35591407 2.13244872] , error: 0.47374429947522945\n",
      "Step: 5274 Weights: [0.35591464 2.13244865] , error: 0.4737442994422573\n",
      "Step: 5275 Weights: [0.35591521 2.13244859] , error: 0.47374429940943447\n",
      "Step: 5276 Weights: [0.35591578 2.13244852] , error: 0.4737442993767625\n",
      "Step: 5277 Weights: [0.35591634 2.13244846] , error: 0.47374429934423795\n",
      "Step: 5278 Weights: [0.35591691 2.13244839] , error: 0.47374429931186146\n",
      "Step: 5279 Weights: [0.35591747 2.13244833] , error: 0.47374429927963374\n",
      "Step: 5280 Weights: [0.35591804 2.13244826] , error: 0.4737442992475513\n",
      "Step: 5281 Weights: [0.3559186 2.1324482] , error: 0.4737442992156164\n",
      "Step: 5282 Weights: [0.35591916 2.13244814] , error: 0.47374429918382654\n",
      "Step: 5283 Weights: [0.35591972 2.13244807] , error: 0.47374429915218086\n",
      "Step: 5284 Weights: [0.35592028 2.13244801] , error: 0.4737442991206802\n",
      "Step: 5285 Weights: [0.35592083 2.13244794] , error: 0.4737442990893221\n",
      "Step: 5286 Weights: [0.35592139 2.13244788] , error: 0.473744299058108\n",
      "Step: 5287 Weights: [0.35592194 2.13244782] , error: 0.47374429902703497\n",
      "Step: 5288 Weights: [0.35592249 2.13244775] , error: 0.4737442989961044\n",
      "Step: 5289 Weights: [0.35592305 2.13244769] , error: 0.4737442989653143\n",
      "Step: 5290 Weights: [0.3559236  2.13244763] , error: 0.47374429893466447\n",
      "Step: 5291 Weights: [0.35592415 2.13244757] , error: 0.47374429890415476\n",
      "Step: 5292 Weights: [0.35592469 2.1324475 ] , error: 0.47374429887378416\n",
      "Step: 5293 Weights: [0.35592524 2.13244744] , error: 0.4737442988435514\n",
      "Step: 5294 Weights: [0.35592579 2.13244738] , error: 0.47374429881345603\n",
      "Step: 5295 Weights: [0.35592633 2.13244732] , error: 0.47374429878349805\n",
      "Step: 5296 Weights: [0.35592687 2.13244725] , error: 0.47374429875367763\n",
      "Step: 5297 Weights: [0.35592741 2.13244719] , error: 0.4737442987239909\n",
      "Step: 5298 Weights: [0.35592795 2.13244713] , error: 0.4737442986944413\n",
      "Step: 5299 Weights: [0.35592849 2.13244707] , error: 0.4737442986650246\n",
      "Step: 5300 Weights: [0.35592903 2.13244701] , error: 0.47374429863574374\n",
      "Step: 5301 Weights: [0.35592957 2.13244695] , error: 0.4737442986065957\n",
      "Step: 5302 Weights: [0.3559301  2.13244688] , error: 0.4737442985775797\n",
      "Step: 5303 Weights: [0.35593064 2.13244682] , error: 0.4737442985486962\n",
      "Step: 5304 Weights: [0.35593117 2.13244676] , error: 0.47374429851994515\n",
      "Step: 5305 Weights: [0.3559317 2.1324467] , error: 0.47374429849132355\n",
      "Step: 5306 Weights: [0.35593223 2.13244664] , error: 0.4737442984628336\n",
      "Step: 5307 Weights: [0.35593276 2.13244658] , error: 0.47374429843447463\n",
      "Step: 5308 Weights: [0.35593329 2.13244652] , error: 0.4737442984062421\n",
      "Step: 5309 Weights: [0.35593382 2.13244646] , error: 0.47374429837813914\n",
      "Step: 5310 Weights: [0.35593434 2.1324464 ] , error: 0.47374429835016457\n",
      "Step: 5311 Weights: [0.35593487 2.13244634] , error: 0.4737442983223164\n",
      "Step: 5312 Weights: [0.35593539 2.13244628] , error: 0.47374429829459697\n",
      "Step: 5313 Weights: [0.35593591 2.13244622] , error: 0.4737442982670024\n",
      "Step: 5314 Weights: [0.35593643 2.13244616] , error: 0.4737442982395331\n",
      "Step: 5315 Weights: [0.35593695 2.1324461 ] , error: 0.47374429821219066\n",
      "Step: 5316 Weights: [0.35593747 2.13244604] , error: 0.47374429818497177\n",
      "Step: 5317 Weights: [0.35593799 2.13244598] , error: 0.4737442981578773\n",
      "Step: 5318 Weights: [0.35593851 2.13244592] , error: 0.4737442981309056\n",
      "Step: 5319 Weights: [0.35593902 2.13244586] , error: 0.4737442981040568\n",
      "Step: 5320 Weights: [0.35593954 2.13244581] , error: 0.473744298077331\n",
      "Step: 5321 Weights: [0.35594005 2.13244575] , error: 0.4737442980507265\n",
      "Step: 5322 Weights: [0.35594056 2.13244569] , error: 0.47374429802424345\n",
      "Step: 5323 Weights: [0.35594107 2.13244563] , error: 0.4737442979978811\n",
      "Step: 5324 Weights: [0.35594158 2.13244557] , error: 0.4737442979716388\n",
      "Step: 5325 Weights: [0.35594209 2.13244551] , error: 0.4737442979455159\n",
      "Step: 5326 Weights: [0.35594259 2.13244546] , error: 0.473744297919512\n",
      "Step: 5327 Weights: [0.3559431 2.1324454] , error: 0.47374429789362693\n",
      "Step: 5328 Weights: [0.35594361 2.13244534] , error: 0.4737442978678589\n",
      "Step: 5329 Weights: [0.35594411 2.13244528] , error: 0.47374429784220945\n",
      "Step: 5330 Weights: [0.35594461 2.13244523] , error: 0.47374429781667526\n",
      "Step: 5331 Weights: [0.35594511 2.13244517] , error: 0.47374429779125815\n",
      "Step: 5332 Weights: [0.35594561 2.13244511] , error: 0.47374429776595717\n",
      "Step: 5333 Weights: [0.35594611 2.13244505] , error: 0.47374429774077154\n",
      "Step: 5334 Weights: [0.35594661 2.132445  ] , error: 0.47374429771570126\n",
      "Step: 5335 Weights: [0.35594711 2.13244494] , error: 0.4737442976907437\n",
      "Step: 5336 Weights: [0.3559476  2.13244488] , error: 0.47374429766590104\n",
      "Step: 5337 Weights: [0.3559481  2.13244483] , error: 0.4737442976411704\n",
      "Step: 5338 Weights: [0.35594859 2.13244477] , error: 0.47374429761655273\n",
      "Step: 5339 Weights: [0.35594908 2.13244471] , error: 0.4737442975920485\n",
      "Step: 5340 Weights: [0.35594957 2.13244466] , error: 0.47374429756765446\n",
      "Step: 5341 Weights: [0.35595006 2.1324446 ] , error: 0.47374429754337144\n",
      "Step: 5342 Weights: [0.35595055 2.13244455] , error: 0.4737442975192003\n",
      "Step: 5343 Weights: [0.35595104 2.13244449] , error: 0.4737442974951379\n",
      "Step: 5344 Weights: [0.35595152 2.13244443] , error: 0.473744297471186\n",
      "Step: 5345 Weights: [0.35595201 2.13244438] , error: 0.47374429744734303\n",
      "Step: 5346 Weights: [0.35595249 2.13244432] , error: 0.47374429742360874\n",
      "Step: 5347 Weights: [0.35595298 2.13244427] , error: 0.4737442973999827\n",
      "Step: 5348 Weights: [0.35595346 2.13244421] , error: 0.473744297376464\n",
      "Step: 5349 Weights: [0.35595394 2.13244416] , error: 0.47374429735305257\n",
      "Step: 5350 Weights: [0.35595442 2.1324441 ] , error: 0.4737442973297476\n",
      "Step: 5351 Weights: [0.3559549  2.13244405] , error: 0.47374429730654827\n",
      "Step: 5352 Weights: [0.35595538 2.13244399] , error: 0.47374429728345524\n",
      "Step: 5353 Weights: [0.35595585 2.13244394] , error: 0.4737442972604682\n",
      "Step: 5354 Weights: [0.35595633 2.13244389] , error: 0.4737442972375852\n",
      "Step: 5355 Weights: [0.3559568  2.13244383] , error: 0.47374429721480604\n",
      "Step: 5356 Weights: [0.35595728 2.13244378] , error: 0.47374429719213085\n",
      "Step: 5357 Weights: [0.35595775 2.13244372] , error: 0.47374429716956\n",
      "Step: 5358 Weights: [0.35595822 2.13244367] , error: 0.47374429714709076\n",
      "Step: 5359 Weights: [0.35595869 2.13244362] , error: 0.4737442971247237\n",
      "Step: 5360 Weights: [0.35595916 2.13244356] , error: 0.473744297102459\n",
      "Step: 5361 Weights: [0.35595963 2.13244351] , error: 0.47374429708029603\n",
      "Step: 5362 Weights: [0.35596009 2.13244345] , error: 0.4737442970582333\n",
      "Step: 5363 Weights: [0.35596056 2.1324434 ] , error: 0.4737442970362723\n",
      "Step: 5364 Weights: [0.35596102 2.13244335] , error: 0.4737442970144099\n",
      "Step: 5365 Weights: [0.35596149 2.1324433 ] , error: 0.4737442969926481\n",
      "Step: 5366 Weights: [0.35596195 2.13244324] , error: 0.4737442969709851\n",
      "Step: 5367 Weights: [0.35596241 2.13244319] , error: 0.47374429694942166\n",
      "Step: 5368 Weights: [0.35596287 2.13244314] , error: 0.4737442969279552\n",
      "Step: 5369 Weights: [0.35596333 2.13244308] , error: 0.47374429690658726\n",
      "Step: 5370 Weights: [0.35596379 2.13244303] , error: 0.4737442968853159\n",
      "Step: 5371 Weights: [0.35596425 2.13244298] , error: 0.47374429686414143\n",
      "Step: 5372 Weights: [0.35596471 2.13244293] , error: 0.4737442968430645\n",
      "Step: 5373 Weights: [0.35596516 2.13244288] , error: 0.4737442968220828\n",
      "Step: 5374 Weights: [0.35596562 2.13244282] , error: 0.4737442968011971\n",
      "Step: 5375 Weights: [0.35596607 2.13244277] , error: 0.4737442967804061\n",
      "Step: 5376 Weights: [0.35596652 2.13244272] , error: 0.47374429675971014\n",
      "Step: 5377 Weights: [0.35596697 2.13244267] , error: 0.4737442967391087\n",
      "Step: 5378 Weights: [0.35596742 2.13244262] , error: 0.473744296718601\n",
      "Step: 5379 Weights: [0.35596787 2.13244257] , error: 0.4737442966981862\n",
      "Step: 5380 Weights: [0.35596832 2.13244251] , error: 0.473744296677865\n",
      "Step: 5381 Weights: [0.35596877 2.13244246] , error: 0.4737442966576355\n",
      "Step: 5382 Weights: [0.35596921 2.13244241] , error: 0.47374429663749906\n",
      "Step: 5383 Weights: [0.35596966 2.13244236] , error: 0.4737442966174532\n",
      "Step: 5384 Weights: [0.3559701  2.13244231] , error: 0.4737442965974995\n",
      "Step: 5385 Weights: [0.35597054 2.13244226] , error: 0.47374429657763717\n",
      "Step: 5386 Weights: [0.35597099 2.13244221] , error: 0.47374429655786465\n",
      "Step: 5387 Weights: [0.35597143 2.13244216] , error: 0.4737442965381831\n",
      "Step: 5388 Weights: [0.35597187 2.13244211] , error: 0.4737442965185902\n",
      "Step: 5389 Weights: [0.35597231 2.13244206] , error: 0.4737442964990866\n",
      "Step: 5390 Weights: [0.35597274 2.13244201] , error: 0.4737442964796721\n",
      "Step: 5391 Weights: [0.35597318 2.13244196] , error: 0.47374429646034627\n",
      "Step: 5392 Weights: [0.35597362 2.13244191] , error: 0.47374429644110794\n",
      "Step: 5393 Weights: [0.35597405 2.13244186] , error: 0.4737442964219578\n",
      "Step: 5394 Weights: [0.35597449 2.13244181] , error: 0.4737442964028951\n",
      "Step: 5395 Weights: [0.35597492 2.13244176] , error: 0.4737442963839186\n",
      "Step: 5396 Weights: [0.35597535 2.13244171] , error: 0.473744296365029\n",
      "Step: 5397 Weights: [0.35597578 2.13244166] , error: 0.4737442963462246\n",
      "Step: 5398 Weights: [0.35597621 2.13244161] , error: 0.47374429632750675\n",
      "Step: 5399 Weights: [0.35597664 2.13244156] , error: 0.4737442963088746\n",
      "Step: 5400 Weights: [0.35597707 2.13244151] , error: 0.4737442962903264\n",
      "Step: 5401 Weights: [0.3559775  2.13244146] , error: 0.4737442962718632\n",
      "Step: 5402 Weights: [0.35597792 2.13244142] , error: 0.4737442962534836\n",
      "Step: 5403 Weights: [0.35597835 2.13244137] , error: 0.47374429623518793\n",
      "Step: 5404 Weights: [0.35597877 2.13244132] , error: 0.47374429621697534\n",
      "Step: 5405 Weights: [0.3559792  2.13244127] , error: 0.4737442961988462\n",
      "Step: 5406 Weights: [0.35597962 2.13244122] , error: 0.473744296180799\n",
      "Step: 5407 Weights: [0.35598004 2.13244117] , error: 0.4737442961628352\n",
      "Step: 5408 Weights: [0.35598046 2.13244113] , error: 0.4737442961449523\n",
      "Step: 5409 Weights: [0.35598088 2.13244108] , error: 0.4737442961271513\n",
      "Step: 5410 Weights: [0.3559813  2.13244103] , error: 0.4737442961094309\n",
      "Step: 5411 Weights: [0.35598172 2.13244098] , error: 0.47374429609179197\n",
      "Step: 5412 Weights: [0.35598213 2.13244093] , error: 0.47374429607423285\n",
      "Step: 5413 Weights: [0.35598255 2.13244089] , error: 0.47374429605675394\n",
      "Step: 5414 Weights: [0.35598296 2.13244084] , error: 0.4737442960393543\n",
      "Step: 5415 Weights: [0.35598338 2.13244079] , error: 0.47374429602203394\n",
      "Step: 5416 Weights: [0.35598379 2.13244074] , error: 0.47374429600479345\n",
      "Step: 5417 Weights: [0.3559842 2.1324407] , error: 0.47374429598763096\n",
      "Step: 5418 Weights: [0.35598461 2.13244065] , error: 0.47374429597054574\n",
      "Step: 5419 Weights: [0.35598502 2.1324406 ] , error: 0.4737442959535396\n",
      "Step: 5420 Weights: [0.35598543 2.13244056] , error: 0.47374429593661055\n",
      "Step: 5421 Weights: [0.35598584 2.13244051] , error: 0.4737442959197582\n",
      "Step: 5422 Weights: [0.35598625 2.13244046] , error: 0.47374429590298267\n",
      "Step: 5423 Weights: [0.35598665 2.13244042] , error: 0.47374429588628364\n",
      "Step: 5424 Weights: [0.35598706 2.13244037] , error: 0.4737442958696611\n",
      "Step: 5425 Weights: [0.35598746 2.13244032] , error: 0.4737442958531143\n",
      "Step: 5426 Weights: [0.35598787 2.13244028] , error: 0.4737442958366432\n",
      "Step: 5427 Weights: [0.35598827 2.13244023] , error: 0.473744295820246\n",
      "Step: 5428 Weights: [0.35598867 2.13244019] , error: 0.4737442958039241\n",
      "Step: 5429 Weights: [0.35598907 2.13244014] , error: 0.473744295787677\n",
      "Step: 5430 Weights: [0.35598947 2.1324401 ] , error: 0.47374429577150273\n",
      "Step: 5431 Weights: [0.35598987 2.13244005] , error: 0.473744295755403\n",
      "Step: 5432 Weights: [0.35599027 2.13244   ] , error: 0.47374429573937615\n",
      "Step: 5433 Weights: [0.35599066 2.13243996] , error: 0.4737442957234233\n",
      "Step: 5434 Weights: [0.35599106 2.13243991] , error: 0.4737442957075422\n",
      "Step: 5435 Weights: [0.35599146 2.13243987] , error: 0.4737442956917339\n",
      "Step: 5436 Weights: [0.35599185 2.13243982] , error: 0.4737442956759975\n",
      "Step: 5437 Weights: [0.35599224 2.13243978] , error: 0.4737442956603326\n",
      "Step: 5438 Weights: [0.35599264 2.13243973] , error: 0.4737442956447388\n",
      "Step: 5439 Weights: [0.35599303 2.13243969] , error: 0.4737442956292169\n",
      "Step: 5440 Weights: [0.35599342 2.13243964] , error: 0.47374429561376497\n",
      "Step: 5441 Weights: [0.35599381 2.1324396 ] , error: 0.47374429559838355\n",
      "Step: 5442 Weights: [0.3559942  2.13243955] , error: 0.4737442955830722\n",
      "Step: 5443 Weights: [0.35599459 2.13243951] , error: 0.4737442955678316\n",
      "Step: 5444 Weights: [0.35599497 2.13243947] , error: 0.4737442955526592\n",
      "Step: 5445 Weights: [0.35599536 2.13243942] , error: 0.4737442955375558\n",
      "Step: 5446 Weights: [0.35599574 2.13243938] , error: 0.4737442955225222\n",
      "Step: 5447 Weights: [0.35599613 2.13243933] , error: 0.47374429550755714\n",
      "Step: 5448 Weights: [0.35599651 2.13243929] , error: 0.4737442954926594\n",
      "Step: 5449 Weights: [0.3559969  2.13243925] , error: 0.47374429547783\n",
      "Step: 5450 Weights: [0.35599728 2.1324392 ] , error: 0.4737442954630672\n",
      "Step: 5451 Weights: [0.35599766 2.13243916] , error: 0.4737442954483727\n",
      "Step: 5452 Weights: [0.35599804 2.13243912] , error: 0.47374429543374486\n",
      "Step: 5453 Weights: [0.35599842 2.13243907] , error: 0.47374429541918384\n",
      "Step: 5454 Weights: [0.3559988  2.13243903] , error: 0.47374429540468943\n",
      "Step: 5455 Weights: [0.35599917 2.13243899] , error: 0.47374429539026064\n",
      "Step: 5456 Weights: [0.35599955 2.13243894] , error: 0.4737442953758977\n",
      "Step: 5457 Weights: [0.35599993 2.1324389 ] , error: 0.47374429536159907\n",
      "Step: 5458 Weights: [0.3560003  2.13243886] , error: 0.4737442953473672\n",
      "Step: 5459 Weights: [0.35600068 2.13243881] , error: 0.4737442953331992\n",
      "Step: 5460 Weights: [0.35600105 2.13243877] , error: 0.47374429531909634\n",
      "Step: 5461 Weights: [0.35600142 2.13243873] , error: 0.4737442953050574\n",
      "Step: 5462 Weights: [0.35600179 2.13243869] , error: 0.4737442952910828\n",
      "Step: 5463 Weights: [0.35600216 2.13243864] , error: 0.4737442952771713\n",
      "Step: 5464 Weights: [0.35600253 2.1324386 ] , error: 0.4737442952633233\n",
      "Step: 5465 Weights: [0.3560029  2.13243856] , error: 0.4737442952495381\n",
      "Step: 5466 Weights: [0.35600327 2.13243852] , error: 0.4737442952358162\n",
      "Step: 5467 Weights: [0.35600364 2.13243847] , error: 0.4737442952221566\n",
      "Step: 5468 Weights: [0.35600401 2.13243843] , error: 0.4737442952085599\n",
      "Step: 5469 Weights: [0.35600437 2.13243839] , error: 0.4737442951950247\n",
      "Step: 5470 Weights: [0.35600474 2.13243835] , error: 0.47374429518155065\n",
      "Step: 5471 Weights: [0.3560051  2.13243831] , error: 0.47374429516813876\n",
      "Step: 5472 Weights: [0.35600546 2.13243827] , error: 0.47374429515478744\n",
      "Step: 5473 Weights: [0.35600583 2.13243822] , error: 0.47374429514149696\n",
      "Step: 5474 Weights: [0.35600619 2.13243818] , error: 0.47374429512826555\n",
      "Step: 5475 Weights: [0.35600655 2.13243814] , error: 0.4737442951150974\n",
      "Step: 5476 Weights: [0.35600691 2.1324381 ] , error: 0.4737442951019882\n",
      "Step: 5477 Weights: [0.35600727 2.13243806] , error: 0.4737442950889382\n",
      "Step: 5478 Weights: [0.35600763 2.13243802] , error: 0.47374429507594784\n",
      "Step: 5479 Weights: [0.35600798 2.13243798] , error: 0.4737442950630169\n",
      "Step: 5480 Weights: [0.35600834 2.13243794] , error: 0.4737442950501444\n",
      "Step: 5481 Weights: [0.3560087 2.1324379] , error: 0.4737442950373306\n",
      "Step: 5482 Weights: [0.35600905 2.13243786] , error: 0.4737442950245755\n",
      "Step: 5483 Weights: [0.3560094  2.13243782] , error: 0.4737442950118778\n",
      "Step: 5484 Weights: [0.35600976 2.13243777] , error: 0.4737442949992388\n",
      "Step: 5485 Weights: [0.35601011 2.13243773] , error: 0.4737442949866571\n",
      "Step: 5486 Weights: [0.35601046 2.13243769] , error: 0.47374429497413284\n",
      "Step: 5487 Weights: [0.35601081 2.13243765] , error: 0.4737442949616657\n",
      "Step: 5488 Weights: [0.35601116 2.13243761] , error: 0.4737442949492551\n",
      "Step: 5489 Weights: [0.35601151 2.13243757] , error: 0.4737442949369008\n",
      "Step: 5490 Weights: [0.35601186 2.13243753] , error: 0.47374429492460257\n",
      "Step: 5491 Weights: [0.35601221 2.13243749] , error: 0.4737442949123614\n",
      "Step: 5492 Weights: [0.35601256 2.13243745] , error: 0.4737442949001772\n",
      "Step: 5493 Weights: [0.3560129  2.13243742] , error: 0.4737442948880451\n",
      "Step: 5494 Weights: [0.35601325 2.13243738] , error: 0.47374429487597036\n",
      "Step: 5495 Weights: [0.35601359 2.13243734] , error: 0.4737442948639505\n",
      "Step: 5496 Weights: [0.35601394 2.1324373 ] , error: 0.47374429485198477\n",
      "Step: 5497 Weights: [0.35601428 2.13243726] , error: 0.4737442948400732\n",
      "Step: 5498 Weights: [0.35601462 2.13243722] , error: 0.473744294828217\n",
      "Step: 5499 Weights: [0.35601496 2.13243718] , error: 0.4737442948164141\n",
      "Step: 5500 Weights: [0.3560153  2.13243714] , error: 0.4737442948046651\n",
      "Step: 5501 Weights: [0.35601564 2.1324371 ] , error: 0.47374429479297026\n",
      "Step: 5502 Weights: [0.35601598 2.13243706] , error: 0.47374429478132885\n",
      "Step: 5503 Weights: [0.35601632 2.13243702] , error: 0.4737442947697396\n",
      "Step: 5504 Weights: [0.35601666 2.13243699] , error: 0.47374429475820284\n",
      "Step: 5505 Weights: [0.356017   2.13243695] , error: 0.4737442947467196\n",
      "Step: 5506 Weights: [0.35601733 2.13243691] , error: 0.4737442947352873\n",
      "Step: 5507 Weights: [0.35601767 2.13243687] , error: 0.47374429472390844\n",
      "Step: 5508 Weights: [0.356018   2.13243683] , error: 0.47374429471258156\n",
      "Step: 5509 Weights: [0.35601834 2.13243679] , error: 0.47374429470130547\n",
      "Step: 5510 Weights: [0.35601867 2.13243676] , error: 0.47374429469008106\n",
      "Step: 5511 Weights: [0.356019   2.13243672] , error: 0.47374429467890833\n",
      "Step: 5512 Weights: [0.35601933 2.13243668] , error: 0.47374429466778517\n",
      "Step: 5513 Weights: [0.35601966 2.13243664] , error: 0.4737442946567134\n",
      "Step: 5514 Weights: [0.35601999 2.1324366 ] , error: 0.4737442946456921\n",
      "Step: 5515 Weights: [0.35602032 2.13243657] , error: 0.47374429463472145\n",
      "Step: 5516 Weights: [0.35602065 2.13243653] , error: 0.4737442946237999\n",
      "Step: 5517 Weights: [0.35602098 2.13243649] , error: 0.4737442946129283\n",
      "Step: 5518 Weights: [0.35602131 2.13243645] , error: 0.47374429460210676\n",
      "Step: 5519 Weights: [0.35602163 2.13243642] , error: 0.4737442945913342\n",
      "Step: 5520 Weights: [0.35602196 2.13243638] , error: 0.47374429458061046\n",
      "Step: 5521 Weights: [0.35602228 2.13243634] , error: 0.4737442945699361\n",
      "Step: 5522 Weights: [0.35602261 2.13243631] , error: 0.47374429455931016\n",
      "Step: 5523 Weights: [0.35602293 2.13243627] , error: 0.47374429454873285\n",
      "Step: 5524 Weights: [0.35602325 2.13243623] , error: 0.47374429453820277\n",
      "Step: 5525 Weights: [0.35602357 2.13243619] , error: 0.47374429452772204\n",
      "Step: 5526 Weights: [0.3560239  2.13243616] , error: 0.4737442945172884\n",
      "Step: 5527 Weights: [0.35602422 2.13243612] , error: 0.4737442945069024\n",
      "Step: 5528 Weights: [0.35602454 2.13243608] , error: 0.4737442944965629\n",
      "Step: 5529 Weights: [0.35602485 2.13243605] , error: 0.47374429448627114\n",
      "Step: 5530 Weights: [0.35602517 2.13243601] , error: 0.47374429447602734\n",
      "Step: 5531 Weights: [0.35602549 2.13243598] , error: 0.47374429446582933\n",
      "Step: 5532 Weights: [0.35602581 2.13243594] , error: 0.47374429445567756\n",
      "Step: 5533 Weights: [0.35602612 2.1324359 ] , error: 0.4737442944455714\n",
      "Step: 5534 Weights: [0.35602644 2.13243587] , error: 0.4737442944355123\n",
      "Step: 5535 Weights: [0.35602675 2.13243583] , error: 0.4737442944254983\n",
      "Step: 5536 Weights: [0.35602707 2.1324358 ] , error: 0.47374429441553\n",
      "Step: 5537 Weights: [0.35602738 2.13243576] , error: 0.47374429440560734\n",
      "Step: 5538 Weights: [0.35602769 2.13243572] , error: 0.4737442943957304\n",
      "Step: 5539 Weights: [0.356028   2.13243569] , error: 0.47374429438589816\n",
      "Step: 5540 Weights: [0.35602831 2.13243565] , error: 0.47374429437611065\n",
      "Step: 5541 Weights: [0.35602863 2.13243562] , error: 0.4737442943663676\n",
      "Step: 5542 Weights: [0.35602893 2.13243558] , error: 0.47374429435666904\n",
      "Step: 5543 Weights: [0.35602924 2.13243555] , error: 0.47374429434701393\n",
      "Step: 5544 Weights: [0.35602955 2.13243551] , error: 0.4737442943374039\n",
      "Step: 5545 Weights: [0.35602986 2.13243548] , error: 0.4737442943278381\n",
      "Step: 5546 Weights: [0.35603017 2.13243544] , error: 0.47374429431831433\n",
      "Step: 5547 Weights: [0.35603047 2.13243541] , error: 0.47374429430883436\n",
      "Step: 5548 Weights: [0.35603078 2.13243537] , error: 0.47374429429939874\n",
      "Step: 5549 Weights: [0.35603108 2.13243534] , error: 0.4737442942900052\n",
      "Step: 5550 Weights: [0.35603139 2.1324353 ] , error: 0.4737442942806539\n",
      "Step: 5551 Weights: [0.35603169 2.13243527] , error: 0.4737442942713465\n",
      "Step: 5552 Weights: [0.35603199 2.13243523] , error: 0.47374429426208053\n",
      "Step: 5553 Weights: [0.35603229 2.1324352 ] , error: 0.4737442942528566\n",
      "Step: 5554 Weights: [0.3560326  2.13243516] , error: 0.4737442942436746\n",
      "Step: 5555 Weights: [0.3560329  2.13243513] , error: 0.47374429423453507\n",
      "Step: 5556 Weights: [0.3560332  2.13243509] , error: 0.47374429422543707\n",
      "Step: 5557 Weights: [0.35603349 2.13243506] , error: 0.47374429421638087\n",
      "Step: 5558 Weights: [0.35603379 2.13243503] , error: 0.4737442942073663\n",
      "Step: 5559 Weights: [0.35603409 2.13243499] , error: 0.4737442941983915\n",
      "Step: 5560 Weights: [0.35603439 2.13243496] , error: 0.47374429418945796\n",
      "Step: 5561 Weights: [0.35603468 2.13243492] , error: 0.4737442941805656\n",
      "Step: 5562 Weights: [0.35603498 2.13243489] , error: 0.4737442941717134\n",
      "Step: 5563 Weights: [0.35603528 2.13243486] , error: 0.4737442941629013\n",
      "Step: 5564 Weights: [0.35603557 2.13243482] , error: 0.4737442941541295\n",
      "Step: 5565 Weights: [0.35603586 2.13243479] , error: 0.473744294145398\n",
      "Step: 5566 Weights: [0.35603616 2.13243476] , error: 0.4737442941367066\n",
      "Step: 5567 Weights: [0.35603645 2.13243472] , error: 0.47374429412805436\n",
      "Step: 5568 Weights: [0.35603674 2.13243469] , error: 0.4737442941194409\n",
      "Step: 5569 Weights: [0.35603703 2.13243466] , error: 0.4737442941108678\n",
      "Step: 5570 Weights: [0.35603732 2.13243462] , error: 0.47374429410233243\n",
      "Step: 5571 Weights: [0.35603761 2.13243459] , error: 0.47374429409383656\n",
      "Step: 5572 Weights: [0.3560379  2.13243456] , error: 0.47374429408537977\n",
      "Step: 5573 Weights: [0.35603819 2.13243452] , error: 0.4737442940769611\n",
      "Step: 5574 Weights: [0.35603848 2.13243449] , error: 0.4737442940685814\n",
      "Step: 5575 Weights: [0.35603876 2.13243446] , error: 0.47374429406023844\n",
      "Step: 5576 Weights: [0.35603905 2.13243442] , error: 0.47374429405193574\n",
      "Step: 5577 Weights: [0.35603934 2.13243439] , error: 0.47374429404366886\n",
      "Step: 5578 Weights: [0.35603962 2.13243436] , error: 0.47374429403544105\n",
      "Step: 5579 Weights: [0.35603991 2.13243433] , error: 0.47374429402724927\n",
      "Step: 5580 Weights: [0.35604019 2.13243429] , error: 0.4737442940190956\n",
      "Step: 5581 Weights: [0.35604047 2.13243426] , error: 0.47374429401097906\n",
      "Step: 5582 Weights: [0.35604076 2.13243423] , error: 0.4737442940029001\n",
      "Step: 5583 Weights: [0.35604104 2.1324342 ] , error: 0.47374429399485674\n",
      "Step: 5584 Weights: [0.35604132 2.13243417] , error: 0.4737442939868507\n",
      "Step: 5585 Weights: [0.3560416  2.13243413] , error: 0.4737442939788813\n",
      "Step: 5586 Weights: [0.35604188 2.1324341 ] , error: 0.47374429397094814\n",
      "Step: 5587 Weights: [0.35604216 2.13243407] , error: 0.47374429396305084\n",
      "Step: 5588 Weights: [0.35604244 2.13243404] , error: 0.47374429395519047\n",
      "Step: 5589 Weights: [0.35604272 2.13243401] , error: 0.4737442939473636\n",
      "Step: 5590 Weights: [0.35604299 2.13243397] , error: 0.4737442939395737\n",
      "Step: 5591 Weights: [0.35604327 2.13243394] , error: 0.4737442939318201\n",
      "Step: 5592 Weights: [0.35604355 2.13243391] , error: 0.473744293924101\n",
      "Step: 5593 Weights: [0.35604382 2.13243388] , error: 0.4737442939164168\n",
      "Step: 5594 Weights: [0.3560441  2.13243385] , error: 0.47374429390876815\n",
      "Step: 5595 Weights: [0.35604437 2.13243382] , error: 0.47374429390115436\n",
      "Step: 5596 Weights: [0.35604465 2.13243379] , error: 0.473744293893575\n",
      "Step: 5597 Weights: [0.35604492 2.13243375] , error: 0.4737442938860307\n",
      "Step: 5598 Weights: [0.35604519 2.13243372] , error: 0.47374429387852035\n",
      "Step: 5599 Weights: [0.35604546 2.13243369] , error: 0.473744293871044\n",
      "Step: 5600 Weights: [0.35604573 2.13243366] , error: 0.4737442938636015\n",
      "Step: 5601 Weights: [0.356046   2.13243363] , error: 0.47374429385619377\n",
      "Step: 5602 Weights: [0.35604627 2.1324336 ] , error: 0.47374429384881944\n",
      "Step: 5603 Weights: [0.35604654 2.13243357] , error: 0.47374429384147837\n",
      "Step: 5604 Weights: [0.35604681 2.13243354] , error: 0.4737442938341715\n",
      "Step: 5605 Weights: [0.35604708 2.13243351] , error: 0.47374429382689653\n",
      "Step: 5606 Weights: [0.35604735 2.13243348] , error: 0.4737442938196556\n",
      "Step: 5607 Weights: [0.35604761 2.13243345] , error: 0.47374429381244787\n",
      "Step: 5608 Weights: [0.35604788 2.13243342] , error: 0.47374429380527294\n",
      "Step: 5609 Weights: [0.35604815 2.13243338] , error: 0.4737442937981302\n",
      "Step: 5610 Weights: [0.35604841 2.13243335] , error: 0.47374429379102084\n",
      "Step: 5611 Weights: [0.35604868 2.13243332] , error: 0.473744293783943\n",
      "Step: 5612 Weights: [0.35604894 2.13243329] , error: 0.47374429377689803\n",
      "Step: 5613 Weights: [0.3560492  2.13243326] , error: 0.4737442937698844\n",
      "Step: 5614 Weights: [0.35604947 2.13243323] , error: 0.4737442937629032\n",
      "Step: 5615 Weights: [0.35604973 2.1324332 ] , error: 0.47374429375595445\n",
      "Step: 5616 Weights: [0.35604999 2.13243317] , error: 0.473744293749036\n",
      "Step: 5617 Weights: [0.35605025 2.13243314] , error: 0.4737442937421493\n",
      "Step: 5618 Weights: [0.35605051 2.13243311] , error: 0.47374429373529536\n",
      "Step: 5619 Weights: [0.35605077 2.13243308] , error: 0.4737442937284705\n",
      "Step: 5620 Weights: [0.35605103 2.13243305] , error: 0.473744293721679\n",
      "Step: 5621 Weights: [0.35605129 2.13243303] , error: 0.4737442937149164\n",
      "Step: 5622 Weights: [0.35605155 2.132433  ] , error: 0.47374429370818605\n",
      "Step: 5623 Weights: [0.3560518  2.13243297] , error: 0.4737442937014854\n",
      "Step: 5624 Weights: [0.35605206 2.13243294] , error: 0.4737442936948166\n",
      "Step: 5625 Weights: [0.35605232 2.13243291] , error: 0.47374429368817705\n",
      "Step: 5626 Weights: [0.35605257 2.13243288] , error: 0.47374429368156795\n",
      "Step: 5627 Weights: [0.35605283 2.13243285] , error: 0.4737442936749893\n",
      "Step: 5628 Weights: [0.35605308 2.13243282] , error: 0.47374429366844006\n",
      "Step: 5629 Weights: [0.35605333 2.13243279] , error: 0.4737442936619211\n",
      "Step: 5630 Weights: [0.35605359 2.13243276] , error: 0.47374429365543186\n",
      "Step: 5631 Weights: [0.35605384 2.13243273] , error: 0.4737442936489715\n",
      "Step: 5632 Weights: [0.35605409 2.1324327 ] , error: 0.4737442936425416\n",
      "Step: 5633 Weights: [0.35605434 2.13243268] , error: 0.4737442936361407\n",
      "Step: 5634 Weights: [0.3560546  2.13243265] , error: 0.4737442936297687\n",
      "Step: 5635 Weights: [0.35605485 2.13243262] , error: 0.47374429362342585\n",
      "Step: 5636 Weights: [0.3560551  2.13243259] , error: 0.47374429361711107\n",
      "Step: 5637 Weights: [0.35605534 2.13243256] , error: 0.4737442936108265\n",
      "Step: 5638 Weights: [0.35605559 2.13243253] , error: 0.47374429360457004\n",
      "Step: 5639 Weights: [0.35605584 2.1324325 ] , error: 0.4737442935983411\n",
      "Step: 5640 Weights: [0.35605609 2.13243248] , error: 0.4737442935921413\n",
      "Step: 5641 Weights: [0.35605634 2.13243245] , error: 0.47374429358596953\n",
      "Step: 5642 Weights: [0.35605658 2.13243242] , error: 0.47374429357982717\n",
      "Step: 5643 Weights: [0.35605683 2.13243239] , error: 0.47374429357371145\n",
      "Step: 5644 Weights: [0.35605707 2.13243236] , error: 0.4737442935676237\n",
      "Step: 5645 Weights: [0.35605732 2.13243234] , error: 0.47374429356156394\n",
      "Step: 5646 Weights: [0.35605756 2.13243231] , error: 0.47374429355553177\n",
      "Step: 5647 Weights: [0.35605781 2.13243228] , error: 0.47374429354952713\n",
      "Step: 5648 Weights: [0.35605805 2.13243225] , error: 0.4737442935435499\n",
      "Step: 5649 Weights: [0.35605829 2.13243222] , error: 0.4737442935375995\n",
      "Step: 5650 Weights: [0.35605853 2.1324322 ] , error: 0.47374429353167674\n",
      "Step: 5651 Weights: [0.35605877 2.13243217] , error: 0.4737442935257804\n",
      "Step: 5652 Weights: [0.35605902 2.13243214] , error: 0.4737442935199119\n",
      "Step: 5653 Weights: [0.35605926 2.13243211] , error: 0.4737442935140695\n",
      "Step: 5654 Weights: [0.3560595  2.13243209] , error: 0.4737442935082529\n",
      "Step: 5655 Weights: [0.35605973 2.13243206] , error: 0.4737442935024637\n",
      "Step: 5656 Weights: [0.35605997 2.13243203] , error: 0.47374429349670055\n",
      "Step: 5657 Weights: [0.35606021 2.132432  ] , error: 0.4737442934909639\n",
      "Step: 5658 Weights: [0.35606045 2.13243198] , error: 0.47374429348525376\n",
      "Step: 5659 Weights: [0.35606069 2.13243195] , error: 0.47374429347956937\n",
      "Step: 5660 Weights: [0.35606092 2.13243192] , error: 0.4737442934739103\n",
      "Step: 5661 Weights: [0.35606116 2.1324319 ] , error: 0.47374429346827773\n",
      "Step: 5662 Weights: [0.35606139 2.13243187] , error: 0.47374429346267\n",
      "Step: 5663 Weights: [0.35606163 2.13243184] , error: 0.4737442934570887\n",
      "Step: 5664 Weights: [0.35606186 2.13243182] , error: 0.4737442934515324\n",
      "Step: 5665 Weights: [0.3560621  2.13243179] , error: 0.4737442934460014\n",
      "Step: 5666 Weights: [0.35606233 2.13243176] , error: 0.4737442934404952\n",
      "Step: 5667 Weights: [0.35606256 2.13243174] , error: 0.47374429343501484\n",
      "Step: 5668 Weights: [0.35606279 2.13243171] , error: 0.47374429342955904\n",
      "Step: 5669 Weights: [0.35606303 2.13243168] , error: 0.4737442934241279\n",
      "Step: 5670 Weights: [0.35606326 2.13243166] , error: 0.47374429341872165\n",
      "Step: 5671 Weights: [0.35606349 2.13243163] , error: 0.473744293413341\n",
      "Step: 5672 Weights: [0.35606372 2.1324316 ] , error: 0.4737442934079841\n",
      "Step: 5673 Weights: [0.35606395 2.13243158] , error: 0.47374429340265095\n",
      "Step: 5674 Weights: [0.35606418 2.13243155] , error: 0.473744293397343\n",
      "Step: 5675 Weights: [0.35606441 2.13243153] , error: 0.47374429339205915\n",
      "Step: 5676 Weights: [0.35606463 2.1324315 ] , error: 0.47374429338679913\n",
      "Step: 5677 Weights: [0.35606486 2.13243147] , error: 0.4737442933815634\n",
      "Step: 5678 Weights: [0.35606509 2.13243145] , error: 0.4737442933763505\n",
      "Step: 5679 Weights: [0.35606531 2.13243142] , error: 0.47374429337116175\n",
      "Step: 5680 Weights: [0.35606554 2.1324314 ] , error: 0.4737442933659974\n",
      "Step: 5681 Weights: [0.35606577 2.13243137] , error: 0.4737442933608557\n",
      "Step: 5682 Weights: [0.35606599 2.13243134] , error: 0.47374429335573787\n",
      "Step: 5683 Weights: [0.35606621 2.13243132] , error: 0.47374429335064405\n",
      "Step: 5684 Weights: [0.35606644 2.13243129] , error: 0.4737442933455723\n",
      "Step: 5685 Weights: [0.35606666 2.13243127] , error: 0.4737442933405245\n",
      "Step: 5686 Weights: [0.35606688 2.13243124] , error: 0.47374429333549856\n",
      "Step: 5687 Weights: [0.35606711 2.13243122] , error: 0.4737442933304973\n",
      "Step: 5688 Weights: [0.35606733 2.13243119] , error: 0.47374429332551704\n",
      "Step: 5689 Weights: [0.35606755 2.13243117] , error: 0.47374429332056034\n",
      "Step: 5690 Weights: [0.35606777 2.13243114] , error: 0.4737442933156256\n",
      "Step: 5691 Weights: [0.35606799 2.13243112] , error: 0.47374429331071427\n",
      "Step: 5692 Weights: [0.35606821 2.13243109] , error: 0.47374429330582485\n",
      "Step: 5693 Weights: [0.35606843 2.13243106] , error: 0.47374429330095724\n",
      "Step: 5694 Weights: [0.35606865 2.13243104] , error: 0.4737442932961124\n",
      "Step: 5695 Weights: [0.35606887 2.13243101] , error: 0.47374429329128964\n",
      "Step: 5696 Weights: [0.35606909 2.13243099] , error: 0.47374429328648887\n",
      "Step: 5697 Weights: [0.3560693  2.13243097] , error: 0.4737442932817102\n",
      "Step: 5698 Weights: [0.35606952 2.13243094] , error: 0.47374429327695267\n",
      "Step: 5699 Weights: [0.35606974 2.13243092] , error: 0.4737442932722167\n",
      "Step: 5700 Weights: [0.35606995 2.13243089] , error: 0.47374429326750245\n",
      "Step: 5701 Weights: [0.35607017 2.13243087] , error: 0.47374429326281026\n",
      "Step: 5702 Weights: [0.35607038 2.13243084] , error: 0.4737442932581385\n",
      "Step: 5703 Weights: [0.3560706  2.13243082] , error: 0.4737442932534894\n",
      "Step: 5704 Weights: [0.35607081 2.13243079] , error: 0.4737442932488608\n",
      "Step: 5705 Weights: [0.35607102 2.13243077] , error: 0.4737442932442528\n",
      "Step: 5706 Weights: [0.35607124 2.13243074] , error: 0.4737442932396662\n",
      "Step: 5707 Weights: [0.35607145 2.13243072] , error: 0.4737442932351005\n",
      "Step: 5708 Weights: [0.35607166 2.1324307 ] , error: 0.4737442932305549\n",
      "Step: 5709 Weights: [0.35607187 2.13243067] , error: 0.4737442932260311\n",
      "Step: 5710 Weights: [0.35607208 2.13243065] , error: 0.4737442932215276\n",
      "Step: 5711 Weights: [0.35607229 2.13243062] , error: 0.4737442932170444\n",
      "Step: 5712 Weights: [0.3560725 2.1324306] , error: 0.4737442932125817\n",
      "Step: 5713 Weights: [0.35607271 2.13243058] , error: 0.47374429320813916\n",
      "Step: 5714 Weights: [0.35607292 2.13243055] , error: 0.4737442932037177\n",
      "Step: 5715 Weights: [0.35607313 2.13243053] , error: 0.4737442931993154\n",
      "Step: 5716 Weights: [0.35607334 2.1324305 ] , error: 0.4737442931949335\n",
      "Step: 5717 Weights: [0.35607355 2.13243048] , error: 0.4737442931905708\n",
      "Step: 5718 Weights: [0.35607375 2.13243046] , error: 0.4737442931862296\n",
      "Step: 5719 Weights: [0.35607396 2.13243043] , error: 0.47374429318190686\n",
      "Step: 5720 Weights: [0.35607417 2.13243041] , error: 0.47374429317760364\n",
      "Step: 5721 Weights: [0.35607437 2.13243039] , error: 0.47374429317332095\n",
      "Step: 5722 Weights: [0.35607458 2.13243036] , error: 0.4737442931690574\n",
      "Step: 5723 Weights: [0.35607478 2.13243034] , error: 0.4737442931648136\n",
      "Step: 5724 Weights: [0.35607499 2.13243032] , error: 0.47374429316058897\n",
      "Step: 5725 Weights: [0.35607519 2.13243029] , error: 0.4737442931563831\n",
      "Step: 5726 Weights: [0.35607539 2.13243027] , error: 0.47374429315219657\n",
      "Step: 5727 Weights: [0.3560756  2.13243025] , error: 0.47374429314802957\n",
      "Step: 5728 Weights: [0.3560758  2.13243022] , error: 0.4737442931438812\n",
      "Step: 5729 Weights: [0.356076  2.1324302] , error: 0.47374429313975197\n",
      "Step: 5730 Weights: [0.3560762  2.13243018] , error: 0.4737442931356417\n",
      "Step: 5731 Weights: [0.3560764  2.13243015] , error: 0.4737442931315494\n",
      "Step: 5732 Weights: [0.3560766  2.13243013] , error: 0.47374429312747646\n",
      "Step: 5733 Weights: [0.3560768  2.13243011] , error: 0.47374429312342137\n",
      "Step: 5734 Weights: [0.356077   2.13243008] , error: 0.4737442931193854\n",
      "Step: 5735 Weights: [0.3560772  2.13243006] , error: 0.47374429311536725\n",
      "Step: 5736 Weights: [0.3560774  2.13243004] , error: 0.473744293111368\n",
      "Step: 5737 Weights: [0.3560776  2.13243002] , error: 0.47374429310738686\n",
      "Step: 5738 Weights: [0.3560778  2.13242999] , error: 0.4737442931034236\n",
      "Step: 5739 Weights: [0.356078   2.13242997] , error: 0.47374429309947885\n",
      "Step: 5740 Weights: [0.35607819 2.13242995] , error: 0.473744293095551\n",
      "Step: 5741 Weights: [0.35607839 2.13242993] , error: 0.47374429309164173\n",
      "Step: 5742 Weights: [0.35607859 2.1324299 ] , error: 0.4737442930877508\n",
      "Step: 5743 Weights: [0.35607878 2.13242988] , error: 0.4737442930838765\n",
      "Step: 5744 Weights: [0.35607898 2.13242986] , error: 0.4737442930800214\n",
      "Step: 5745 Weights: [0.35607917 2.13242984] , error: 0.47374429307618227\n",
      "Step: 5746 Weights: [0.35607937 2.13242981] , error: 0.47374429307236154\n",
      "Step: 5747 Weights: [0.35607956 2.13242979] , error: 0.47374429306855814\n",
      "Step: 5748 Weights: [0.35607975 2.13242977] , error: 0.47374429306477217\n",
      "Step: 5749 Weights: [0.35607995 2.13242975] , error: 0.4737442930610026\n",
      "Step: 5750 Weights: [0.35608014 2.13242973] , error: 0.4737442930572509\n",
      "Step: 5751 Weights: [0.35608033 2.1324297 ] , error: 0.47374429305351573\n",
      "Step: 5752 Weights: [0.35608052 2.13242968] , error: 0.4737442930497982\n",
      "Step: 5753 Weights: [0.35608071 2.13242966] , error: 0.4737442930460976\n",
      "Step: 5754 Weights: [0.3560809  2.13242964] , error: 0.4737442930424133\n",
      "Step: 5755 Weights: [0.3560811  2.13242962] , error: 0.473744293038747\n",
      "Step: 5756 Weights: [0.35608129 2.13242959] , error: 0.4737442930350957\n",
      "Step: 5757 Weights: [0.35608147 2.13242957] , error: 0.4737442930314627\n",
      "Step: 5758 Weights: [0.35608166 2.13242955] , error: 0.4737442930278453\n",
      "Step: 5759 Weights: [0.35608185 2.13242953] , error: 0.47374429302424415\n",
      "Step: 5760 Weights: [0.35608204 2.13242951] , error: 0.47374429302065946\n",
      "Step: 5761 Weights: [0.35608223 2.13242949] , error: 0.4737442930170918\n",
      "Step: 5762 Weights: [0.35608242 2.13242947] , error: 0.47374429301353965\n",
      "Step: 5763 Weights: [0.3560826  2.13242944] , error: 0.47374429301000387\n",
      "Step: 5764 Weights: [0.35608279 2.13242942] , error: 0.4737442930064844\n",
      "Step: 5765 Weights: [0.35608298 2.1324294 ] , error: 0.47374429300298154\n",
      "Step: 5766 Weights: [0.35608316 2.13242938] , error: 0.4737442929994935\n",
      "Step: 5767 Weights: [0.35608335 2.13242936] , error: 0.473744292996023\n",
      "Step: 5768 Weights: [0.35608353 2.13242934] , error: 0.47374429299256676\n",
      "Step: 5769 Weights: [0.35608372 2.13242932] , error: 0.4737442929891263\n",
      "Step: 5770 Weights: [0.3560839 2.1324293] , error: 0.4737442929857019\n",
      "Step: 5771 Weights: [0.35608408 2.13242927] , error: 0.47374429298229304\n",
      "Step: 5772 Weights: [0.35608427 2.13242925] , error: 0.4737442929789003\n",
      "Step: 5773 Weights: [0.35608445 2.13242923] , error: 0.47374429297552245\n",
      "Step: 5774 Weights: [0.35608463 2.13242921] , error: 0.47374429297216003\n",
      "Step: 5775 Weights: [0.35608481 2.13242919] , error: 0.4737442929688127\n",
      "Step: 5776 Weights: [0.35608499 2.13242917] , error: 0.4737442929654806\n",
      "Step: 5777 Weights: [0.35608518 2.13242915] , error: 0.4737442929621646\n",
      "Step: 5778 Weights: [0.35608536 2.13242913] , error: 0.47374429295886317\n",
      "Step: 5779 Weights: [0.35608554 2.13242911] , error: 0.4737442929555759\n",
      "Step: 5780 Weights: [0.35608572 2.13242909] , error: 0.4737442929523045\n",
      "Step: 5781 Weights: [0.3560859  2.13242907] , error: 0.47374429294904746\n",
      "Step: 5782 Weights: [0.35608607 2.13242905] , error: 0.4737442929458067\n",
      "Step: 5783 Weights: [0.35608625 2.13242903] , error: 0.4737442929425788\n",
      "Step: 5784 Weights: [0.35608643 2.13242901] , error: 0.4737442929393668\n",
      "Step: 5785 Weights: [0.35608661 2.13242899] , error: 0.473744292936169\n",
      "Step: 5786 Weights: [0.35608679 2.13242897] , error: 0.4737442929329864\n",
      "Step: 5787 Weights: [0.35608696 2.13242895] , error: 0.47374429292981773\n",
      "Step: 5788 Weights: [0.35608714 2.13242893] , error: 0.47374429292666276\n",
      "Step: 5789 Weights: [0.35608732 2.13242891] , error: 0.47374429292352355\n",
      "Step: 5790 Weights: [0.35608749 2.13242889] , error: 0.47374429292039794\n",
      "Step: 5791 Weights: [0.35608767 2.13242886] , error: 0.4737442929172865\n",
      "Step: 5792 Weights: [0.35608784 2.13242884] , error: 0.47374429291418924\n",
      "Step: 5793 Weights: [0.35608802 2.13242883] , error: 0.47374429291110637\n",
      "Step: 5794 Weights: [0.35608819 2.13242881] , error: 0.4737442929080369\n",
      "Step: 5795 Weights: [0.35608836 2.13242879] , error: 0.4737442929049822\n",
      "Step: 5796 Weights: [0.35608854 2.13242877] , error: 0.4737442929019407\n",
      "Step: 5797 Weights: [0.35608871 2.13242875] , error: 0.4737442928989139\n",
      "Step: 5798 Weights: [0.35608888 2.13242873] , error: 0.4737442928959002\n",
      "Step: 5799 Weights: [0.35608906 2.13242871] , error: 0.47374429289290065\n",
      "Step: 5800 Weights: [0.35608923 2.13242869] , error: 0.47374429288991476\n",
      "Step: 5801 Weights: [0.3560894  2.13242867] , error: 0.4737442928869423\n",
      "Step: 5802 Weights: [0.35608957 2.13242865] , error: 0.47374429288398334\n",
      "Step: 5803 Weights: [0.35608974 2.13242863] , error: 0.4737442928810377\n",
      "Step: 5804 Weights: [0.35608991 2.13242861] , error: 0.47374429287810604\n",
      "Step: 5805 Weights: [0.35609008 2.13242859] , error: 0.47374429287518754\n",
      "Step: 5806 Weights: [0.35609025 2.13242857] , error: 0.4737442928722825\n",
      "Step: 5807 Weights: [0.35609042 2.13242855] , error: 0.4737442928693902\n",
      "Step: 5808 Weights: [0.35609059 2.13242853] , error: 0.473744292866511\n",
      "Step: 5809 Weights: [0.35609076 2.13242851] , error: 0.47374429286364544\n",
      "Step: 5810 Weights: [0.35609092 2.13242849] , error: 0.47374429286079284\n",
      "Step: 5811 Weights: [0.35609109 2.13242847] , error: 0.4737442928579525\n",
      "Step: 5812 Weights: [0.35609126 2.13242845] , error: 0.4737442928551257\n",
      "Step: 5813 Weights: [0.35609142 2.13242844] , error: 0.47374429285231245\n",
      "Step: 5814 Weights: [0.35609159 2.13242842] , error: 0.47374429284951136\n",
      "Step: 5815 Weights: [0.35609176 2.1324284 ] , error: 0.47374429284672287\n",
      "Step: 5816 Weights: [0.35609192 2.13242838] , error: 0.47374429284394737\n",
      "Step: 5817 Weights: [0.35609209 2.13242836] , error: 0.4737442928411838\n",
      "Step: 5818 Weights: [0.35609225 2.13242834] , error: 0.47374429283843317\n",
      "Step: 5819 Weights: [0.35609242 2.13242832] , error: 0.47374429283569564\n",
      "Step: 5820 Weights: [0.35609258 2.1324283 ] , error: 0.47374429283297104\n",
      "Step: 5821 Weights: [0.35609275 2.13242828] , error: 0.4737442928302576\n",
      "Step: 5822 Weights: [0.35609291 2.13242827] , error: 0.4737442928275569\n",
      "Step: 5823 Weights: [0.35609307 2.13242825] , error: 0.4737442928248681\n",
      "Step: 5824 Weights: [0.35609323 2.13242823] , error: 0.473744292822192\n",
      "Step: 5825 Weights: [0.3560934  2.13242821] , error: 0.4737442928195289\n",
      "Step: 5826 Weights: [0.35609356 2.13242819] , error: 0.4737442928168763\n",
      "Step: 5827 Weights: [0.35609372 2.13242817] , error: 0.4737442928142368\n",
      "Step: 5828 Weights: [0.35609388 2.13242815] , error: 0.4737442928116096\n",
      "Step: 5829 Weights: [0.35609404 2.13242814] , error: 0.47374429280899366\n",
      "Step: 5830 Weights: [0.3560942  2.13242812] , error: 0.4737442928063903\n",
      "Step: 5831 Weights: [0.35609436 2.1324281 ] , error: 0.4737442928037978\n",
      "Step: 5832 Weights: [0.35609452 2.13242808] , error: 0.47374429280121705\n",
      "Step: 5833 Weights: [0.35609468 2.13242806] , error: 0.47374429279864916\n",
      "Step: 5834 Weights: [0.35609484 2.13242804] , error: 0.4737442927960924\n",
      "Step: 5835 Weights: [0.356095   2.13242803] , error: 0.47374429279354724\n",
      "Step: 5836 Weights: [0.35609516 2.13242801] , error: 0.4737442927910146\n",
      "Step: 5837 Weights: [0.35609531 2.13242799] , error: 0.4737442927884928\n",
      "Step: 5838 Weights: [0.35609547 2.13242797] , error: 0.47374429278598224\n",
      "Step: 5839 Weights: [0.35609563 2.13242795] , error: 0.4737442927834834\n",
      "Step: 5840 Weights: [0.35609579 2.13242794] , error: 0.4737442927809956\n",
      "Step: 5841 Weights: [0.35609594 2.13242792] , error: 0.4737442927785197\n",
      "Step: 5842 Weights: [0.3560961 2.1324279] , error: 0.47374429277605457\n",
      "Step: 5843 Weights: [0.35609625 2.13242788] , error: 0.473744292773601\n",
      "Step: 5844 Weights: [0.35609641 2.13242787] , error: 0.47374429277115804\n",
      "Step: 5845 Weights: [0.35609656 2.13242785] , error: 0.47374429276872615\n",
      "Step: 5846 Weights: [0.35609672 2.13242783] , error: 0.4737442927663064\n",
      "Step: 5847 Weights: [0.35609687 2.13242781] , error: 0.47374429276389785\n",
      "Step: 5848 Weights: [0.35609703 2.13242779] , error: 0.4737442927614994\n",
      "Step: 5849 Weights: [0.35609718 2.13242778] , error: 0.4737442927591113\n",
      "Step: 5850 Weights: [0.35609733 2.13242776] , error: 0.4737442927567347\n",
      "Step: 5851 Weights: [0.35609749 2.13242774] , error: 0.47374429275436947\n",
      "Step: 5852 Weights: [0.35609764 2.13242772] , error: 0.4737442927520138\n",
      "Step: 5853 Weights: [0.35609779 2.13242771] , error: 0.4737442927496706\n",
      "Step: 5854 Weights: [0.35609794 2.13242769] , error: 0.4737442927473368\n",
      "Step: 5855 Weights: [0.3560981  2.13242767] , error: 0.4737442927450135\n",
      "Step: 5856 Weights: [0.35609825 2.13242766] , error: 0.473744292742702\n",
      "Step: 5857 Weights: [0.3560984  2.13242764] , error: 0.4737442927403997\n",
      "Step: 5858 Weights: [0.35609855 2.13242762] , error: 0.4737442927381088\n",
      "Step: 5859 Weights: [0.3560987 2.1324276] , error: 0.4737442927358275\n",
      "Step: 5860 Weights: [0.35609885 2.13242759] , error: 0.473744292733557\n",
      "Step: 5861 Weights: [0.356099   2.13242757] , error: 0.4737442927312969\n",
      "Step: 5862 Weights: [0.35609915 2.13242755] , error: 0.4737442927290469\n",
      "Step: 5863 Weights: [0.3560993  2.13242754] , error: 0.4737442927268069\n",
      "Step: 5864 Weights: [0.35609944 2.13242752] , error: 0.47374429272457835\n",
      "Step: 5865 Weights: [0.35609959 2.1324275 ] , error: 0.4737442927223605\n",
      "Step: 5866 Weights: [0.35609974 2.13242748] , error: 0.47374429272014995\n",
      "Step: 5867 Weights: [0.35609989 2.13242747] , error: 0.4737442927179511\n",
      "Step: 5868 Weights: [0.35610003 2.13242745] , error: 0.47374429271576146\n",
      "Step: 5869 Weights: [0.35610018 2.13242743] , error: 0.47374429271358215\n",
      "Step: 5870 Weights: [0.35610033 2.13242742] , error: 0.4737442927114138\n",
      "Step: 5871 Weights: [0.35610047 2.1324274 ] , error: 0.4737442927092541\n",
      "Step: 5872 Weights: [0.35610062 2.13242738] , error: 0.4737442927071052\n",
      "Step: 5873 Weights: [0.35610076 2.13242737] , error: 0.4737442927049656\n",
      "Step: 5874 Weights: [0.35610091 2.13242735] , error: 0.47374429270283547\n",
      "Step: 5875 Weights: [0.35610105 2.13242733] , error: 0.4737442927007152\n",
      "Step: 5876 Weights: [0.3561012  2.13242732] , error: 0.47374429269860474\n",
      "Step: 5877 Weights: [0.35610134 2.1324273 ] , error: 0.4737442926965038\n",
      "Step: 5878 Weights: [0.35610149 2.13242728] , error: 0.4737442926944124\n",
      "Step: 5879 Weights: [0.35610163 2.13242727] , error: 0.47374429269233126\n",
      "Step: 5880 Weights: [0.35610177 2.13242725] , error: 0.4737442926902587\n",
      "Step: 5881 Weights: [0.35610192 2.13242724] , error: 0.4737442926881953\n",
      "Step: 5882 Weights: [0.35610206 2.13242722] , error: 0.47374429268614215\n",
      "Step: 5883 Weights: [0.3561022 2.1324272] , error: 0.47374429268409785\n",
      "Step: 5884 Weights: [0.35610234 2.13242719] , error: 0.47374429268206275\n",
      "Step: 5885 Weights: [0.35610248 2.13242717] , error: 0.47374429268003754\n",
      "Step: 5886 Weights: [0.35610262 2.13242715] , error: 0.4737442926780211\n",
      "Step: 5887 Weights: [0.35610277 2.13242714] , error: 0.47374429267601514\n",
      "Step: 5888 Weights: [0.35610291 2.13242712] , error: 0.4737442926740149\n",
      "Step: 5889 Weights: [0.35610305 2.13242711] , error: 0.47374429267202767\n",
      "Step: 5890 Weights: [0.35610319 2.13242709] , error: 0.4737442926700479\n",
      "Step: 5891 Weights: [0.35610333 2.13242707] , error: 0.4737442926680765\n",
      "Step: 5892 Weights: [0.35610347 2.13242706] , error: 0.4737442926661152\n",
      "Step: 5893 Weights: [0.3561036  2.13242704] , error: 0.4737442926641622\n",
      "Step: 5894 Weights: [0.35610374 2.13242703] , error: 0.4737442926622182\n",
      "Step: 5895 Weights: [0.35610388 2.13242701] , error: 0.4737442926602829\n",
      "Step: 5896 Weights: [0.35610402 2.13242699] , error: 0.4737442926583568\n",
      "Step: 5897 Weights: [0.35610416 2.13242698] , error: 0.47374429265643864\n",
      "Step: 5898 Weights: [0.35610429 2.13242696] , error: 0.4737442926545303\n",
      "Step: 5899 Weights: [0.35610443 2.13242695] , error: 0.47374429265263057\n",
      "Step: 5900 Weights: [0.35610457 2.13242693] , error: 0.4737442926507393\n",
      "Step: 5901 Weights: [0.3561047  2.13242692] , error: 0.47374429264885554\n",
      "Step: 5902 Weights: [0.35610484 2.1324269 ] , error: 0.4737442926469818\n",
      "Step: 5903 Weights: [0.35610498 2.13242689] , error: 0.4737442926451164\n",
      "Step: 5904 Weights: [0.35610511 2.13242687] , error: 0.47374429264325874\n",
      "Step: 5905 Weights: [0.35610525 2.13242685] , error: 0.4737442926414104\n",
      "Step: 5906 Weights: [0.35610538 2.13242684] , error: 0.47374429263956963\n",
      "Step: 5907 Weights: [0.35610552 2.13242682] , error: 0.47374429263773854\n",
      "Step: 5908 Weights: [0.35610565 2.13242681] , error: 0.4737442926359139\n",
      "Step: 5909 Weights: [0.35610578 2.13242679] , error: 0.47374429263409923\n",
      "Step: 5910 Weights: [0.35610592 2.13242678] , error: 0.47374429263229184\n",
      "Step: 5911 Weights: [0.35610605 2.13242676] , error: 0.4737442926304929\n",
      "Step: 5912 Weights: [0.35610618 2.13242675] , error: 0.47374429262870277\n",
      "Step: 5913 Weights: [0.35610632 2.13242673] , error: 0.4737442926269202\n",
      "Step: 5914 Weights: [0.35610645 2.13242672] , error: 0.47374429262514595\n",
      "Step: 5915 Weights: [0.35610658 2.1324267 ] , error: 0.4737442926233792\n",
      "Step: 5916 Weights: [0.35610671 2.13242669] , error: 0.47374429262162154\n",
      "Step: 5917 Weights: [0.35610684 2.13242667] , error: 0.4737442926198715\n",
      "Step: 5918 Weights: [0.35610698 2.13242666] , error: 0.4737442926181289\n",
      "Step: 5919 Weights: [0.35610711 2.13242664] , error: 0.47374429261639517\n",
      "Step: 5920 Weights: [0.35610724 2.13242663] , error: 0.47374429261466855\n",
      "Step: 5921 Weights: [0.35610737 2.13242661] , error: 0.47374429261295015\n",
      "Step: 5922 Weights: [0.3561075 2.1324266] , error: 0.47374429261123924\n",
      "Step: 5923 Weights: [0.35610763 2.13242658] , error: 0.47374429260953693\n",
      "Step: 5924 Weights: [0.35610776 2.13242657] , error: 0.4737442926078418\n",
      "Step: 5925 Weights: [0.35610789 2.13242655] , error: 0.47374429260615447\n",
      "Step: 5926 Weights: [0.35610801 2.13242654] , error: 0.47374429260447415\n",
      "Step: 5927 Weights: [0.35610814 2.13242652] , error: 0.47374429260280265\n",
      "Step: 5928 Weights: [0.35610827 2.13242651] , error: 0.47374429260113765\n",
      "Step: 5929 Weights: [0.3561084  2.13242649] , error: 0.4737442925994806\n",
      "Step: 5930 Weights: [0.35610853 2.13242648] , error: 0.47374429259783163\n",
      "Step: 5931 Weights: [0.35610865 2.13242646] , error: 0.47374429259618955\n",
      "Step: 5932 Weights: [0.35610878 2.13242645] , error: 0.47374429259455575\n",
      "Step: 5933 Weights: [0.35610891 2.13242644] , error: 0.47374429259292805\n",
      "Step: 5934 Weights: [0.35610904 2.13242642] , error: 0.47374429259130885\n",
      "Step: 5935 Weights: [0.35610916 2.13242641] , error: 0.4737442925896973\n",
      "Step: 5936 Weights: [0.35610929 2.13242639] , error: 0.4737442925880925\n",
      "Step: 5937 Weights: [0.35610941 2.13242638] , error: 0.4737442925864954\n",
      "Step: 5938 Weights: [0.35610954 2.13242636] , error: 0.4737442925849049\n",
      "Step: 5939 Weights: [0.35610966 2.13242635] , error: 0.4737442925833222\n",
      "Step: 5940 Weights: [0.35610979 2.13242634] , error: 0.4737442925817467\n",
      "Step: 5941 Weights: [0.35610991 2.13242632] , error: 0.47374429258017764\n",
      "Step: 5942 Weights: [0.35611004 2.13242631] , error: 0.4737442925786165\n",
      "Step: 5943 Weights: [0.35611016 2.13242629] , error: 0.473744292577062\n",
      "Step: 5944 Weights: [0.35611028 2.13242628] , error: 0.47374429257551537\n",
      "Step: 5945 Weights: [0.35611041 2.13242626] , error: 0.4737442925739745\n",
      "Step: 5946 Weights: [0.35611053 2.13242625] , error: 0.47374429257244155\n",
      "Step: 5947 Weights: [0.35611065 2.13242624] , error: 0.4737442925709156\n",
      "Step: 5948 Weights: [0.35611078 2.13242622] , error: 0.47374429256939615\n",
      "Step: 5949 Weights: [0.3561109  2.13242621] , error: 0.47374429256788414\n",
      "Step: 5950 Weights: [0.35611102 2.13242619] , error: 0.47374429256637907\n",
      "Step: 5951 Weights: [0.35611114 2.13242618] , error: 0.47374429256487954\n",
      "Step: 5952 Weights: [0.35611126 2.13242617] , error: 0.4737442925633887\n",
      "Step: 5953 Weights: [0.35611138 2.13242615] , error: 0.47374429256190387\n",
      "Step: 5954 Weights: [0.35611151 2.13242614] , error: 0.4737442925604253\n",
      "Step: 5955 Weights: [0.35611163 2.13242612] , error: 0.4737442925589539\n",
      "Step: 5956 Weights: [0.35611175 2.13242611] , error: 0.4737442925574896\n",
      "Step: 5957 Weights: [0.35611187 2.1324261 ] , error: 0.47374429255603134\n",
      "Step: 5958 Weights: [0.35611199 2.13242608] , error: 0.4737442925545803\n",
      "Step: 5959 Weights: [0.35611211 2.13242607] , error: 0.47374429255313466\n",
      "Step: 5960 Weights: [0.35611222 2.13242606] , error: 0.4737442925516976\n",
      "Step: 5961 Weights: [0.35611234 2.13242604] , error: 0.4737442925502653\n",
      "Step: 5962 Weights: [0.35611246 2.13242603] , error: 0.4737442925488401\n",
      "Step: 5963 Weights: [0.35611258 2.13242602] , error: 0.473744292547422\n",
      "Step: 5964 Weights: [0.3561127 2.132426 ] , error: 0.47374429254600925\n",
      "Step: 5965 Weights: [0.35611282 2.13242599] , error: 0.473744292544604\n",
      "Step: 5966 Weights: [0.35611293 2.13242598] , error: 0.47374429254320427\n",
      "Step: 5967 Weights: [0.35611305 2.13242596] , error: 0.47374429254181155\n",
      "Step: 5968 Weights: [0.35611317 2.13242595] , error: 0.4737442925404248\n",
      "Step: 5969 Weights: [0.35611329 2.13242594] , error: 0.4737442925390448\n",
      "Step: 5970 Weights: [0.3561134  2.13242592] , error: 0.4737442925376713\n",
      "Step: 5971 Weights: [0.35611352 2.13242591] , error: 0.47374429253630335\n",
      "Step: 5972 Weights: [0.35611363 2.1324259 ] , error: 0.47374429253494077\n",
      "Step: 5973 Weights: [0.35611375 2.13242588] , error: 0.4737442925335859\n",
      "Step: 5974 Weights: [0.35611387 2.13242587] , error: 0.47374429253223777\n",
      "Step: 5975 Weights: [0.35611398 2.13242586] , error: 0.4737442925308944\n",
      "Step: 5976 Weights: [0.3561141  2.13242584] , error: 0.47374429252955713\n",
      "Step: 5977 Weights: [0.35611421 2.13242583] , error: 0.473744292528226\n",
      "Step: 5978 Weights: [0.35611432 2.13242582] , error: 0.47374429252690176\n",
      "Step: 5979 Weights: [0.35611444 2.1324258 ] , error: 0.4737442925255836\n",
      "Step: 5980 Weights: [0.35611455 2.13242579] , error: 0.47374429252427036\n",
      "Step: 5981 Weights: [0.35611467 2.13242578] , error: 0.4737442925229641\n",
      "Step: 5982 Weights: [0.35611478 2.13242576] , error: 0.47374429252166295\n",
      "Step: 5983 Weights: [0.35611489 2.13242575] , error: 0.47374429252036854\n",
      "Step: 5984 Weights: [0.35611501 2.13242574] , error: 0.4737442925190788\n",
      "Step: 5985 Weights: [0.35611512 2.13242573] , error: 0.4737442925177964\n",
      "Step: 5986 Weights: [0.35611523 2.13242571] , error: 0.47374429251651884\n",
      "Step: 5987 Weights: [0.35611534 2.1324257 ] , error: 0.4737442925152479\n",
      "Step: 5988 Weights: [0.35611545 2.13242569] , error: 0.4737442925139821\n",
      "Step: 5989 Weights: [0.35611557 2.13242567] , error: 0.47374429251272215\n",
      "Step: 5990 Weights: [0.35611568 2.13242566] , error: 0.47374429251146905\n",
      "Step: 5991 Weights: [0.35611579 2.13242565] , error: 0.4737442925102197\n",
      "Step: 5992 Weights: [0.3561159  2.13242564] , error: 0.473744292508977\n",
      "Step: 5993 Weights: [0.35611601 2.13242562] , error: 0.47374429250773986\n",
      "Step: 5994 Weights: [0.35611612 2.13242561] , error: 0.4737442925065093\n",
      "Step: 5995 Weights: [0.35611623 2.1324256 ] , error: 0.4737442925052836\n",
      "Step: 5996 Weights: [0.35611634 2.13242559] , error: 0.4737442925040628\n",
      "Step: 5997 Weights: [0.35611645 2.13242557] , error: 0.4737442925028489\n",
      "Step: 5998 Weights: [0.35611656 2.13242556] , error: 0.47374429250163913\n",
      "Step: 5999 Weights: [0.35611667 2.13242555] , error: 0.4737442925004358\n",
      "Step: 6000 Weights: [0.35611678 2.13242554] , error: 0.4737442924992373\n",
      "Step: 6001 Weights: [0.35611689 2.13242552] , error: 0.47374429249804517\n",
      "Step: 6002 Weights: [0.35611699 2.13242551] , error: 0.4737442924968584\n",
      "Step: 6003 Weights: [0.3561171 2.1324255] , error: 0.47374429249567607\n",
      "Step: 6004 Weights: [0.35611721 2.13242549] , error: 0.47374429249450006\n",
      "Step: 6005 Weights: [0.35611732 2.13242547] , error: 0.4737442924933287\n",
      "Step: 6006 Weights: [0.35611742 2.13242546] , error: 0.47374429249216304\n",
      "Step: 6007 Weights: [0.35611753 2.13242545] , error: 0.4737442924910022\n",
      "Step: 6008 Weights: [0.35611764 2.13242544] , error: 0.4737442924898472\n",
      "Step: 6009 Weights: [0.35611775 2.13242543] , error: 0.4737442924886972\n",
      "Step: 6010 Weights: [0.35611785 2.13242541] , error: 0.47374429248755423\n",
      "Step: 6011 Weights: [0.35611796 2.1324254 ] , error: 0.47374429248641303\n",
      "Step: 6012 Weights: [0.35611806 2.13242539] , error: 0.4737442924852792\n",
      "Step: 6013 Weights: [0.35611817 2.13242538] , error: 0.47374429248415045\n",
      "Step: 6014 Weights: [0.35611827 2.13242536] , error: 0.47374429248302674\n",
      "Step: 6015 Weights: [0.35611838 2.13242535] , error: 0.4737442924819074\n",
      "Step: 6016 Weights: [0.35611848 2.13242534] , error: 0.47374429248079364\n",
      "Step: 6017 Weights: [0.35611859 2.13242533] , error: 0.4737442924796853\n",
      "Step: 6018 Weights: [0.35611869 2.13242532] , error: 0.473744292478582\n",
      "Step: 6019 Weights: [0.3561188 2.1324253] , error: 0.4737442924774832\n",
      "Step: 6020 Weights: [0.3561189  2.13242529] , error: 0.47374429247638894\n",
      "Step: 6021 Weights: [0.35611901 2.13242528] , error: 0.47374429247530114\n",
      "Step: 6022 Weights: [0.35611911 2.13242527] , error: 0.47374429247421745\n",
      "Step: 6023 Weights: [0.35611921 2.13242526] , error: 0.4737442924731383\n",
      "Step: 6024 Weights: [0.35611932 2.13242525] , error: 0.4737442924720652\n",
      "Step: 6025 Weights: [0.35611942 2.13242523] , error: 0.47374429247099537\n",
      "Step: 6026 Weights: [0.35611952 2.13242522] , error: 0.47374429246993205\n",
      "Step: 6027 Weights: [0.35611962 2.13242521] , error: 0.4737442924688726\n",
      "Step: 6028 Weights: [0.35611973 2.1324252 ] , error: 0.473744292467819\n",
      "Step: 6029 Weights: [0.35611983 2.13242519] , error: 0.4737442924667689\n",
      "Step: 6030 Weights: [0.35611993 2.13242518] , error: 0.4737442924657242\n",
      "Step: 6031 Weights: [0.35612003 2.13242516] , error: 0.47374429246468397\n",
      "Step: 6032 Weights: [0.35612013 2.13242515] , error: 0.4737442924636497\n",
      "Step: 6033 Weights: [0.35612023 2.13242514] , error: 0.47374429246261873\n",
      "Step: 6034 Weights: [0.35612033 2.13242513] , error: 0.4737442924615921\n",
      "Step: 6035 Weights: [0.35612043 2.13242512] , error: 0.47374429246057115\n",
      "Step: 6036 Weights: [0.35612053 2.13242511] , error: 0.47374429245955574\n",
      "Step: 6037 Weights: [0.35612063 2.13242509] , error: 0.4737442924585434\n",
      "Step: 6038 Weights: [0.35612073 2.13242508] , error: 0.47374429245753547\n",
      "Step: 6039 Weights: [0.35612083 2.13242507] , error: 0.4737442924565328\n",
      "Step: 6040 Weights: [0.35612093 2.13242506] , error: 0.47374429245553584\n",
      "Step: 6041 Weights: [0.35612103 2.13242505] , error: 0.47374429245454164\n",
      "Step: 6042 Weights: [0.35612113 2.13242504] , error: 0.47374429245355276\n",
      "Step: 6043 Weights: [0.35612123 2.13242503] , error: 0.473744292452568\n",
      "Step: 6044 Weights: [0.35612133 2.13242502] , error: 0.4737442924515885\n",
      "Step: 6045 Weights: [0.35612143 2.132425  ] , error: 0.47374429245061245\n",
      "Step: 6046 Weights: [0.35612152 2.13242499] , error: 0.4737442924496419\n",
      "Step: 6047 Weights: [0.35612162 2.13242498] , error: 0.4737442924486751\n",
      "Step: 6048 Weights: [0.35612172 2.13242497] , error: 0.47374429244771193\n",
      "Step: 6049 Weights: [0.35612182 2.13242496] , error: 0.4737442924467544\n",
      "Step: 6050 Weights: [0.35612191 2.13242495] , error: 0.47374429244580035\n",
      "Step: 6051 Weights: [0.35612201 2.13242494] , error: 0.47374429244485244\n",
      "Step: 6052 Weights: [0.35612211 2.13242493] , error: 0.473744292443907\n",
      "Step: 6053 Weights: [0.3561222  2.13242492] , error: 0.47374429244296584\n",
      "Step: 6054 Weights: [0.3561223 2.1324249] , error: 0.4737442924420303\n",
      "Step: 6055 Weights: [0.35612239 2.13242489] , error: 0.47374429244109767\n",
      "Step: 6056 Weights: [0.35612249 2.13242488] , error: 0.47374429244017\n",
      "Step: 6057 Weights: [0.35612259 2.13242487] , error: 0.47374429243924676\n",
      "Step: 6058 Weights: [0.35612268 2.13242486] , error: 0.47374429243832744\n",
      "Step: 6059 Weights: [0.35612278 2.13242485] , error: 0.4737442924374122\n",
      "Step: 6060 Weights: [0.35612287 2.13242484] , error: 0.4737442924365013\n",
      "Step: 6061 Weights: [0.35612297 2.13242483] , error: 0.47374429243559457\n",
      "Step: 6062 Weights: [0.35612306 2.13242482] , error: 0.47374429243469174\n",
      "Step: 6063 Weights: [0.35612315 2.13242481] , error: 0.47374429243379257\n",
      "Step: 6064 Weights: [0.35612325 2.1324248 ] , error: 0.4737442924328988\n",
      "Step: 6065 Weights: [0.35612334 2.13242478] , error: 0.4737442924320078\n",
      "Step: 6066 Weights: [0.35612344 2.13242477] , error: 0.4737442924311216\n",
      "Step: 6067 Weights: [0.35612353 2.13242476] , error: 0.4737442924302395\n",
      "Step: 6068 Weights: [0.35612362 2.13242475] , error: 0.4737442924293618\n",
      "Step: 6069 Weights: [0.35612372 2.13242474] , error: 0.47374429242848703\n",
      "Step: 6070 Weights: [0.35612381 2.13242473] , error: 0.47374429242761673\n",
      "Step: 6071 Weights: [0.3561239  2.13242472] , error: 0.47374429242675054\n",
      "Step: 6072 Weights: [0.35612399 2.13242471] , error: 0.4737442924258879\n",
      "Step: 6073 Weights: [0.35612409 2.1324247 ] , error: 0.47374429242502947\n",
      "Step: 6074 Weights: [0.35612418 2.13242469] , error: 0.47374429242417515\n",
      "Step: 6075 Weights: [0.35612427 2.13242468] , error: 0.4737442924233245\n",
      "Step: 6076 Weights: [0.35612436 2.13242467] , error: 0.47374429242247795\n",
      "Step: 6077 Weights: [0.35612445 2.13242466] , error: 0.47374429242163435\n",
      "Step: 6078 Weights: [0.35612454 2.13242465] , error: 0.4737442924207953\n",
      "Step: 6079 Weights: [0.35612463 2.13242464] , error: 0.47374429241995997\n",
      "Step: 6080 Weights: [0.35612472 2.13242463] , error: 0.47374429241912874\n",
      "Step: 6081 Weights: [0.35612481 2.13242462] , error: 0.4737442924183005\n",
      "Step: 6082 Weights: [0.3561249  2.13242461] , error: 0.47374429241747695\n",
      "Step: 6083 Weights: [0.35612499 2.1324246 ] , error: 0.4737442924166564\n",
      "Step: 6084 Weights: [0.35612508 2.13242459] , error: 0.4737442924158401\n",
      "Step: 6085 Weights: [0.35612517 2.13242458] , error: 0.47374429241502775\n",
      "Step: 6086 Weights: [0.35612526 2.13242457] , error: 0.47374429241421834\n",
      "Step: 6087 Weights: [0.35612535 2.13242456] , error: 0.4737442924134132\n",
      "Step: 6088 Weights: [0.35612544 2.13242454] , error: 0.47374429241261184\n",
      "Step: 6089 Weights: [0.35612553 2.13242453] , error: 0.47374429241181326\n",
      "Step: 6090 Weights: [0.35612562 2.13242452] , error: 0.47374429241101856\n",
      "Step: 6091 Weights: [0.35612571 2.13242451] , error: 0.4737442924102286\n",
      "Step: 6092 Weights: [0.3561258 2.1324245] , error: 0.47374429240944127\n",
      "Step: 6093 Weights: [0.35612588 2.13242449] , error: 0.47374429240865784\n",
      "Step: 6094 Weights: [0.35612597 2.13242448] , error: 0.4737442924078774\n",
      "Step: 6095 Weights: [0.35612606 2.13242447] , error: 0.4737442924071007\n",
      "Step: 6096 Weights: [0.35612615 2.13242446] , error: 0.4737442924063282\n",
      "Step: 6097 Weights: [0.35612623 2.13242445] , error: 0.4737442924055595\n",
      "Step: 6098 Weights: [0.35612632 2.13242444] , error: 0.473744292404793\n",
      "Step: 6099 Weights: [0.35612641 2.13242443] , error: 0.4737442924040307\n",
      "Step: 6100 Weights: [0.35612649 2.13242442] , error: 0.4737442924032719\n",
      "Step: 6101 Weights: [0.35612658 2.13242441] , error: 0.4737442924025168\n",
      "Step: 6102 Weights: [0.35612667 2.1324244 ] , error: 0.47374429240176447\n",
      "Step: 6103 Weights: [0.35612675 2.13242439] , error: 0.4737442924010155\n",
      "Step: 6104 Weights: [0.35612684 2.13242439] , error: 0.47374429240027016\n",
      "Step: 6105 Weights: [0.35612692 2.13242438] , error: 0.47374429239952887\n",
      "Step: 6106 Weights: [0.35612701 2.13242437] , error: 0.4737442923987905\n",
      "Step: 6107 Weights: [0.35612709 2.13242436] , error: 0.4737442923980559\n",
      "Step: 6108 Weights: [0.35612718 2.13242435] , error: 0.47374429239732324\n",
      "Step: 6109 Weights: [0.35612726 2.13242434] , error: 0.4737442923965947\n",
      "Step: 6110 Weights: [0.35612735 2.13242433] , error: 0.47374429239586996\n",
      "Step: 6111 Weights: [0.35612743 2.13242432] , error: 0.4737442923951484\n",
      "Step: 6112 Weights: [0.35612752 2.13242431] , error: 0.47374429239442983\n",
      "Step: 6113 Weights: [0.3561276 2.1324243] , error: 0.47374429239371435\n",
      "Step: 6114 Weights: [0.35612769 2.13242429] , error: 0.47374429239300353\n",
      "Step: 6115 Weights: [0.35612777 2.13242428] , error: 0.4737442923922949\n",
      "Step: 6116 Weights: [0.35612785 2.13242427] , error: 0.473744292391589\n",
      "Step: 6117 Weights: [0.35612794 2.13242426] , error: 0.4737442923908869\n",
      "Step: 6118 Weights: [0.35612802 2.13242425] , error: 0.4737442923901881\n",
      "Step: 6119 Weights: [0.3561281  2.13242424] , error: 0.4737442923894919\n",
      "Step: 6120 Weights: [0.35612819 2.13242423] , error: 0.47374429238879934\n",
      "Step: 6121 Weights: [0.35612827 2.13242422] , error: 0.47374429238810956\n",
      "Step: 6122 Weights: [0.35612835 2.13242421] , error: 0.47374429238742277\n",
      "Step: 6123 Weights: [0.35612843 2.1324242 ] , error: 0.4737442923867393\n",
      "Step: 6124 Weights: [0.35612851 2.13242419] , error: 0.4737442923860592\n",
      "Step: 6125 Weights: [0.3561286  2.13242418] , error: 0.4737442923853833\n",
      "Step: 6126 Weights: [0.35612868 2.13242417] , error: 0.4737442923847085\n",
      "Step: 6127 Weights: [0.35612876 2.13242417] , error: 0.47374429238403815\n",
      "Step: 6128 Weights: [0.35612884 2.13242416] , error: 0.47374429238337035\n",
      "Step: 6129 Weights: [0.35612892 2.13242415] , error: 0.47374429238270543\n",
      "Step: 6130 Weights: [0.356129   2.13242414] , error: 0.47374429238204396\n",
      "Step: 6131 Weights: [0.35612908 2.13242413] , error: 0.47374429238138516\n",
      "Step: 6132 Weights: [0.35612916 2.13242412] , error: 0.473744292380729\n",
      "Step: 6133 Weights: [0.35612924 2.13242411] , error: 0.4737442923800761\n",
      "Step: 6134 Weights: [0.35612932 2.1324241 ] , error: 0.47374429237942633\n",
      "Step: 6135 Weights: [0.3561294  2.13242409] , error: 0.4737442923787794\n",
      "Step: 6136 Weights: [0.35612948 2.13242408] , error: 0.4737442923781352\n",
      "Step: 6137 Weights: [0.35612956 2.13242407] , error: 0.4737442923774944\n",
      "Step: 6138 Weights: [0.35612964 2.13242406] , error: 0.47374429237685695\n",
      "Step: 6139 Weights: [0.35612972 2.13242406] , error: 0.4737442923762213\n",
      "Step: 6140 Weights: [0.3561298  2.13242405] , error: 0.4737442923755891\n",
      "Step: 6141 Weights: [0.35612988 2.13242404] , error: 0.4737442923749603\n",
      "Step: 6142 Weights: [0.35612996 2.13242403] , error: 0.473744292374333\n",
      "Step: 6143 Weights: [0.35613004 2.13242402] , error: 0.4737442923737102\n",
      "Step: 6144 Weights: [0.35613012 2.13242401] , error: 0.4737442923730889\n",
      "Step: 6145 Weights: [0.35613019 2.132424  ] , error: 0.47374429237247134\n",
      "Step: 6146 Weights: [0.35613027 2.13242399] , error: 0.473744292371856\n",
      "Step: 6147 Weights: [0.35613035 2.13242398] , error: 0.47374429237124405\n",
      "Step: 6148 Weights: [0.35613043 2.13242397] , error: 0.473744292370635\n",
      "Step: 6149 Weights: [0.3561305  2.13242397] , error: 0.47374429237002735\n",
      "Step: 6150 Weights: [0.35613058 2.13242396] , error: 0.4737442923694234\n",
      "Step: 6151 Weights: [0.35613066 2.13242395] , error: 0.4737442923688221\n",
      "Step: 6152 Weights: [0.35613074 2.13242394] , error: 0.4737442923682238\n",
      "Step: 6153 Weights: [0.35613081 2.13242393] , error: 0.4737442923676276\n",
      "Step: 6154 Weights: [0.35613089 2.13242392] , error: 0.4737442923670351\n",
      "Step: 6155 Weights: [0.35613097 2.13242391] , error: 0.4737442923664448\n",
      "Step: 6156 Weights: [0.35613104 2.1324239 ] , error: 0.47374429236585663\n",
      "Step: 6157 Weights: [0.35613112 2.1324239 ] , error: 0.47374429236527205\n",
      "Step: 6158 Weights: [0.35613119 2.13242389] , error: 0.47374429236468946\n",
      "Step: 6159 Weights: [0.35613127 2.13242388] , error: 0.47374429236410986\n",
      "Step: 6160 Weights: [0.35613134 2.13242387] , error: 0.4737442923635332\n",
      "Step: 6161 Weights: [0.35613142 2.13242386] , error: 0.47374429236295784\n",
      "Step: 6162 Weights: [0.3561315  2.13242385] , error: 0.4737442923623859\n",
      "Step: 6163 Weights: [0.35613157 2.13242384] , error: 0.47374429236181725\n",
      "Step: 6164 Weights: [0.35613164 2.13242384] , error: 0.4737442923612505\n",
      "Step: 6165 Weights: [0.35613172 2.13242383] , error: 0.4737442923606865\n",
      "Step: 6166 Weights: [0.35613179 2.13242382] , error: 0.47374429236012594\n",
      "Step: 6167 Weights: [0.35613187 2.13242381] , error: 0.4737442923595665\n",
      "Step: 6168 Weights: [0.35613194 2.1324238 ] , error: 0.47374429235900994\n",
      "Step: 6169 Weights: [0.35613202 2.13242379] , error: 0.473744292358456\n",
      "Step: 6170 Weights: [0.35613209 2.13242378] , error: 0.4737442923579053\n",
      "Step: 6171 Weights: [0.35613216 2.13242378] , error: 0.47374429235735593\n",
      "Step: 6172 Weights: [0.35613224 2.13242377] , error: 0.47374429235680954\n",
      "Step: 6173 Weights: [0.35613231 2.13242376] , error: 0.47374429235626614\n",
      "Step: 6174 Weights: [0.35613238 2.13242375] , error: 0.47374429235572496\n",
      "Step: 6175 Weights: [0.35613246 2.13242374] , error: 0.4737442923551853\n",
      "Step: 6176 Weights: [0.35613253 2.13242373] , error: 0.4737442923546497\n",
      "Step: 6177 Weights: [0.3561326  2.13242373] , error: 0.4737442923541151\n",
      "Step: 6178 Weights: [0.35613267 2.13242372] , error: 0.47374429235358384\n",
      "Step: 6179 Weights: [0.35613275 2.13242371] , error: 0.47374429235305443\n",
      "Step: 6180 Weights: [0.35613282 2.1324237 ] , error: 0.4737442923525279\n",
      "Step: 6181 Weights: [0.35613289 2.13242369] , error: 0.4737442923520038\n",
      "Step: 6182 Weights: [0.35613296 2.13242368] , error: 0.47374429235148185\n",
      "Step: 6183 Weights: [0.35613303 2.13242368] , error: 0.4737442923509627\n",
      "Step: 6184 Weights: [0.35613311 2.13242367] , error: 0.4737442923504458\n",
      "Step: 6185 Weights: [0.35613318 2.13242366] , error: 0.47374429234993026\n",
      "Step: 6186 Weights: [0.35613325 2.13242365] , error: 0.47374429234941856\n",
      "Step: 6187 Weights: [0.35613332 2.13242364] , error: 0.47374429234890836\n",
      "Step: 6188 Weights: [0.35613339 2.13242364] , error: 0.4737442923484003\n",
      "Step: 6189 Weights: [0.35613346 2.13242363] , error: 0.47374429234789456\n",
      "Step: 6190 Weights: [0.35613353 2.13242362] , error: 0.4737442923473909\n",
      "Step: 6191 Weights: [0.3561336  2.13242361] , error: 0.4737442923468909\n",
      "Step: 6192 Weights: [0.35613367 2.1324236 ] , error: 0.47374429234639187\n",
      "Step: 6193 Weights: [0.35613374 2.1324236 ] , error: 0.47374429234589566\n",
      "Step: 6194 Weights: [0.35613381 2.13242359] , error: 0.4737442923454015\n",
      "Step: 6195 Weights: [0.35613388 2.13242358] , error: 0.47374429234491056\n",
      "Step: 6196 Weights: [0.35613395 2.13242357] , error: 0.4737442923444206\n",
      "Step: 6197 Weights: [0.35613402 2.13242356] , error: 0.47374429234393317\n",
      "Step: 6198 Weights: [0.35613409 2.13242356] , error: 0.47374429234344806\n",
      "Step: 6199 Weights: [0.35613416 2.13242355] , error: 0.47374429234296456\n",
      "Step: 6200 Weights: [0.35613423 2.13242354] , error: 0.4737442923424844\n",
      "Step: 6201 Weights: [0.3561343  2.13242353] , error: 0.4737442923420053\n",
      "Step: 6202 Weights: [0.35613437 2.13242352] , error: 0.4737442923415289\n",
      "Step: 6203 Weights: [0.35613443 2.13242352] , error: 0.4737442923410548\n",
      "Step: 6204 Weights: [0.3561345  2.13242351] , error: 0.47374429234058274\n",
      "Step: 6205 Weights: [0.35613457 2.1324235 ] , error: 0.4737442923401135\n",
      "Step: 6206 Weights: [0.35613464 2.13242349] , error: 0.47374429233964516\n",
      "Step: 6207 Weights: [0.35613471 2.13242349] , error: 0.4737442923391796\n",
      "Step: 6208 Weights: [0.35613477 2.13242348] , error: 0.47374429233871607\n",
      "Step: 6209 Weights: [0.35613484 2.13242347] , error: 0.4737442923382549\n",
      "Step: 6210 Weights: [0.35613491 2.13242346] , error: 0.47374429233779647\n",
      "Step: 6211 Weights: [0.35613498 2.13242345] , error: 0.473744292337339\n",
      "Step: 6212 Weights: [0.35613504 2.13242345] , error: 0.47374429233688325\n",
      "Step: 6213 Weights: [0.35613511 2.13242344] , error: 0.4737442923364303\n",
      "Step: 6214 Weights: [0.35613518 2.13242343] , error: 0.4737442923359794\n",
      "Step: 6215 Weights: [0.35613524 2.13242342] , error: 0.47374429233553117\n",
      "Step: 6216 Weights: [0.35613531 2.13242342] , error: 0.4737442923350839\n",
      "Step: 6217 Weights: [0.35613538 2.13242341] , error: 0.47374429233463894\n",
      "Step: 6218 Weights: [0.35613544 2.1324234 ] , error: 0.47374429233419557\n",
      "Step: 6219 Weights: [0.35613551 2.13242339] , error: 0.47374429233375526\n",
      "Step: 6220 Weights: [0.35613557 2.13242339] , error: 0.47374429233331605\n",
      "Step: 6221 Weights: [0.35613564 2.13242338] , error: 0.473744292332881\n",
      "Step: 6222 Weights: [0.35613571 2.13242337] , error: 0.4737442923324447\n",
      "Step: 6223 Weights: [0.35613577 2.13242336] , error: 0.47374429233201176\n",
      "Step: 6224 Weights: [0.35613584 2.13242336] , error: 0.47374429233158133\n",
      "Step: 6225 Weights: [0.3561359  2.13242335] , error: 0.4737442923311528\n",
      "Step: 6226 Weights: [0.35613597 2.13242334] , error: 0.4737442923307254\n",
      "Step: 6227 Weights: [0.35613603 2.13242333] , error: 0.47374429233030035\n",
      "Step: 6228 Weights: [0.3561361  2.13242333] , error: 0.4737442923298774\n",
      "Step: 6229 Weights: [0.35613616 2.13242332] , error: 0.4737442923294571\n",
      "Step: 6230 Weights: [0.35613622 2.13242331] , error: 0.47374429232903703\n",
      "Step: 6231 Weights: [0.35613629 2.1324233 ] , error: 0.4737442923286196\n",
      "Step: 6232 Weights: [0.35613635 2.1324233 ] , error: 0.47374429232820536\n",
      "Step: 6233 Weights: [0.35613642 2.13242329] , error: 0.473744292327792\n",
      "Step: 6234 Weights: [0.35613648 2.13242328] , error: 0.47374429232737986\n",
      "Step: 6235 Weights: [0.35613654 2.13242328] , error: 0.47374429232697013\n",
      "Step: 6236 Weights: [0.35613661 2.13242327] , error: 0.47374429232656257\n",
      "Step: 6237 Weights: [0.35613667 2.13242326] , error: 0.47374429232615617\n",
      "Step: 6238 Weights: [0.35613673 2.13242325] , error: 0.473744292325752\n",
      "Step: 6239 Weights: [0.3561368  2.13242325] , error: 0.4737442923253501\n",
      "Step: 6240 Weights: [0.35613686 2.13242324] , error: 0.4737442923249497\n",
      "Step: 6241 Weights: [0.35613692 2.13242323] , error: 0.4737442923245506\n",
      "Step: 6242 Weights: [0.35613699 2.13242322] , error: 0.47374429232415377\n",
      "Step: 6243 Weights: [0.35613705 2.13242322] , error: 0.4737442923237589\n",
      "Step: 6244 Weights: [0.35613711 2.13242321] , error: 0.47374429232336523\n",
      "Step: 6245 Weights: [0.35613717 2.1324232 ] , error: 0.47374429232297394\n",
      "Step: 6246 Weights: [0.35613723 2.1324232 ] , error: 0.473744292322584\n",
      "Step: 6247 Weights: [0.3561373  2.13242319] , error: 0.473744292322197\n",
      "Step: 6248 Weights: [0.35613736 2.13242318] , error: 0.47374429232181103\n",
      "Step: 6249 Weights: [0.35613742 2.13242318] , error: 0.47374429232142684\n",
      "Step: 6250 Weights: [0.35613748 2.13242317] , error: 0.4737442923210435\n",
      "Step: 6251 Weights: [0.35613754 2.13242316] , error: 0.47374429232066306\n",
      "Step: 6252 Weights: [0.3561376  2.13242315] , error: 0.47374429232028326\n",
      "Step: 6253 Weights: [0.35613766 2.13242315] , error: 0.47374429231990584\n",
      "Step: 6254 Weights: [0.35613773 2.13242314] , error: 0.47374429231953075\n",
      "Step: 6255 Weights: [0.35613779 2.13242313] , error: 0.4737442923191558\n",
      "Step: 6256 Weights: [0.35613785 2.13242313] , error: 0.4737442923187849\n",
      "Step: 6257 Weights: [0.35613791 2.13242312] , error: 0.4737442923184136\n",
      "Step: 6258 Weights: [0.35613797 2.13242311] , error: 0.4737442923180444\n",
      "Step: 6259 Weights: [0.35613803 2.13242311] , error: 0.47374429231767745\n",
      "Step: 6260 Weights: [0.35613809 2.1324231 ] , error: 0.4737442923173116\n",
      "Step: 6261 Weights: [0.35613815 2.13242309] , error: 0.47374429231694803\n",
      "Step: 6262 Weights: [0.35613821 2.13242308] , error: 0.47374429231658566\n",
      "Step: 6263 Weights: [0.35613827 2.13242308] , error: 0.47374429231622484\n",
      "Step: 6264 Weights: [0.35613833 2.13242307] , error: 0.4737442923158665\n",
      "Step: 6265 Weights: [0.35613839 2.13242306] , error: 0.4737442923155089\n",
      "Step: 6266 Weights: [0.35613845 2.13242306] , error: 0.4737442923151534\n",
      "Step: 6267 Weights: [0.35613851 2.13242305] , error: 0.4737442923147998\n",
      "Step: 6268 Weights: [0.35613856 2.13242304] , error: 0.47374429231444726\n",
      "Step: 6269 Weights: [0.35613862 2.13242304] , error: 0.47374429231409676\n",
      "Step: 6270 Weights: [0.35613868 2.13242303] , error: 0.47374429231374715\n",
      "Step: 6271 Weights: [0.35613874 2.13242302] , error: 0.47374429231339976\n",
      "Step: 6272 Weights: [0.3561388  2.13242302] , error: 0.4737442923130536\n",
      "Step: 6273 Weights: [0.35613886 2.13242301] , error: 0.47374429231270887\n",
      "Step: 6274 Weights: [0.35613892 2.132423  ] , error: 0.47374429231236614\n",
      "Step: 6275 Weights: [0.35613897 2.132423  ] , error: 0.47374429231202525\n",
      "Step: 6276 Weights: [0.35613903 2.13242299] , error: 0.4737442923116848\n",
      "Step: 6277 Weights: [0.35613909 2.13242298] , error: 0.47374429231134674\n",
      "Step: 6278 Weights: [0.35613915 2.13242298] , error: 0.47374429231101\n",
      "Step: 6279 Weights: [0.3561392  2.13242297] , error: 0.47374429231067505\n",
      "Step: 6280 Weights: [0.35613926 2.13242296] , error: 0.4737442923103421\n",
      "Step: 6281 Weights: [0.35613932 2.13242296] , error: 0.47374429231000875\n",
      "Step: 6282 Weights: [0.35613938 2.13242295] , error: 0.47374429230967885\n",
      "Step: 6283 Weights: [0.35613943 2.13242294] , error: 0.4737442923093492\n",
      "Step: 6284 Weights: [0.35613949 2.13242294] , error: 0.47374429230902176\n",
      "Step: 6285 Weights: [0.35613955 2.13242293] , error: 0.47374429230869636\n",
      "Step: 6286 Weights: [0.3561396  2.13242293] , error: 0.4737442923083717\n",
      "Step: 6287 Weights: [0.35613966 2.13242292] , error: 0.47374429230804854\n",
      "Step: 6288 Weights: [0.35613972 2.13242291] , error: 0.4737442923077266\n",
      "Step: 6289 Weights: [0.35613977 2.13242291] , error: 0.4737442923074063\n",
      "Step: 6290 Weights: [0.35613983 2.1324229 ] , error: 0.47374429230708837\n",
      "Step: 6291 Weights: [0.35613989 2.13242289] , error: 0.4737442923067711\n",
      "Step: 6292 Weights: [0.35613994 2.13242289] , error: 0.4737442923064549\n",
      "Step: 6293 Weights: [0.35614    2.13242288] , error: 0.4737442923061401\n",
      "Step: 6294 Weights: [0.35614005 2.13242287] , error: 0.47374429230582776\n",
      "Step: 6295 Weights: [0.35614011 2.13242287] , error: 0.4737442923055158\n",
      "Step: 6296 Weights: [0.35614016 2.13242286] , error: 0.47374429230520543\n",
      "Step: 6297 Weights: [0.35614022 2.13242285] , error: 0.4737442923048963\n",
      "Step: 6298 Weights: [0.35614027 2.13242285] , error: 0.4737442923045898\n",
      "Step: 6299 Weights: [0.35614033 2.13242284] , error: 0.47374429230428383\n",
      "Step: 6300 Weights: [0.35614038 2.13242284] , error: 0.47374429230397913\n",
      "Step: 6301 Weights: [0.35614044 2.13242283] , error: 0.4737442923036763\n",
      "Step: 6302 Weights: [0.35614049 2.13242282] , error: 0.4737442923033741\n",
      "Step: 6303 Weights: [0.35614055 2.13242282] , error: 0.47374429230307424\n",
      "Step: 6304 Weights: [0.3561406  2.13242281] , error: 0.4737442923027752\n",
      "Step: 6305 Weights: [0.35614066 2.1324228 ] , error: 0.4737442923024775\n",
      "Step: 6306 Weights: [0.35614071 2.1324228 ] , error: 0.4737442923021812\n",
      "Step: 6307 Weights: [0.35614076 2.13242279] , error: 0.47374429230188597\n",
      "Step: 6308 Weights: [0.35614082 2.13242279] , error: 0.4737442923015925\n",
      "Step: 6309 Weights: [0.35614087 2.13242278] , error: 0.4737442923013009\n",
      "Step: 6310 Weights: [0.35614093 2.13242277] , error: 0.4737442923010097\n",
      "Step: 6311 Weights: [0.35614098 2.13242277] , error: 0.47374429230072046\n",
      "Step: 6312 Weights: [0.35614103 2.13242276] , error: 0.47374429230043225\n",
      "Step: 6313 Weights: [0.35614109 2.13242276] , error: 0.47374429230014525\n",
      "Step: 6314 Weights: [0.35614114 2.13242275] , error: 0.47374429229985904\n",
      "Step: 6315 Weights: [0.35614119 2.13242274] , error: 0.4737442922995746\n",
      "Step: 6316 Weights: [0.35614124 2.13242274] , error: 0.4737442922992917\n",
      "Step: 6317 Weights: [0.3561413  2.13242273] , error: 0.47374429229900983\n",
      "Step: 6318 Weights: [0.35614135 2.13242273] , error: 0.47374429229872944\n",
      "Step: 6319 Weights: [0.3561414  2.13242272] , error: 0.4737442922984504\n",
      "Step: 6320 Weights: [0.35614145 2.13242271] , error: 0.4737442922981726\n",
      "Step: 6321 Weights: [0.35614151 2.13242271] , error: 0.47374429229789594\n",
      "Step: 6322 Weights: [0.35614156 2.1324227 ] , error: 0.47374429229761983\n",
      "Step: 6323 Weights: [0.35614161 2.1324227 ] , error: 0.4737442922973458\n",
      "Step: 6324 Weights: [0.35614166 2.13242269] , error: 0.4737442922970731\n",
      "Step: 6325 Weights: [0.35614171 2.13242268] , error: 0.4737442922968027\n",
      "Step: 6326 Weights: [0.35614177 2.13242268] , error: 0.47374429229653076\n",
      "Step: 6327 Weights: [0.35614182 2.13242267] , error: 0.4737442922962614\n",
      "Step: 6328 Weights: [0.35614187 2.13242267] , error: 0.4737442922959936\n",
      "Step: 6329 Weights: [0.35614192 2.13242266] , error: 0.4737442922957267\n",
      "Step: 6330 Weights: [0.35614197 2.13242265] , error: 0.4737442922954616\n",
      "Step: 6331 Weights: [0.35614202 2.13242265] , error: 0.473744292295198\n",
      "Step: 6332 Weights: [0.35614207 2.13242264] , error: 0.4737442922949344\n",
      "Step: 6333 Weights: [0.35614213 2.13242264] , error: 0.4737442922946725\n",
      "Step: 6334 Weights: [0.35614218 2.13242263] , error: 0.47374429229441195\n",
      "Step: 6335 Weights: [0.35614223 2.13242263] , error: 0.4737442922941519\n",
      "Step: 6336 Weights: [0.35614228 2.13242262] , error: 0.47374429229389386\n",
      "Step: 6337 Weights: [0.35614233 2.13242261] , error: 0.4737442922936368\n",
      "Step: 6338 Weights: [0.35614238 2.13242261] , error: 0.4737442922933802\n",
      "Step: 6339 Weights: [0.35614243 2.1324226 ] , error: 0.4737442922931258\n",
      "Step: 6340 Weights: [0.35614248 2.1324226 ] , error: 0.47374429229287157\n",
      "Step: 6341 Weights: [0.35614253 2.13242259] , error: 0.4737442922926195\n",
      "Step: 6342 Weights: [0.35614258 2.13242259] , error: 0.4737442922923685\n",
      "Step: 6343 Weights: [0.35614263 2.13242258] , error: 0.4737442922921178\n",
      "Step: 6344 Weights: [0.35614268 2.13242257] , error: 0.47374429229186826\n",
      "Step: 6345 Weights: [0.35614273 2.13242257] , error: 0.47374429229162063\n",
      "Step: 6346 Weights: [0.35614278 2.13242256] , error: 0.47374429229137477\n",
      "Step: 6347 Weights: [0.35614283 2.13242256] , error: 0.47374429229112824\n",
      "Step: 6348 Weights: [0.35614287 2.13242255] , error: 0.4737442922908844\n",
      "Step: 6349 Weights: [0.35614292 2.13242255] , error: 0.4737442922906403\n",
      "Step: 6350 Weights: [0.35614297 2.13242254] , error: 0.4737442922903987\n",
      "Step: 6351 Weights: [0.35614302 2.13242253] , error: 0.47374429229015624\n",
      "Step: 6352 Weights: [0.35614307 2.13242253] , error: 0.4737442922899163\n",
      "Step: 6353 Weights: [0.35614312 2.13242252] , error: 0.47374429228967796\n",
      "Step: 6354 Weights: [0.35614317 2.13242252] , error: 0.4737442922894402\n",
      "Step: 6355 Weights: [0.35614322 2.13242251] , error: 0.4737442922892021\n",
      "Step: 6356 Weights: [0.35614326 2.13242251] , error: 0.473744292288967\n",
      "Step: 6357 Weights: [0.35614331 2.1324225 ] , error: 0.4737442922887326\n",
      "Step: 6358 Weights: [0.35614336 2.1324225 ] , error: 0.4737442922884987\n",
      "Step: 6359 Weights: [0.35614341 2.13242249] , error: 0.4737442922882661\n",
      "Step: 6360 Weights: [0.35614346 2.13242248] , error: 0.4737442922880343\n",
      "Step: 6361 Weights: [0.3561435  2.13242248] , error: 0.4737442922878046\n",
      "Step: 6362 Weights: [0.35614355 2.13242247] , error: 0.4737442922875752\n",
      "Step: 6363 Weights: [0.3561436  2.13242247] , error: 0.47374429228734644\n",
      "Step: 6364 Weights: [0.35614365 2.13242246] , error: 0.4737442922871187\n",
      "Step: 6365 Weights: [0.35614369 2.13242246] , error: 0.47374429228689285\n",
      "Step: 6366 Weights: [0.35614374 2.13242245] , error: 0.4737442922866672\n",
      "Step: 6367 Weights: [0.35614379 2.13242245] , error: 0.47374429228644277\n",
      "Step: 6368 Weights: [0.35614383 2.13242244] , error: 0.47374429228621995\n",
      "Step: 6369 Weights: [0.35614388 2.13242244] , error: 0.47374429228599824\n",
      "Step: 6370 Weights: [0.35614393 2.13242243] , error: 0.4737442922857762\n",
      "Step: 6371 Weights: [0.35614397 2.13242243] , error: 0.47374429228555587\n",
      "Step: 6372 Weights: [0.35614402 2.13242242] , error: 0.47374429228533704\n",
      "Step: 6373 Weights: [0.35614407 2.13242241] , error: 0.47374429228511905\n",
      "Step: 6374 Weights: [0.35614411 2.13242241] , error: 0.473744292284901\n",
      "Step: 6375 Weights: [0.35614416 2.1324224 ] , error: 0.47374429228468606\n",
      "Step: 6376 Weights: [0.35614421 2.1324224 ] , error: 0.47374429228447024\n",
      "Step: 6377 Weights: [0.35614425 2.13242239] , error: 0.473744292284256\n",
      "Step: 6378 Weights: [0.3561443  2.13242239] , error: 0.4737442922840417\n",
      "Step: 6379 Weights: [0.35614434 2.13242238] , error: 0.47374429228383075\n",
      "Step: 6380 Weights: [0.35614439 2.13242238] , error: 0.4737442922836189\n",
      "Step: 6381 Weights: [0.35614444 2.13242237] , error: 0.47374429228340864\n",
      "Step: 6382 Weights: [0.35614448 2.13242237] , error: 0.4737442922832\n",
      "Step: 6383 Weights: [0.35614453 2.13242236] , error: 0.4737442922829908\n",
      "Step: 6384 Weights: [0.35614457 2.13242236] , error: 0.4737442922827835\n",
      "Step: 6385 Weights: [0.35614462 2.13242235] , error: 0.4737442922825766\n",
      "Step: 6386 Weights: [0.35614466 2.13242235] , error: 0.473744292282371\n",
      "Step: 6387 Weights: [0.35614471 2.13242234] , error: 0.47374429228216713\n",
      "Step: 6388 Weights: [0.35614475 2.13242234] , error: 0.4737442922819632\n",
      "Step: 6389 Weights: [0.3561448  2.13242233] , error: 0.4737442922817602\n",
      "Step: 6390 Weights: [0.35614484 2.13242233] , error: 0.473744292281558\n",
      "Step: 6391 Weights: [0.35614489 2.13242232] , error: 0.47374429228135706\n",
      "Step: 6392 Weights: [0.35614493 2.13242232] , error: 0.4737442922811572\n",
      "Step: 6393 Weights: [0.35614497 2.13242231] , error: 0.4737442922809578\n",
      "Step: 6394 Weights: [0.35614502 2.13242231] , error: 0.4737442922807603\n",
      "Step: 6395 Weights: [0.35614506 2.1324223 ] , error: 0.47374429228056236\n",
      "Step: 6396 Weights: [0.35614511 2.1324223 ] , error: 0.4737442922803665\n",
      "Step: 6397 Weights: [0.35614515 2.13242229] , error: 0.47374429228017023\n",
      "Step: 6398 Weights: [0.35614519 2.13242229] , error: 0.4737442922799758\n",
      "Step: 6399 Weights: [0.35614524 2.13242228] , error: 0.4737442922797827\n",
      "Step: 6400 Weights: [0.35614528 2.13242228] , error: 0.47374429227958914\n",
      "Step: 6401 Weights: [0.35614533 2.13242227] , error: 0.4737442922793972\n",
      "Step: 6402 Weights: [0.35614537 2.13242227] , error: 0.47374429227920567\n",
      "Step: 6403 Weights: [0.35614541 2.13242226] , error: 0.4737442922790155\n",
      "Step: 6404 Weights: [0.35614546 2.13242226] , error: 0.4737442922788271\n",
      "Step: 6405 Weights: [0.3561455  2.13242225] , error: 0.4737442922786377\n",
      "Step: 6406 Weights: [0.35614554 2.13242225] , error: 0.47374429227845044\n",
      "Step: 6407 Weights: [0.35614558 2.13242224] , error: 0.47374429227826365\n",
      "Step: 6408 Weights: [0.35614563 2.13242224] , error: 0.4737442922780777\n",
      "Step: 6409 Weights: [0.35614567 2.13242223] , error: 0.47374429227789194\n",
      "Step: 6410 Weights: [0.35614571 2.13242223] , error: 0.473744292277708\n",
      "Step: 6411 Weights: [0.35614576 2.13242222] , error: 0.47374429227752424\n",
      "Step: 6412 Weights: [0.3561458  2.13242222] , error: 0.4737442922773424\n",
      "Step: 6413 Weights: [0.35614584 2.13242221] , error: 0.47374429227716075\n",
      "Step: 6414 Weights: [0.35614588 2.13242221] , error: 0.4737442922769795\n",
      "Step: 6415 Weights: [0.35614593 2.1324222 ] , error: 0.4737442922767998\n",
      "Step: 6416 Weights: [0.35614597 2.1324222 ] , error: 0.4737442922766195\n",
      "Step: 6417 Weights: [0.35614601 2.13242219] , error: 0.4737442922764415\n",
      "Step: 6418 Weights: [0.35614605 2.13242219] , error: 0.47374429227626375\n",
      "Step: 6419 Weights: [0.35614609 2.13242218] , error: 0.473744292276087\n",
      "Step: 6420 Weights: [0.35614613 2.13242218] , error: 0.47374429227591136\n",
      "Step: 6421 Weights: [0.35614618 2.13242217] , error: 0.47374429227573545\n",
      "Step: 6422 Weights: [0.35614622 2.13242217] , error: 0.47374429227556103\n",
      "Step: 6423 Weights: [0.35614626 2.13242216] , error: 0.4737442922753876\n",
      "Step: 6424 Weights: [0.3561463  2.13242216] , error: 0.4737442922752145\n",
      "Step: 6425 Weights: [0.35614634 2.13242215] , error: 0.47374429227504233\n",
      "Step: 6426 Weights: [0.35614638 2.13242215] , error: 0.47374429227487197\n",
      "Step: 6427 Weights: [0.35614642 2.13242215] , error: 0.47374429227470016\n",
      "Step: 6428 Weights: [0.35614646 2.13242214] , error: 0.47374429227453074\n",
      "Step: 6429 Weights: [0.35614651 2.13242214] , error: 0.4737442922743622\n",
      "Step: 6430 Weights: [0.35614655 2.13242213] , error: 0.4737442922741941\n",
      "Step: 6431 Weights: [0.35614659 2.13242213] , error: 0.4737442922740268\n",
      "Step: 6432 Weights: [0.35614663 2.13242212] , error: 0.4737442922738593\n",
      "Step: 6433 Weights: [0.35614667 2.13242212] , error: 0.4737442922736936\n",
      "Step: 6434 Weights: [0.35614671 2.13242211] , error: 0.473744292273529\n",
      "Step: 6435 Weights: [0.35614675 2.13242211] , error: 0.4737442922733636\n",
      "Step: 6436 Weights: [0.35614679 2.1324221 ] , error: 0.47374429227320014\n",
      "Step: 6437 Weights: [0.35614683 2.1324221 ] , error: 0.4737442922730375\n",
      "Step: 6438 Weights: [0.35614687 2.13242209] , error: 0.47374429227287507\n",
      "Step: 6439 Weights: [0.35614691 2.13242209] , error: 0.47374429227271364\n",
      "Step: 6440 Weights: [0.35614695 2.13242209] , error: 0.47374429227255327\n",
      "Step: 6441 Weights: [0.35614699 2.13242208] , error: 0.4737442922723939\n",
      "Step: 6442 Weights: [0.35614703 2.13242208] , error: 0.4737442922722338\n",
      "Step: 6443 Weights: [0.35614707 2.13242207] , error: 0.4737442922720757\n",
      "Step: 6444 Weights: [0.35614711 2.13242207] , error: 0.47374429227191794\n",
      "Step: 6445 Weights: [0.35614715 2.13242206] , error: 0.4737442922717609\n",
      "Step: 6446 Weights: [0.35614719 2.13242206] , error: 0.47374429227160497\n",
      "Step: 6447 Weights: [0.35614723 2.13242205] , error: 0.47374429227144915\n",
      "Step: 6448 Weights: [0.35614726 2.13242205] , error: 0.473744292271294\n",
      "Step: 6449 Weights: [0.3561473  2.13242204] , error: 0.47374429227113957\n",
      "Step: 6450 Weights: [0.35614734 2.13242204] , error: 0.4737442922709859\n",
      "Step: 6451 Weights: [0.35614738 2.13242204] , error: 0.47374429227083364\n",
      "Step: 6452 Weights: [0.35614742 2.13242203] , error: 0.4737442922706813\n",
      "Step: 6453 Weights: [0.35614746 2.13242203] , error: 0.47374429227053033\n",
      "Step: 6454 Weights: [0.3561475  2.13242202] , error: 0.47374429227037956\n",
      "Step: 6455 Weights: [0.35614754 2.13242202] , error: 0.47374429227022863\n",
      "Step: 6456 Weights: [0.35614757 2.13242201] , error: 0.47374429227007925\n",
      "Step: 6457 Weights: [0.35614761 2.13242201] , error: 0.4737442922699318\n",
      "Step: 6458 Weights: [0.35614765 2.132422  ] , error: 0.4737442922697834\n",
      "Step: 6459 Weights: [0.35614769 2.132422  ] , error: 0.4737442922696362\n",
      "Step: 6460 Weights: [0.35614773 2.132422  ] , error: 0.47374429226948966\n",
      "Step: 6461 Weights: [0.35614777 2.13242199] , error: 0.4737442922693432\n",
      "Step: 6462 Weights: [0.3561478  2.13242199] , error: 0.4737442922691985\n",
      "Step: 6463 Weights: [0.35614784 2.13242198] , error: 0.4737442922690532\n",
      "Step: 6464 Weights: [0.35614788 2.13242198] , error: 0.4737442922689087\n",
      "Step: 6465 Weights: [0.35614792 2.13242197] , error: 0.4737442922687658\n",
      "Step: 6466 Weights: [0.35614795 2.13242197] , error: 0.4737442922686231\n",
      "Step: 6467 Weights: [0.35614799 2.13242197] , error: 0.47374429226848147\n",
      "Step: 6468 Weights: [0.35614803 2.13242196] , error: 0.4737442922683399\n",
      "Step: 6469 Weights: [0.35614807 2.13242196] , error: 0.4737442922681988\n",
      "Step: 6470 Weights: [0.3561481  2.13242195] , error: 0.47374429226805864\n",
      "Step: 6471 Weights: [0.35614814 2.13242195] , error: 0.47374429226791986\n",
      "Step: 6472 Weights: [0.35614818 2.13242194] , error: 0.4737442922677806\n",
      "Step: 6473 Weights: [0.35614821 2.13242194] , error: 0.4737442922676431\n",
      "Step: 6474 Weights: [0.35614825 2.13242194] , error: 0.47374429226750436\n",
      "Step: 6475 Weights: [0.35614829 2.13242193] , error: 0.4737442922673678\n",
      "Step: 6476 Weights: [0.35614832 2.13242193] , error: 0.4737442922672318\n",
      "Step: 6477 Weights: [0.35614836 2.13242192] , error: 0.47374429226709636\n",
      "Step: 6478 Weights: [0.3561484  2.13242192] , error: 0.473744292266961\n",
      "Step: 6479 Weights: [0.35614843 2.13242192] , error: 0.47374429226682596\n",
      "Step: 6480 Weights: [0.35614847 2.13242191] , error: 0.47374429226669307\n",
      "Step: 6481 Weights: [0.35614851 2.13242191] , error: 0.47374429226655923\n",
      "Step: 6482 Weights: [0.35614854 2.1324219 ] , error: 0.4737442922664266\n",
      "Step: 6483 Weights: [0.35614858 2.1324219 ] , error: 0.47374429226629433\n",
      "Step: 6484 Weights: [0.35614862 2.13242189] , error: 0.4737442922661633\n",
      "Step: 6485 Weights: [0.35614865 2.13242189] , error: 0.47374429226603276\n",
      "Step: 6486 Weights: [0.35614869 2.13242189] , error: 0.4737442922659022\n",
      "Step: 6487 Weights: [0.35614872 2.13242188] , error: 0.47374429226577214\n",
      "Step: 6488 Weights: [0.35614876 2.13242188] , error: 0.4737442922656437\n",
      "Step: 6489 Weights: [0.35614879 2.13242187] , error: 0.47374429226551407\n",
      "Step: 6490 Weights: [0.35614883 2.13242187] , error: 0.47374429226538706\n",
      "Step: 6491 Weights: [0.35614887 2.13242187] , error: 0.47374429226525994\n",
      "Step: 6492 Weights: [0.3561489  2.13242186] , error: 0.4737442922651329\n",
      "Step: 6493 Weights: [0.35614894 2.13242186] , error: 0.47374429226500614\n",
      "Step: 6494 Weights: [0.35614897 2.13242185] , error: 0.4737442922648814\n",
      "Step: 6495 Weights: [0.35614901 2.13242185] , error: 0.4737442922647559\n",
      "Step: 6496 Weights: [0.35614904 2.13242185] , error: 0.47374429226463155\n",
      "Step: 6497 Weights: [0.35614908 2.13242184] , error: 0.4737442922645073\n",
      "Step: 6498 Weights: [0.35614911 2.13242184] , error: 0.4737442922643844\n",
      "Step: 6499 Weights: [0.35614915 2.13242183] , error: 0.47374429226426196\n",
      "Step: 6500 Weights: [0.35614918 2.13242183] , error: 0.47374429226413967\n",
      "Step: 6501 Weights: [0.35614922 2.13242183] , error: 0.47374429226401826\n",
      "Step: 6502 Weights: [0.35614925 2.13242182] , error: 0.473744292263897\n",
      "Step: 6503 Weights: [0.35614928 2.13242182] , error: 0.47374429226377573\n",
      "Step: 6504 Weights: [0.35614932 2.13242181] , error: 0.4737442922636565\n",
      "Step: 6505 Weights: [0.35614935 2.13242181] , error: 0.47374429226353765\n",
      "Step: 6506 Weights: [0.35614939 2.13242181] , error: 0.47374429226341874\n",
      "Step: 6507 Weights: [0.35614942 2.1324218 ] , error: 0.47374429226330045\n",
      "Step: 6508 Weights: [0.35614946 2.1324218 ] , error: 0.47374429226318177\n",
      "Step: 6509 Weights: [0.35614949 2.13242179] , error: 0.4737442922630649\n",
      "Step: 6510 Weights: [0.35614952 2.13242179] , error: 0.4737442922629478\n",
      "Step: 6511 Weights: [0.35614956 2.13242179] , error: 0.4737442922628318\n",
      "Step: 6512 Weights: [0.35614959 2.13242178] , error: 0.47374429226271686\n",
      "Step: 6513 Weights: [0.35614963 2.13242178] , error: 0.4737442922626011\n",
      "Step: 6514 Weights: [0.35614966 2.13242178] , error: 0.47374429226248665\n",
      "Step: 6515 Weights: [0.35614969 2.13242177] , error: 0.47374429226237347\n",
      "Step: 6516 Weights: [0.35614973 2.13242177] , error: 0.4737442922622584\n",
      "Step: 6517 Weights: [0.35614976 2.13242176] , error: 0.47374429226214576\n",
      "Step: 6518 Weights: [0.35614979 2.13242176] , error: 0.4737442922620335\n",
      "Step: 6519 Weights: [0.35614983 2.13242176] , error: 0.47374429226192133\n",
      "Step: 6520 Weights: [0.35614986 2.13242175] , error: 0.47374429226181\n",
      "Step: 6521 Weights: [0.35614989 2.13242175] , error: 0.47374429226169923\n",
      "Step: 6522 Weights: [0.35614993 2.13242174] , error: 0.47374429226158804\n",
      "Step: 6523 Weights: [0.35614996 2.13242174] , error: 0.4737442922614783\n",
      "Step: 6524 Weights: [0.35614999 2.13242174] , error: 0.4737442922613687\n",
      "Step: 6525 Weights: [0.35615002 2.13242173] , error: 0.4737442922612599\n",
      "Step: 6526 Weights: [0.35615006 2.13242173] , error: 0.47374429226115145\n",
      "Step: 6527 Weights: [0.35615009 2.13242173] , error: 0.4737442922610431\n",
      "Step: 6528 Weights: [0.35615012 2.13242172] , error: 0.47374429226093623\n",
      "Step: 6529 Weights: [0.35615015 2.13242172] , error: 0.47374429226082887\n",
      "Step: 6530 Weights: [0.35615019 2.13242171] , error: 0.47374429226072184\n",
      "Step: 6531 Weights: [0.35615022 2.13242171] , error: 0.47374429226061576\n",
      "Step: 6532 Weights: [0.35615025 2.13242171] , error: 0.4737442922605106\n",
      "Step: 6533 Weights: [0.35615028 2.1324217 ] , error: 0.4737442922604057\n",
      "Step: 6534 Weights: [0.35615032 2.1324217 ] , error: 0.4737442922603006\n",
      "Step: 6535 Weights: [0.35615035 2.1324217 ] , error: 0.47374429226019643\n",
      "Step: 6536 Weights: [0.35615038 2.13242169] , error: 0.47374429226009357\n",
      "Step: 6537 Weights: [0.35615041 2.13242169] , error: 0.4737442922599897\n",
      "Step: 6538 Weights: [0.35615044 2.13242169] , error: 0.473744292259887\n",
      "Step: 6539 Weights: [0.35615048 2.13242168] , error: 0.47374429225978426\n",
      "Step: 6540 Weights: [0.35615051 2.13242168] , error: 0.47374429225968323\n",
      "Step: 6541 Weights: [0.35615054 2.13242167] , error: 0.4737442922595816\n",
      "Step: 6542 Weights: [0.35615057 2.13242167] , error: 0.4737442922594808\n",
      "Step: 6543 Weights: [0.3561506  2.13242167] , error: 0.4737442922593806\n",
      "Step: 6544 Weights: [0.35615063 2.13242166] , error: 0.4737442922592804\n",
      "Step: 6545 Weights: [0.35615067 2.13242166] , error: 0.4737442922591814\n",
      "Step: 6546 Weights: [0.3561507  2.13242166] , error: 0.47374429225908243\n",
      "Step: 6547 Weights: [0.35615073 2.13242165] , error: 0.4737442922589833\n",
      "Step: 6548 Weights: [0.35615076 2.13242165] , error: 0.4737442922588852\n",
      "Step: 6549 Weights: [0.35615079 2.13242165] , error: 0.4737442922587878\n",
      "Step: 6550 Weights: [0.35615082 2.13242164] , error: 0.4737442922586904\n",
      "Step: 6551 Weights: [0.35615085 2.13242164] , error: 0.47374429225859405\n",
      "Step: 6552 Weights: [0.35615088 2.13242164] , error: 0.4737442922584967\n",
      "Step: 6553 Weights: [0.35615091 2.13242163] , error: 0.4737442922584012\n",
      "Step: 6554 Weights: [0.35615094 2.13242163] , error: 0.47374429225830583\n",
      "Step: 6555 Weights: [0.35615097 2.13242162] , error: 0.47374429225821113\n",
      "Step: 6556 Weights: [0.35615101 2.13242162] , error: 0.4737442922581163\n",
      "Step: 6557 Weights: [0.35615104 2.13242162] , error: 0.4737442922580215\n",
      "Step: 6558 Weights: [0.35615107 2.13242161] , error: 0.4737442922579286\n",
      "Step: 6559 Weights: [0.3561511  2.13242161] , error: 0.47374429225783554\n",
      "Step: 6560 Weights: [0.35615113 2.13242161] , error: 0.47374429225774206\n",
      "Step: 6561 Weights: [0.35615116 2.1324216 ] , error: 0.4737442922576496\n",
      "Step: 6562 Weights: [0.35615119 2.1324216 ] , error: 0.47374429225755765\n",
      "Step: 6563 Weights: [0.35615122 2.1324216 ] , error: 0.4737442922574657\n",
      "Step: 6564 Weights: [0.35615125 2.13242159] , error: 0.4737442922573748\n",
      "Step: 6565 Weights: [0.35615128 2.13242159] , error: 0.4737442922572842\n",
      "Step: 6566 Weights: [0.35615131 2.13242159] , error: 0.47374429225719333\n",
      "Step: 6567 Weights: [0.35615134 2.13242158] , error: 0.4737442922571033\n",
      "Step: 6568 Weights: [0.35615137 2.13242158] , error: 0.47374429225701387\n",
      "Step: 6569 Weights: [0.3561514  2.13242158] , error: 0.47374429225692505\n",
      "Step: 6570 Weights: [0.35615143 2.13242157] , error: 0.47374429225683645\n",
      "Step: 6571 Weights: [0.35615146 2.13242157] , error: 0.47374429225674797\n",
      "Step: 6572 Weights: [0.35615149 2.13242157] , error: 0.4737442922566603\n",
      "Step: 6573 Weights: [0.35615151 2.13242156] , error: 0.47374429225657183\n",
      "Step: 6574 Weights: [0.35615154 2.13242156] , error: 0.4737442922564852\n",
      "Step: 6575 Weights: [0.35615157 2.13242156] , error: 0.473744292256398\n",
      "Step: 6576 Weights: [0.3561516  2.13242155] , error: 0.47374429225631265\n",
      "Step: 6577 Weights: [0.35615163 2.13242155] , error: 0.47374429225622616\n",
      "Step: 6578 Weights: [0.35615166 2.13242155] , error: 0.4737442922561401\n",
      "Step: 6579 Weights: [0.35615169 2.13242154] , error: 0.47374429225605474\n",
      "Step: 6580 Weights: [0.35615172 2.13242154] , error: 0.47374429225597103\n",
      "Step: 6581 Weights: [0.35615175 2.13242154] , error: 0.47374429225588555\n",
      "Step: 6582 Weights: [0.35615178 2.13242153] , error: 0.4737442922558024\n",
      "Step: 6583 Weights: [0.35615181 2.13242153] , error: 0.4737442922557191\n",
      "Step: 6584 Weights: [0.35615183 2.13242153] , error: 0.47374429225563586\n",
      "Step: 6585 Weights: [0.35615186 2.13242152] , error: 0.47374429225555226\n",
      "Step: 6586 Weights: [0.35615189 2.13242152] , error: 0.4737442922554702\n",
      "Step: 6587 Weights: [0.35615192 2.13242152] , error: 0.4737442922553874\n",
      "Step: 6588 Weights: [0.35615195 2.13242151] , error: 0.47374429225530645\n",
      "Step: 6589 Weights: [0.35615198 2.13242151] , error: 0.4737442922552244\n",
      "Step: 6590 Weights: [0.356152   2.13242151] , error: 0.4737442922551439\n",
      "Step: 6591 Weights: [0.35615203 2.1324215 ] , error: 0.4737442922550624\n",
      "Step: 6592 Weights: [0.35615206 2.1324215 ] , error: 0.47374429225498244\n",
      "Step: 6593 Weights: [0.35615209 2.1324215 ] , error: 0.4737442922549027\n",
      "Step: 6594 Weights: [0.35615212 2.13242149] , error: 0.4737442922548229\n",
      "Step: 6595 Weights: [0.35615215 2.13242149] , error: 0.4737442922547438\n",
      "Step: 6596 Weights: [0.35615217 2.13242149] , error: 0.4737442922546653\n",
      "Step: 6597 Weights: [0.3561522  2.13242148] , error: 0.47374429225458675\n",
      "Step: 6598 Weights: [0.35615223 2.13242148] , error: 0.4737442922545093\n",
      "Step: 6599 Weights: [0.35615226 2.13242148] , error: 0.47374429225443065\n",
      "Step: 6600 Weights: [0.35615228 2.13242148] , error: 0.4737442922543541\n",
      "Step: 6601 Weights: [0.35615231 2.13242147] , error: 0.47374429225427606\n",
      "Step: 6602 Weights: [0.35615234 2.13242147] , error: 0.4737442922542003\n",
      "Step: 6603 Weights: [0.35615237 2.13242147] , error: 0.47374429225412384\n",
      "Step: 6604 Weights: [0.35615239 2.13242146] , error: 0.47374429225404696\n",
      "Step: 6605 Weights: [0.35615242 2.13242146] , error: 0.47374429225397147\n",
      "Step: 6606 Weights: [0.35615245 2.13242146] , error: 0.47374429225389647\n",
      "Step: 6607 Weights: [0.35615248 2.13242145] , error: 0.47374429225382186\n",
      "Step: 6608 Weights: [0.3561525  2.13242145] , error: 0.47374429225374715\n",
      "Step: 6609 Weights: [0.35615253 2.13242145] , error: 0.47374429225367315\n",
      "Step: 6610 Weights: [0.35615256 2.13242144] , error: 0.47374429225359893\n",
      "Step: 6611 Weights: [0.35615258 2.13242144] , error: 0.4737442922535251\n",
      "Step: 6612 Weights: [0.35615261 2.13242144] , error: 0.47374429225345155\n",
      "Step: 6613 Weights: [0.35615264 2.13242143] , error: 0.47374429225337816\n",
      "Step: 6614 Weights: [0.35615266 2.13242143] , error: 0.4737442922533061\n",
      "Step: 6615 Weights: [0.35615269 2.13242143] , error: 0.4737442922532337\n",
      "Step: 6616 Weights: [0.35615272 2.13242143] , error: 0.4737442922531618\n",
      "Step: 6617 Weights: [0.35615274 2.13242142] , error: 0.47374429225309045\n",
      "Step: 6618 Weights: [0.35615277 2.13242142] , error: 0.47374429225301895\n",
      "Step: 6619 Weights: [0.3561528  2.13242142] , error: 0.47374429225294834\n",
      "Step: 6620 Weights: [0.35615282 2.13242141] , error: 0.473744292252877\n",
      "Step: 6621 Weights: [0.35615285 2.13242141] , error: 0.4737442922528074\n",
      "Step: 6622 Weights: [0.35615288 2.13242141] , error: 0.4737442922527373\n",
      "Step: 6623 Weights: [0.3561529 2.1324214] , error: 0.473744292252668\n",
      "Step: 6624 Weights: [0.35615293 2.1324214 ] , error: 0.47374429225259823\n",
      "Step: 6625 Weights: [0.35615296 2.1324214 ] , error: 0.4737442922525289\n",
      "Step: 6626 Weights: [0.35615298 2.1324214 ] , error: 0.47374429225246073\n",
      "Step: 6627 Weights: [0.35615301 2.13242139] , error: 0.47374429225239234\n",
      "Step: 6628 Weights: [0.35615303 2.13242139] , error: 0.4737442922523235\n",
      "Step: 6629 Weights: [0.35615306 2.13242139] , error: 0.4737442922522559\n",
      "Step: 6630 Weights: [0.35615309 2.13242138] , error: 0.4737442922521891\n",
      "Step: 6631 Weights: [0.35615311 2.13242138] , error: 0.47374429225212084\n",
      "Step: 6632 Weights: [0.35615314 2.13242138] , error: 0.47374429225205505\n",
      "Step: 6633 Weights: [0.35615316 2.13242137] , error: 0.47374429225198766\n",
      "Step: 6634 Weights: [0.35615319 2.13242137] , error: 0.47374429225192183\n",
      "Step: 6635 Weights: [0.35615321 2.13242137] , error: 0.4737442922518557\n",
      "Step: 6636 Weights: [0.35615324 2.13242137] , error: 0.47374429225179043\n",
      "Step: 6637 Weights: [0.35615326 2.13242136] , error: 0.473744292251725\n",
      "Step: 6638 Weights: [0.35615329 2.13242136] , error: 0.4737442922516595\n",
      "Step: 6639 Weights: [0.35615331 2.13242136] , error: 0.4737442922515954\n",
      "Step: 6640 Weights: [0.35615334 2.13242135] , error: 0.47374429225153025\n",
      "Step: 6641 Weights: [0.35615337 2.13242135] , error: 0.47374429225146675\n",
      "Step: 6642 Weights: [0.35615339 2.13242135] , error: 0.4737442922514019\n",
      "Step: 6643 Weights: [0.35615342 2.13242135] , error: 0.4737442922513392\n",
      "Step: 6644 Weights: [0.35615344 2.13242134] , error: 0.4737442922512751\n",
      "Step: 6645 Weights: [0.35615347 2.13242134] , error: 0.4737442922512124\n",
      "Step: 6646 Weights: [0.35615349 2.13242134] , error: 0.47374429225114967\n",
      "Step: 6647 Weights: [0.35615352 2.13242133] , error: 0.47374429225108766\n",
      "Step: 6648 Weights: [0.35615354 2.13242133] , error: 0.4737442922510252\n",
      "Step: 6649 Weights: [0.35615356 2.13242133] , error: 0.47374429225096376\n",
      "Step: 6650 Weights: [0.35615359 2.13242133] , error: 0.47374429225090164\n",
      "Step: 6651 Weights: [0.35615361 2.13242132] , error: 0.4737442922508406\n",
      "Step: 6652 Weights: [0.35615364 2.13242132] , error: 0.4737442922507788\n",
      "Step: 6653 Weights: [0.35615366 2.13242132] , error: 0.4737442922507192\n",
      "Step: 6654 Weights: [0.35615369 2.13242131] , error: 0.47374429225065845\n",
      "Step: 6655 Weights: [0.35615371 2.13242131] , error: 0.47374429225059805\n",
      "Step: 6656 Weights: [0.35615374 2.13242131] , error: 0.4737442922505376\n",
      "Step: 6657 Weights: [0.35615376 2.13242131] , error: 0.47374429225047854\n",
      "Step: 6658 Weights: [0.35615378 2.1324213 ] , error: 0.4737442922504187\n",
      "Step: 6659 Weights: [0.35615381 2.1324213 ] , error: 0.47374429225035997\n",
      "Step: 6660 Weights: [0.35615383 2.1324213 ] , error: 0.4737442922503009\n",
      "Step: 6661 Weights: [0.35615386 2.1324213 ] , error: 0.4737442922502423\n",
      "Step: 6662 Weights: [0.35615388 2.13242129] , error: 0.4737442922501839\n",
      "Step: 6663 Weights: [0.35615391 2.13242129] , error: 0.47374429225012543\n",
      "Step: 6664 Weights: [0.35615393 2.13242129] , error: 0.47374429225006837\n",
      "Step: 6665 Weights: [0.35615395 2.13242128] , error: 0.4737442922500109\n",
      "Step: 6666 Weights: [0.35615398 2.13242128] , error: 0.4737442922499533\n",
      "Step: 6667 Weights: [0.356154   2.13242128] , error: 0.47374429224989645\n",
      "Step: 6668 Weights: [0.35615402 2.13242128] , error: 0.47374429224983927\n",
      "Step: 6669 Weights: [0.35615405 2.13242127] , error: 0.47374429224978354\n",
      "Step: 6670 Weights: [0.35615407 2.13242127] , error: 0.4737442922497269\n",
      "Step: 6671 Weights: [0.35615409 2.13242127] , error: 0.4737442922496712\n",
      "Step: 6672 Weights: [0.35615412 2.13242127] , error: 0.473744292249616\n",
      "Step: 6673 Weights: [0.35615414 2.13242126] , error: 0.4737442922495605\n",
      "Step: 6674 Weights: [0.35615416 2.13242126] , error: 0.47374429224950493\n",
      "Step: 6675 Weights: [0.35615419 2.13242126] , error: 0.4737442922494496\n",
      "Step: 6676 Weights: [0.35615421 2.13242125] , error: 0.4737442922493953\n",
      "Step: 6677 Weights: [0.35615423 2.13242125] , error: 0.47374429224934084\n",
      "Step: 6678 Weights: [0.35615426 2.13242125] , error: 0.47374429224928605\n",
      "Step: 6679 Weights: [0.35615428 2.13242125] , error: 0.4737442922492323\n",
      "Step: 6680 Weights: [0.3561543  2.13242124] , error: 0.4737442922491787\n",
      "Step: 6681 Weights: [0.35615433 2.13242124] , error: 0.47374429224912507\n",
      "Step: 6682 Weights: [0.35615435 2.13242124] , error: 0.47374429224907233\n",
      "Step: 6683 Weights: [0.35615437 2.13242124] , error: 0.47374429224901904\n",
      "Step: 6684 Weights: [0.3561544  2.13242123] , error: 0.4737442922489667\n",
      "Step: 6685 Weights: [0.35615442 2.13242123] , error: 0.4737442922489138\n",
      "Step: 6686 Weights: [0.35615444 2.13242123] , error: 0.4737442922488611\n",
      "Step: 6687 Weights: [0.35615446 2.13242123] , error: 0.4737442922488102\n",
      "Step: 6688 Weights: [0.35615449 2.13242122] , error: 0.4737442922487579\n",
      "Step: 6689 Weights: [0.35615451 2.13242122] , error: 0.47374429224870634\n",
      "Step: 6690 Weights: [0.35615453 2.13242122] , error: 0.47374429224865483\n",
      "Step: 6691 Weights: [0.35615455 2.13242122] , error: 0.47374429224860465\n",
      "Step: 6692 Weights: [0.35615458 2.13242121] , error: 0.47374429224855313\n",
      "Step: 6693 Weights: [0.3561546  2.13242121] , error: 0.4737442922485028\n",
      "Step: 6694 Weights: [0.35615462 2.13242121] , error: 0.4737442922484514\n",
      "Step: 6695 Weights: [0.35615464 2.13242121] , error: 0.47374429224840153\n",
      "Step: 6696 Weights: [0.35615467 2.1324212 ] , error: 0.47374429224835235\n",
      "Step: 6697 Weights: [0.35615469 2.1324212 ] , error: 0.47374429224830245\n",
      "Step: 6698 Weights: [0.35615471 2.1324212 ] , error: 0.4737442922482527\n",
      "Step: 6699 Weights: [0.35615473 2.1324212 ] , error: 0.4737442922482033\n",
      "Step: 6700 Weights: [0.35615475 2.13242119] , error: 0.4737442922481552\n",
      "Step: 6701 Weights: [0.35615478 2.13242119] , error: 0.47374429224810594\n",
      "Step: 6702 Weights: [0.3561548  2.13242119] , error: 0.4737442922480575\n",
      "Step: 6703 Weights: [0.35615482 2.13242119] , error: 0.4737442922480092\n",
      "Step: 6704 Weights: [0.35615484 2.13242118] , error: 0.4737442922479607\n",
      "Step: 6705 Weights: [0.35615486 2.13242118] , error: 0.4737442922479129\n",
      "Step: 6706 Weights: [0.35615488 2.13242118] , error: 0.4737442922478655\n",
      "Step: 6707 Weights: [0.35615491 2.13242118] , error: 0.47374429224781817\n",
      "Step: 6708 Weights: [0.35615493 2.13242117] , error: 0.4737442922477698\n",
      "Step: 6709 Weights: [0.35615495 2.13242117] , error: 0.4737442922477233\n",
      "Step: 6710 Weights: [0.35615497 2.13242117] , error: 0.47374429224767645\n",
      "Step: 6711 Weights: [0.35615499 2.13242117] , error: 0.4737442922476297\n",
      "Step: 6712 Weights: [0.35615501 2.13242116] , error: 0.4737442922475842\n",
      "Step: 6713 Weights: [0.35615504 2.13242116] , error: 0.47374429224753767\n",
      "Step: 6714 Weights: [0.35615506 2.13242116] , error: 0.4737442922474913\n",
      "Step: 6715 Weights: [0.35615508 2.13242116] , error: 0.47374429224744524\n",
      "Step: 6716 Weights: [0.3561551  2.13242115] , error: 0.47374429224739956\n",
      "Step: 6717 Weights: [0.35615512 2.13242115] , error: 0.4737442922473547\n",
      "Step: 6718 Weights: [0.35615514 2.13242115] , error: 0.47374429224730885\n",
      "Step: 6719 Weights: [0.35615516 2.13242115] , error: 0.473744292247265\n",
      "Step: 6720 Weights: [0.35615518 2.13242114] , error: 0.4737442922472194\n",
      "Step: 6721 Weights: [0.3561552  2.13242114] , error: 0.4737442922471746\n",
      "Step: 6722 Weights: [0.35615523 2.13242114] , error: 0.47374429224713055\n",
      "Step: 6723 Weights: [0.35615525 2.13242114] , error: 0.4737442922470868\n",
      "Step: 6724 Weights: [0.35615527 2.13242113] , error: 0.47374429224704306\n",
      "Step: 6725 Weights: [0.35615529 2.13242113] , error: 0.473744292246999\n",
      "Step: 6726 Weights: [0.35615531 2.13242113] , error: 0.47374429224695563\n",
      "Step: 6727 Weights: [0.35615533 2.13242113] , error: 0.47374429224691234\n",
      "Step: 6728 Weights: [0.35615535 2.13242112] , error: 0.4737442922468689\n",
      "Step: 6729 Weights: [0.35615537 2.13242112] , error: 0.4737442922468258\n",
      "Step: 6730 Weights: [0.35615539 2.13242112] , error: 0.47374429224678405\n",
      "Step: 6731 Weights: [0.35615541 2.13242112] , error: 0.4737442922467408\n",
      "Step: 6732 Weights: [0.35615543 2.13242112] , error: 0.47374429224669845\n",
      "Step: 6733 Weights: [0.35615545 2.13242111] , error: 0.47374429224665615\n",
      "Step: 6734 Weights: [0.35615547 2.13242111] , error: 0.47374429224661463\n",
      "Step: 6735 Weights: [0.35615549 2.13242111] , error: 0.47374429224657233\n",
      "Step: 6736 Weights: [0.35615551 2.13242111] , error: 0.4737442922465311\n",
      "Step: 6737 Weights: [0.35615553 2.1324211 ] , error: 0.4737442922464894\n",
      "Step: 6738 Weights: [0.35615555 2.1324211 ] , error: 0.4737442922464483\n",
      "Step: 6739 Weights: [0.35615557 2.1324211 ] , error: 0.4737442922464074\n",
      "Step: 6740 Weights: [0.35615559 2.1324211 ] , error: 0.47374429224636616\n",
      "Step: 6741 Weights: [0.35615561 2.13242109] , error: 0.47374429224632597\n",
      "Step: 6742 Weights: [0.35615563 2.13242109] , error: 0.47374429224628556\n",
      "Step: 6743 Weights: [0.35615565 2.13242109] , error: 0.4737442922462448\n",
      "Step: 6744 Weights: [0.35615567 2.13242109] , error: 0.4737442922462055\n",
      "Step: 6745 Weights: [0.35615569 2.13242109] , error: 0.47374429224616543\n",
      "Step: 6746 Weights: [0.35615571 2.13242108] , error: 0.4737442922461253\n",
      "Step: 6747 Weights: [0.35615573 2.13242108] , error: 0.47374429224608605\n",
      "Step: 6748 Weights: [0.35615575 2.13242108] , error: 0.47374429224604697\n",
      "Step: 6749 Weights: [0.35615577 2.13242108] , error: 0.4737442922460077\n",
      "Step: 6750 Weights: [0.35615579 2.13242107] , error: 0.47374429224596804\n",
      "Step: 6751 Weights: [0.35615581 2.13242107] , error: 0.4737442922459286\n",
      "Step: 6752 Weights: [0.35615583 2.13242107] , error: 0.47374429224589076\n",
      "Step: 6753 Weights: [0.35615585 2.13242107] , error: 0.47374429224585246\n",
      "Step: 6754 Weights: [0.35615587 2.13242106] , error: 0.4737442922458136\n",
      "Step: 6755 Weights: [0.35615589 2.13242106] , error: 0.47374429224577586\n",
      "Step: 6756 Weights: [0.35615591 2.13242106] , error: 0.47374429224573794\n",
      "Step: 6757 Weights: [0.35615593 2.13242106] , error: 0.4737442922457\n",
      "Step: 6758 Weights: [0.35615595 2.13242106] , error: 0.47374429224566184\n",
      "Step: 6759 Weights: [0.35615597 2.13242105] , error: 0.47374429224562536\n",
      "Step: 6760 Weights: [0.35615599 2.13242105] , error: 0.47374429224558706\n",
      "Step: 6761 Weights: [0.35615601 2.13242105] , error: 0.4737442922455508\n",
      "Step: 6762 Weights: [0.35615602 2.13242105] , error: 0.47374429224551307\n",
      "Step: 6763 Weights: [0.35615604 2.13242105] , error: 0.473744292245477\n",
      "Step: 6764 Weights: [0.35615606 2.13242104] , error: 0.47374429224544035\n",
      "Step: 6765 Weights: [0.35615608 2.13242104] , error: 0.4737442922454035\n",
      "Step: 6766 Weights: [0.3561561  2.13242104] , error: 0.4737442922453674\n",
      "Step: 6767 Weights: [0.35615612 2.13242104] , error: 0.47374429224533116\n",
      "Step: 6768 Weights: [0.35615614 2.13242103] , error: 0.47374429224529524\n",
      "Step: 6769 Weights: [0.35615616 2.13242103] , error: 0.47374429224526027\n",
      "Step: 6770 Weights: [0.35615618 2.13242103] , error: 0.4737442922452243\n",
      "Step: 6771 Weights: [0.35615619 2.13242103] , error: 0.47374429224518866\n",
      "Step: 6772 Weights: [0.35615621 2.13242103] , error: 0.47374429224515296\n",
      "Step: 6773 Weights: [0.35615623 2.13242102] , error: 0.4737442922451185\n",
      "Step: 6774 Weights: [0.35615625 2.13242102] , error: 0.473744292245083\n",
      "Step: 6775 Weights: [0.35615627 2.13242102] , error: 0.4737442922450483\n",
      "Step: 6776 Weights: [0.35615629 2.13242102] , error: 0.4737442922450136\n",
      "Step: 6777 Weights: [0.35615631 2.13242102] , error: 0.47374429224498005\n",
      "Step: 6778 Weights: [0.35615632 2.13242101] , error: 0.4737442922449457\n",
      "Step: 6779 Weights: [0.35615634 2.13242101] , error: 0.47374429224491055\n",
      "Step: 6780 Weights: [0.35615636 2.13242101] , error: 0.4737442922448769\n",
      "Step: 6781 Weights: [0.35615638 2.13242101] , error: 0.47374429224484266\n",
      "Step: 6782 Weights: [0.3561564 2.132421 ] , error: 0.4737442922448088\n",
      "Step: 6783 Weights: [0.35615642 2.132421  ] , error: 0.47374429224477554\n",
      "Step: 6784 Weights: [0.35615643 2.132421  ] , error: 0.47374429224474257\n",
      "Step: 6785 Weights: [0.35615645 2.132421  ] , error: 0.4737442922447084\n",
      "Step: 6786 Weights: [0.35615647 2.132421  ] , error: 0.4737442922446765\n",
      "Step: 6787 Weights: [0.35615649 2.13242099] , error: 0.47374429224464354\n",
      "Step: 6788 Weights: [0.35615651 2.13242099] , error: 0.47374429224461\n",
      "Step: 6789 Weights: [0.35615652 2.13242099] , error: 0.47374429224457737\n",
      "Step: 6790 Weights: [0.35615654 2.13242099] , error: 0.4737442922445449\n",
      "Step: 6791 Weights: [0.35615656 2.13242099] , error: 0.47374429224451264\n",
      "Step: 6792 Weights: [0.35615658 2.13242098] , error: 0.4737442922444808\n",
      "Step: 6793 Weights: [0.3561566  2.13242098] , error: 0.47374429224444814\n",
      "Step: 6794 Weights: [0.35615661 2.13242098] , error: 0.4737442922444158\n",
      "Step: 6795 Weights: [0.35615663 2.13242098] , error: 0.4737442922443841\n",
      "Step: 6796 Weights: [0.35615665 2.13242098] , error: 0.4737442922443532\n",
      "Step: 6797 Weights: [0.35615667 2.13242097] , error: 0.47374429224432174\n",
      "Step: 6798 Weights: [0.35615668 2.13242097] , error: 0.47374429224429\n",
      "Step: 6799 Weights: [0.3561567  2.13242097] , error: 0.4737442922442593\n",
      "Step: 6800 Weights: [0.35615672 2.13242097] , error: 0.4737442922442287\n",
      "Step: 6801 Weights: [0.35615674 2.13242097] , error: 0.473744292244197\n",
      "Step: 6802 Weights: [0.35615675 2.13242096] , error: 0.47374429224416637\n",
      "Step: 6803 Weights: [0.35615677 2.13242096] , error: 0.47374429224413556\n",
      "Step: 6804 Weights: [0.35615679 2.13242096] , error: 0.4737442922441052\n",
      "Step: 6805 Weights: [0.35615681 2.13242096] , error: 0.47374429224407455\n",
      "Step: 6806 Weights: [0.35615682 2.13242096] , error: 0.47374429224404435\n",
      "Step: 6807 Weights: [0.35615684 2.13242095] , error: 0.47374429224401426\n",
      "Step: 6808 Weights: [0.35615686 2.13242095] , error: 0.4737442922439845\n",
      "Step: 6809 Weights: [0.35615688 2.13242095] , error: 0.4737442922439546\n",
      "Step: 6810 Weights: [0.35615689 2.13242095] , error: 0.47374429224392545\n",
      "Step: 6811 Weights: [0.35615691 2.13242095] , error: 0.47374429224389575\n",
      "Step: 6812 Weights: [0.35615693 2.13242094] , error: 0.4737442922438658\n",
      "Step: 6813 Weights: [0.35615694 2.13242094] , error: 0.4737442922438369\n",
      "Step: 6814 Weights: [0.35615696 2.13242094] , error: 0.4737442922438077\n",
      "Step: 6815 Weights: [0.35615698 2.13242094] , error: 0.4737442922437791\n",
      "Step: 6816 Weights: [0.35615699 2.13242094] , error: 0.4737442922437495\n",
      "Step: 6817 Weights: [0.35615701 2.13242093] , error: 0.47374429224372183\n",
      "Step: 6818 Weights: [0.35615703 2.13242093] , error: 0.4737442922436925\n",
      "Step: 6819 Weights: [0.35615704 2.13242093] , error: 0.4737442922436642\n",
      "Step: 6820 Weights: [0.35615706 2.13242093] , error: 0.47374429224363646\n",
      "Step: 6821 Weights: [0.35615708 2.13242093] , error: 0.47374429224360753\n",
      "Step: 6822 Weights: [0.35615709 2.13242092] , error: 0.47374429224357917\n",
      "Step: 6823 Weights: [0.35615711 2.13242092] , error: 0.473744292243552\n",
      "Step: 6824 Weights: [0.35615713 2.13242092] , error: 0.4737442922435243\n",
      "Step: 6825 Weights: [0.35615714 2.13242092] , error: 0.4737442922434957\n",
      "Step: 6826 Weights: [0.35615716 2.13242092] , error: 0.4737442922434669\n",
      "Step: 6827 Weights: [0.35615718 2.13242092] , error: 0.47374429224344133\n",
      "Step: 6828 Weights: [0.35615719 2.13242091] , error: 0.47374429224341386\n",
      "Step: 6829 Weights: [0.35615721 2.13242091] , error: 0.4737442922433861\n",
      "Step: 6830 Weights: [0.35615723 2.13242091] , error: 0.47374429224335945\n",
      "Step: 6831 Weights: [0.35615724 2.13242091] , error: 0.4737442922433322\n",
      "Step: 6832 Weights: [0.35615726 2.13242091] , error: 0.47374429224330533\n",
      "Step: 6833 Weights: [0.35615728 2.1324209 ] , error: 0.47374429224327896\n",
      "Step: 6834 Weights: [0.35615729 2.1324209 ] , error: 0.4737442922432522\n",
      "Step: 6835 Weights: [0.35615731 2.1324209 ] , error: 0.473744292243226\n",
      "Step: 6836 Weights: [0.35615732 2.1324209 ] , error: 0.4737442922431996\n",
      "Step: 6837 Weights: [0.35615734 2.1324209 ] , error: 0.4737442922431727\n",
      "Step: 6838 Weights: [0.35615736 2.13242089] , error: 0.4737442922431473\n",
      "Step: 6839 Weights: [0.35615737 2.13242089] , error: 0.47374429224312103\n",
      "Step: 6840 Weights: [0.35615739 2.13242089] , error: 0.4737442922430955\n",
      "Step: 6841 Weights: [0.3561574  2.13242089] , error: 0.47374429224306963\n",
      "Step: 6842 Weights: [0.35615742 2.13242089] , error: 0.47374429224304426\n",
      "Step: 6843 Weights: [0.35615744 2.13242089] , error: 0.4737442922430179\n",
      "Step: 6844 Weights: [0.35615745 2.13242088] , error: 0.47374429224299375\n",
      "Step: 6845 Weights: [0.35615747 2.13242088] , error: 0.4737442922429676\n",
      "Step: 6846 Weights: [0.35615748 2.13242088] , error: 0.47374429224294284\n",
      "Step: 6847 Weights: [0.3561575  2.13242088] , error: 0.47374429224291725\n",
      "Step: 6848 Weights: [0.35615751 2.13242088] , error: 0.4737442922428927\n",
      "Step: 6849 Weights: [0.35615753 2.13242088] , error: 0.4737442922428679\n",
      "Step: 6850 Weights: [0.35615755 2.13242087] , error: 0.47374429224284303\n",
      "Step: 6851 Weights: [0.35615756 2.13242087] , error: 0.47374429224281817\n",
      "Step: 6852 Weights: [0.35615758 2.13242087] , error: 0.47374429224279396\n",
      "Step: 6853 Weights: [0.35615759 2.13242087] , error: 0.47374429224276965\n",
      "Step: 6854 Weights: [0.35615761 2.13242087] , error: 0.47374429224274683\n",
      "Step: 6855 Weights: [0.35615762 2.13242086] , error: 0.4737442922427212\n",
      "Step: 6856 Weights: [0.35615764 2.13242086] , error: 0.47374429224269765\n",
      "Step: 6857 Weights: [0.35615765 2.13242086] , error: 0.4737442922426732\n",
      "Step: 6858 Weights: [0.35615767 2.13242086] , error: 0.47374429224264925\n",
      "Step: 6859 Weights: [0.35615769 2.13242086] , error: 0.47374429224262554\n",
      "Step: 6860 Weights: [0.3561577  2.13242086] , error: 0.4737442922426028\n",
      "Step: 6861 Weights: [0.35615772 2.13242085] , error: 0.4737442922425788\n",
      "Step: 6862 Weights: [0.35615773 2.13242085] , error: 0.47374429224255443\n",
      "Step: 6863 Weights: [0.35615775 2.13242085] , error: 0.47374429224253173\n",
      "Step: 6864 Weights: [0.35615776 2.13242085] , error: 0.47374429224250836\n",
      "Step: 6865 Weights: [0.35615778 2.13242085] , error: 0.47374429224248576\n",
      "Step: 6866 Weights: [0.35615779 2.13242085] , error: 0.47374429224246317\n",
      "Step: 6867 Weights: [0.35615781 2.13242084] , error: 0.4737442922424399\n",
      "Step: 6868 Weights: [0.35615782 2.13242084] , error: 0.4737442922424164\n",
      "Step: 6869 Weights: [0.35615784 2.13242084] , error: 0.47374429224239445\n",
      "Step: 6870 Weights: [0.35615785 2.13242084] , error: 0.47374429224237247\n",
      "Step: 6871 Weights: [0.35615787 2.13242084] , error: 0.4737442922423495\n",
      "Step: 6872 Weights: [0.35615788 2.13242083] , error: 0.4737442922423273\n",
      "Step: 6873 Weights: [0.3561579  2.13242083] , error: 0.4737442922423043\n",
      "Step: 6874 Weights: [0.35615791 2.13242083] , error: 0.4737442922422823\n",
      "Step: 6875 Weights: [0.35615793 2.13242083] , error: 0.47374429224226045\n",
      "Step: 6876 Weights: [0.35615794 2.13242083] , error: 0.4737442922422383\n",
      "Step: 6877 Weights: [0.35615795 2.13242083] , error: 0.4737442922422165\n",
      "Step: 6878 Weights: [0.35615797 2.13242082] , error: 0.47374429224219516\n",
      "Step: 6879 Weights: [0.35615798 2.13242082] , error: 0.47374429224217274\n",
      "Step: 6880 Weights: [0.356158   2.13242082] , error: 0.47374429224215164\n",
      "Step: 6881 Weights: [0.35615801 2.13242082] , error: 0.47374429224212966\n",
      "Step: 6882 Weights: [0.35615803 2.13242082] , error: 0.47374429224210873\n",
      "Step: 6883 Weights: [0.35615804 2.13242082] , error: 0.47374429224208786\n",
      "Step: 6884 Weights: [0.35615806 2.13242081] , error: 0.47374429224206654\n",
      "Step: 6885 Weights: [0.35615807 2.13242081] , error: 0.4737442922420452\n",
      "Step: 6886 Weights: [0.35615809 2.13242081] , error: 0.47374429224202425\n",
      "Step: 6887 Weights: [0.3561581  2.13242081] , error: 0.4737442922420035\n",
      "Step: 6888 Weights: [0.35615811 2.13242081] , error: 0.47374429224198256\n",
      "Step: 6889 Weights: [0.35615813 2.13242081] , error: 0.47374429224196246\n",
      "Step: 6890 Weights: [0.35615814 2.13242081] , error: 0.4737442922419419\n",
      "Step: 6891 Weights: [0.35615816 2.1324208 ] , error: 0.4737442922419214\n",
      "Step: 6892 Weights: [0.35615817 2.1324208 ] , error: 0.4737442922419005\n",
      "Step: 6893 Weights: [0.35615819 2.1324208 ] , error: 0.47374429224188075\n",
      "Step: 6894 Weights: [0.3561582 2.1324208] , error: 0.4737442922418603\n",
      "Step: 6895 Weights: [0.35615821 2.1324208 ] , error: 0.4737442922418401\n",
      "Step: 6896 Weights: [0.35615823 2.1324208 ] , error: 0.47374429224182046\n",
      "Step: 6897 Weights: [0.35615824 2.13242079] , error: 0.47374429224180054\n",
      "Step: 6898 Weights: [0.35615826 2.13242079] , error: 0.47374429224177994\n",
      "Step: 6899 Weights: [0.35615827 2.13242079] , error: 0.4737442922417609\n",
      "Step: 6900 Weights: [0.35615828 2.13242079] , error: 0.47374429224174097\n",
      "Step: 6901 Weights: [0.3561583  2.13242079] , error: 0.47374429224172154\n",
      "Step: 6902 Weights: [0.35615831 2.13242079] , error: 0.4737442922417021\n",
      "Step: 6903 Weights: [0.35615833 2.13242078] , error: 0.47374429224168263\n",
      "Step: 6904 Weights: [0.35615834 2.13242078] , error: 0.47374429224166303\n",
      "Step: 6905 Weights: [0.35615835 2.13242078] , error: 0.47374429224164366\n",
      "Step: 6906 Weights: [0.35615837 2.13242078] , error: 0.4737442922416244\n",
      "Step: 6907 Weights: [0.35615838 2.13242078] , error: 0.4737442922416059\n",
      "Step: 6908 Weights: [0.35615839 2.13242078] , error: 0.47374429224158593\n",
      "Step: 6909 Weights: [0.35615841 2.13242077] , error: 0.47374429224156805\n",
      "Step: 6910 Weights: [0.35615842 2.13242077] , error: 0.47374429224154885\n",
      "Step: 6911 Weights: [0.35615844 2.13242077] , error: 0.47374429224153025\n",
      "Step: 6912 Weights: [0.35615845 2.13242077] , error: 0.47374429224151166\n",
      "Step: 6913 Weights: [0.35615846 2.13242077] , error: 0.4737442922414935\n",
      "Step: 6914 Weights: [0.35615848 2.13242077] , error: 0.47374429224147496\n",
      "Step: 6915 Weights: [0.35615849 2.13242077] , error: 0.4737442922414563\n",
      "Step: 6916 Weights: [0.3561585  2.13242076] , error: 0.4737442922414373\n",
      "Step: 6917 Weights: [0.35615852 2.13242076] , error: 0.4737442922414194\n",
      "Step: 6918 Weights: [0.35615853 2.13242076] , error: 0.47374429224140185\n",
      "Step: 6919 Weights: [0.35615854 2.13242076] , error: 0.47374429224138354\n",
      "Step: 6920 Weights: [0.35615856 2.13242076] , error: 0.4737442922413659\n",
      "Step: 6921 Weights: [0.35615857 2.13242076] , error: 0.473744292241348\n",
      "Step: 6922 Weights: [0.35615858 2.13242075] , error: 0.47374429224133047\n",
      "Step: 6923 Weights: [0.3561586  2.13242075] , error: 0.4737442922413125\n",
      "Step: 6924 Weights: [0.35615861 2.13242075] , error: 0.47374429224129483\n",
      "Step: 6925 Weights: [0.35615862 2.13242075] , error: 0.47374429224127645\n",
      "Step: 6926 Weights: [0.35615864 2.13242075] , error: 0.47374429224125947\n",
      "Step: 6927 Weights: [0.35615865 2.13242075] , error: 0.47374429224124176\n",
      "Step: 6928 Weights: [0.35615866 2.13242075] , error: 0.47374429224122555\n",
      "Step: 6929 Weights: [0.35615867 2.13242074] , error: 0.4737442922412072\n",
      "Step: 6930 Weights: [0.35615869 2.13242074] , error: 0.4737442922411905\n",
      "Step: 6931 Weights: [0.3561587  2.13242074] , error: 0.4737442922411733\n",
      "Step: 6932 Weights: [0.35615871 2.13242074] , error: 0.47374429224115655\n",
      "Step: 6933 Weights: [0.35615873 2.13242074] , error: 0.47374429224113995\n",
      "Step: 6934 Weights: [0.35615874 2.13242074] , error: 0.47374429224112247\n",
      "Step: 6935 Weights: [0.35615875 2.13242074] , error: 0.47374429224110626\n",
      "Step: 6936 Weights: [0.35615877 2.13242073] , error: 0.4737442922410894\n",
      "Step: 6937 Weights: [0.35615878 2.13242073] , error: 0.47374429224107245\n",
      "Step: 6938 Weights: [0.35615879 2.13242073] , error: 0.4737442922410562\n",
      "Step: 6939 Weights: [0.3561588  2.13242073] , error: 0.4737442922410395\n",
      "Step: 6940 Weights: [0.35615882 2.13242073] , error: 0.4737442922410232\n",
      "Step: 6941 Weights: [0.35615883 2.13242073] , error: 0.47374429224100734\n",
      "Step: 6942 Weights: [0.35615884 2.13242073] , error: 0.4737442922409907\n",
      "Step: 6943 Weights: [0.35615885 2.13242072] , error: 0.47374429224097525\n",
      "Step: 6944 Weights: [0.35615887 2.13242072] , error: 0.47374429224095826\n",
      "Step: 6945 Weights: [0.35615888 2.13242072] , error: 0.4737442922409423\n",
      "Step: 6946 Weights: [0.35615889 2.13242072] , error: 0.4737442922409259\n",
      "Step: 6947 Weights: [0.3561589  2.13242072] , error: 0.4737442922409103\n",
      "Step: 6948 Weights: [0.35615892 2.13242072] , error: 0.4737442922408955\n",
      "Step: 6949 Weights: [0.35615893 2.13242072] , error: 0.4737442922408792\n",
      "Step: 6950 Weights: [0.35615894 2.13242071] , error: 0.4737442922408641\n",
      "Step: 6951 Weights: [0.35615895 2.13242071] , error: 0.47374429224084785\n",
      "Step: 6952 Weights: [0.35615897 2.13242071] , error: 0.4737442922408324\n",
      "Step: 6953 Weights: [0.35615898 2.13242071] , error: 0.4737442922408168\n",
      "Step: 6954 Weights: [0.35615899 2.13242071] , error: 0.4737442922408015\n",
      "Step: 6955 Weights: [0.356159   2.13242071] , error: 0.4737442922407866\n",
      "Step: 6956 Weights: [0.35615902 2.13242071] , error: 0.4737442922407717\n",
      "Step: 6957 Weights: [0.35615903 2.1324207 ] , error: 0.47374429224075565\n",
      "Step: 6958 Weights: [0.35615904 2.1324207 ] , error: 0.4737442922407408\n",
      "Step: 6959 Weights: [0.35615905 2.1324207 ] , error: 0.4737442922407261\n",
      "Step: 6960 Weights: [0.35615906 2.1324207 ] , error: 0.4737442922407106\n",
      "Step: 6961 Weights: [0.35615908 2.1324207 ] , error: 0.47374429224069653\n",
      "Step: 6962 Weights: [0.35615909 2.1324207 ] , error: 0.4737442922406812\n",
      "Step: 6963 Weights: [0.3561591 2.1324207] , error: 0.47374429224066616\n",
      "Step: 6964 Weights: [0.35615911 2.13242069] , error: 0.4737442922406523\n",
      "Step: 6965 Weights: [0.35615913 2.13242069] , error: 0.47374429224063724\n",
      "Step: 6966 Weights: [0.35615914 2.13242069] , error: 0.4737442922406223\n",
      "Step: 6967 Weights: [0.35615915 2.13242069] , error: 0.4737442922406074\n",
      "Step: 6968 Weights: [0.35615916 2.13242069] , error: 0.4737442922405932\n",
      "Step: 6969 Weights: [0.35615917 2.13242069] , error: 0.47374429224057946\n",
      "Step: 6970 Weights: [0.35615918 2.13242069] , error: 0.47374429224056447\n",
      "Step: 6971 Weights: [0.3561592  2.13242068] , error: 0.4737442922405508\n",
      "Step: 6972 Weights: [0.35615921 2.13242068] , error: 0.4737442922405365\n",
      "Step: 6973 Weights: [0.35615922 2.13242068] , error: 0.4737442922405224\n",
      "Step: 6974 Weights: [0.35615923 2.13242068] , error: 0.47374429224050907\n",
      "Step: 6975 Weights: [0.35615924 2.13242068] , error: 0.4737442922404945\n",
      "Step: 6976 Weights: [0.35615926 2.13242068] , error: 0.47374429224048065\n",
      "Step: 6977 Weights: [0.35615927 2.13242068] , error: 0.47374429224046666\n",
      "Step: 6978 Weights: [0.35615928 2.13242068] , error: 0.47374429224045345\n",
      "Step: 6979 Weights: [0.35615929 2.13242067] , error: 0.4737442922404393\n",
      "Step: 6980 Weights: [0.3561593  2.13242067] , error: 0.47374429224042564\n",
      "Step: 6981 Weights: [0.35615931 2.13242067] , error: 0.4737442922404125\n",
      "Step: 6982 Weights: [0.35615933 2.13242067] , error: 0.47374429224039843\n",
      "Step: 6983 Weights: [0.35615934 2.13242067] , error: 0.4737442922403856\n",
      "Step: 6984 Weights: [0.35615935 2.13242067] , error: 0.4737442922403711\n",
      "Step: 6985 Weights: [0.35615936 2.13242067] , error: 0.4737442922403579\n",
      "Step: 6986 Weights: [0.35615937 2.13242066] , error: 0.47374429224034437\n",
      "Step: 6987 Weights: [0.35615938 2.13242066] , error: 0.47374429224033254\n",
      "Step: 6988 Weights: [0.35615939 2.13242066] , error: 0.47374429224031794\n",
      "Step: 6989 Weights: [0.35615941 2.13242066] , error: 0.47374429224030584\n",
      "Step: 6990 Weights: [0.35615942 2.13242066] , error: 0.4737442922402924\n",
      "Step: 6991 Weights: [0.35615943 2.13242066] , error: 0.47374429224027986\n",
      "Step: 6992 Weights: [0.35615944 2.13242066] , error: 0.47374429224026654\n",
      "Step: 6993 Weights: [0.35615945 2.13242066] , error: 0.47374429224025305\n",
      "Step: 6994 Weights: [0.35615946 2.13242065] , error: 0.4737442922402406\n",
      "Step: 6995 Weights: [0.35615947 2.13242065] , error: 0.4737442922402288\n",
      "Step: 6996 Weights: [0.35615948 2.13242065] , error: 0.4737442922402157\n",
      "Step: 6997 Weights: [0.3561595  2.13242065] , error: 0.47374429224020215\n",
      "Step: 6998 Weights: [0.35615951 2.13242065] , error: 0.4737442922401905\n",
      "Step: 6999 Weights: [0.35615952 2.13242065] , error: 0.4737442922401775\n",
      "Step: 7000 Weights: [0.35615953 2.13242065] , error: 0.47374429224016534\n",
      "Step: 7001 Weights: [0.35615954 2.13242065] , error: 0.4737442922401529\n",
      "Step: 7002 Weights: [0.35615955 2.13242064] , error: 0.4737442922401406\n",
      "Step: 7003 Weights: [0.35615956 2.13242064] , error: 0.4737442922401285\n",
      "Step: 7004 Weights: [0.35615957 2.13242064] , error: 0.4737442922401163\n",
      "Step: 7005 Weights: [0.35615958 2.13242064] , error: 0.47374429224010445\n",
      "Step: 7006 Weights: [0.35615959 2.13242064] , error: 0.47374429224009246\n",
      "Step: 7007 Weights: [0.35615961 2.13242064] , error: 0.47374429224007986\n",
      "Step: 7008 Weights: [0.35615962 2.13242064] , error: 0.47374429224006737\n",
      "Step: 7009 Weights: [0.35615963 2.13242064] , error: 0.473744292240056\n",
      "Step: 7010 Weights: [0.35615964 2.13242063] , error: 0.4737442922400443\n",
      "Step: 7011 Weights: [0.35615965 2.13242063] , error: 0.4737442922400323\n",
      "Step: 7012 Weights: [0.35615966 2.13242063] , error: 0.4737442922400196\n",
      "Step: 7013 Weights: [0.35615967 2.13242063] , error: 0.47374429224000847\n",
      "Step: 7014 Weights: [0.35615968 2.13242063] , error: 0.4737442922399969\n",
      "Step: 7015 Weights: [0.35615969 2.13242063] , error: 0.47374429223998527\n",
      "Step: 7016 Weights: [0.3561597  2.13242063] , error: 0.4737442922399734\n",
      "Step: 7017 Weights: [0.35615971 2.13242063] , error: 0.47374429223996206\n",
      "Step: 7018 Weights: [0.35615972 2.13242062] , error: 0.4737442922399505\n",
      "Step: 7019 Weights: [0.35615973 2.13242062] , error: 0.47374429223993897\n",
      "Step: 7020 Weights: [0.35615975 2.13242062] , error: 0.4737442922399283\n",
      "Step: 7021 Weights: [0.35615976 2.13242062] , error: 0.4737442922399162\n",
      "Step: 7022 Weights: [0.35615977 2.13242062] , error: 0.473744292239905\n",
      "Step: 7023 Weights: [0.35615978 2.13242062] , error: 0.47374429223989406\n",
      "Step: 7024 Weights: [0.35615979 2.13242062] , error: 0.47374429223988246\n",
      "Step: 7025 Weights: [0.3561598  2.13242062] , error: 0.4737442922398705\n",
      "Step: 7026 Weights: [0.35615981 2.13242061] , error: 0.47374429223986086\n",
      "Step: 7027 Weights: [0.35615982 2.13242061] , error: 0.4737442922398489\n",
      "Step: 7028 Weights: [0.35615983 2.13242061] , error: 0.4737442922398386\n",
      "Step: 7029 Weights: [0.35615984 2.13242061] , error: 0.47374429223982784\n",
      "Step: 7030 Weights: [0.35615985 2.13242061] , error: 0.4737442922398167\n",
      "Step: 7031 Weights: [0.35615986 2.13242061] , error: 0.47374429223980585\n",
      "Step: 7032 Weights: [0.35615987 2.13242061] , error: 0.473744292239795\n",
      "Step: 7033 Weights: [0.35615988 2.13242061] , error: 0.47374429223978465\n",
      "Step: 7034 Weights: [0.35615989 2.13242061] , error: 0.4737442922397739\n",
      "Step: 7035 Weights: [0.3561599 2.1324206] , error: 0.4737442922397629\n",
      "Step: 7036 Weights: [0.35615991 2.1324206 ] , error: 0.47374429223975256\n",
      "Step: 7037 Weights: [0.35615992 2.1324206 ] , error: 0.47374429223974224\n",
      "Step: 7038 Weights: [0.35615993 2.1324206 ] , error: 0.4737442922397318\n",
      "Step: 7039 Weights: [0.35615994 2.1324206 ] , error: 0.4737442922397207\n",
      "Step: 7040 Weights: [0.35615995 2.1324206 ] , error: 0.473744292239711\n",
      "Step: 7041 Weights: [0.35615996 2.1324206 ] , error: 0.47374429223969994\n",
      "Step: 7042 Weights: [0.35615997 2.1324206 ] , error: 0.4737442922396899\n",
      "Step: 7043 Weights: [0.35615998 2.13242059] , error: 0.4737442922396796\n",
      "Step: 7044 Weights: [0.35615999 2.13242059] , error: 0.47374429223966924\n",
      "Step: 7045 Weights: [0.35616    2.13242059] , error: 0.4737442922396595\n",
      "Step: 7046 Weights: [0.35616001 2.13242059] , error: 0.47374429223965\n",
      "Step: 7047 Weights: [0.35616002 2.13242059] , error: 0.47374429223963943\n",
      "Step: 7048 Weights: [0.35616003 2.13242059] , error: 0.47374429223962977\n",
      "Step: 7049 Weights: [0.35616004 2.13242059] , error: 0.47374429223961945\n",
      "Step: 7050 Weights: [0.35616005 2.13242059] , error: 0.47374429223960984\n",
      "Step: 7051 Weights: [0.35616006 2.13242059] , error: 0.47374429223959924\n",
      "Step: 7052 Weights: [0.35616007 2.13242058] , error: 0.47374429223959025\n",
      "Step: 7053 Weights: [0.35616008 2.13242058] , error: 0.4737442922395805\n",
      "Step: 7054 Weights: [0.35616009 2.13242058] , error: 0.47374429223957004\n",
      "Step: 7055 Weights: [0.3561601  2.13242058] , error: 0.47374429223956116\n",
      "Step: 7056 Weights: [0.35616011 2.13242058] , error: 0.47374429223955083\n",
      "Step: 7057 Weights: [0.35616012 2.13242058] , error: 0.4737442922395409\n",
      "Step: 7058 Weights: [0.35616013 2.13242058] , error: 0.4737442922395319\n",
      "Step: 7059 Weights: [0.35616014 2.13242058] , error: 0.47374429223952297\n",
      "Step: 7060 Weights: [0.35616015 2.13242058] , error: 0.4737442922395128\n",
      "Step: 7061 Weights: [0.35616016 2.13242057] , error: 0.4737442922395032\n",
      "Step: 7062 Weights: [0.35616017 2.13242057] , error: 0.47374429223949416\n",
      "Step: 7063 Weights: [0.35616018 2.13242057] , error: 0.47374429223948494\n",
      "Step: 7064 Weights: [0.35616019 2.13242057] , error: 0.47374429223947556\n",
      "Step: 7065 Weights: [0.3561602  2.13242057] , error: 0.47374429223946624\n",
      "Step: 7066 Weights: [0.35616021 2.13242057] , error: 0.47374429223945685\n",
      "Step: 7067 Weights: [0.35616022 2.13242057] , error: 0.473744292239448\n",
      "Step: 7068 Weights: [0.35616023 2.13242057] , error: 0.47374429223943815\n",
      "Step: 7069 Weights: [0.35616024 2.13242057] , error: 0.4737442922394293\n",
      "Step: 7070 Weights: [0.35616025 2.13242056] , error: 0.4737442922394207\n",
      "Step: 7071 Weights: [0.35616026 2.13242056] , error: 0.4737442922394114\n",
      "Step: 7072 Weights: [0.35616026 2.13242056] , error: 0.47374429223940207\n",
      "Step: 7073 Weights: [0.35616027 2.13242056] , error: 0.47374429223939424\n",
      "Step: 7074 Weights: [0.35616028 2.13242056] , error: 0.473744292239385\n",
      "Step: 7075 Weights: [0.35616029 2.13242056] , error: 0.47374429223937564\n",
      "Step: 7076 Weights: [0.3561603  2.13242056] , error: 0.4737442922393671\n",
      "Step: 7077 Weights: [0.35616031 2.13242056] , error: 0.47374429223935877\n",
      "Step: 7078 Weights: [0.35616032 2.13242056] , error: 0.47374429223935033\n",
      "Step: 7079 Weights: [0.35616033 2.13242055] , error: 0.4737442922393402\n",
      "Step: 7080 Weights: [0.35616034 2.13242055] , error: 0.4737442922393322\n",
      "Step: 7081 Weights: [0.35616035 2.13242055] , error: 0.4737442922393238\n",
      "Step: 7082 Weights: [0.35616036 2.13242055] , error: 0.47374429223931525\n",
      "Step: 7083 Weights: [0.35616037 2.13242055] , error: 0.4737442922393064\n",
      "Step: 7084 Weights: [0.35616038 2.13242055] , error: 0.47374429223929865\n",
      "Step: 7085 Weights: [0.35616039 2.13242055] , error: 0.4737442922392895\n",
      "Step: 7086 Weights: [0.35616039 2.13242055] , error: 0.47374429223928094\n",
      "Step: 7087 Weights: [0.3561604  2.13242055] , error: 0.47374429223927284\n",
      "Step: 7088 Weights: [0.35616041 2.13242055] , error: 0.4737442922392645\n",
      "Step: 7089 Weights: [0.35616042 2.13242054] , error: 0.4737442922392559\n",
      "Step: 7090 Weights: [0.35616043 2.13242054] , error: 0.47374429223924763\n",
      "Step: 7091 Weights: [0.35616044 2.13242054] , error: 0.47374429223924003\n",
      "Step: 7092 Weights: [0.35616045 2.13242054] , error: 0.4737442922392321\n",
      "Step: 7093 Weights: [0.35616046 2.13242054] , error: 0.4737442922392237\n",
      "Step: 7094 Weights: [0.35616047 2.13242054] , error: 0.4737442922392146\n",
      "Step: 7095 Weights: [0.35616048 2.13242054] , error: 0.4737442922392065\n",
      "Step: 7096 Weights: [0.35616048 2.13242054] , error: 0.4737442922391996\n",
      "Step: 7097 Weights: [0.35616049 2.13242054] , error: 0.47374429223919146\n",
      "Step: 7098 Weights: [0.3561605  2.13242054] , error: 0.47374429223918324\n",
      "Step: 7099 Weights: [0.35616051 2.13242053] , error: 0.47374429223917514\n",
      "Step: 7100 Weights: [0.35616052 2.13242053] , error: 0.47374429223916736\n",
      "Step: 7101 Weights: [0.35616053 2.13242053] , error: 0.47374429223915937\n",
      "Step: 7102 Weights: [0.35616054 2.13242053] , error: 0.47374429223915154\n",
      "Step: 7103 Weights: [0.35616055 2.13242053] , error: 0.47374429223914366\n",
      "Step: 7104 Weights: [0.35616055 2.13242053] , error: 0.47374429223913567\n",
      "Step: 7105 Weights: [0.35616056 2.13242053] , error: 0.4737442922391285\n",
      "Step: 7106 Weights: [0.35616057 2.13242053] , error: 0.47374429223912096\n",
      "Step: 7107 Weights: [0.35616058 2.13242053] , error: 0.4737442922391131\n",
      "Step: 7108 Weights: [0.35616059 2.13242053] , error: 0.4737442922391055\n",
      "Step: 7109 Weights: [0.3561606  2.13242052] , error: 0.4737442922390981\n",
      "Step: 7110 Weights: [0.35616061 2.13242052] , error: 0.47374429223909087\n",
      "Step: 7111 Weights: [0.35616062 2.13242052] , error: 0.4737442922390835\n",
      "Step: 7112 Weights: [0.35616062 2.13242052] , error: 0.4737442922390747\n",
      "Step: 7113 Weights: [0.35616063 2.13242052] , error: 0.47374429223906783\n",
      "Step: 7114 Weights: [0.35616064 2.13242052] , error: 0.4737442922390609\n",
      "Step: 7115 Weights: [0.35616065 2.13242052] , error: 0.47374429223905334\n",
      "Step: 7116 Weights: [0.35616066 2.13242052] , error: 0.4737442922390466\n",
      "Step: 7117 Weights: [0.35616067 2.13242052] , error: 0.4737442922390383\n",
      "Step: 7118 Weights: [0.35616068 2.13242052] , error: 0.47374429223903186\n",
      "Step: 7119 Weights: [0.35616068 2.13242051] , error: 0.4737442922390245\n",
      "Step: 7120 Weights: [0.35616069 2.13242051] , error: 0.4737442922390165\n",
      "Step: 7121 Weights: [0.3561607  2.13242051] , error: 0.47374429223900943\n",
      "Step: 7122 Weights: [0.35616071 2.13242051] , error: 0.47374429223900233\n",
      "Step: 7123 Weights: [0.35616072 2.13242051] , error: 0.4737442922389957\n",
      "Step: 7124 Weights: [0.35616073 2.13242051] , error: 0.47374429223898884\n",
      "Step: 7125 Weights: [0.35616073 2.13242051] , error: 0.4737442922389815\n",
      "Step: 7126 Weights: [0.35616074 2.13242051] , error: 0.4737442922389741\n",
      "Step: 7127 Weights: [0.35616075 2.13242051] , error: 0.47374429223896725\n",
      "Step: 7128 Weights: [0.35616076 2.13242051] , error: 0.4737442922389603\n",
      "Step: 7129 Weights: [0.35616077 2.1324205 ] , error: 0.4737442922389532\n",
      "Step: 7130 Weights: [0.35616078 2.1324205 ] , error: 0.47374429223894676\n",
      "Step: 7131 Weights: [0.35616078 2.1324205 ] , error: 0.4737442922389399\n",
      "Step: 7132 Weights: [0.35616079 2.1324205 ] , error: 0.4737442922389328\n",
      "Step: 7133 Weights: [0.3561608 2.1324205] , error: 0.4737442922389259\n",
      "Step: 7134 Weights: [0.35616081 2.1324205 ] , error: 0.47374429223892\n",
      "Step: 7135 Weights: [0.35616082 2.1324205 ] , error: 0.47374429223891257\n",
      "Step: 7136 Weights: [0.35616082 2.1324205 ] , error: 0.47374429223890596\n",
      "Step: 7137 Weights: [0.35616083 2.1324205 ] , error: 0.47374429223889936\n",
      "Step: 7138 Weights: [0.35616084 2.1324205 ] , error: 0.4737442922388926\n",
      "Step: 7139 Weights: [0.35616085 2.1324205 ] , error: 0.4737442922388855\n",
      "Step: 7140 Weights: [0.35616086 2.13242049] , error: 0.4737442922388797\n",
      "Step: 7141 Weights: [0.35616087 2.13242049] , error: 0.4737442922388724\n",
      "Step: 7142 Weights: [0.35616087 2.13242049] , error: 0.47374429223886616\n",
      "Step: 7143 Weights: [0.35616088 2.13242049] , error: 0.4737442922388592\n",
      "Step: 7144 Weights: [0.35616089 2.13242049] , error: 0.4737442922388536\n",
      "Step: 7145 Weights: [0.3561609  2.13242049] , error: 0.4737442922388473\n",
      "Step: 7146 Weights: [0.3561609  2.13242049] , error: 0.47374429223884074\n",
      "Step: 7147 Weights: [0.35616091 2.13242049] , error: 0.473744292238835\n",
      "Step: 7148 Weights: [0.35616092 2.13242049] , error: 0.4737442922388284\n",
      "Step: 7149 Weights: [0.35616093 2.13242049] , error: 0.473744292238822\n",
      "Step: 7150 Weights: [0.35616094 2.13242049] , error: 0.473744292238816\n",
      "Step: 7151 Weights: [0.35616094 2.13242048] , error: 0.47374429223880915\n",
      "Step: 7152 Weights: [0.35616095 2.13242048] , error: 0.4737442922388029\n",
      "Step: 7153 Weights: [0.35616096 2.13242048] , error: 0.47374429223879727\n",
      "Step: 7154 Weights: [0.35616097 2.13242048] , error: 0.4737442922387904\n",
      "Step: 7155 Weights: [0.35616098 2.13242048] , error: 0.4737442922387842\n",
      "Step: 7156 Weights: [0.35616098 2.13242048] , error: 0.47374429223877806\n",
      "Step: 7157 Weights: [0.35616099 2.13242048] , error: 0.4737442922387718\n",
      "Step: 7158 Weights: [0.356161   2.13242048] , error: 0.473744292238766\n",
      "Step: 7159 Weights: [0.35616101 2.13242048] , error: 0.4737442922387596\n",
      "Step: 7160 Weights: [0.35616101 2.13242048] , error: 0.47374429223875414\n",
      "Step: 7161 Weights: [0.35616102 2.13242048] , error: 0.47374429223874776\n",
      "Step: 7162 Weights: [0.35616103 2.13242047] , error: 0.47374429223874254\n",
      "Step: 7163 Weights: [0.35616104 2.13242047] , error: 0.47374429223873704\n",
      "Step: 7164 Weights: [0.35616105 2.13242047] , error: 0.47374429223873027\n",
      "Step: 7165 Weights: [0.35616105 2.13242047] , error: 0.4737442922387247\n",
      "Step: 7166 Weights: [0.35616106 2.13242047] , error: 0.473744292238719\n",
      "Step: 7167 Weights: [0.35616107 2.13242047] , error: 0.4737442922387129\n",
      "Step: 7168 Weights: [0.35616108 2.13242047] , error: 0.4737442922387074\n",
      "Step: 7169 Weights: [0.35616108 2.13242047] , error: 0.47374429223870196\n",
      "Step: 7170 Weights: [0.35616109 2.13242047] , error: 0.4737442922386958\n",
      "Step: 7171 Weights: [0.3561611  2.13242047] , error: 0.47374429223868947\n",
      "Step: 7172 Weights: [0.35616111 2.13242047] , error: 0.47374429223868453\n",
      "Step: 7173 Weights: [0.35616111 2.13242047] , error: 0.47374429223867826\n",
      "Step: 7174 Weights: [0.35616112 2.13242046] , error: 0.47374429223867354\n",
      "Step: 7175 Weights: [0.35616113 2.13242046] , error: 0.47374429223866704\n",
      "Step: 7176 Weights: [0.35616114 2.13242046] , error: 0.4737442922386623\n",
      "Step: 7177 Weights: [0.35616114 2.13242046] , error: 0.4737442922386547\n",
      "Step: 7178 Weights: [0.35616115 2.13242046] , error: 0.4737442922386503\n",
      "Step: 7179 Weights: [0.35616116 2.13242046] , error: 0.47374429223864506\n",
      "Step: 7180 Weights: [0.35616116 2.13242046] , error: 0.4737442922386397\n",
      "Step: 7181 Weights: [0.35616117 2.13242046] , error: 0.4737442922386347\n",
      "Step: 7182 Weights: [0.35616118 2.13242046] , error: 0.4737442922386287\n",
      "Step: 7183 Weights: [0.35616119 2.13242046] , error: 0.47374429223862313\n",
      "Step: 7184 Weights: [0.35616119 2.13242046] , error: 0.47374429223861875\n",
      "Step: 7185 Weights: [0.3561612  2.13242046] , error: 0.47374429223861253\n",
      "Step: 7186 Weights: [0.35616121 2.13242045] , error: 0.4737442922386071\n",
      "Step: 7187 Weights: [0.35616122 2.13242045] , error: 0.4737442922386022\n",
      "Step: 7188 Weights: [0.35616122 2.13242045] , error: 0.4737442922385965\n",
      "Step: 7189 Weights: [0.35616123 2.13242045] , error: 0.4737442922385915\n",
      "Step: 7190 Weights: [0.35616124 2.13242045] , error: 0.47374429223858644\n",
      "Step: 7191 Weights: [0.35616124 2.13242045] , error: 0.47374429223858094\n",
      "Step: 7192 Weights: [0.35616125 2.13242045] , error: 0.47374429223857545\n",
      "Step: 7193 Weights: [0.35616126 2.13242045] , error: 0.4737442922385706\n",
      "Step: 7194 Weights: [0.35616127 2.13242045] , error: 0.47374429223856573\n",
      "Step: 7195 Weights: [0.35616127 2.13242045] , error: 0.4737442922385605\n",
      "Step: 7196 Weights: [0.35616128 2.13242045] , error: 0.4737442922385555\n",
      "Step: 7197 Weights: [0.35616129 2.13242045] , error: 0.4737442922385502\n",
      "Step: 7198 Weights: [0.35616129 2.13242044] , error: 0.47374429223854514\n",
      "Step: 7199 Weights: [0.3561613  2.13242044] , error: 0.4737442922385401\n",
      "Step: 7200 Weights: [0.35616131 2.13242044] , error: 0.4737442922385351\n",
      "Step: 7201 Weights: [0.35616132 2.13242044] , error: 0.47374429223853\n",
      "Step: 7202 Weights: [0.35616132 2.13242044] , error: 0.4737442922385251\n",
      "Step: 7203 Weights: [0.35616133 2.13242044] , error: 0.4737442922385198\n",
      "Step: 7204 Weights: [0.35616134 2.13242044] , error: 0.47374429223851516\n",
      "Step: 7205 Weights: [0.35616134 2.13242044] , error: 0.4737442922385111\n",
      "Step: 7206 Weights: [0.35616135 2.13242044] , error: 0.4737442922385053\n",
      "Step: 7207 Weights: [0.35616136 2.13242044] , error: 0.4737442922385011\n",
      "Step: 7208 Weights: [0.35616136 2.13242044] , error: 0.4737442922384967\n",
      "Step: 7209 Weights: [0.35616137 2.13242044] , error: 0.47374429223849085\n",
      "Step: 7210 Weights: [0.35616138 2.13242044] , error: 0.4737442922384865\n",
      "Step: 7211 Weights: [0.35616138 2.13242043] , error: 0.4737442922384819\n",
      "Step: 7212 Weights: [0.35616139 2.13242043] , error: 0.47374429223847747\n",
      "Step: 7213 Weights: [0.3561614  2.13242043] , error: 0.4737442922384727\n",
      "Step: 7214 Weights: [0.35616141 2.13242043] , error: 0.4737442922384677\n",
      "Step: 7215 Weights: [0.35616141 2.13242043] , error: 0.4737442922384632\n",
      "Step: 7216 Weights: [0.35616142 2.13242043] , error: 0.4737442922384586\n",
      "Step: 7217 Weights: [0.35616143 2.13242043] , error: 0.4737442922384534\n",
      "Step: 7218 Weights: [0.35616143 2.13242043] , error: 0.47374429223844905\n",
      "Step: 7219 Weights: [0.35616144 2.13242043] , error: 0.4737442922384445\n",
      "Step: 7220 Weights: [0.35616145 2.13242043] , error: 0.47374429223843995\n",
      "Step: 7221 Weights: [0.35616145 2.13242043] , error: 0.4737442922384353\n",
      "Step: 7222 Weights: [0.35616146 2.13242043] , error: 0.47374429223843084\n",
      "Step: 7223 Weights: [0.35616147 2.13242043] , error: 0.4737442922384264\n",
      "Step: 7224 Weights: [0.35616147 2.13242042] , error: 0.473744292238422\n",
      "Step: 7225 Weights: [0.35616148 2.13242042] , error: 0.47374429223841774\n",
      "Step: 7226 Weights: [0.35616149 2.13242042] , error: 0.4737442922384133\n",
      "Step: 7227 Weights: [0.35616149 2.13242042] , error: 0.4737442922384085\n",
      "Step: 7228 Weights: [0.3561615  2.13242042] , error: 0.47374429223840425\n",
      "Step: 7229 Weights: [0.35616151 2.13242042] , error: 0.47374429223839976\n",
      "Step: 7230 Weights: [0.35616151 2.13242042] , error: 0.47374429223839537\n",
      "Step: 7231 Weights: [0.35616152 2.13242042] , error: 0.47374429223839076\n",
      "Step: 7232 Weights: [0.35616153 2.13242042] , error: 0.4737442922383873\n",
      "Step: 7233 Weights: [0.35616153 2.13242042] , error: 0.4737442922383826\n",
      "Step: 7234 Weights: [0.35616154 2.13242042] , error: 0.47374429223837844\n",
      "Step: 7235 Weights: [0.35616154 2.13242042] , error: 0.4737442922383735\n",
      "Step: 7236 Weights: [0.35616155 2.13242042] , error: 0.47374429223836945\n",
      "Step: 7237 Weights: [0.35616156 2.13242041] , error: 0.47374429223836534\n",
      "Step: 7238 Weights: [0.35616156 2.13242041] , error: 0.47374429223836156\n",
      "Step: 7239 Weights: [0.35616157 2.13242041] , error: 0.4737442922383573\n",
      "Step: 7240 Weights: [0.35616158 2.13242041] , error: 0.4737442922383528\n",
      "Step: 7241 Weights: [0.35616158 2.13242041] , error: 0.4737442922383488\n",
      "Step: 7242 Weights: [0.35616159 2.13242041] , error: 0.4737442922383447\n",
      "Step: 7243 Weights: [0.3561616  2.13242041] , error: 0.47374429223834036\n",
      "Step: 7244 Weights: [0.3561616  2.13242041] , error: 0.47374429223833603\n",
      "Step: 7245 Weights: [0.35616161 2.13242041] , error: 0.47374429223833237\n",
      "Step: 7246 Weights: [0.35616161 2.13242041] , error: 0.47374429223832865\n",
      "Step: 7247 Weights: [0.35616162 2.13242041] , error: 0.4737442922383243\n",
      "Step: 7248 Weights: [0.35616163 2.13242041] , error: 0.4737442922383196\n",
      "Step: 7249 Weights: [0.35616163 2.13242041] , error: 0.4737442922383159\n",
      "Step: 7250 Weights: [0.35616164 2.13242041] , error: 0.4737442922383125\n",
      "Step: 7251 Weights: [0.35616165 2.1324204 ] , error: 0.4737442922383082\n",
      "Step: 7252 Weights: [0.35616165 2.1324204 ] , error: 0.47374429223830383\n",
      "Step: 7253 Weights: [0.35616166 2.1324204 ] , error: 0.47374429223830045\n",
      "Step: 7254 Weights: [0.35616167 2.1324204 ] , error: 0.4737442922382966\n",
      "Step: 7255 Weights: [0.35616167 2.1324204 ] , error: 0.47374429223829295\n",
      "Step: 7256 Weights: [0.35616168 2.1324204 ] , error: 0.4737442922382895\n",
      "Step: 7257 Weights: [0.35616168 2.1324204 ] , error: 0.4737442922382854\n",
      "Step: 7258 Weights: [0.35616169 2.1324204 ] , error: 0.47374429223828124\n",
      "Step: 7259 Weights: [0.3561617 2.1324204] , error: 0.47374429223827774\n",
      "Step: 7260 Weights: [0.3561617 2.1324204] , error: 0.4737442922382733\n",
      "Step: 7261 Weights: [0.35616171 2.1324204 ] , error: 0.47374429223826986\n",
      "Step: 7262 Weights: [0.35616171 2.1324204 ] , error: 0.4737442922382658\n",
      "Step: 7263 Weights: [0.35616172 2.1324204 ] , error: 0.4737442922382623\n",
      "Step: 7264 Weights: [0.35616173 2.1324204 ] , error: 0.47374429223825787\n",
      "Step: 7265 Weights: [0.35616173 2.13242039] , error: 0.47374429223825515\n",
      "Step: 7266 Weights: [0.35616174 2.13242039] , error: 0.4737442922382513\n",
      "Step: 7267 Weights: [0.35616174 2.13242039] , error: 0.4737442922382471\n",
      "Step: 7268 Weights: [0.35616175 2.13242039] , error: 0.47374429223824366\n",
      "Step: 7269 Weights: [0.35616176 2.13242039] , error: 0.47374429223823994\n",
      "Step: 7270 Weights: [0.35616176 2.13242039] , error: 0.47374429223823583\n",
      "Step: 7271 Weights: [0.35616177 2.13242039] , error: 0.4737442922382331\n",
      "Step: 7272 Weights: [0.35616177 2.13242039] , error: 0.47374429223822917\n",
      "Step: 7273 Weights: [0.35616178 2.13242039] , error: 0.4737442922382259\n",
      "Step: 7274 Weights: [0.35616179 2.13242039] , error: 0.47374429223822223\n",
      "Step: 7275 Weights: [0.35616179 2.13242039] , error: 0.47374429223821823\n",
      "Step: 7276 Weights: [0.3561618  2.13242039] , error: 0.4737442922382151\n",
      "Step: 7277 Weights: [0.3561618  2.13242039] , error: 0.4737442922382112\n",
      "Step: 7278 Weights: [0.35616181 2.13242039] , error: 0.473744292238208\n",
      "Step: 7279 Weights: [0.35616182 2.13242038] , error: 0.47374429223820413\n",
      "Step: 7280 Weights: [0.35616182 2.13242038] , error: 0.47374429223820086\n",
      "Step: 7281 Weights: [0.35616183 2.13242038] , error: 0.47374429223819736\n",
      "Step: 7282 Weights: [0.35616183 2.13242038] , error: 0.4737442922381945\n",
      "Step: 7283 Weights: [0.35616184 2.13242038] , error: 0.47374429223819015\n",
      "Step: 7284 Weights: [0.35616185 2.13242038] , error: 0.4737442922381876\n",
      "Step: 7285 Weights: [0.35616185 2.13242038] , error: 0.47374429223818376\n",
      "Step: 7286 Weights: [0.35616186 2.13242038] , error: 0.47374429223818054\n",
      "Step: 7287 Weights: [0.35616186 2.13242038] , error: 0.47374429223817704\n",
      "Step: 7288 Weights: [0.35616187 2.13242038] , error: 0.47374429223817366\n",
      "Step: 7289 Weights: [0.35616187 2.13242038] , error: 0.4737442922381698\n",
      "Step: 7290 Weights: [0.35616188 2.13242038] , error: 0.47374429223816733\n",
      "Step: 7291 Weights: [0.35616189 2.13242038] , error: 0.4737442922381641\n",
      "Step: 7292 Weights: [0.35616189 2.13242038] , error: 0.4737442922381609\n",
      "Step: 7293 Weights: [0.3561619  2.13242038] , error: 0.47374429223815656\n",
      "Step: 7294 Weights: [0.3561619  2.13242038] , error: 0.4737442922381542\n",
      "Step: 7295 Weights: [0.35616191 2.13242037] , error: 0.4737442922381507\n",
      "Step: 7296 Weights: [0.35616191 2.13242037] , error: 0.47374429223814823\n",
      "Step: 7297 Weights: [0.35616192 2.13242037] , error: 0.4737442922381459\n",
      "Step: 7298 Weights: [0.35616192 2.13242037] , error: 0.4737442922381413\n",
      "Step: 7299 Weights: [0.35616193 2.13242037] , error: 0.473744292238138\n",
      "Step: 7300 Weights: [0.35616194 2.13242037] , error: 0.47374429223813475\n",
      "Step: 7301 Weights: [0.35616194 2.13242037] , error: 0.4737442922381317\n",
      "Step: 7302 Weights: [0.35616195 2.13242037] , error: 0.4737442922381287\n",
      "Step: 7303 Weights: [0.35616195 2.13242037] , error: 0.4737442922381254\n",
      "Step: 7304 Weights: [0.35616196 2.13242037] , error: 0.4737442922381225\n",
      "Step: 7305 Weights: [0.35616196 2.13242037] , error: 0.4737442922381189\n",
      "Step: 7306 Weights: [0.35616197 2.13242037] , error: 0.47374429223811654\n",
      "Step: 7307 Weights: [0.35616197 2.13242037] , error: 0.47374429223811276\n",
      "Step: 7308 Weights: [0.35616198 2.13242037] , error: 0.4737442922381102\n",
      "Step: 7309 Weights: [0.35616199 2.13242037] , error: 0.47374429223810643\n",
      "Step: 7310 Weights: [0.35616199 2.13242036] , error: 0.4737442922381041\n",
      "Step: 7311 Weights: [0.356162   2.13242036] , error: 0.47374429223810066\n",
      "Step: 7312 Weights: [0.356162   2.13242036] , error: 0.47374429223809733\n",
      "Step: 7313 Weights: [0.35616201 2.13242036] , error: 0.47374429223809467\n",
      "Step: 7314 Weights: [0.35616201 2.13242036] , error: 0.47374429223809184\n",
      "Step: 7315 Weights: [0.35616202 2.13242036] , error: 0.47374429223808956\n",
      "Step: 7316 Weights: [0.35616202 2.13242036] , error: 0.4737442922380861\n",
      "Step: 7317 Weights: [0.35616203 2.13242036] , error: 0.473744292238083\n",
      "Step: 7318 Weights: [0.35616203 2.13242036] , error: 0.4737442922380801\n",
      "Step: 7319 Weights: [0.35616204 2.13242036] , error: 0.4737442922380766\n",
      "Step: 7320 Weights: [0.35616205 2.13242036] , error: 0.47374429223807457\n",
      "Step: 7321 Weights: [0.35616205 2.13242036] , error: 0.47374429223807185\n",
      "Step: 7322 Weights: [0.35616206 2.13242036] , error: 0.47374429223806913\n",
      "Step: 7323 Weights: [0.35616206 2.13242036] , error: 0.47374429223806586\n",
      "Step: 7324 Weights: [0.35616207 2.13242036] , error: 0.473744292238063\n",
      "Step: 7325 Weights: [0.35616207 2.13242036] , error: 0.47374429223806\n",
      "Step: 7326 Weights: [0.35616208 2.13242036] , error: 0.47374429223805736\n",
      "Step: 7327 Weights: [0.35616208 2.13242035] , error: 0.4737442922380549\n",
      "Step: 7328 Weights: [0.35616209 2.13242035] , error: 0.4737442922380519\n",
      "Step: 7329 Weights: [0.35616209 2.13242035] , error: 0.47374429223804915\n",
      "Step: 7330 Weights: [0.3561621  2.13242035] , error: 0.4737442922380468\n",
      "Step: 7331 Weights: [0.3561621  2.13242035] , error: 0.4737442922380435\n",
      "Step: 7332 Weights: [0.35616211 2.13242035] , error: 0.4737442922380411\n",
      "Step: 7333 Weights: [0.35616211 2.13242035] , error: 0.47374429223803816\n",
      "Step: 7334 Weights: [0.35616212 2.13242035] , error: 0.4737442922380349\n",
      "Step: 7335 Weights: [0.35616212 2.13242035] , error: 0.4737442922380324\n",
      "Step: 7336 Weights: [0.35616213 2.13242035] , error: 0.4737442922380303\n",
      "Step: 7337 Weights: [0.35616213 2.13242035] , error: 0.47374429223802716\n",
      "Step: 7338 Weights: [0.35616214 2.13242035] , error: 0.4737442922380249\n",
      "Step: 7339 Weights: [0.35616214 2.13242035] , error: 0.4737442922380213\n",
      "Step: 7340 Weights: [0.35616215 2.13242035] , error: 0.4737442922380188\n",
      "Step: 7341 Weights: [0.35616215 2.13242035] , error: 0.473744292238017\n",
      "Step: 7342 Weights: [0.35616216 2.13242035] , error: 0.47374429223801395\n",
      "Step: 7343 Weights: [0.35616216 2.13242035] , error: 0.4737442922380112\n",
      "Step: 7344 Weights: [0.35616217 2.13242034] , error: 0.4737442922380092\n",
      "Step: 7345 Weights: [0.35616218 2.13242034] , error: 0.4737442922380062\n",
      "Step: 7346 Weights: [0.35616218 2.13242034] , error: 0.4737442922380039\n",
      "Step: 7347 Weights: [0.35616219 2.13242034] , error: 0.47374429223800146\n",
      "Step: 7348 Weights: [0.35616219 2.13242034] , error: 0.4737442922379991\n",
      "Step: 7349 Weights: [0.3561622  2.13242034] , error: 0.4737442922379964\n",
      "Step: 7350 Weights: [0.3561622  2.13242034] , error: 0.47374429223799375\n",
      "Step: 7351 Weights: [0.35616221 2.13242034] , error: 0.47374429223799097\n",
      "Step: 7352 Weights: [0.35616221 2.13242034] , error: 0.47374429223798914\n",
      "Step: 7353 Weights: [0.35616222 2.13242034] , error: 0.47374429223798575\n",
      "Step: 7354 Weights: [0.35616222 2.13242034] , error: 0.47374429223798376\n",
      "Step: 7355 Weights: [0.35616222 2.13242034] , error: 0.47374429223798176\n",
      "Step: 7356 Weights: [0.35616223 2.13242034] , error: 0.4737442922379781\n",
      "Step: 7357 Weights: [0.35616223 2.13242034] , error: 0.47374429223797626\n",
      "Step: 7358 Weights: [0.35616224 2.13242034] , error: 0.4737442922379743\n",
      "Step: 7359 Weights: [0.35616224 2.13242034] , error: 0.4737442922379713\n",
      "Step: 7360 Weights: [0.35616225 2.13242034] , error: 0.47374429223796916\n",
      "Step: 7361 Weights: [0.35616225 2.13242033] , error: 0.4737442922379669\n",
      "Step: 7362 Weights: [0.35616226 2.13242033] , error: 0.47374429223796455\n",
      "Step: 7363 Weights: [0.35616226 2.13242033] , error: 0.4737442922379616\n",
      "Step: 7364 Weights: [0.35616227 2.13242033] , error: 0.4737442922379598\n",
      "Step: 7365 Weights: [0.35616227 2.13242033] , error: 0.47374429223795783\n",
      "Step: 7366 Weights: [0.35616228 2.13242033] , error: 0.4737442922379551\n",
      "Step: 7367 Weights: [0.35616228 2.13242033] , error: 0.47374429223795234\n",
      "Step: 7368 Weights: [0.35616229 2.13242033] , error: 0.4737442922379499\n",
      "Step: 7369 Weights: [0.35616229 2.13242033] , error: 0.473744292237948\n",
      "Step: 7370 Weights: [0.3561623  2.13242033] , error: 0.47374429223794623\n",
      "Step: 7371 Weights: [0.3561623  2.13242033] , error: 0.4737442922379437\n",
      "Step: 7372 Weights: [0.35616231 2.13242033] , error: 0.47374429223794073\n",
      "Step: 7373 Weights: [0.35616231 2.13242033] , error: 0.47374429223793885\n",
      "Step: 7374 Weights: [0.35616232 2.13242033] , error: 0.4737442922379368\n",
      "Step: 7375 Weights: [0.35616232 2.13242033] , error: 0.47374429223793446\n",
      "Step: 7376 Weights: [0.35616233 2.13242033] , error: 0.4737442922379324\n",
      "Step: 7377 Weights: [0.35616233 2.13242033] , error: 0.4737442922379292\n",
      "Step: 7378 Weights: [0.35616234 2.13242033] , error: 0.4737442922379272\n",
      "Step: 7379 Weights: [0.35616234 2.13242033] , error: 0.47374429223792514\n",
      "Step: 7380 Weights: [0.35616234 2.13242032] , error: 0.4737442922379237\n",
      "Step: 7381 Weights: [0.35616235 2.13242032] , error: 0.4737442922379205\n",
      "Step: 7382 Weights: [0.35616235 2.13242032] , error: 0.47374429223791875\n",
      "Step: 7383 Weights: [0.35616236 2.13242032] , error: 0.4737442922379168\n",
      "Step: 7384 Weights: [0.35616236 2.13242032] , error: 0.4737442922379147\n",
      "Step: 7385 Weights: [0.35616237 2.13242032] , error: 0.47374429223791226\n",
      "Step: 7386 Weights: [0.35616237 2.13242032] , error: 0.47374429223791165\n",
      "Step: 7387 Weights: [0.35616238 2.13242032] , error: 0.4737442922379086\n",
      "Step: 7388 Weights: [0.35616238 2.13242032] , error: 0.4737442922379056\n",
      "Step: 7389 Weights: [0.35616239 2.13242032] , error: 0.4737442922379039\n",
      "Step: 7390 Weights: [0.35616239 2.13242032] , error: 0.4737442922379015\n",
      "Step: 7391 Weights: [0.3561624  2.13242032] , error: 0.4737442922378993\n",
      "Step: 7392 Weights: [0.3561624  2.13242032] , error: 0.4737442922378976\n",
      "Step: 7393 Weights: [0.3561624  2.13242032] , error: 0.4737442922378956\n",
      "Step: 7394 Weights: [0.35616241 2.13242032] , error: 0.4737442922378934\n",
      "Step: 7395 Weights: [0.35616241 2.13242032] , error: 0.47374429223789166\n",
      "Step: 7396 Weights: [0.35616242 2.13242032] , error: 0.47374429223788944\n",
      "Step: 7397 Weights: [0.35616242 2.13242032] , error: 0.47374429223788767\n",
      "Step: 7398 Weights: [0.35616243 2.13242032] , error: 0.4737442922378849\n",
      "Step: 7399 Weights: [0.35616243 2.13242031] , error: 0.4737442922378834\n",
      "Step: 7400 Weights: [0.35616244 2.13242031] , error: 0.4737442922378815\n",
      "Step: 7401 Weights: [0.35616244 2.13242031] , error: 0.4737442922378795\n",
      "Step: 7402 Weights: [0.35616244 2.13242031] , error: 0.47374429223787723\n",
      "Step: 7403 Weights: [0.35616245 2.13242031] , error: 0.4737442922378755\n",
      "Step: 7404 Weights: [0.35616245 2.13242031] , error: 0.4737442922378734\n",
      "Step: 7405 Weights: [0.35616246 2.13242031] , error: 0.4737442922378713\n",
      "Step: 7406 Weights: [0.35616246 2.13242031] , error: 0.47374429223786907\n",
      "Step: 7407 Weights: [0.35616247 2.13242031] , error: 0.473744292237867\n",
      "Step: 7408 Weights: [0.35616247 2.13242031] , error: 0.4737442922378657\n",
      "Step: 7409 Weights: [0.35616248 2.13242031] , error: 0.4737442922378642\n",
      "Step: 7410 Weights: [0.35616248 2.13242031] , error: 0.47374429223786124\n",
      "Step: 7411 Weights: [0.35616248 2.13242031] , error: 0.47374429223785985\n",
      "Step: 7412 Weights: [0.35616249 2.13242031] , error: 0.4737442922378573\n",
      "Step: 7413 Weights: [0.35616249 2.13242031] , error: 0.47374429223785564\n",
      "Step: 7414 Weights: [0.3561625  2.13242031] , error: 0.4737442922378539\n",
      "Step: 7415 Weights: [0.3561625  2.13242031] , error: 0.4737442922378528\n",
      "Step: 7416 Weights: [0.35616251 2.13242031] , error: 0.47374429223785064\n",
      "Step: 7417 Weights: [0.35616251 2.13242031] , error: 0.4737442922378485\n",
      "Step: 7418 Weights: [0.35616251 2.13242031] , error: 0.47374429223784675\n",
      "Step: 7419 Weights: [0.35616252 2.1324203 ] , error: 0.4737442922378442\n",
      "Step: 7420 Weights: [0.35616252 2.1324203 ] , error: 0.4737442922378428\n",
      "Step: 7421 Weights: [0.35616253 2.1324203 ] , error: 0.473744292237841\n",
      "Step: 7422 Weights: [0.35616253 2.1324203 ] , error: 0.47374429223783954\n",
      "Step: 7423 Weights: [0.35616254 2.1324203 ] , error: 0.4737442922378375\n",
      "Step: 7424 Weights: [0.35616254 2.1324203 ] , error: 0.473744292237836\n",
      "Step: 7425 Weights: [0.35616254 2.1324203 ] , error: 0.4737442922378339\n",
      "Step: 7426 Weights: [0.35616255 2.1324203 ] , error: 0.4737442922378327\n",
      "Step: 7427 Weights: [0.35616255 2.1324203 ] , error: 0.4737442922378305\n",
      "Step: 7428 Weights: [0.35616256 2.1324203 ] , error: 0.47374429223782927\n",
      "Step: 7429 Weights: [0.35616256 2.1324203 ] , error: 0.47374429223782627\n",
      "Step: 7430 Weights: [0.35616256 2.1324203 ] , error: 0.47374429223782477\n",
      "Step: 7431 Weights: [0.35616257 2.1324203 ] , error: 0.4737442922378232\n",
      "Step: 7432 Weights: [0.35616257 2.1324203 ] , error: 0.4737442922378214\n",
      "Step: 7433 Weights: [0.35616258 2.1324203 ] , error: 0.47374429223782016\n",
      "Step: 7434 Weights: [0.35616258 2.1324203 ] , error: 0.473744292237818\n",
      "Step: 7435 Weights: [0.35616259 2.1324203 ] , error: 0.4737442922378149\n",
      "Step: 7436 Weights: [0.35616259 2.1324203 ] , error: 0.4737442922378148\n",
      "Step: 7437 Weights: [0.35616259 2.1324203 ] , error: 0.47374429223781356\n",
      "Step: 7438 Weights: [0.3561626 2.1324203] , error: 0.47374429223781134\n",
      "Step: 7439 Weights: [0.3561626 2.1324203] , error: 0.47374429223780984\n",
      "Step: 7440 Weights: [0.35616261 2.13242029] , error: 0.473744292237808\n",
      "Step: 7441 Weights: [0.35616261 2.13242029] , error: 0.4737442922378068\n",
      "Step: 7442 Weights: [0.35616261 2.13242029] , error: 0.47374429223780407\n",
      "Step: 7443 Weights: [0.35616262 2.13242029] , error: 0.47374429223780334\n",
      "Step: 7444 Weights: [0.35616262 2.13242029] , error: 0.4737442922378021\n",
      "Step: 7445 Weights: [0.35616263 2.13242029] , error: 0.4737442922377995\n",
      "Step: 7446 Weights: [0.35616263 2.13242029] , error: 0.4737442922377982\n",
      "Step: 7447 Weights: [0.35616263 2.13242029] , error: 0.4737442922377963\n",
      "Step: 7448 Weights: [0.35616264 2.13242029] , error: 0.47374429223779496\n",
      "Step: 7449 Weights: [0.35616264 2.13242029] , error: 0.4737442922377931\n",
      "Step: 7450 Weights: [0.35616265 2.13242029] , error: 0.47374429223779163\n",
      "Step: 7451 Weights: [0.35616265 2.13242029] , error: 0.47374429223778974\n",
      "Step: 7452 Weights: [0.35616265 2.13242029] , error: 0.47374429223778874\n",
      "Step: 7453 Weights: [0.35616266 2.13242029] , error: 0.47374429223778675\n",
      "Step: 7454 Weights: [0.35616266 2.13242029] , error: 0.47374429223778614\n",
      "Step: 7455 Weights: [0.35616267 2.13242029] , error: 0.473744292237784\n",
      "Step: 7456 Weights: [0.35616267 2.13242029] , error: 0.4737442922377826\n",
      "Step: 7457 Weights: [0.35616267 2.13242029] , error: 0.4737442922377809\n",
      "Step: 7458 Weights: [0.35616268 2.13242029] , error: 0.47374429223777903\n",
      "Step: 7459 Weights: [0.35616268 2.13242029] , error: 0.47374429223777814\n",
      "Step: 7460 Weights: [0.35616269 2.13242029] , error: 0.47374429223777603\n",
      "Step: 7461 Weights: [0.35616269 2.13242029] , error: 0.4737442922377749\n",
      "Step: 7462 Weights: [0.35616269 2.13242028] , error: 0.4737442922377732\n",
      "Step: 7463 Weights: [0.3561627  2.13242028] , error: 0.47374429223777126\n",
      "Step: 7464 Weights: [0.3561627  2.13242028] , error: 0.47374429223777015\n",
      "Step: 7465 Weights: [0.3561627  2.13242028] , error: 0.4737442922377685\n",
      "Step: 7466 Weights: [0.35616271 2.13242028] , error: 0.47374429223776715\n",
      "Step: 7467 Weights: [0.35616271 2.13242028] , error: 0.4737442922377661\n",
      "Step: 7468 Weights: [0.35616272 2.13242028] , error: 0.4737442922377642\n",
      "Step: 7469 Weights: [0.35616272 2.13242028] , error: 0.4737442922377626\n",
      "Step: 7470 Weights: [0.35616272 2.13242028] , error: 0.4737442922377606\n",
      "Step: 7471 Weights: [0.35616273 2.13242028] , error: 0.4737442922377597\n",
      "Step: 7472 Weights: [0.35616273 2.13242028] , error: 0.4737442922377587\n",
      "Step: 7473 Weights: [0.35616273 2.13242028] , error: 0.47374429223775694\n",
      "Step: 7474 Weights: [0.35616274 2.13242028] , error: 0.4737442922377558\n",
      "Step: 7475 Weights: [0.35616274 2.13242028] , error: 0.47374429223775466\n",
      "Step: 7476 Weights: [0.35616275 2.13242028] , error: 0.4737442922377527\n",
      "Step: 7477 Weights: [0.35616275 2.13242028] , error: 0.47374429223775155\n",
      "Step: 7478 Weights: [0.35616275 2.13242028] , error: 0.47374429223775016\n",
      "Step: 7479 Weights: [0.35616276 2.13242028] , error: 0.4737442922377483\n",
      "Step: 7480 Weights: [0.35616276 2.13242028] , error: 0.47374429223774756\n",
      "Step: 7481 Weights: [0.35616276 2.13242028] , error: 0.473744292237746\n",
      "Step: 7482 Weights: [0.35616277 2.13242028] , error: 0.4737442922377446\n",
      "Step: 7483 Weights: [0.35616277 2.13242028] , error: 0.47374429223774306\n",
      "Step: 7484 Weights: [0.35616278 2.13242028] , error: 0.4737442922377417\n",
      "Step: 7485 Weights: [0.35616278 2.13242027] , error: 0.4737442922377401\n",
      "Step: 7486 Weights: [0.35616278 2.13242027] , error: 0.4737442922377391\n",
      "Step: 7487 Weights: [0.35616279 2.13242027] , error: 0.4737442922377378\n",
      "Step: 7488 Weights: [0.35616279 2.13242027] , error: 0.47374429223773673\n",
      "Step: 7489 Weights: [0.35616279 2.13242027] , error: 0.4737442922377348\n",
      "Step: 7490 Weights: [0.3561628  2.13242027] , error: 0.4737442922377336\n",
      "Step: 7491 Weights: [0.3561628  2.13242027] , error: 0.4737442922377319\n",
      "Step: 7492 Weights: [0.3561628  2.13242027] , error: 0.4737442922377314\n",
      "Step: 7493 Weights: [0.35616281 2.13242027] , error: 0.4737442922377294\n",
      "Step: 7494 Weights: [0.35616281 2.13242027] , error: 0.4737442922377284\n",
      "Step: 7495 Weights: [0.35616282 2.13242027] , error: 0.47374429223772696\n",
      "Step: 7496 Weights: [0.35616282 2.13242027] , error: 0.4737442922377258\n",
      "Step: 7497 Weights: [0.35616282 2.13242027] , error: 0.4737442922377244\n",
      "Step: 7498 Weights: [0.35616283 2.13242027] , error: 0.4737442922377235\n",
      "Step: 7499 Weights: [0.35616283 2.13242027] , error: 0.4737442922377223\n",
      "Step: 7500 Weights: [0.35616283 2.13242027] , error: 0.47374429223772085\n",
      "Step: 7501 Weights: [0.35616284 2.13242027] , error: 0.47374429223771986\n",
      "Step: 7502 Weights: [0.35616284 2.13242027] , error: 0.4737442922377176\n",
      "Step: 7503 Weights: [0.35616284 2.13242027] , error: 0.473744292237717\n",
      "Step: 7504 Weights: [0.35616285 2.13242027] , error: 0.47374429223771486\n",
      "Step: 7505 Weights: [0.35616285 2.13242027] , error: 0.47374429223771397\n",
      "Step: 7506 Weights: [0.35616285 2.13242027] , error: 0.473744292237713\n",
      "Step: 7507 Weights: [0.35616286 2.13242027] , error: 0.4737442922377117\n",
      "Step: 7508 Weights: [0.35616286 2.13242027] , error: 0.47374429223771125\n",
      "Step: 7509 Weights: [0.35616286 2.13242027] , error: 0.47374429223770925\n",
      "Step: 7510 Weights: [0.35616287 2.13242026] , error: 0.47374429223770803\n",
      "Step: 7511 Weights: [0.35616287 2.13242026] , error: 0.4737442922377068\n",
      "Step: 7512 Weights: [0.35616288 2.13242026] , error: 0.47374429223770576\n",
      "Step: 7513 Weights: [0.35616288 2.13242026] , error: 0.47374429223770453\n",
      "Step: 7514 Weights: [0.35616288 2.13242026] , error: 0.47374429223770337\n",
      "Step: 7515 Weights: [0.35616289 2.13242026] , error: 0.4737442922377023\n",
      "Step: 7516 Weights: [0.35616289 2.13242026] , error: 0.4737442922377008\n",
      "Step: 7517 Weights: [0.35616289 2.13242026] , error: 0.4737442922377004\n",
      "Step: 7518 Weights: [0.3561629  2.13242026] , error: 0.47374429223769904\n",
      "Step: 7519 Weights: [0.3561629  2.13242026] , error: 0.473744292237697\n",
      "Step: 7520 Weights: [0.3561629  2.13242026] , error: 0.4737442922376966\n",
      "Step: 7521 Weights: [0.35616291 2.13242026] , error: 0.47374429223769476\n",
      "Step: 7522 Weights: [0.35616291 2.13242026] , error: 0.47374429223769443\n",
      "Step: 7523 Weights: [0.35616291 2.13242026] , error: 0.4737442922376934\n",
      "Step: 7524 Weights: [0.35616292 2.13242026] , error: 0.4737442922376919\n",
      "Step: 7525 Weights: [0.35616292 2.13242026] , error: 0.473744292237691\n",
      "Step: 7526 Weights: [0.35616292 2.13242026] , error: 0.4737442922376889\n",
      "Step: 7527 Weights: [0.35616293 2.13242026] , error: 0.47374429223768794\n",
      "Step: 7528 Weights: [0.35616293 2.13242026] , error: 0.4737442922376867\n",
      "Step: 7529 Weights: [0.35616293 2.13242026] , error: 0.47374429223768566\n",
      "Step: 7530 Weights: [0.35616294 2.13242026] , error: 0.4737442922376847\n",
      "Step: 7531 Weights: [0.35616294 2.13242026] , error: 0.4737442922376845\n",
      "Step: 7532 Weights: [0.35616294 2.13242026] , error: 0.47374429223768266\n",
      "Step: 7533 Weights: [0.35616295 2.13242026] , error: 0.47374429223768183\n",
      "Step: 7534 Weights: [0.35616295 2.13242026] , error: 0.47374429223768094\n",
      "Step: 7535 Weights: [0.35616295 2.13242026] , error: 0.4737442922376791\n",
      "Step: 7536 Weights: [0.35616296 2.13242025] , error: 0.4737442922376779\n",
      "Step: 7537 Weights: [0.35616296 2.13242025] , error: 0.47374429223767767\n",
      "Step: 7538 Weights: [0.35616296 2.13242025] , error: 0.4737442922376768\n",
      "Step: 7539 Weights: [0.35616297 2.13242025] , error: 0.47374429223767545\n",
      "Step: 7540 Weights: [0.35616297 2.13242025] , error: 0.47374429223767367\n",
      "Step: 7541 Weights: [0.35616297 2.13242025] , error: 0.4737442922376729\n",
      "Step: 7542 Weights: [0.35616298 2.13242025] , error: 0.47374429223767156\n",
      "Step: 7543 Weights: [0.35616298 2.13242025] , error: 0.4737442922376709\n",
      "Step: 7544 Weights: [0.35616298 2.13242025] , error: 0.47374429223766984\n",
      "Step: 7545 Weights: [0.35616298 2.13242025] , error: 0.473744292237669\n",
      "Step: 7546 Weights: [0.35616299 2.13242025] , error: 0.4737442922376678\n",
      "Step: 7547 Weights: [0.35616299 2.13242025] , error: 0.47374429223766634\n",
      "Step: 7548 Weights: [0.35616299 2.13242025] , error: 0.47374429223766573\n",
      "Step: 7549 Weights: [0.356163   2.13242025] , error: 0.473744292237665\n",
      "Step: 7550 Weights: [0.356163   2.13242025] , error: 0.473744292237664\n",
      "Step: 7551 Weights: [0.356163   2.13242025] , error: 0.4737442922376644\n",
      "Step: 7552 Weights: [0.35616301 2.13242025] , error: 0.4737442922376619\n",
      "Step: 7553 Weights: [0.35616301 2.13242025] , error: 0.47374429223766035\n",
      "Step: 7554 Weights: [0.35616301 2.13242025] , error: 0.47374429223765985\n",
      "Step: 7555 Weights: [0.35616302 2.13242025] , error: 0.4737442922376589\n",
      "Step: 7556 Weights: [0.35616302 2.13242025] , error: 0.47374429223765735\n",
      "Step: 7557 Weights: [0.35616302 2.13242025] , error: 0.47374429223765735\n",
      "Step: 7558 Weights: [0.35616303 2.13242025] , error: 0.4737442922376558\n",
      "Step: 7559 Weights: [0.35616303 2.13242025] , error: 0.4737442922376543\n",
      "Step: 7560 Weights: [0.35616303 2.13242025] , error: 0.4737442922376539\n",
      "Step: 7561 Weights: [0.35616303 2.13242025] , error: 0.47374429223765246\n",
      "Step: 7562 Weights: [0.35616304 2.13242025] , error: 0.4737442922376517\n",
      "Step: 7563 Weights: [0.35616304 2.13242024] , error: 0.4737442922376517\n",
      "Step: 7564 Weights: [0.35616304 2.13242024] , error: 0.4737442922376509\n",
      "Step: 7565 Weights: [0.35616305 2.13242024] , error: 0.4737442922376495\n",
      "Step: 7566 Weights: [0.35616305 2.13242024] , error: 0.4737442922376482\n",
      "Step: 7567 Weights: [0.35616305 2.13242024] , error: 0.47374429223764725\n",
      "Step: 7568 Weights: [0.35616306 2.13242024] , error: 0.47374429223764647\n",
      "Step: 7569 Weights: [0.35616306 2.13242024] , error: 0.47374429223764497\n",
      "Step: 7570 Weights: [0.35616306 2.13242024] , error: 0.47374429223764447\n",
      "Step: 7571 Weights: [0.35616307 2.13242024] , error: 0.47374429223764325\n",
      "Step: 7572 Weights: [0.35616307 2.13242024] , error: 0.47374429223764336\n",
      "Step: 7573 Weights: [0.35616307 2.13242024] , error: 0.4737442922376423\n",
      "Step: 7574 Weights: [0.35616307 2.13242024] , error: 0.4737442922376411\n",
      "Step: 7575 Weights: [0.35616308 2.13242024] , error: 0.4737442922376399\n",
      "Step: 7576 Weights: [0.35616308 2.13242024] , error: 0.47374429223763903\n",
      "Step: 7577 Weights: [0.35616308 2.13242024] , error: 0.47374429223763836\n",
      "Step: 7578 Weights: [0.35616309 2.13242024] , error: 0.4737442922376372\n",
      "Step: 7579 Weights: [0.35616309 2.13242024] , error: 0.4737442922376366\n",
      "Step: 7580 Weights: [0.35616309 2.13242024] , error: 0.47374429223763553\n",
      "Step: 7581 Weights: [0.3561631  2.13242024] , error: 0.47374429223763453\n",
      "Step: 7582 Weights: [0.3561631  2.13242024] , error: 0.47374429223763337\n",
      "Step: 7583 Weights: [0.3561631  2.13242024] , error: 0.4737442922376331\n",
      "Step: 7584 Weights: [0.3561631  2.13242024] , error: 0.4737442922376319\n",
      "Step: 7585 Weights: [0.35616311 2.13242024] , error: 0.47374429223763115\n",
      "Step: 7586 Weights: [0.35616311 2.13242024] , error: 0.4737442922376307\n",
      "Step: 7587 Weights: [0.35616311 2.13242024] , error: 0.4737442922376297\n",
      "Step: 7588 Weights: [0.35616312 2.13242024] , error: 0.4737442922376292\n",
      "Step: 7589 Weights: [0.35616312 2.13242024] , error: 0.47374429223762726\n",
      "Step: 7590 Weights: [0.35616312 2.13242024] , error: 0.47374429223762654\n",
      "Step: 7591 Weights: [0.35616312 2.13242024] , error: 0.47374429223762643\n",
      "Step: 7592 Weights: [0.35616313 2.13242024] , error: 0.4737442922376249\n",
      "Step: 7593 Weights: [0.35616313 2.13242023] , error: 0.4737442922376241\n",
      "Step: 7594 Weights: [0.35616313 2.13242023] , error: 0.47374429223762354\n",
      "Step: 7595 Weights: [0.35616314 2.13242023] , error: 0.4737442922376231\n",
      "Step: 7596 Weights: [0.35616314 2.13242023] , error: 0.4737442922376225\n",
      "Step: 7597 Weights: [0.35616314 2.13242023] , error: 0.4737442922376215\n",
      "Step: 7598 Weights: [0.35616314 2.13242023] , error: 0.47374429223762077\n",
      "Step: 7599 Weights: [0.35616315 2.13242023] , error: 0.4737442922376194\n",
      "Step: 7600 Weights: [0.35616315 2.13242023] , error: 0.47374429223761894\n",
      "Step: 7601 Weights: [0.35616315 2.13242023] , error: 0.47374429223761827\n",
      "Step: 7602 Weights: [0.35616316 2.13242023] , error: 0.473744292237617\n",
      "Step: 7603 Weights: [0.35616316 2.13242023] , error: 0.4737442922376164\n",
      "Step: 7604 Weights: [0.35616316 2.13242023] , error: 0.47374429223761577\n",
      "Step: 7605 Weights: [0.35616316 2.13242023] , error: 0.4737442922376148\n",
      "Step: 7606 Weights: [0.35616317 2.13242023] , error: 0.47374429223761416\n",
      "Step: 7607 Weights: [0.35616317 2.13242023] , error: 0.47374429223761316\n",
      "Step: 7608 Weights: [0.35616317 2.13242023] , error: 0.4737442922376127\n",
      "Step: 7609 Weights: [0.35616317 2.13242023] , error: 0.47374429223761155\n",
      "Step: 7610 Weights: [0.35616318 2.13242023] , error: 0.4737442922376104\n",
      "Step: 7611 Weights: [0.35616318 2.13242023] , error: 0.47374429223761\n",
      "Step: 7612 Weights: [0.35616318 2.13242023] , error: 0.4737442922376096\n",
      "Step: 7613 Weights: [0.35616319 2.13242023] , error: 0.4737442922376085\n",
      "Step: 7614 Weights: [0.35616319 2.13242023] , error: 0.47374429223760733\n",
      "Step: 7615 Weights: [0.35616319 2.13242023] , error: 0.47374429223760695\n",
      "Step: 7616 Weights: [0.35616319 2.13242023] , error: 0.47374429223760706\n",
      "Step: 7617 Weights: [0.3561632  2.13242023] , error: 0.4737442922376056\n",
      "Step: 7618 Weights: [0.3561632  2.13242023] , error: 0.4737442922376045\n",
      "Step: 7619 Weights: [0.3561632  2.13242023] , error: 0.47374429223760417\n",
      "Step: 7620 Weights: [0.3561632  2.13242023] , error: 0.4737442922376027\n",
      "Step: 7621 Weights: [0.35616321 2.13242023] , error: 0.4737442922376025\n",
      "Step: 7622 Weights: [0.35616321 2.13242023] , error: 0.47374429223760184\n",
      "Step: 7623 Weights: [0.35616321 2.13242023] , error: 0.473744292237601\n",
      "Step: 7624 Weights: [0.35616322 2.13242022] , error: 0.4737442922376007\n",
      "Step: 7625 Weights: [0.35616322 2.13242022] , error: 0.47374429223759995\n",
      "Step: 7626 Weights: [0.35616322 2.13242022] , error: 0.4737442922375998\n",
      "Step: 7627 Weights: [0.35616322 2.13242022] , error: 0.4737442922375983\n",
      "Step: 7628 Weights: [0.35616323 2.13242022] , error: 0.4737442922375978\n",
      "Step: 7629 Weights: [0.35616323 2.13242022] , error: 0.47374429223759723\n",
      "Step: 7630 Weights: [0.35616323 2.13242022] , error: 0.47374429223759595\n",
      "Step: 7631 Weights: [0.35616323 2.13242022] , error: 0.4737442922375957\n",
      "Step: 7632 Weights: [0.35616324 2.13242022] , error: 0.473744292237595\n",
      "Step: 7633 Weights: [0.35616324 2.13242022] , error: 0.47374429223759473\n",
      "Step: 7634 Weights: [0.35616324 2.13242022] , error: 0.47374429223759346\n",
      "Step: 7635 Weights: [0.35616324 2.13242022] , error: 0.47374429223759223\n",
      "Step: 7636 Weights: [0.35616325 2.13242022] , error: 0.47374429223759285\n",
      "Step: 7637 Weights: [0.35616325 2.13242022] , error: 0.47374429223759174\n",
      "Step: 7638 Weights: [0.35616325 2.13242022] , error: 0.4737442922375906\n",
      "Step: 7639 Weights: [0.35616325 2.13242022] , error: 0.47374429223758996\n",
      "Step: 7640 Weights: [0.35616326 2.13242022] , error: 0.4737442922375893\n",
      "Step: 7641 Weights: [0.35616326 2.13242022] , error: 0.4737442922375889\n",
      "Step: 7642 Weights: [0.35616326 2.13242022] , error: 0.47374429223758835\n",
      "Step: 7643 Weights: [0.35616327 2.13242022] , error: 0.4737442922375876\n",
      "Step: 7644 Weights: [0.35616327 2.13242022] , error: 0.47374429223758735\n",
      "Step: 7645 Weights: [0.35616327 2.13242022] , error: 0.47374429223758596\n",
      "Step: 7646 Weights: [0.35616327 2.13242022] , error: 0.47374429223758585\n",
      "Step: 7647 Weights: [0.35616328 2.13242022] , error: 0.4737442922375851\n",
      "Step: 7648 Weights: [0.35616328 2.13242022] , error: 0.47374429223758413\n",
      "Step: 7649 Weights: [0.35616328 2.13242022] , error: 0.4737442922375836\n",
      "Step: 7650 Weights: [0.35616328 2.13242022] , error: 0.47374429223758274\n",
      "Step: 7651 Weights: [0.35616329 2.13242022] , error: 0.4737442922375819\n",
      "Step: 7652 Weights: [0.35616329 2.13242022] , error: 0.47374429223758147\n",
      "Step: 7653 Weights: [0.35616329 2.13242022] , error: 0.4737442922375804\n",
      "Step: 7654 Weights: [0.35616329 2.13242022] , error: 0.4737442922375802\n",
      "Step: 7655 Weights: [0.3561633  2.13242022] , error: 0.47374429223757986\n",
      "Step: 7656 Weights: [0.3561633  2.13242022] , error: 0.4737442922375794\n",
      "Step: 7657 Weights: [0.3561633  2.13242022] , error: 0.4737442922375784\n",
      "Step: 7658 Weights: [0.3561633  2.13242021] , error: 0.47374429223757786\n",
      "Step: 7659 Weights: [0.35616331 2.13242021] , error: 0.47374429223757747\n",
      "Step: 7660 Weights: [0.35616331 2.13242021] , error: 0.4737442922375769\n",
      "Step: 7661 Weights: [0.35616331 2.13242021] , error: 0.47374429223757586\n",
      "Step: 7662 Weights: [0.35616331 2.13242021] , error: 0.47374429223757575\n",
      "Step: 7663 Weights: [0.35616332 2.13242021] , error: 0.47374429223757497\n",
      "Step: 7664 Weights: [0.35616332 2.13242021] , error: 0.47374429223757436\n",
      "Step: 7665 Weights: [0.35616332 2.13242021] , error: 0.47374429223757397\n",
      "Step: 7666 Weights: [0.35616332 2.13242021] , error: 0.4737442922375733\n",
      "Step: 7667 Weights: [0.35616332 2.13242021] , error: 0.4737442922375724\n",
      "Step: 7668 Weights: [0.35616333 2.13242021] , error: 0.4737442922375713\n",
      "Step: 7669 Weights: [0.35616333 2.13242021] , error: 0.4737442922375713\n",
      "Step: 7670 Weights: [0.35616333 2.13242021] , error: 0.47374429223757053\n",
      "Step: 7671 Weights: [0.35616333 2.13242021] , error: 0.47374429223756953\n",
      "Step: 7672 Weights: [0.35616334 2.13242021] , error: 0.47374429223756964\n",
      "Step: 7673 Weights: [0.35616334 2.13242021] , error: 0.47374429223756853\n",
      "Step: 7674 Weights: [0.35616334 2.13242021] , error: 0.4737442922375681\n",
      "Step: 7675 Weights: [0.35616334 2.13242021] , error: 0.4737442922375675\n",
      "Step: 7676 Weights: [0.35616335 2.13242021] , error: 0.4737442922375671\n",
      "Step: 7677 Weights: [0.35616335 2.13242021] , error: 0.4737442922375672\n",
      "Step: 7678 Weights: [0.35616335 2.13242021] , error: 0.4737442922375654\n",
      "Step: 7679 Weights: [0.35616335 2.13242021] , error: 0.4737442922375655\n",
      "Step: 7680 Weights: [0.35616336 2.13242021] , error: 0.4737442922375644\n",
      "Step: 7681 Weights: [0.35616336 2.13242021] , error: 0.47374429223756426\n",
      "Step: 7682 Weights: [0.35616336 2.13242021] , error: 0.47374429223756426\n",
      "Step: 7683 Weights: [0.35616336 2.13242021] , error: 0.4737442922375634\n",
      "Step: 7684 Weights: [0.35616337 2.13242021] , error: 0.47374429223756304\n",
      "Step: 7685 Weights: [0.35616337 2.13242021] , error: 0.47374429223756165\n",
      "Step: 7686 Weights: [0.35616337 2.13242021] , error: 0.47374429223756176\n",
      "Step: 7687 Weights: [0.35616337 2.13242021] , error: 0.4737442922375616\n",
      "Step: 7688 Weights: [0.35616337 2.13242021] , error: 0.4737442922375605\n",
      "Step: 7689 Weights: [0.35616338 2.13242021] , error: 0.47374429223756\n",
      "Step: 7690 Weights: [0.35616338 2.13242021] , error: 0.4737442922375602\n",
      "Step: 7691 Weights: [0.35616338 2.13242021] , error: 0.47374429223755954\n",
      "Step: 7692 Weights: [0.35616338 2.13242021] , error: 0.4737442922375582\n",
      "Step: 7693 Weights: [0.35616339 2.13242021] , error: 0.47374429223755765\n",
      "Step: 7694 Weights: [0.35616339 2.13242021] , error: 0.47374429223755743\n",
      "Step: 7695 Weights: [0.35616339 2.1324202 ] , error: 0.473744292237557\n",
      "Step: 7696 Weights: [0.35616339 2.1324202 ] , error: 0.4737442922375566\n",
      "Step: 7697 Weights: [0.35616339 2.1324202 ] , error: 0.4737442922375559\n",
      "Step: 7698 Weights: [0.3561634 2.1324202] , error: 0.4737442922375552\n",
      "Step: 7699 Weights: [0.3561634 2.1324202] , error: 0.47374429223755526\n",
      "Step: 7700 Weights: [0.3561634 2.1324202] , error: 0.47374429223755404\n",
      "Step: 7701 Weights: [0.3561634 2.1324202] , error: 0.4737442922375544\n",
      "Step: 7702 Weights: [0.35616341 2.1324202 ] , error: 0.47374429223755304\n",
      "Step: 7703 Weights: [0.35616341 2.1324202 ] , error: 0.47374429223755227\n",
      "Step: 7704 Weights: [0.35616341 2.1324202 ] , error: 0.4737442922375527\n",
      "Step: 7705 Weights: [0.35616341 2.1324202 ] , error: 0.4737442922375521\n",
      "Step: 7706 Weights: [0.35616341 2.1324202 ] , error: 0.4737442922375515\n",
      "Step: 7707 Weights: [0.35616342 2.1324202 ] , error: 0.47374429223755143\n",
      "Step: 7708 Weights: [0.35616342 2.1324202 ] , error: 0.4737442922375499\n",
      "Step: 7709 Weights: [0.35616342 2.1324202 ] , error: 0.47374429223754966\n",
      "Step: 7710 Weights: [0.35616342 2.1324202 ] , error: 0.4737442922375495\n",
      "Step: 7711 Weights: [0.35616343 2.1324202 ] , error: 0.4737442922375491\n",
      "Step: 7712 Weights: [0.35616343 2.1324202 ] , error: 0.4737442922375482\n",
      "Step: 7713 Weights: [0.35616343 2.1324202 ] , error: 0.473744292237548\n",
      "Step: 7714 Weights: [0.35616343 2.1324202 ] , error: 0.47374429223754755\n",
      "Step: 7715 Weights: [0.35616343 2.1324202 ] , error: 0.4737442922375469\n",
      "Step: 7716 Weights: [0.35616344 2.1324202 ] , error: 0.4737442922375466\n",
      "Step: 7717 Weights: [0.35616344 2.1324202 ] , error: 0.4737442922375454\n",
      "Step: 7718 Weights: [0.35616344 2.1324202 ] , error: 0.47374429223754566\n",
      "Step: 7719 Weights: [0.35616344 2.1324202 ] , error: 0.4737442922375452\n",
      "Step: 7720 Weights: [0.35616345 2.1324202 ] , error: 0.47374429223754433\n",
      "Step: 7721 Weights: [0.35616345 2.1324202 ] , error: 0.4737442922375453\n",
      "Step: 7722 Weights: [0.35616345 2.1324202 ] , error: 0.47374429223754383\n",
      "Step: 7723 Weights: [0.35616345 2.1324202 ] , error: 0.47374429223754266\n",
      "Step: 7724 Weights: [0.35616345 2.1324202 ] , error: 0.47374429223754333\n",
      "Step: 7725 Weights: [0.35616346 2.1324202 ] , error: 0.4737442922375419\n",
      "Step: 7726 Weights: [0.35616346 2.1324202 ] , error: 0.47374429223754183\n",
      "Step: 7727 Weights: [0.35616346 2.1324202 ] , error: 0.4737442922375411\n",
      "Step: 7728 Weights: [0.35616346 2.1324202 ] , error: 0.4737442922375405\n",
      "Step: 7729 Weights: [0.35616346 2.1324202 ] , error: 0.47374429223754067\n",
      "Step: 7730 Weights: [0.35616347 2.1324202 ] , error: 0.4737442922375401\n",
      "Step: 7731 Weights: [0.35616347 2.1324202 ] , error: 0.4737442922375394\n",
      "Step: 7732 Weights: [0.35616347 2.1324202 ] , error: 0.47374429223753944\n",
      "Step: 7733 Weights: [0.35616347 2.1324202 ] , error: 0.47374429223753817\n",
      "Step: 7734 Weights: [0.35616347 2.1324202 ] , error: 0.4737442922375381\n",
      "Step: 7735 Weights: [0.35616348 2.1324202 ] , error: 0.47374429223753817\n",
      "Step: 7736 Weights: [0.35616348 2.13242019] , error: 0.47374429223753733\n",
      "Step: 7737 Weights: [0.35616348 2.13242019] , error: 0.47374429223753667\n",
      "Step: 7738 Weights: [0.35616348 2.13242019] , error: 0.4737442922375366\n",
      "Step: 7739 Weights: [0.35616349 2.13242019] , error: 0.47374429223753645\n",
      "Step: 7740 Weights: [0.35616349 2.13242019] , error: 0.4737442922375354\n",
      "Step: 7741 Weights: [0.35616349 2.13242019] , error: 0.47374429223753517\n",
      "Step: 7742 Weights: [0.35616349 2.13242019] , error: 0.4737442922375351\n",
      "Step: 7743 Weights: [0.35616349 2.13242019] , error: 0.4737442922375342\n",
      "Step: 7744 Weights: [0.3561635  2.13242019] , error: 0.4737442922375341\n",
      "Step: 7745 Weights: [0.3561635  2.13242019] , error: 0.4737442922375338\n",
      "Step: 7746 Weights: [0.3561635  2.13242019] , error: 0.4737442922375338\n",
      "Step: 7747 Weights: [0.3561635  2.13242019] , error: 0.47374429223753295\n",
      "Step: 7748 Weights: [0.3561635  2.13242019] , error: 0.47374429223753195\n",
      "Step: 7749 Weights: [0.35616351 2.13242019] , error: 0.4737442922375317\n",
      "Step: 7750 Weights: [0.35616351 2.13242019] , error: 0.4737442922375311\n",
      "Step: 7751 Weights: [0.35616351 2.13242019] , error: 0.47374429223753156\n",
      "Step: 7752 Weights: [0.35616351 2.13242019] , error: 0.47374429223753023\n",
      "Step: 7753 Weights: [0.35616351 2.13242019] , error: 0.47374429223753095\n",
      "Step: 7754 Weights: [0.35616352 2.13242019] , error: 0.47374429223753\n",
      "Step: 7755 Weights: [0.35616352 2.13242019] , error: 0.47374429223752973\n",
      "Step: 7756 Weights: [0.35616352 2.13242019] , error: 0.47374429223752956\n",
      "Step: 7757 Weights: [0.35616352 2.13242019] , error: 0.4737442922375287\n",
      "Step: 7758 Weights: [0.35616352 2.13242019] , error: 0.4737442922375281\n",
      "Step: 7759 Weights: [0.35616353 2.13242019] , error: 0.47374429223752834\n",
      "Step: 7760 Weights: [0.35616353 2.13242019] , error: 0.4737442922375282\n",
      "Step: 7761 Weights: [0.35616353 2.13242019] , error: 0.4737442922375267\n",
      "Step: 7762 Weights: [0.35616353 2.13242019] , error: 0.47374429223752673\n",
      "Step: 7763 Weights: [0.35616353 2.13242019] , error: 0.473744292237527\n",
      "Step: 7764 Weights: [0.35616354 2.13242019] , error: 0.4737442922375258\n",
      "Step: 7765 Weights: [0.35616354 2.13242019] , error: 0.47374429223752623\n",
      "Step: 7766 Weights: [0.35616354 2.13242019] , error: 0.47374429223752546\n",
      "Step: 7767 Weights: [0.35616354 2.13242019] , error: 0.473744292237525\n",
      "Step: 7768 Weights: [0.35616354 2.13242019] , error: 0.4737442922375249\n",
      "Step: 7769 Weights: [0.35616354 2.13242019] , error: 0.4737442922375245\n",
      "Step: 7770 Weights: [0.35616355 2.13242019] , error: 0.4737442922375241\n",
      "Step: 7771 Weights: [0.35616355 2.13242019] , error: 0.4737442922375239\n",
      "Step: 7772 Weights: [0.35616355 2.13242019] , error: 0.4737442922375228\n",
      "Step: 7773 Weights: [0.35616355 2.13242019] , error: 0.4737442922375224\n",
      "Step: 7774 Weights: [0.35616355 2.13242019] , error: 0.47374429223752207\n",
      "Step: 7775 Weights: [0.35616356 2.13242019] , error: 0.47374429223752174\n",
      "Step: 7776 Weights: [0.35616356 2.13242019] , error: 0.4737442922375215\n",
      "Step: 7777 Weights: [0.35616356 2.13242019] , error: 0.47374429223752146\n",
      "Step: 7778 Weights: [0.35616356 2.13242019] , error: 0.4737442922375207\n",
      "Step: 7779 Weights: [0.35616356 2.13242019] , error: 0.4737442922375203\n",
      "Step: 7780 Weights: [0.35616357 2.13242018] , error: 0.47374429223752024\n",
      "Step: 7781 Weights: [0.35616357 2.13242018] , error: 0.47374429223751957\n",
      "Step: 7782 Weights: [0.35616357 2.13242018] , error: 0.4737442922375195\n",
      "Step: 7783 Weights: [0.35616357 2.13242018] , error: 0.47374429223751957\n",
      "Step: 7784 Weights: [0.35616357 2.13242018] , error: 0.4737442922375184\n",
      "Step: 7785 Weights: [0.35616357 2.13242018] , error: 0.47374429223751835\n",
      "Step: 7786 Weights: [0.35616358 2.13242018] , error: 0.4737442922375181\n",
      "Step: 7787 Weights: [0.35616358 2.13242018] , error: 0.4737442922375183\n",
      "Step: 7788 Weights: [0.35616358 2.13242018] , error: 0.4737442922375176\n",
      "Step: 7789 Weights: [0.35616358 2.13242018] , error: 0.47374429223751713\n",
      "Step: 7790 Weights: [0.35616358 2.13242018] , error: 0.4737442922375168\n",
      "Step: 7791 Weights: [0.35616359 2.13242018] , error: 0.47374429223751585\n",
      "Step: 7792 Weights: [0.35616359 2.13242018] , error: 0.4737442922375165\n",
      "Step: 7793 Weights: [0.35616359 2.13242018] , error: 0.47374429223751524\n",
      "Step: 7794 Weights: [0.35616359 2.13242018] , error: 0.47374429223751513\n",
      "Step: 7795 Weights: [0.35616359 2.13242018] , error: 0.47374429223751485\n",
      "Step: 7796 Weights: [0.35616359 2.13242018] , error: 0.473744292237515\n",
      "Step: 7797 Weights: [0.3561636  2.13242018] , error: 0.4737442922375138\n",
      "Step: 7798 Weights: [0.3561636  2.13242018] , error: 0.47374429223751424\n",
      "Step: 7799 Weights: [0.3561636  2.13242018] , error: 0.47374429223751374\n",
      "Step: 7800 Weights: [0.3561636  2.13242018] , error: 0.47374429223751363\n",
      "Step: 7801 Weights: [0.3561636  2.13242018] , error: 0.473744292237513\n",
      "Step: 7802 Weights: [0.35616361 2.13242018] , error: 0.47374429223751297\n",
      "Step: 7803 Weights: [0.35616361 2.13242018] , error: 0.4737442922375128\n",
      "Step: 7804 Weights: [0.35616361 2.13242018] , error: 0.4737442922375121\n",
      "Step: 7805 Weights: [0.35616361 2.13242018] , error: 0.4737442922375119\n",
      "Step: 7806 Weights: [0.35616361 2.13242018] , error: 0.47374429223751147\n",
      "Step: 7807 Weights: [0.35616361 2.13242018] , error: 0.47374429223751113\n",
      "Step: 7808 Weights: [0.35616362 2.13242018] , error: 0.4737442922375105\n",
      "Step: 7809 Weights: [0.35616362 2.13242018] , error: 0.47374429223751036\n",
      "Step: 7810 Weights: [0.35616362 2.13242018] , error: 0.47374429223751013\n",
      "Step: 7811 Weights: [0.35616362 2.13242018] , error: 0.4737442922375102\n",
      "Step: 7812 Weights: [0.35616362 2.13242018] , error: 0.473744292237509\n",
      "Step: 7813 Weights: [0.35616362 2.13242018] , error: 0.47374429223751\n",
      "Step: 7814 Weights: [0.35616363 2.13242018] , error: 0.47374429223750936\n",
      "Step: 7815 Weights: [0.35616363 2.13242018] , error: 0.47374429223750913\n",
      "Step: 7816 Weights: [0.35616363 2.13242018] , error: 0.47374429223750797\n",
      "Step: 7817 Weights: [0.35616363 2.13242018] , error: 0.4737442922375088\n",
      "Step: 7818 Weights: [0.35616363 2.13242018] , error: 0.47374429223750747\n",
      "Step: 7819 Weights: [0.35616364 2.13242018] , error: 0.473744292237508\n",
      "Step: 7820 Weights: [0.35616364 2.13242018] , error: 0.4737442922375069\n",
      "Step: 7821 Weights: [0.35616364 2.13242018] , error: 0.47374429223750647\n",
      "Step: 7822 Weights: [0.35616364 2.13242018] , error: 0.4737442922375066\n",
      "Step: 7823 Weights: [0.35616364 2.13242018] , error: 0.47374429223750675\n",
      "Step: 7824 Weights: [0.35616364 2.13242018] , error: 0.4737442922375062\n",
      "Step: 7825 Weights: [0.35616365 2.13242018] , error: 0.4737442922375057\n",
      "Step: 7826 Weights: [0.35616365 2.13242018] , error: 0.4737442922375059\n",
      "Step: 7827 Weights: [0.35616365 2.13242018] , error: 0.4737442922375053\n",
      "Step: 7828 Weights: [0.35616365 2.13242018] , error: 0.473744292237505\n",
      "Step: 7829 Weights: [0.35616365 2.13242017] , error: 0.4737442922375042\n",
      "Step: 7830 Weights: [0.35616365 2.13242017] , error: 0.4737442922375049\n",
      "Step: 7831 Weights: [0.35616366 2.13242017] , error: 0.4737442922375036\n",
      "Step: 7832 Weights: [0.35616366 2.13242017] , error: 0.4737442922375039\n",
      "Step: 7833 Weights: [0.35616366 2.13242017] , error: 0.47374429223750336\n",
      "Step: 7834 Weights: [0.35616366 2.13242017] , error: 0.47374429223750275\n",
      "Step: 7835 Weights: [0.35616366 2.13242017] , error: 0.4737442922375035\n",
      "Step: 7836 Weights: [0.35616366 2.13242017] , error: 0.47374429223750353\n",
      "Step: 7837 Weights: [0.35616367 2.13242017] , error: 0.47374429223750253\n",
      "Step: 7838 Weights: [0.35616367 2.13242017] , error: 0.473744292237502\n",
      "Step: 7839 Weights: [0.35616367 2.13242017] , error: 0.47374429223750153\n",
      "Step: 7840 Weights: [0.35616367 2.13242017] , error: 0.47374429223750225\n",
      "Step: 7841 Weights: [0.35616367 2.13242017] , error: 0.473744292237502\n",
      "Step: 7842 Weights: [0.35616367 2.13242017] , error: 0.47374429223750114\n",
      "Step: 7843 Weights: [0.35616368 2.13242017] , error: 0.47374429223750075\n",
      "Step: 7844 Weights: [0.35616368 2.13242017] , error: 0.47374429223750036\n",
      "Step: 7845 Weights: [0.35616368 2.13242017] , error: 0.4737442922375002\n",
      "Step: 7846 Weights: [0.35616368 2.13242017] , error: 0.4737442922374998\n",
      "Step: 7847 Weights: [0.35616368 2.13242017] , error: 0.47374429223750025\n",
      "Step: 7848 Weights: [0.35616368 2.13242017] , error: 0.47374429223749887\n",
      "Step: 7849 Weights: [0.35616368 2.13242017] , error: 0.47374429223749964\n",
      "Step: 7850 Weights: [0.35616369 2.13242017] , error: 0.4737442922374991\n",
      "Step: 7851 Weights: [0.35616369 2.13242017] , error: 0.4737442922374987\n",
      "Step: 7852 Weights: [0.35616369 2.13242017] , error: 0.473744292237499\n",
      "Step: 7853 Weights: [0.35616369 2.13242017] , error: 0.47374429223749814\n",
      "Step: 7854 Weights: [0.35616369 2.13242017] , error: 0.4737442922374978\n",
      "Step: 7855 Weights: [0.35616369 2.13242017] , error: 0.47374429223749764\n",
      "Step: 7856 Weights: [0.3561637  2.13242017] , error: 0.4737442922374978\n",
      "Step: 7857 Weights: [0.3561637  2.13242017] , error: 0.47374429223749676\n",
      "Step: 7858 Weights: [0.3561637  2.13242017] , error: 0.4737442922374967\n",
      "Step: 7859 Weights: [0.3561637  2.13242017] , error: 0.47374429223749703\n",
      "Step: 7860 Weights: [0.3561637  2.13242017] , error: 0.47374429223749687\n",
      "Step: 7861 Weights: [0.3561637  2.13242017] , error: 0.4737442922374965\n",
      "Step: 7862 Weights: [0.35616371 2.13242017] , error: 0.47374429223749537\n",
      "Step: 7863 Weights: [0.35616371 2.13242017] , error: 0.47374429223749615\n",
      "Step: 7864 Weights: [0.35616371 2.13242017] , error: 0.4737442922374958\n",
      "Step: 7865 Weights: [0.35616371 2.13242017] , error: 0.4737442922374952\n",
      "Step: 7866 Weights: [0.35616371 2.13242017] , error: 0.47374429223749537\n",
      "Step: 7867 Weights: [0.35616371 2.13242017] , error: 0.47374429223749426\n",
      "Step: 7868 Weights: [0.35616371 2.13242017] , error: 0.4737442922374949\n",
      "Step: 7869 Weights: [0.35616372 2.13242017] , error: 0.4737442922374944\n",
      "Step: 7870 Weights: [0.35616372 2.13242017] , error: 0.47374429223749476\n",
      "Step: 7871 Weights: [0.35616372 2.13242017] , error: 0.4737442922374945\n",
      "Step: 7872 Weights: [0.35616372 2.13242017] , error: 0.47374429223749426\n",
      "Step: 7873 Weights: [0.35616372 2.13242017] , error: 0.47374429223749376\n",
      "Step: 7874 Weights: [0.35616372 2.13242017] , error: 0.47374429223749326\n",
      "Step: 7875 Weights: [0.35616372 2.13242017] , error: 0.47374429223749304\n",
      "Step: 7876 Weights: [0.35616373 2.13242017] , error: 0.47374429223749276\n",
      "Step: 7877 Weights: [0.35616373 2.13242017] , error: 0.473744292237493\n",
      "Step: 7878 Weights: [0.35616373 2.13242017] , error: 0.47374429223749237\n",
      "Step: 7879 Weights: [0.35616373 2.13242017] , error: 0.47374429223749204\n",
      "Step: 7880 Weights: [0.35616373 2.13242017] , error: 0.47374429223749176\n",
      "Step: 7881 Weights: [0.35616373 2.13242017] , error: 0.47374429223749115\n",
      "Step: 7882 Weights: [0.35616374 2.13242017] , error: 0.4737442922374917\n",
      "Step: 7883 Weights: [0.35616374 2.13242017] , error: 0.47374429223749126\n",
      "Step: 7884 Weights: [0.35616374 2.13242017] , error: 0.4737442922374907\n",
      "Step: 7885 Weights: [0.35616374 2.13242016] , error: 0.47374429223749137\n",
      "Step: 7886 Weights: [0.35616374 2.13242016] , error: 0.47374429223749026\n",
      "Step: 7887 Weights: [0.35616374 2.13242016] , error: 0.4737442922374906\n",
      "Step: 7888 Weights: [0.35616374 2.13242016] , error: 0.4737442922374901\n",
      "Step: 7889 Weights: [0.35616375 2.13242016] , error: 0.4737442922374901\n",
      "Step: 7890 Weights: [0.35616375 2.13242016] , error: 0.47374429223748954\n",
      "Step: 7891 Weights: [0.35616375 2.13242016] , error: 0.4737442922374894\n",
      "Step: 7892 Weights: [0.35616375 2.13242016] , error: 0.47374429223748926\n",
      "Step: 7893 Weights: [0.35616375 2.13242016] , error: 0.47374429223748865\n",
      "Step: 7894 Weights: [0.35616375 2.13242016] , error: 0.4737442922374886\n",
      "Step: 7895 Weights: [0.35616375 2.13242016] , error: 0.4737442922374882\n",
      "Step: 7896 Weights: [0.35616376 2.13242016] , error: 0.473744292237489\n",
      "Step: 7897 Weights: [0.35616376 2.13242016] , error: 0.4737442922374881\n",
      "Step: 7898 Weights: [0.35616376 2.13242016] , error: 0.4737442922374879\n",
      "Step: 7899 Weights: [0.35616376 2.13242016] , error: 0.47374429223748754\n",
      "Step: 7900 Weights: [0.35616376 2.13242016] , error: 0.47374429223748793\n",
      "Step: 7901 Weights: [0.35616376 2.13242016] , error: 0.473744292237487\n",
      "Step: 7902 Weights: [0.35616376 2.13242016] , error: 0.4737442922374874\n",
      "Step: 7903 Weights: [0.35616377 2.13242016] , error: 0.47374429223748693\n",
      "Step: 7904 Weights: [0.35616377 2.13242016] , error: 0.4737442922374874\n",
      "Step: 7905 Weights: [0.35616377 2.13242016] , error: 0.47374429223748715\n",
      "Step: 7906 Weights: [0.35616377 2.13242016] , error: 0.47374429223748604\n",
      "Step: 7907 Weights: [0.35616377 2.13242016] , error: 0.4737442922374861\n",
      "Step: 7908 Weights: [0.35616377 2.13242016] , error: 0.47374429223748576\n",
      "Step: 7909 Weights: [0.35616377 2.13242016] , error: 0.47374429223748565\n",
      "Step: 7910 Weights: [0.35616378 2.13242016] , error: 0.4737442922374854\n",
      "Step: 7911 Weights: [0.35616378 2.13242016] , error: 0.47374429223748526\n",
      "Step: 7912 Weights: [0.35616378 2.13242016] , error: 0.473744292237485\n",
      "Step: 7913 Weights: [0.35616378 2.13242016] , error: 0.47374429223748465\n",
      "Step: 7914 Weights: [0.35616378 2.13242016] , error: 0.47374429223748515\n",
      "Step: 7915 Weights: [0.35616378 2.13242016] , error: 0.47374429223748493\n",
      "Step: 7916 Weights: [0.35616378 2.13242016] , error: 0.4737442922374834\n",
      "Step: 7917 Weights: [0.35616379 2.13242016] , error: 0.47374429223748415\n",
      "Step: 7918 Weights: [0.35616379 2.13242016] , error: 0.4737442922374841\n",
      "Step: 7919 Weights: [0.35616379 2.13242016] , error: 0.4737442922374846\n",
      "Step: 7920 Weights: [0.35616379 2.13242016] , error: 0.4737442922374833\n",
      "Step: 7921 Weights: [0.35616379 2.13242016] , error: 0.473744292237483\n",
      "Step: 7922 Weights: [0.35616379 2.13242016] , error: 0.4737442922374828\n",
      "Step: 7923 Weights: [0.35616379 2.13242016] , error: 0.4737442922374835\n",
      "Step: 7924 Weights: [0.35616379 2.13242016] , error: 0.47374429223748254\n",
      "Step: 7925 Weights: [0.3561638  2.13242016] , error: 0.47374429223748293\n",
      "Step: 7926 Weights: [0.3561638  2.13242016] , error: 0.4737442922374823\n",
      "Step: 7927 Weights: [0.3561638  2.13242016] , error: 0.47374429223748243\n",
      "Step: 7928 Weights: [0.3561638  2.13242016] , error: 0.47374429223748193\n",
      "Step: 7929 Weights: [0.3561638  2.13242016] , error: 0.4737442922374822\n",
      "Step: 7930 Weights: [0.3561638  2.13242016] , error: 0.4737442922374822\n",
      "Step: 7931 Weights: [0.3561638  2.13242016] , error: 0.47374429223748143\n",
      "Step: 7932 Weights: [0.35616381 2.13242016] , error: 0.4737442922374816\n",
      "Step: 7933 Weights: [0.35616381 2.13242016] , error: 0.4737442922374821\n",
      "Step: 7934 Weights: [0.35616381 2.13242016] , error: 0.4737442922374797\n",
      "Step: 7935 Weights: [0.35616381 2.13242016] , error: 0.47374429223748116\n",
      "Step: 7936 Weights: [0.35616381 2.13242016] , error: 0.4737442922374806\n",
      "Step: 7937 Weights: [0.35616381 2.13242016] , error: 0.47374429223748094\n",
      "Step: 7938 Weights: [0.35616381 2.13242016] , error: 0.4737442922374804\n",
      "Step: 7939 Weights: [0.35616381 2.13242016] , error: 0.4737442922374807\n",
      "Step: 7940 Weights: [0.35616382 2.13242016] , error: 0.47374429223748027\n",
      "Step: 7941 Weights: [0.35616382 2.13242016] , error: 0.4737442922374802\n",
      "Step: 7942 Weights: [0.35616382 2.13242016] , error: 0.4737442922374798\n",
      "Step: 7943 Weights: [0.35616382 2.13242016] , error: 0.47374429223747977\n",
      "Step: 7944 Weights: [0.35616382 2.13242016] , error: 0.4737442922374792\n",
      "Step: 7945 Weights: [0.35616382 2.13242016] , error: 0.47374429223747877\n",
      "Step: 7946 Weights: [0.35616382 2.13242016] , error: 0.47374429223747916\n",
      "Step: 7947 Weights: [0.35616382 2.13242016] , error: 0.4737442922374797\n",
      "Step: 7948 Weights: [0.35616383 2.13242016] , error: 0.473744292237479\n",
      "Step: 7949 Weights: [0.35616383 2.13242015] , error: 0.4737442922374787\n",
      "Step: 7950 Weights: [0.35616383 2.13242015] , error: 0.4737442922374785\n",
      "Step: 7951 Weights: [0.35616383 2.13242015] , error: 0.4737442922374783\n",
      "Step: 7952 Weights: [0.35616383 2.13242015] , error: 0.4737442922374785\n",
      "Step: 7953 Weights: [0.35616383 2.13242015] , error: 0.47374429223747816\n",
      "Step: 7954 Weights: [0.35616383 2.13242015] , error: 0.4737442922374778\n",
      "Step: 7955 Weights: [0.35616383 2.13242015] , error: 0.47374429223747794\n",
      "Step: 7956 Weights: [0.35616384 2.13242015] , error: 0.473744292237477\n",
      "Step: 7957 Weights: [0.35616384 2.13242015] , error: 0.4737442922374768\n",
      "Step: 7958 Weights: [0.35616384 2.13242015] , error: 0.4737442922374774\n",
      "Step: 7959 Weights: [0.35616384 2.13242015] , error: 0.47374429223747777\n",
      "Step: 7960 Weights: [0.35616384 2.13242015] , error: 0.47374429223747705\n",
      "Step: 7961 Weights: [0.35616384 2.13242015] , error: 0.4737442922374767\n",
      "Step: 7962 Weights: [0.35616384 2.13242015] , error: 0.47374429223747616\n",
      "Step: 7963 Weights: [0.35616384 2.13242015] , error: 0.4737442922374767\n",
      "Step: 7964 Weights: [0.35616385 2.13242015] , error: 0.4737442922374769\n",
      "Step: 7965 Weights: [0.35616385 2.13242015] , error: 0.47374429223747583\n",
      "Step: 7966 Weights: [0.35616385 2.13242015] , error: 0.4737442922374753\n",
      "Step: 7967 Weights: [0.35616385 2.13242015] , error: 0.4737442922374761\n",
      "Step: 7968 Weights: [0.35616385 2.13242015] , error: 0.4737442922374757\n",
      "Step: 7969 Weights: [0.35616385 2.13242015] , error: 0.47374429223747583\n",
      "Step: 7970 Weights: [0.35616385 2.13242015] , error: 0.4737442922374754\n",
      "Step: 7971 Weights: [0.35616385 2.13242015] , error: 0.4737442922374764\n",
      "Step: 7972 Weights: [0.35616386 2.13242015] , error: 0.47374429223747516\n",
      "Step: 7973 Weights: [0.35616386 2.13242015] , error: 0.4737442922374745\n",
      "Step: 7974 Weights: [0.35616386 2.13242015] , error: 0.47374429223747505\n",
      "Step: 7975 Weights: [0.35616386 2.13242015] , error: 0.47374429223747405\n",
      "Step: 7976 Weights: [0.35616386 2.13242015] , error: 0.47374429223747483\n",
      "Step: 7977 Weights: [0.35616386 2.13242015] , error: 0.4737442922374745\n",
      "Step: 7978 Weights: [0.35616386 2.13242015] , error: 0.47374429223747455\n",
      "Step: 7979 Weights: [0.35616386 2.13242015] , error: 0.4737442922374744\n",
      "Step: 7980 Weights: [0.35616387 2.13242015] , error: 0.47374429223747433\n",
      "Step: 7981 Weights: [0.35616387 2.13242015] , error: 0.4737442922374745\n",
      "Step: 7982 Weights: [0.35616387 2.13242015] , error: 0.4737442922374734\n",
      "Step: 7983 Weights: [0.35616387 2.13242015] , error: 0.4737442922374743\n",
      "Step: 7984 Weights: [0.35616387 2.13242015] , error: 0.47374429223747366\n",
      "Step: 7985 Weights: [0.35616387 2.13242015] , error: 0.4737442922374734\n",
      "Step: 7986 Weights: [0.35616387 2.13242015] , error: 0.4737442922374733\n",
      "Step: 7987 Weights: [0.35616387 2.13242015] , error: 0.4737442922374733\n",
      "Step: 7988 Weights: [0.35616387 2.13242015] , error: 0.47374429223747394\n",
      "Step: 7989 Weights: [0.35616388 2.13242015] , error: 0.47374429223747316\n",
      "Step: 7990 Weights: [0.35616388 2.13242015] , error: 0.4737442922374724\n",
      "Step: 7991 Weights: [0.35616388 2.13242015] , error: 0.4737442922374709\n",
      "Step: 7992 Weights: [0.35616388 2.13242015] , error: 0.4737442922374721\n",
      "Step: 7993 Weights: [0.35616388 2.13242015] , error: 0.4737442922374725\n",
      "Step: 7994 Weights: [0.35616388 2.13242015] , error: 0.47374429223747244\n",
      "Step: 7995 Weights: [0.35616388 2.13242015] , error: 0.4737442922374725\n",
      "Step: 7996 Weights: [0.35616388 2.13242015] , error: 0.4737442922374718\n",
      "Step: 7997 Weights: [0.35616389 2.13242015] , error: 0.4737442922374717\n",
      "Step: 7998 Weights: [0.35616389 2.13242015] , error: 0.47374429223747194\n",
      "Step: 7999 Weights: [0.35616389 2.13242015] , error: 0.4737442922374716\n",
      "Step: 8000 Weights: [0.35616389 2.13242015] , error: 0.47374429223747105\n",
      "Step: 8001 Weights: [0.35616389 2.13242015] , error: 0.4737442922374711\n",
      "Step: 8002 Weights: [0.35616389 2.13242015] , error: 0.47374429223747083\n",
      "Step: 8003 Weights: [0.35616389 2.13242015] , error: 0.4737442922374707\n",
      "Step: 8004 Weights: [0.35616389 2.13242015] , error: 0.4737442922374708\n",
      "Step: 8005 Weights: [0.35616389 2.13242015] , error: 0.47374429223747005\n",
      "Step: 8006 Weights: [0.3561639  2.13242015] , error: 0.4737442922374707\n",
      "Step: 8007 Weights: [0.3561639  2.13242015] , error: 0.47374429223747017\n",
      "Step: 8008 Weights: [0.3561639  2.13242015] , error: 0.4737442922374703\n",
      "Step: 8009 Weights: [0.3561639  2.13242015] , error: 0.4737442922374704\n",
      "Step: 8010 Weights: [0.3561639  2.13242015] , error: 0.4737442922374697\n",
      "Step: 8011 Weights: [0.3561639  2.13242015] , error: 0.47374429223746983\n",
      "Step: 8012 Weights: [0.3561639  2.13242015] , error: 0.47374429223746983\n",
      "Step: 8013 Weights: [0.3561639  2.13242015] , error: 0.4737442922374699\n",
      "Step: 8014 Weights: [0.3561639  2.13242015] , error: 0.47374429223747\n",
      "Step: 8015 Weights: [0.35616391 2.13242015] , error: 0.4737442922374696\n",
      "Step: 8016 Weights: [0.35616391 2.13242015] , error: 0.47374429223746894\n",
      "Step: 8017 Weights: [0.35616391 2.13242015] , error: 0.4737442922374694\n",
      "Step: 8018 Weights: [0.35616391 2.13242015] , error: 0.473744292237469\n",
      "Step: 8019 Weights: [0.35616391 2.13242015] , error: 0.47374429223746856\n",
      "Step: 8020 Weights: [0.35616391 2.13242015] , error: 0.4737442922374685\n",
      "Step: 8021 Weights: [0.35616391 2.13242015] , error: 0.47374429223746806\n",
      "Step: 8022 Weights: [0.35616391 2.13242015] , error: 0.47374429223746817\n",
      "Step: 8023 Weights: [0.35616391 2.13242015] , error: 0.4737442922374683\n",
      "Step: 8024 Weights: [0.35616391 2.13242014] , error: 0.4737442922374677\n",
      "Step: 8025 Weights: [0.35616392 2.13242014] , error: 0.4737442922374677\n",
      "Step: 8026 Weights: [0.35616392 2.13242014] , error: 0.47374429223746795\n",
      "Step: 8027 Weights: [0.35616392 2.13242014] , error: 0.4737442922374686\n",
      "Step: 8028 Weights: [0.35616392 2.13242014] , error: 0.47374429223746767\n",
      "Step: 8029 Weights: [0.35616392 2.13242014] , error: 0.4737442922374683\n",
      "Step: 8030 Weights: [0.35616392 2.13242014] , error: 0.47374429223746806\n",
      "Step: 8031 Weights: [0.35616392 2.13242014] , error: 0.47374429223746783\n",
      "Step: 8032 Weights: [0.35616392 2.13242014] , error: 0.47374429223746767\n",
      "Step: 8033 Weights: [0.35616392 2.13242014] , error: 0.47374429223746717\n",
      "Step: 8034 Weights: [0.35616393 2.13242014] , error: 0.4737442922374667\n",
      "Step: 8035 Weights: [0.35616393 2.13242014] , error: 0.47374429223746717\n",
      "Step: 8036 Weights: [0.35616393 2.13242014] , error: 0.4737442922374668\n",
      "Step: 8037 Weights: [0.35616393 2.13242014] , error: 0.4737442922374665\n",
      "Step: 8038 Weights: [0.35616393 2.13242014] , error: 0.47374429223746656\n",
      "Step: 8039 Weights: [0.35616393 2.13242014] , error: 0.4737442922374666\n",
      "Step: 8040 Weights: [0.35616393 2.13242014] , error: 0.4737442922374664\n",
      "Step: 8041 Weights: [0.35616393 2.13242014] , error: 0.4737442922374662\n",
      "Step: 8042 Weights: [0.35616393 2.13242014] , error: 0.47374429223746645\n",
      "Step: 8043 Weights: [0.35616393 2.13242014] , error: 0.4737442922374658\n",
      "Step: 8044 Weights: [0.35616394 2.13242014] , error: 0.47374429223746584\n",
      "Step: 8045 Weights: [0.35616394 2.13242014] , error: 0.4737442922374662\n",
      "Step: 8046 Weights: [0.35616394 2.13242014] , error: 0.47374429223746617\n",
      "Step: 8047 Weights: [0.35616394 2.13242014] , error: 0.473744292237466\n",
      "Step: 8048 Weights: [0.35616394 2.13242014] , error: 0.47374429223746567\n",
      "Step: 8049 Weights: [0.35616394 2.13242014] , error: 0.47374429223746584\n",
      "Step: 8050 Weights: [0.35616394 2.13242014] , error: 0.4737442922374654\n",
      "Step: 8051 Weights: [0.35616394 2.13242014] , error: 0.4737442922374655\n",
      "Step: 8052 Weights: [0.35616394 2.13242014] , error: 0.47374429223746567\n",
      "Step: 8053 Weights: [0.35616394 2.13242014] , error: 0.47374429223746517\n",
      "Step: 8054 Weights: [0.35616395 2.13242014] , error: 0.47374429223746517\n",
      "Step: 8055 Weights: [0.35616395 2.13242014] , error: 0.4737442922374653\n",
      "Step: 8056 Weights: [0.35616395 2.13242014] , error: 0.47374429223746484\n",
      "Step: 8057 Weights: [0.35616395 2.13242014] , error: 0.47374429223746484\n",
      "Step: 8058 Weights: [0.35616395 2.13242014] , error: 0.4737442922374644\n",
      "Step: 8059 Weights: [0.35616395 2.13242014] , error: 0.4737442922374641\n",
      "Step: 8060 Weights: [0.35616395 2.13242014] , error: 0.4737442922374643\n",
      "Step: 8061 Weights: [0.35616395 2.13242014] , error: 0.4737442922374645\n",
      "Step: 8062 Weights: [0.35616395 2.13242014] , error: 0.47374429223746417\n",
      "Step: 8063 Weights: [0.35616395 2.13242014] , error: 0.47374429223746456\n",
      "Step: 8064 Weights: [0.35616396 2.13242014] , error: 0.47374429223746406\n",
      "Step: 8065 Weights: [0.35616396 2.13242014] , error: 0.47374429223746406\n",
      "Step: 8066 Weights: [0.35616396 2.13242014] , error: 0.4737442922374635\n",
      "Step: 8067 Weights: [0.35616396 2.13242014] , error: 0.47374429223746356\n",
      "Step: 8068 Weights: [0.35616396 2.13242014] , error: 0.47374429223746367\n",
      "Step: 8069 Weights: [0.35616396 2.13242014] , error: 0.47374429223746345\n",
      "Step: 8070 Weights: [0.35616396 2.13242014] , error: 0.47374429223746334\n",
      "Step: 8071 Weights: [0.35616396 2.13242014] , error: 0.47374429223746284\n",
      "Step: 8072 Weights: [0.35616396 2.13242014] , error: 0.47374429223746306\n",
      "Step: 8073 Weights: [0.35616396 2.13242014] , error: 0.4737442922374635\n",
      "Step: 8074 Weights: [0.35616397 2.13242014] , error: 0.4737442922374631\n",
      "Step: 8075 Weights: [0.35616397 2.13242014] , error: 0.4737442922374625\n",
      "Step: 8076 Weights: [0.35616397 2.13242014] , error: 0.4737442922374629\n",
      "Step: 8077 Weights: [0.35616397 2.13242014] , error: 0.473744292237463\n",
      "Step: 8078 Weights: [0.35616397 2.13242014] , error: 0.4737442922374626\n",
      "Step: 8079 Weights: [0.35616397 2.13242014] , error: 0.4737442922374625\n",
      "Step: 8080 Weights: [0.35616397 2.13242014] , error: 0.4737442922374623\n",
      "Step: 8081 Weights: [0.35616397 2.13242014] , error: 0.4737442922374627\n",
      "Step: 8082 Weights: [0.35616397 2.13242014] , error: 0.4737442922374621\n",
      "Step: 8083 Weights: [0.35616397 2.13242014] , error: 0.4737442922374622\n",
      "Step: 8084 Weights: [0.35616397 2.13242014] , error: 0.47374429223746234\n",
      "Step: 8085 Weights: [0.35616398 2.13242014] , error: 0.4737442922374623\n",
      "Step: 8086 Weights: [0.35616398 2.13242014] , error: 0.47374429223746234\n",
      "Step: 8087 Weights: [0.35616398 2.13242014] , error: 0.47374429223746195\n",
      "Step: 8088 Weights: [0.35616398 2.13242014] , error: 0.47374429223746184\n",
      "Step: 8089 Weights: [0.35616398 2.13242014] , error: 0.4737442922374612\n",
      "Step: 8090 Weights: [0.35616398 2.13242014] , error: 0.4737442922374614\n",
      "Step: 8091 Weights: [0.35616398 2.13242014] , error: 0.47374429223746173\n",
      "Step: 8092 Weights: [0.35616398 2.13242014] , error: 0.4737442922374618\n",
      "Step: 8093 Weights: [0.35616398 2.13242014] , error: 0.4737442922374617\n",
      "Step: 8094 Weights: [0.35616398 2.13242014] , error: 0.47374429223746184\n",
      "Step: 8095 Weights: [0.35616399 2.13242014] , error: 0.473744292237461\n",
      "Step: 8096 Weights: [0.35616399 2.13242014] , error: 0.47374429223746156\n",
      "Step: 8097 Weights: [0.35616399 2.13242014] , error: 0.4737442922374613\n",
      "Step: 8098 Weights: [0.35616399 2.13242014] , error: 0.47374429223746045\n",
      "Step: 8099 Weights: [0.35616399 2.13242014] , error: 0.47374429223746106\n",
      "Step: 8100 Weights: [0.35616399 2.13242014] , error: 0.4737442922374602\n",
      "Step: 8101 Weights: [0.35616399 2.13242014] , error: 0.47374429223746106\n",
      "Step: 8102 Weights: [0.35616399 2.13242014] , error: 0.47374429223746084\n",
      "Step: 8103 Weights: [0.35616399 2.13242014] , error: 0.47374429223746073\n",
      "Step: 8104 Weights: [0.35616399 2.13242014] , error: 0.4737442922374605\n",
      "Step: 8105 Weights: [0.35616399 2.13242014] , error: 0.47374429223746106\n",
      "Step: 8106 Weights: [0.35616399 2.13242014] , error: 0.4737442922374607\n",
      "Step: 8107 Weights: [0.356164   2.13242014] , error: 0.47374429223746\n",
      "Step: 8108 Weights: [0.356164   2.13242014] , error: 0.47374429223746006\n",
      "Step: 8109 Weights: [0.356164   2.13242014] , error: 0.4737442922374595\n",
      "Step: 8110 Weights: [0.356164   2.13242014] , error: 0.47374429223745995\n",
      "Step: 8111 Weights: [0.356164   2.13242014] , error: 0.47374429223746\n",
      "Step: 8112 Weights: [0.356164   2.13242014] , error: 0.47374429223746034\n",
      "Step: 8113 Weights: [0.356164   2.13242014] , error: 0.4737442922374601\n",
      "Step: 8114 Weights: [0.356164   2.13242013] , error: 0.4737442922374596\n",
      "Step: 8115 Weights: [0.356164   2.13242013] , error: 0.4737442922374603\n",
      "Step: 8116 Weights: [0.356164   2.13242013] , error: 0.47374429223746\n",
      "Step: 8117 Weights: [0.356164   2.13242013] , error: 0.47374429223745923\n",
      "Step: 8118 Weights: [0.35616401 2.13242013] , error: 0.47374429223745984\n",
      "Step: 8119 Weights: [0.35616401 2.13242013] , error: 0.47374429223745884\n",
      "Step: 8120 Weights: [0.35616401 2.13242013] , error: 0.4737442922374589\n",
      "Step: 8121 Weights: [0.35616401 2.13242013] , error: 0.4737442922374596\n",
      "Step: 8122 Weights: [0.35616401 2.13242013] , error: 0.4737442922374586\n",
      "Step: 8123 Weights: [0.35616401 2.13242013] , error: 0.47374429223745906\n",
      "Step: 8124 Weights: [0.35616401 2.13242013] , error: 0.47374429223745884\n",
      "Step: 8125 Weights: [0.35616401 2.13242013] , error: 0.4737442922374595\n",
      "Step: 8126 Weights: [0.35616401 2.13242013] , error: 0.4737442922374587\n",
      "Step: 8127 Weights: [0.35616401 2.13242013] , error: 0.4737442922374595\n",
      "Step: 8128 Weights: [0.35616401 2.13242013] , error: 0.4737442922374585\n",
      "Step: 8129 Weights: [0.35616401 2.13242013] , error: 0.47374429223745845\n",
      "Step: 8130 Weights: [0.35616402 2.13242013] , error: 0.47374429223745823\n",
      "Step: 8131 Weights: [0.35616402 2.13242013] , error: 0.47374429223745795\n",
      "Step: 8132 Weights: [0.35616402 2.13242013] , error: 0.4737442922374581\n",
      "Step: 8133 Weights: [0.35616402 2.13242013] , error: 0.4737442922374578\n",
      "Step: 8134 Weights: [0.35616402 2.13242013] , error: 0.47374429223745856\n",
      "Step: 8135 Weights: [0.35616402 2.13242013] , error: 0.47374429223745873\n",
      "Step: 8136 Weights: [0.35616402 2.13242013] , error: 0.4737442922374584\n",
      "Step: 8137 Weights: [0.35616402 2.13242013] , error: 0.47374429223745806\n",
      "Step: 8138 Weights: [0.35616402 2.13242013] , error: 0.4737442922374583\n",
      "Step: 8139 Weights: [0.35616402 2.13242013] , error: 0.4737442922374574\n",
      "Step: 8140 Weights: [0.35616402 2.13242013] , error: 0.4737442922374583\n",
      "Step: 8141 Weights: [0.35616402 2.13242013] , error: 0.47374429223745845\n",
      "Step: 8142 Weights: [0.35616403 2.13242013] , error: 0.4737442922374584\n",
      "Step: 8143 Weights: [0.35616403 2.13242013] , error: 0.47374429223745795\n",
      "Step: 8144 Weights: [0.35616403 2.13242013] , error: 0.47374429223745773\n",
      "Step: 8145 Weights: [0.35616403 2.13242013] , error: 0.47374429223745823\n",
      "Step: 8146 Weights: [0.35616403 2.13242013] , error: 0.4737442922374575\n",
      "Step: 8147 Weights: [0.35616403 2.13242013] , error: 0.47374429223745734\n",
      "Step: 8148 Weights: [0.35616403 2.13242013] , error: 0.4737442922374576\n",
      "Step: 8149 Weights: [0.35616403 2.13242013] , error: 0.4737442922374571\n",
      "Step: 8150 Weights: [0.35616403 2.13242013] , error: 0.47374429223745695\n",
      "Step: 8151 Weights: [0.35616403 2.13242013] , error: 0.47374429223745695\n",
      "Step: 8152 Weights: [0.35616403 2.13242013] , error: 0.4737442922374576\n",
      "Step: 8153 Weights: [0.35616403 2.13242013] , error: 0.47374429223745773\n",
      "Step: 8154 Weights: [0.35616404 2.13242013] , error: 0.4737442922374567\n",
      "Step: 8155 Weights: [0.35616404 2.13242013] , error: 0.4737442922374568\n",
      "Step: 8156 Weights: [0.35616404 2.13242013] , error: 0.47374429223745684\n",
      "Step: 8157 Weights: [0.35616404 2.13242013] , error: 0.473744292237457\n",
      "Step: 8158 Weights: [0.35616404 2.13242013] , error: 0.4737442922374564\n",
      "Step: 8159 Weights: [0.35616404 2.13242013] , error: 0.47374429223745673\n",
      "Step: 8160 Weights: [0.35616404 2.13242013] , error: 0.4737442922374564\n",
      "Step: 8161 Weights: [0.35616404 2.13242013] , error: 0.47374429223745707\n",
      "Step: 8162 Weights: [0.35616404 2.13242013] , error: 0.4737442922374563\n",
      "Step: 8163 Weights: [0.35616404 2.13242013] , error: 0.4737442922374567\n",
      "Step: 8164 Weights: [0.35616404 2.13242013] , error: 0.473744292237456\n",
      "Step: 8165 Weights: [0.35616404 2.13242013] , error: 0.473744292237456\n",
      "Step: 8166 Weights: [0.35616404 2.13242013] , error: 0.47374429223745584\n",
      "Step: 8167 Weights: [0.35616405 2.13242013] , error: 0.473744292237456\n",
      "Step: 8168 Weights: [0.35616405 2.13242013] , error: 0.47374429223745596\n",
      "Step: 8169 Weights: [0.35616405 2.13242013] , error: 0.47374429223745596\n",
      "Step: 8170 Weights: [0.35616405 2.13242013] , error: 0.4737442922374556\n",
      "Step: 8171 Weights: [0.35616405 2.13242013] , error: 0.47374429223745584\n",
      "Step: 8172 Weights: [0.35616405 2.13242013] , error: 0.4737442922374554\n",
      "Step: 8173 Weights: [0.35616405 2.13242013] , error: 0.4737442922374552\n",
      "Step: 8174 Weights: [0.35616405 2.13242013] , error: 0.47374429223745573\n",
      "Step: 8175 Weights: [0.35616405 2.13242013] , error: 0.47374429223745584\n",
      "Step: 8176 Weights: [0.35616405 2.13242013] , error: 0.47374429223745573\n",
      "Step: 8177 Weights: [0.35616405 2.13242013] , error: 0.4737442922374556\n",
      "Step: 8178 Weights: [0.35616405 2.13242013] , error: 0.47374429223745573\n",
      "Step: 8179 Weights: [0.35616405 2.13242013] , error: 0.4737442922374554\n",
      "Step: 8180 Weights: [0.35616406 2.13242013] , error: 0.4737442922374553\n",
      "Step: 8181 Weights: [0.35616406 2.13242013] , error: 0.47374429223745534\n",
      "Step: 8182 Weights: [0.35616406 2.13242013] , error: 0.4737442922374547\n",
      "Step: 8183 Weights: [0.35616406 2.13242013] , error: 0.4737442922374552\n",
      "Step: 8184 Weights: [0.35616406 2.13242013] , error: 0.4737442922374553\n",
      "Step: 8185 Weights: [0.35616406 2.13242013] , error: 0.4737442922374548\n",
      "Step: 8186 Weights: [0.35616406 2.13242013] , error: 0.47374429223745507\n",
      "Step: 8187 Weights: [0.35616406 2.13242013] , error: 0.4737442922374544\n",
      "Step: 8188 Weights: [0.35616406 2.13242013] , error: 0.47374429223745435\n",
      "Step: 8189 Weights: [0.35616406 2.13242013] , error: 0.4737442922374552\n",
      "Step: 8190 Weights: [0.35616406 2.13242013] , error: 0.47374429223745484\n",
      "Step: 8191 Weights: [0.35616406 2.13242013] , error: 0.473744292237455\n",
      "Step: 8192 Weights: [0.35616406 2.13242013] , error: 0.47374429223745457\n",
      "Step: 8193 Weights: [0.35616406 2.13242013] , error: 0.4737442922374548\n",
      "Step: 8194 Weights: [0.35616407 2.13242013] , error: 0.47374429223745473\n",
      "Step: 8195 Weights: [0.35616407 2.13242013] , error: 0.4737442922374544\n",
      "Step: 8196 Weights: [0.35616407 2.13242013] , error: 0.4737442922374545\n",
      "Step: 8197 Weights: [0.35616407 2.13242013] , error: 0.47374429223745385\n",
      "Step: 8198 Weights: [0.35616407 2.13242013] , error: 0.4737442922374541\n",
      "Step: 8199 Weights: [0.35616407 2.13242013] , error: 0.4737442922374539\n",
      "Step: 8200 Weights: [0.35616407 2.13242013] , error: 0.4737442922374535\n",
      "Step: 8201 Weights: [0.35616407 2.13242013] , error: 0.47374429223745373\n",
      "Step: 8202 Weights: [0.35616407 2.13242013] , error: 0.47374429223745435\n",
      "Step: 8203 Weights: [0.35616407 2.13242013] , error: 0.4737442922374534\n",
      "Step: 8204 Weights: [0.35616407 2.13242013] , error: 0.47374429223745407\n",
      "Step: 8205 Weights: [0.35616407 2.13242013] , error: 0.47374429223745335\n",
      "Step: 8206 Weights: [0.35616407 2.13242013] , error: 0.47374429223745457\n",
      "Step: 8207 Weights: [0.35616407 2.13242013] , error: 0.4737442922374537\n",
      "Step: 8208 Weights: [0.35616408 2.13242013] , error: 0.4737442922374536\n",
      "Step: 8209 Weights: [0.35616408 2.13242013] , error: 0.4737442922374541\n",
      "Step: 8210 Weights: [0.35616408 2.13242013] , error: 0.47374429223745407\n",
      "Step: 8211 Weights: [0.35616408 2.13242013] , error: 0.47374429223745357\n",
      "Step: 8212 Weights: [0.35616408 2.13242013] , error: 0.47374429223745307\n",
      "Step: 8213 Weights: [0.35616408 2.13242013] , error: 0.4737442922374533\n",
      "Step: 8214 Weights: [0.35616408 2.13242013] , error: 0.47374429223745335\n",
      "Step: 8215 Weights: [0.35616408 2.13242013] , error: 0.47374429223745324\n",
      "Step: 8216 Weights: [0.35616408 2.13242013] , error: 0.47374429223745346\n",
      "Step: 8217 Weights: [0.35616408 2.13242013] , error: 0.47374429223745373\n",
      "Step: 8218 Weights: [0.35616408 2.13242013] , error: 0.47374429223745396\n",
      "Step: 8219 Weights: [0.35616408 2.13242013] , error: 0.4737442922374536\n",
      "Step: 8220 Weights: [0.35616408 2.13242013] , error: 0.4737442922374534\n",
      "Step: 8221 Weights: [0.35616408 2.13242013] , error: 0.4737442922374535\n",
      "Step: 8222 Weights: [0.35616409 2.13242013] , error: 0.4737442922374528\n",
      "Step: 8223 Weights: [0.35616409 2.13242013] , error: 0.47374429223745373\n",
      "Step: 8224 Weights: [0.35616409 2.13242013] , error: 0.47374429223745307\n",
      "Step: 8225 Weights: [0.35616409 2.13242013] , error: 0.47374429223745346\n",
      "Step: 8226 Weights: [0.35616409 2.13242013] , error: 0.4737442922374533\n",
      "Step: 8227 Weights: [0.35616409 2.13242013] , error: 0.4737442922374533\n",
      "Step: 8228 Weights: [0.35616409 2.13242012] , error: 0.47374429223745335\n",
      "Step: 8229 Weights: [0.35616409 2.13242012] , error: 0.4737442922374531\n",
      "Step: 8230 Weights: [0.35616409 2.13242012] , error: 0.4737442922374524\n",
      "Step: 8231 Weights: [0.35616409 2.13242012] , error: 0.47374429223745224\n",
      "Step: 8232 Weights: [0.35616409 2.13242012] , error: 0.4737442922374526\n",
      "Step: 8233 Weights: [0.35616409 2.13242012] , error: 0.4737442922374531\n",
      "Step: 8234 Weights: [0.35616409 2.13242012] , error: 0.47374429223745246\n",
      "Step: 8235 Weights: [0.35616409 2.13242012] , error: 0.4737442922374529\n",
      "Step: 8236 Weights: [0.35616409 2.13242012] , error: 0.4737442922374525\n",
      "Step: 8237 Weights: [0.3561641  2.13242012] , error: 0.4737442922374524\n",
      "Step: 8238 Weights: [0.3561641  2.13242012] , error: 0.47374429223745285\n",
      "Step: 8239 Weights: [0.3561641  2.13242012] , error: 0.4737442922374524\n",
      "Step: 8240 Weights: [0.3561641  2.13242012] , error: 0.47374429223745274\n",
      "Step: 8241 Weights: [0.3561641  2.13242012] , error: 0.47374429223745235\n",
      "Step: 8242 Weights: [0.3561641  2.13242012] , error: 0.47374429223745235\n",
      "Step: 8243 Weights: [0.3561641  2.13242012] , error: 0.47374429223745285\n",
      "Step: 8244 Weights: [0.3561641  2.13242012] , error: 0.4737442922374528\n",
      "Step: 8245 Weights: [0.3561641  2.13242012] , error: 0.4737442922374523\n",
      "Step: 8246 Weights: [0.3561641  2.13242012] , error: 0.47374429223745174\n",
      "Step: 8247 Weights: [0.3561641  2.13242012] , error: 0.4737442922374518\n",
      "Step: 8248 Weights: [0.3561641  2.13242012] , error: 0.473744292237452\n",
      "Step: 8249 Weights: [0.3561641  2.13242012] , error: 0.47374429223745157\n",
      "Step: 8250 Weights: [0.3561641  2.13242012] , error: 0.47374429223745185\n",
      "Step: 8251 Weights: [0.3561641  2.13242012] , error: 0.4737442922374523\n",
      "Step: 8252 Weights: [0.35616411 2.13242012] , error: 0.4737442922374513\n",
      "Step: 8253 Weights: [0.35616411 2.13242012] , error: 0.47374429223745174\n",
      "Step: 8254 Weights: [0.35616411 2.13242012] , error: 0.47374429223745196\n",
      "Step: 8255 Weights: [0.35616411 2.13242012] , error: 0.4737442922374515\n",
      "Step: 8256 Weights: [0.35616411 2.13242012] , error: 0.4737442922374515\n",
      "Step: 8257 Weights: [0.35616411 2.13242012] , error: 0.4737442922374524\n",
      "Step: 8258 Weights: [0.35616411 2.13242012] , error: 0.47374429223745146\n",
      "Step: 8259 Weights: [0.35616411 2.13242012] , error: 0.47374429223745157\n",
      "Step: 8260 Weights: [0.35616411 2.13242012] , error: 0.4737442922374521\n",
      "Step: 8261 Weights: [0.35616411 2.13242012] , error: 0.4737442922374516\n",
      "Step: 8262 Weights: [0.35616411 2.13242012] , error: 0.4737442922374515\n",
      "Step: 8263 Weights: [0.35616411 2.13242012] , error: 0.4737442922374516\n",
      "Step: 8264 Weights: [0.35616411 2.13242012] , error: 0.4737442922374515\n",
      "Step: 8265 Weights: [0.35616411 2.13242012] , error: 0.47374429223745085\n",
      "Step: 8266 Weights: [0.35616411 2.13242012] , error: 0.47374429223745146\n",
      "Step: 8267 Weights: [0.35616411 2.13242012] , error: 0.4737442922374512\n",
      "Step: 8268 Weights: [0.35616412 2.13242012] , error: 0.4737442922374516\n",
      "Step: 8269 Weights: [0.35616412 2.13242012] , error: 0.47374429223745107\n",
      "Step: 8270 Weights: [0.35616412 2.13242012] , error: 0.4737442922374515\n",
      "Step: 8271 Weights: [0.35616412 2.13242012] , error: 0.4737442922374511\n",
      "Step: 8272 Weights: [0.35616412 2.13242012] , error: 0.47374429223745107\n",
      "Step: 8273 Weights: [0.35616412 2.13242012] , error: 0.47374429223745135\n",
      "Step: 8274 Weights: [0.35616412 2.13242012] , error: 0.47374429223745107\n",
      "Step: 8275 Weights: [0.35616412 2.13242012] , error: 0.4737442922374504\n",
      "Step: 8276 Weights: [0.35616412 2.13242012] , error: 0.4737442922374514\n",
      "Step: 8277 Weights: [0.35616412 2.13242012] , error: 0.47374429223745107\n",
      "Step: 8278 Weights: [0.35616412 2.13242012] , error: 0.4737442922374506\n",
      "Step: 8279 Weights: [0.35616412 2.13242012] , error: 0.47374429223745124\n",
      "Step: 8280 Weights: [0.35616412 2.13242012] , error: 0.47374429223745135\n",
      "Step: 8281 Weights: [0.35616412 2.13242012] , error: 0.4737442922374508\n",
      "Step: 8282 Weights: [0.35616412 2.13242012] , error: 0.4737442922374506\n",
      "Step: 8283 Weights: [0.35616412 2.13242012] , error: 0.47374429223745057\n",
      "Step: 8284 Weights: [0.35616412 2.13242012] , error: 0.4737442922374507\n",
      "Step: 8285 Weights: [0.35616413 2.13242012] , error: 0.4737442922374509\n",
      "Step: 8286 Weights: [0.35616413 2.13242012] , error: 0.4737442922374513\n",
      "Step: 8287 Weights: [0.35616413 2.13242012] , error: 0.4737442922374501\n",
      "Step: 8288 Weights: [0.35616413 2.13242012] , error: 0.47374429223745024\n",
      "Step: 8289 Weights: [0.35616413 2.13242012] , error: 0.47374429223745074\n",
      "Step: 8290 Weights: [0.35616413 2.13242012] , error: 0.47374429223745057\n",
      "Step: 8291 Weights: [0.35616413 2.13242012] , error: 0.47374429223745074\n",
      "Step: 8292 Weights: [0.35616413 2.13242012] , error: 0.4737442922374502\n",
      "Step: 8293 Weights: [0.35616413 2.13242012] , error: 0.47374429223745035\n",
      "Step: 8294 Weights: [0.35616413 2.13242012] , error: 0.47374429223745007\n",
      "Step: 8295 Weights: [0.35616413 2.13242012] , error: 0.47374429223745057\n",
      "Step: 8296 Weights: [0.35616413 2.13242012] , error: 0.4737442922374504\n",
      "Step: 8297 Weights: [0.35616413 2.13242012] , error: 0.4737442922374505\n",
      "Step: 8298 Weights: [0.35616413 2.13242012] , error: 0.4737442922374506\n",
      "Step: 8299 Weights: [0.35616413 2.13242012] , error: 0.47374429223745\n",
      "Step: 8300 Weights: [0.35616413 2.13242012] , error: 0.47374429223744996\n",
      "Step: 8301 Weights: [0.35616413 2.13242012] , error: 0.47374429223745007\n",
      "Step: 8302 Weights: [0.35616414 2.13242012] , error: 0.4737442922374502\n",
      "Step: 8303 Weights: [0.35616414 2.13242012] , error: 0.47374429223744996\n",
      "Step: 8304 Weights: [0.35616414 2.13242012] , error: 0.4737442922374497\n",
      "Step: 8305 Weights: [0.35616414 2.13242012] , error: 0.47374429223745024\n",
      "Step: 8306 Weights: [0.35616414 2.13242012] , error: 0.4737442922374498\n",
      "Step: 8307 Weights: [0.35616414 2.13242012] , error: 0.47374429223744974\n",
      "Step: 8308 Weights: [0.35616414 2.13242012] , error: 0.4737442922374501\n",
      "Step: 8309 Weights: [0.35616414 2.13242012] , error: 0.4737442922374501\n",
      "Step: 8310 Weights: [0.35616414 2.13242012] , error: 0.4737442922374498\n",
      "Step: 8311 Weights: [0.35616414 2.13242012] , error: 0.4737442922374492\n",
      "Step: 8312 Weights: [0.35616414 2.13242012] , error: 0.4737442922374499\n",
      "Step: 8313 Weights: [0.35616414 2.13242012] , error: 0.4737442922374495\n",
      "Step: 8314 Weights: [0.35616414 2.13242012] , error: 0.4737442922374498\n",
      "Step: 8315 Weights: [0.35616414 2.13242012] , error: 0.47374429223745035\n",
      "Step: 8316 Weights: [0.35616414 2.13242012] , error: 0.4737442922374499\n",
      "Step: 8317 Weights: [0.35616414 2.13242012] , error: 0.47374429223745\n",
      "Step: 8318 Weights: [0.35616414 2.13242012] , error: 0.47374429223744924\n",
      "Step: 8319 Weights: [0.35616414 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8320 Weights: [0.35616415 2.13242012] , error: 0.47374429223744935\n",
      "Step: 8321 Weights: [0.35616415 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8322 Weights: [0.35616415 2.13242012] , error: 0.47374429223744957\n",
      "Step: 8323 Weights: [0.35616415 2.13242012] , error: 0.4737442922374495\n",
      "Step: 8324 Weights: [0.35616415 2.13242012] , error: 0.4737442922374493\n",
      "Step: 8325 Weights: [0.35616415 2.13242012] , error: 0.4737442922374496\n",
      "Step: 8326 Weights: [0.35616415 2.13242012] , error: 0.47374429223744874\n",
      "Step: 8327 Weights: [0.35616415 2.13242012] , error: 0.47374429223744924\n",
      "Step: 8328 Weights: [0.35616415 2.13242012] , error: 0.47374429223744907\n",
      "Step: 8329 Weights: [0.35616415 2.13242012] , error: 0.47374429223744885\n",
      "Step: 8330 Weights: [0.35616415 2.13242012] , error: 0.47374429223744763\n",
      "Step: 8331 Weights: [0.35616415 2.13242012] , error: 0.47374429223744935\n",
      "Step: 8332 Weights: [0.35616415 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8333 Weights: [0.35616415 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8334 Weights: [0.35616415 2.13242012] , error: 0.47374429223744935\n",
      "Step: 8335 Weights: [0.35616415 2.13242012] , error: 0.47374429223744907\n",
      "Step: 8336 Weights: [0.35616415 2.13242012] , error: 0.47374429223744885\n",
      "Step: 8337 Weights: [0.35616415 2.13242012] , error: 0.47374429223744874\n",
      "Step: 8338 Weights: [0.35616415 2.13242012] , error: 0.47374429223744907\n",
      "Step: 8339 Weights: [0.35616416 2.13242012] , error: 0.4737442922374492\n",
      "Step: 8340 Weights: [0.35616416 2.13242012] , error: 0.4737442922374488\n",
      "Step: 8341 Weights: [0.35616416 2.13242012] , error: 0.47374429223744874\n",
      "Step: 8342 Weights: [0.35616416 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8343 Weights: [0.35616416 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8344 Weights: [0.35616416 2.13242012] , error: 0.47374429223744896\n",
      "Step: 8345 Weights: [0.35616416 2.13242012] , error: 0.4737442922374484\n",
      "Step: 8346 Weights: [0.35616416 2.13242012] , error: 0.473744292237449\n",
      "Step: 8347 Weights: [0.35616416 2.13242012] , error: 0.47374429223744885\n",
      "Step: 8348 Weights: [0.35616416 2.13242012] , error: 0.4737442922374492\n",
      "Step: 8349 Weights: [0.35616416 2.13242012] , error: 0.4737442922374485\n",
      "Step: 8350 Weights: [0.35616416 2.13242012] , error: 0.4737442922374484\n",
      "Step: 8351 Weights: [0.35616416 2.13242012] , error: 0.47374429223744885\n",
      "Step: 8352 Weights: [0.35616416 2.13242012] , error: 0.4737442922374487\n",
      "Step: 8353 Weights: [0.35616416 2.13242012] , error: 0.4737442922374486\n",
      "Step: 8354 Weights: [0.35616416 2.13242012] , error: 0.4737442922374487\n",
      "Step: 8355 Weights: [0.35616416 2.13242012] , error: 0.47374429223744796\n",
      "Step: 8356 Weights: [0.35616416 2.13242012] , error: 0.473744292237449\n",
      "Step: 8357 Weights: [0.35616416 2.13242012] , error: 0.4737442922374488\n",
      "Step: 8358 Weights: [0.35616416 2.13242012] , error: 0.47374429223744896\n",
      "Step: 8359 Weights: [0.35616417 2.13242012] , error: 0.47374429223744896\n",
      "Step: 8360 Weights: [0.35616417 2.13242012] , error: 0.4737442922374485\n",
      "Step: 8361 Weights: [0.35616417 2.13242012] , error: 0.47374429223744796\n",
      "Step: 8362 Weights: [0.35616417 2.13242012] , error: 0.4737442922374485\n",
      "Step: 8363 Weights: [0.35616417 2.13242012] , error: 0.47374429223744774\n",
      "Step: 8364 Weights: [0.35616417 2.13242012] , error: 0.4737442922374483\n",
      "Step: 8365 Weights: [0.35616417 2.13242012] , error: 0.47374429223744774\n",
      "Step: 8366 Weights: [0.35616417 2.13242012] , error: 0.47374429223744785\n",
      "Step: 8367 Weights: [0.35616417 2.13242012] , error: 0.47374429223744796\n",
      "Step: 8368 Weights: [0.35616417 2.13242012] , error: 0.4737442922374479\n",
      "Step: 8369 Weights: [0.35616417 2.13242012] , error: 0.47374429223744857\n",
      "Step: 8370 Weights: [0.35616417 2.13242012] , error: 0.4737442922374484\n",
      "Step: 8371 Weights: [0.35616417 2.13242012] , error: 0.47374429223744785\n",
      "Step: 8372 Weights: [0.35616417 2.13242012] , error: 0.47374429223744785\n",
      "Step: 8373 Weights: [0.35616417 2.13242012] , error: 0.4737442922374487\n",
      "Step: 8374 Weights: [0.35616417 2.13242012] , error: 0.4737442922374481\n",
      "Step: 8375 Weights: [0.35616417 2.13242012] , error: 0.47374429223744835\n",
      "Step: 8376 Weights: [0.35616417 2.13242012] , error: 0.47374429223744813\n",
      "Step: 8377 Weights: [0.35616417 2.13242012] , error: 0.47374429223744785\n",
      "Step: 8378 Weights: [0.35616417 2.13242012] , error: 0.4737442922374482\n",
      "Step: 8379 Weights: [0.35616418 2.13242012] , error: 0.47374429223744835\n",
      "Step: 8380 Weights: [0.35616418 2.13242012] , error: 0.4737442922374474\n",
      "Step: 8381 Weights: [0.35616418 2.13242012] , error: 0.47374429223744857\n",
      "Step: 8382 Weights: [0.35616418 2.13242011] , error: 0.4737442922374482\n",
      "Step: 8383 Weights: [0.35616418 2.13242011] , error: 0.47374429223744713\n",
      "Step: 8384 Weights: [0.35616418 2.13242011] , error: 0.4737442922374481\n",
      "Step: 8385 Weights: [0.35616418 2.13242011] , error: 0.4737442922374478\n",
      "Step: 8386 Weights: [0.35616418 2.13242011] , error: 0.47374429223744824\n",
      "Step: 8387 Weights: [0.35616418 2.13242011] , error: 0.47374429223744774\n",
      "Step: 8388 Weights: [0.35616418 2.13242011] , error: 0.4737442922374482\n",
      "Step: 8389 Weights: [0.35616418 2.13242011] , error: 0.47374429223744785\n",
      "Step: 8390 Weights: [0.35616418 2.13242011] , error: 0.47374429223744813\n",
      "Step: 8391 Weights: [0.35616418 2.13242011] , error: 0.47374429223744735\n",
      "Step: 8392 Weights: [0.35616418 2.13242011] , error: 0.4737442922374482\n",
      "Step: 8393 Weights: [0.35616418 2.13242011] , error: 0.4737442922374479\n",
      "Step: 8394 Weights: [0.35616418 2.13242011] , error: 0.4737442922374474\n",
      "Step: 8395 Weights: [0.35616418 2.13242011] , error: 0.4737442922374476\n",
      "Step: 8396 Weights: [0.35616418 2.13242011] , error: 0.4737442922374475\n",
      "Step: 8397 Weights: [0.35616418 2.13242011] , error: 0.47374429223744685\n",
      "Step: 8398 Weights: [0.35616418 2.13242011] , error: 0.47374429223744796\n",
      "Step: 8399 Weights: [0.35616418 2.13242011] , error: 0.47374429223744735\n",
      "Step: 8400 Weights: [0.35616418 2.13242011] , error: 0.4737442922374475\n",
      "Step: 8401 Weights: [0.35616419 2.13242011] , error: 0.473744292237447\n",
      "Step: 8402 Weights: [0.35616419 2.13242011] , error: 0.47374429223744796\n",
      "Step: 8403 Weights: [0.35616419 2.13242011] , error: 0.47374429223744713\n",
      "Step: 8404 Weights: [0.35616419 2.13242011] , error: 0.4737442922374471\n",
      "Step: 8405 Weights: [0.35616419 2.13242011] , error: 0.47374429223744713\n",
      "Step: 8406 Weights: [0.35616419 2.13242011] , error: 0.473744292237447\n",
      "Step: 8407 Weights: [0.35616419 2.13242011] , error: 0.4737442922374471\n",
      "Step: 8408 Weights: [0.35616419 2.13242011] , error: 0.4737442922374471\n",
      "Step: 8409 Weights: [0.35616419 2.13242011] , error: 0.4737442922374471\n",
      "Step: 8410 Weights: [0.35616419 2.13242011] , error: 0.4737442922374475\n",
      "Step: 8411 Weights: [0.35616419 2.13242011] , error: 0.4737442922374472\n",
      "Step: 8412 Weights: [0.35616419 2.13242011] , error: 0.4737442922374471\n",
      "Step: 8413 Weights: [0.35616419 2.13242011] , error: 0.47374429223744735\n",
      "Step: 8414 Weights: [0.35616419 2.13242011] , error: 0.4737442922374475\n",
      "Step: 8415 Weights: [0.35616419 2.13242011] , error: 0.4737442922374472\n",
      "Step: 8416 Weights: [0.35616419 2.13242011] , error: 0.47374429223744746\n",
      "Step: 8417 Weights: [0.35616419 2.13242011] , error: 0.47374429223744774\n",
      "Step: 8418 Weights: [0.35616419 2.13242011] , error: 0.4737442922374474\n",
      "Step: 8419 Weights: [0.35616419 2.13242011] , error: 0.4737442922374478\n",
      "Step: 8420 Weights: [0.35616419 2.13242011] , error: 0.4737442922374475\n",
      "Step: 8421 Weights: [0.35616419 2.13242011] , error: 0.47374429223744685\n",
      "Step: 8422 Weights: [0.35616419 2.13242011] , error: 0.4737442922374465\n",
      "Step: 8423 Weights: [0.3561642  2.13242011] , error: 0.4737442922374474\n",
      "Step: 8424 Weights: [0.3561642  2.13242011] , error: 0.4737442922374469\n",
      "Step: 8425 Weights: [0.3561642  2.13242011] , error: 0.4737442922374464\n",
      "Step: 8426 Weights: [0.3561642  2.13242011] , error: 0.4737442922374472\n",
      "Step: 8427 Weights: [0.3561642  2.13242011] , error: 0.4737442922374475\n",
      "Step: 8428 Weights: [0.3561642  2.13242011] , error: 0.47374429223744713\n",
      "Step: 8429 Weights: [0.3561642  2.13242011] , error: 0.4737442922374473\n",
      "Step: 8430 Weights: [0.3561642  2.13242011] , error: 0.4737442922374472\n",
      "Step: 8431 Weights: [0.3561642  2.13242011] , error: 0.4737442922374463\n",
      "Step: 8432 Weights: [0.3561642  2.13242011] , error: 0.4737442922374473\n",
      "Step: 8433 Weights: [0.3561642  2.13242011] , error: 0.4737442922374466\n",
      "Step: 8434 Weights: [0.3561642  2.13242011] , error: 0.47374429223744713\n",
      "Step: 8435 Weights: [0.3561642  2.13242011] , error: 0.47374429223744663\n",
      "Step: 8436 Weights: [0.3561642  2.13242011] , error: 0.47374429223744696\n",
      "Step: 8437 Weights: [0.3561642  2.13242011] , error: 0.47374429223744685\n",
      "Step: 8438 Weights: [0.3561642  2.13242011] , error: 0.47374429223744663\n",
      "Step: 8439 Weights: [0.3561642  2.13242011] , error: 0.4737442922374469\n",
      "Step: 8440 Weights: [0.3561642  2.13242011] , error: 0.47374429223744696\n",
      "Step: 8441 Weights: [0.3561642  2.13242011] , error: 0.47374429223744713\n",
      "Step: 8442 Weights: [0.3561642  2.13242011] , error: 0.47374429223744663\n",
      "Step: 8443 Weights: [0.3561642  2.13242011] , error: 0.47374429223744685\n",
      "Step: 8444 Weights: [0.3561642  2.13242011] , error: 0.47374429223744735\n",
      "Step: 8445 Weights: [0.3561642  2.13242011] , error: 0.4737442922374469\n",
      "Step: 8446 Weights: [0.3561642  2.13242011] , error: 0.4737442922374469\n",
      "Step: 8447 Weights: [0.35616421 2.13242011] , error: 0.4737442922374459\n",
      "Step: 8448 Weights: [0.35616421 2.13242011] , error: 0.4737442922374462\n",
      "Step: 8449 Weights: [0.35616421 2.13242011] , error: 0.47374429223744624\n",
      "Step: 8450 Weights: [0.35616421 2.13242011] , error: 0.47374429223744685\n",
      "Step: 8451 Weights: [0.35616421 2.13242011] , error: 0.4737442922374468\n",
      "Step: 8452 Weights: [0.35616421 2.13242011] , error: 0.4737442922374468\n",
      "Step: 8453 Weights: [0.35616421 2.13242011] , error: 0.47374429223744663\n",
      "Step: 8454 Weights: [0.35616421 2.13242011] , error: 0.47374429223744674\n",
      "Step: 8455 Weights: [0.35616421 2.13242011] , error: 0.47374429223744646\n",
      "Step: 8456 Weights: [0.35616421 2.13242011] , error: 0.4737442922374459\n",
      "Step: 8457 Weights: [0.35616421 2.13242011] , error: 0.4737442922374463\n",
      "Step: 8458 Weights: [0.35616421 2.13242011] , error: 0.4737442922374465\n",
      "Step: 8459 Weights: [0.35616421 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8460 Weights: [0.35616421 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8461 Weights: [0.35616421 2.13242011] , error: 0.47374429223744624\n",
      "Step: 8462 Weights: [0.35616421 2.13242011] , error: 0.47374429223744663\n",
      "Step: 8463 Weights: [0.35616421 2.13242011] , error: 0.4737442922374463\n",
      "Step: 8464 Weights: [0.35616421 2.13242011] , error: 0.47374429223744624\n",
      "Step: 8465 Weights: [0.35616421 2.13242011] , error: 0.47374429223744674\n",
      "Step: 8466 Weights: [0.35616421 2.13242011] , error: 0.4737442922374464\n",
      "Step: 8467 Weights: [0.35616421 2.13242011] , error: 0.4737442922374463\n",
      "Step: 8468 Weights: [0.35616421 2.13242011] , error: 0.47374429223744635\n",
      "Step: 8469 Weights: [0.35616421 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8470 Weights: [0.35616421 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8471 Weights: [0.35616421 2.13242011] , error: 0.4737442922374469\n",
      "Step: 8472 Weights: [0.35616422 2.13242011] , error: 0.4737442922374464\n",
      "Step: 8473 Weights: [0.35616422 2.13242011] , error: 0.4737442922374462\n",
      "Step: 8474 Weights: [0.35616422 2.13242011] , error: 0.4737442922374465\n",
      "Step: 8475 Weights: [0.35616422 2.13242011] , error: 0.47374429223744646\n",
      "Step: 8476 Weights: [0.35616422 2.13242011] , error: 0.4737442922374463\n",
      "Step: 8477 Weights: [0.35616422 2.13242011] , error: 0.4737442922374464\n",
      "Step: 8478 Weights: [0.35616422 2.13242011] , error: 0.4737442922374467\n",
      "Step: 8479 Weights: [0.35616422 2.13242011] , error: 0.4737442922374467\n",
      "Step: 8480 Weights: [0.35616422 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8481 Weights: [0.35616422 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8482 Weights: [0.35616422 2.13242011] , error: 0.4737442922374458\n",
      "Step: 8483 Weights: [0.35616422 2.13242011] , error: 0.4737442922374462\n",
      "Step: 8484 Weights: [0.35616422 2.13242011] , error: 0.47374429223744674\n",
      "Step: 8485 Weights: [0.35616422 2.13242011] , error: 0.4737442922374459\n",
      "Step: 8486 Weights: [0.35616422 2.13242011] , error: 0.47374429223744646\n",
      "Step: 8487 Weights: [0.35616422 2.13242011] , error: 0.47374429223744596\n",
      "Step: 8488 Weights: [0.35616422 2.13242011] , error: 0.47374429223744624\n",
      "Step: 8489 Weights: [0.35616422 2.13242011] , error: 0.4737442922374465\n",
      "Step: 8490 Weights: [0.35616422 2.13242011] , error: 0.47374429223744596\n",
      "Step: 8491 Weights: [0.35616422 2.13242011] , error: 0.4737442922374462\n",
      "Step: 8492 Weights: [0.35616422 2.13242011] , error: 0.47374429223744546\n",
      "Step: 8493 Weights: [0.35616422 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8494 Weights: [0.35616422 2.13242011] , error: 0.473744292237446\n",
      "Step: 8495 Weights: [0.35616422 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8496 Weights: [0.35616422 2.13242011] , error: 0.47374429223744546\n",
      "Step: 8497 Weights: [0.35616422 2.13242011] , error: 0.4737442922374463\n",
      "Step: 8498 Weights: [0.35616422 2.13242011] , error: 0.4737442922374464\n",
      "Step: 8499 Weights: [0.35616423 2.13242011] , error: 0.47374429223744574\n",
      "Step: 8500 Weights: [0.35616423 2.13242011] , error: 0.47374429223744574\n",
      "Step: 8501 Weights: [0.35616423 2.13242011] , error: 0.4737442922374457\n",
      "Step: 8502 Weights: [0.35616423 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8503 Weights: [0.35616423 2.13242011] , error: 0.4737442922374459\n",
      "Step: 8504 Weights: [0.35616423 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8505 Weights: [0.35616423 2.13242011] , error: 0.47374429223744574\n",
      "Step: 8506 Weights: [0.35616423 2.13242011] , error: 0.473744292237446\n",
      "Step: 8507 Weights: [0.35616423 2.13242011] , error: 0.473744292237446\n",
      "Step: 8508 Weights: [0.35616423 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8509 Weights: [0.35616423 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8510 Weights: [0.35616423 2.13242011] , error: 0.4737442922374456\n",
      "Step: 8511 Weights: [0.35616423 2.13242011] , error: 0.47374429223744596\n",
      "Step: 8512 Weights: [0.35616423 2.13242011] , error: 0.47374429223744513\n",
      "Step: 8513 Weights: [0.35616423 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8514 Weights: [0.35616423 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8515 Weights: [0.35616423 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8516 Weights: [0.35616423 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8517 Weights: [0.35616423 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8518 Weights: [0.35616423 2.13242011] , error: 0.4737442922374456\n",
      "Step: 8519 Weights: [0.35616423 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8520 Weights: [0.35616423 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8521 Weights: [0.35616423 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8522 Weights: [0.35616423 2.13242011] , error: 0.4737442922374457\n",
      "Step: 8523 Weights: [0.35616423 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8524 Weights: [0.35616423 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8525 Weights: [0.35616423 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8526 Weights: [0.35616423 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8527 Weights: [0.35616423 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8528 Weights: [0.35616424 2.13242011] , error: 0.47374429223744546\n",
      "Step: 8529 Weights: [0.35616424 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8530 Weights: [0.35616424 2.13242011] , error: 0.47374429223744613\n",
      "Step: 8531 Weights: [0.35616424 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8532 Weights: [0.35616424 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8533 Weights: [0.35616424 2.13242011] , error: 0.4737442922374456\n",
      "Step: 8534 Weights: [0.35616424 2.13242011] , error: 0.47374429223744535\n",
      "Step: 8535 Weights: [0.35616424 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8536 Weights: [0.35616424 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8537 Weights: [0.35616424 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8538 Weights: [0.35616424 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8539 Weights: [0.35616424 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8540 Weights: [0.35616424 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8541 Weights: [0.35616424 2.13242011] , error: 0.47374429223744646\n",
      "Step: 8542 Weights: [0.35616424 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8543 Weights: [0.35616424 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8544 Weights: [0.35616424 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8545 Weights: [0.35616424 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8546 Weights: [0.35616424 2.13242011] , error: 0.4737442922374456\n",
      "Step: 8547 Weights: [0.35616424 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8548 Weights: [0.35616424 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8549 Weights: [0.35616424 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8550 Weights: [0.35616424 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8551 Weights: [0.35616424 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8552 Weights: [0.35616424 2.13242011] , error: 0.473744292237445\n",
      "Step: 8553 Weights: [0.35616424 2.13242011] , error: 0.4737442922374459\n",
      "Step: 8554 Weights: [0.35616424 2.13242011] , error: 0.4737442922374449\n",
      "Step: 8555 Weights: [0.35616424 2.13242011] , error: 0.473744292237445\n",
      "Step: 8556 Weights: [0.35616424 2.13242011] , error: 0.47374429223744546\n",
      "Step: 8557 Weights: [0.35616424 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8558 Weights: [0.35616425 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8559 Weights: [0.35616425 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8560 Weights: [0.35616425 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8561 Weights: [0.35616425 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8562 Weights: [0.35616425 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8563 Weights: [0.35616425 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8564 Weights: [0.35616425 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8565 Weights: [0.35616425 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8566 Weights: [0.35616425 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8567 Weights: [0.35616425 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8568 Weights: [0.35616425 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8569 Weights: [0.35616425 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8570 Weights: [0.35616425 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8571 Weights: [0.35616425 2.13242011] , error: 0.47374429223744496\n",
      "Step: 8572 Weights: [0.35616425 2.13242011] , error: 0.4737442922374456\n",
      "Step: 8573 Weights: [0.35616425 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8574 Weights: [0.35616425 2.13242011] , error: 0.473744292237445\n",
      "Step: 8575 Weights: [0.35616425 2.13242011] , error: 0.47374429223744513\n",
      "Step: 8576 Weights: [0.35616425 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8577 Weights: [0.35616425 2.13242011] , error: 0.4737442922374449\n",
      "Step: 8578 Weights: [0.35616425 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8579 Weights: [0.35616425 2.13242011] , error: 0.4737442922374447\n",
      "Step: 8580 Weights: [0.35616425 2.13242011] , error: 0.4737442922374445\n",
      "Step: 8581 Weights: [0.35616425 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8582 Weights: [0.35616425 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8583 Weights: [0.35616425 2.13242011] , error: 0.4737442922374449\n",
      "Step: 8584 Weights: [0.35616425 2.13242011] , error: 0.473744292237445\n",
      "Step: 8585 Weights: [0.35616425 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8586 Weights: [0.35616425 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8587 Weights: [0.35616425 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8588 Weights: [0.35616425 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8589 Weights: [0.35616425 2.13242011] , error: 0.47374429223744513\n",
      "Step: 8590 Weights: [0.35616425 2.13242011] , error: 0.4737442922374445\n",
      "Step: 8591 Weights: [0.35616426 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8592 Weights: [0.35616426 2.13242011] , error: 0.4737442922374447\n",
      "Step: 8593 Weights: [0.35616426 2.13242011] , error: 0.47374429223744496\n",
      "Step: 8594 Weights: [0.35616426 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8595 Weights: [0.35616426 2.13242011] , error: 0.47374429223744363\n",
      "Step: 8596 Weights: [0.35616426 2.13242011] , error: 0.47374429223744463\n",
      "Step: 8597 Weights: [0.35616426 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8598 Weights: [0.35616426 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8599 Weights: [0.35616426 2.13242011] , error: 0.47374429223744463\n",
      "Step: 8600 Weights: [0.35616426 2.13242011] , error: 0.4737442922374444\n",
      "Step: 8601 Weights: [0.35616426 2.13242011] , error: 0.4737442922374445\n",
      "Step: 8602 Weights: [0.35616426 2.13242011] , error: 0.473744292237445\n",
      "Step: 8603 Weights: [0.35616426 2.13242011] , error: 0.4737442922374443\n",
      "Step: 8604 Weights: [0.35616426 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8605 Weights: [0.35616426 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8606 Weights: [0.35616426 2.13242011] , error: 0.4737442922374448\n",
      "Step: 8607 Weights: [0.35616426 2.13242011] , error: 0.4737442922374444\n",
      "Step: 8608 Weights: [0.35616426 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8609 Weights: [0.35616426 2.13242011] , error: 0.4737442922374445\n",
      "Step: 8610 Weights: [0.35616426 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8611 Weights: [0.35616426 2.13242011] , error: 0.4737442922374444\n",
      "Step: 8612 Weights: [0.35616426 2.13242011] , error: 0.4737442922374449\n",
      "Step: 8613 Weights: [0.35616426 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8614 Weights: [0.35616426 2.13242011] , error: 0.4737442922374445\n",
      "Step: 8615 Weights: [0.35616426 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8616 Weights: [0.35616426 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8617 Weights: [0.35616426 2.13242011] , error: 0.4737442922374444\n",
      "Step: 8618 Weights: [0.35616426 2.13242011] , error: 0.4737442922374449\n",
      "Step: 8619 Weights: [0.35616426 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8620 Weights: [0.35616426 2.13242011] , error: 0.4737442922374441\n",
      "Step: 8621 Weights: [0.35616426 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8622 Weights: [0.35616426 2.13242011] , error: 0.4737442922374443\n",
      "Step: 8623 Weights: [0.35616426 2.1324201 ] , error: 0.47374429223744485\n",
      "Step: 8624 Weights: [0.35616426 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8625 Weights: [0.35616426 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8626 Weights: [0.35616426 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8627 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374448\n",
      "Step: 8628 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744424\n",
      "Step: 8629 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374448\n",
      "Step: 8630 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8631 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8632 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374451\n",
      "Step: 8633 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8634 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8635 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374448\n",
      "Step: 8636 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8637 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8638 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8639 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8640 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374448\n",
      "Step: 8641 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374444\n",
      "Step: 8642 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8643 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374444\n",
      "Step: 8644 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374447\n",
      "Step: 8645 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374447\n",
      "Step: 8646 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8647 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374447\n",
      "Step: 8648 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744496\n",
      "Step: 8649 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8650 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8651 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8652 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8653 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8654 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374451\n",
      "Step: 8655 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8656 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8657 Weights: [0.35616427 2.1324201 ] , error: 0.473744292237445\n",
      "Step: 8658 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8659 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8660 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8661 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8662 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374447\n",
      "Step: 8663 Weights: [0.35616427 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8664 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8665 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374446\n",
      "Step: 8666 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8667 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8668 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8669 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374446\n",
      "Step: 8670 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8671 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374445\n",
      "Step: 8672 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374444\n",
      "Step: 8673 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744496\n",
      "Step: 8674 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374448\n",
      "Step: 8675 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374445\n",
      "Step: 8676 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744463\n",
      "Step: 8677 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8678 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8679 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8680 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8681 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8682 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8683 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8684 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8685 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8686 Weights: [0.35616428 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8687 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8688 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8689 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8690 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8691 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744474\n",
      "Step: 8692 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8693 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8694 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8695 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8696 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8697 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8698 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8699 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8700 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8701 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8702 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8703 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8704 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8705 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8706 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8707 Weights: [0.35616429 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8708 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8709 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8710 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8711 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8712 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8713 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8714 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8715 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8716 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8717 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8718 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8719 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374445\n",
      "Step: 8720 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8721 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8722 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8723 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8724 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8725 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8726 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8727 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8728 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8729 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8730 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8731 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8732 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744424\n",
      "Step: 8733 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8734 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8735 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8736 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8737 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8738 Weights: [0.35616429 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8739 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8740 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8741 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8742 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8743 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8744 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8745 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8746 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8747 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8748 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8749 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374444\n",
      "Step: 8750 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8751 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8752 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8753 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8754 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8755 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8756 Weights: [0.3561643 2.1324201] , error: 0.4737442922374437\n",
      "Step: 8757 Weights: [0.3561643 2.1324201] , error: 0.47374429223744313\n",
      "Step: 8758 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8759 Weights: [0.3561643 2.1324201] , error: 0.4737442922374445\n",
      "Step: 8760 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8761 Weights: [0.3561643 2.1324201] , error: 0.47374429223744324\n",
      "Step: 8762 Weights: [0.3561643 2.1324201] , error: 0.4737442922374432\n",
      "Step: 8763 Weights: [0.3561643 2.1324201] , error: 0.47374429223744374\n",
      "Step: 8764 Weights: [0.3561643 2.1324201] , error: 0.47374429223744374\n",
      "Step: 8765 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8766 Weights: [0.3561643 2.1324201] , error: 0.473744292237444\n",
      "Step: 8767 Weights: [0.3561643 2.1324201] , error: 0.4737442922374437\n",
      "Step: 8768 Weights: [0.3561643 2.1324201] , error: 0.4737442922374436\n",
      "Step: 8769 Weights: [0.3561643 2.1324201] , error: 0.4737442922374438\n",
      "Step: 8770 Weights: [0.3561643 2.1324201] , error: 0.47374429223744363\n",
      "Step: 8771 Weights: [0.3561643 2.1324201] , error: 0.4737442922374443\n",
      "Step: 8772 Weights: [0.3561643 2.1324201] , error: 0.4737442922374436\n",
      "Step: 8773 Weights: [0.3561643 2.1324201] , error: 0.4737442922374441\n",
      "Step: 8774 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8775 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8776 Weights: [0.3561643 2.1324201] , error: 0.47374429223744363\n",
      "Step: 8777 Weights: [0.3561643 2.1324201] , error: 0.47374429223744347\n",
      "Step: 8778 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8779 Weights: [0.3561643 2.1324201] , error: 0.47374429223744524\n",
      "Step: 8780 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8781 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8782 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8783 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8784 Weights: [0.3561643 2.1324201] , error: 0.47374429223744374\n",
      "Step: 8785 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8786 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8787 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8788 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8789 Weights: [0.3561643 2.1324201] , error: 0.4737442922374438\n",
      "Step: 8790 Weights: [0.3561643 2.1324201] , error: 0.4737442922374444\n",
      "Step: 8791 Weights: [0.3561643 2.1324201] , error: 0.47374429223744313\n",
      "Step: 8792 Weights: [0.3561643 2.1324201] , error: 0.4737442922374434\n",
      "Step: 8793 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8794 Weights: [0.3561643 2.1324201] , error: 0.4737442922374439\n",
      "Step: 8795 Weights: [0.3561643 2.1324201] , error: 0.4737442922374441\n",
      "Step: 8796 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8797 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8798 Weights: [0.3561643 2.1324201] , error: 0.4737442922374437\n",
      "Step: 8799 Weights: [0.3561643 2.1324201] , error: 0.47374429223744363\n",
      "Step: 8800 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8801 Weights: [0.3561643 2.1324201] , error: 0.4737442922374438\n",
      "Step: 8802 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8803 Weights: [0.3561643 2.1324201] , error: 0.47374429223744313\n",
      "Step: 8804 Weights: [0.3561643 2.1324201] , error: 0.47374429223744435\n",
      "Step: 8805 Weights: [0.3561643 2.1324201] , error: 0.47374429223744374\n",
      "Step: 8806 Weights: [0.3561643 2.1324201] , error: 0.4737442922374439\n",
      "Step: 8807 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8808 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8809 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8810 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8811 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8812 Weights: [0.35616431 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8813 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8814 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8815 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8816 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8817 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8818 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8819 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8820 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8821 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8822 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8823 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8824 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8825 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8826 Weights: [0.35616431 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8827 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8828 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8829 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8830 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8831 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8832 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8833 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8834 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8835 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8836 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8837 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8838 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8839 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8840 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8841 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8842 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8843 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8844 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8845 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8846 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8847 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 8848 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8849 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8850 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8851 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8852 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8853 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8854 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8855 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8856 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8857 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 8858 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8859 Weights: [0.35616431 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8860 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8861 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8862 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8863 Weights: [0.35616431 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8864 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8865 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8866 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8867 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8868 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8869 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8870 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8871 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8872 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8873 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374419\n",
      "Step: 8874 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8875 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8876 Weights: [0.35616432 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8877 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8878 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8879 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8880 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8881 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8882 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8883 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8884 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8885 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8886 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8887 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8888 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8889 Weights: [0.35616432 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8890 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8891 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8892 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8893 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8894 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8895 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8896 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8897 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8898 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8899 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8900 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8901 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8902 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8903 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8904 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8905 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8906 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8907 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8908 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8909 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8910 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 8911 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8912 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8913 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8914 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8915 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8916 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8917 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8918 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8919 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8920 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8921 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8922 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8923 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8924 Weights: [0.35616432 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8925 Weights: [0.35616432 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8926 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8927 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8928 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8929 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 8930 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8931 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8932 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8933 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 8934 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 8935 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8936 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8937 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8938 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8939 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 8940 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 8941 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8942 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8943 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8944 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8945 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374426\n",
      "Step: 8946 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8947 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 8948 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8949 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8950 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8951 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8952 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8953 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8954 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 8955 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8956 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8957 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8958 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8959 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8960 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8961 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8962 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8963 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8964 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8965 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8966 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8967 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8968 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8969 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8970 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8971 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8972 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8973 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8974 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8975 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8976 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8977 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8978 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8979 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374444\n",
      "Step: 8980 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8981 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8982 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8983 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8984 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8985 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8986 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374427\n",
      "Step: 8987 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8988 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8989 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8990 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 8991 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8992 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374427\n",
      "Step: 8993 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8994 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 8995 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 8996 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 8997 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8998 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8999 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 9000 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 9001 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 9002 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9003 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9004 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9005 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9006 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 9007 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9008 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9009 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9010 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9011 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9012 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9013 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 9014 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9015 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 9016 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744247\n",
      "Step: 9017 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9018 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9019 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9020 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 9021 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9022 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9023 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9024 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 9025 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9026 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9027 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9028 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 9029 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 9030 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9031 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9032 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9033 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9034 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9035 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 9036 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9037 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9038 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9039 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9040 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 9041 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 9042 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9043 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9044 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9045 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374426\n",
      "Step: 9046 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9047 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9048 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9049 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9050 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 9051 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 9052 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9053 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9054 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9055 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9056 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9057 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 9058 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9059 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9060 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9061 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9062 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9063 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9064 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9065 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9066 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9067 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9068 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9069 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9070 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 9071 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9072 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 9073 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9074 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374426\n",
      "Step: 9075 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9076 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 9077 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9078 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9079 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9080 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9081 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9082 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9083 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9084 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9085 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9086 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9087 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 9088 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9089 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374427\n",
      "Step: 9090 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9091 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9092 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374425\n",
      "Step: 9093 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9094 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9095 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9096 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374425\n",
      "Step: 9097 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9098 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9099 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9100 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9101 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9102 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374424\n",
      "Step: 9103 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9104 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9105 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9106 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9107 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9108 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9109 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374425\n",
      "Step: 9110 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374426\n",
      "Step: 9111 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9112 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9113 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9114 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9115 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9116 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9117 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9118 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9119 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9120 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9121 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9122 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9123 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9124 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374425\n",
      "Step: 9125 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 9126 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9127 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9128 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9129 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9130 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9131 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9132 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9133 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9134 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9135 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9136 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9137 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9138 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9139 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9140 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9141 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 9142 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9143 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9144 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9145 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9146 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9147 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9148 Weights: [0.35616435 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9149 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 9150 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9151 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9152 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 9153 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9154 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9155 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9156 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9157 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9158 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9159 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9160 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9161 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9162 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9163 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9164 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 9165 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9166 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9167 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744247\n",
      "Step: 9168 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9169 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9170 Weights: [0.35616435 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9171 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744197\n",
      "Step: 9172 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 9173 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 9174 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744235\n",
      "Step: 9175 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9176 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9177 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374425\n",
      "Step: 9178 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9179 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9180 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9181 Weights: [0.35616435 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9182 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9183 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9184 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 9185 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9186 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9187 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9188 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 9189 Weights: [0.35616435 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9190 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9191 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9192 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9193 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 9194 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9195 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9196 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9197 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9198 Weights: [0.35616435 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9199 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9200 Weights: [0.35616435 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9201 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9202 Weights: [0.35616435 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9203 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9204 Weights: [0.35616435 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9205 Weights: [0.35616435 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9206 Weights: [0.35616435 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9207 Weights: [0.35616435 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9208 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9209 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9210 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9211 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9212 Weights: [0.35616435 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9213 Weights: [0.35616435 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9214 Weights: [0.35616435 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9215 Weights: [0.35616435 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9216 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9217 Weights: [0.35616435 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9218 Weights: [0.35616435 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9219 Weights: [0.35616435 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9220 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9221 Weights: [0.35616435 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9222 Weights: [0.35616435 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9223 Weights: [0.35616435 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9224 Weights: [0.35616435 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9225 Weights: [0.35616435 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9226 Weights: [0.35616435 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9227 Weights: [0.35616435 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9228 Weights: [0.35616435 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9229 Weights: [0.35616435 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9230 Weights: [0.35616435 2.13242009] , error: 0.473744292237443\n",
      "Step: 9231 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9232 Weights: [0.35616435 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9233 Weights: [0.35616435 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9234 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9235 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9236 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9237 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9238 Weights: [0.35616435 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9239 Weights: [0.35616435 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9240 Weights: [0.35616435 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9241 Weights: [0.35616435 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9242 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9243 Weights: [0.35616435 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9244 Weights: [0.35616435 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9245 Weights: [0.35616435 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9246 Weights: [0.35616435 2.13242009] , error: 0.473744292237443\n",
      "Step: 9247 Weights: [0.35616435 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9248 Weights: [0.35616435 2.13242009] , error: 0.473744292237443\n",
      "Step: 9249 Weights: [0.35616435 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9250 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9251 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9252 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9253 Weights: [0.35616436 2.13242009] , error: 0.4737442922374442\n",
      "Step: 9254 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9255 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9256 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9257 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9258 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9259 Weights: [0.35616436 2.13242009] , error: 0.4737442922374415\n",
      "Step: 9260 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9261 Weights: [0.35616436 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9262 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9263 Weights: [0.35616436 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9264 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9265 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9266 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9267 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9268 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9269 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9270 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9271 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9272 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9273 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9274 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9275 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9276 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9277 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9278 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9279 Weights: [0.35616436 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9280 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9281 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9282 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9283 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9284 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9285 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9286 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9287 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9288 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9289 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9290 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9291 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9292 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9293 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9294 Weights: [0.35616436 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9295 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9296 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9297 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9298 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9299 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9300 Weights: [0.35616436 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9301 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9302 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9303 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9304 Weights: [0.35616436 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9305 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9306 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9307 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9308 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9309 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9310 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9311 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9312 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9313 Weights: [0.35616436 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9314 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9315 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9316 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9317 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9318 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9319 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9320 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9321 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9322 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9323 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9324 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9325 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9326 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9327 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9328 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9329 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9330 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9331 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9332 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9333 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9334 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9335 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9336 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9337 Weights: [0.35616436 2.13242009] , error: 0.4737442922374437\n",
      "Step: 9338 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9339 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9340 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9341 Weights: [0.35616436 2.13242009] , error: 0.47374429223744374\n",
      "Step: 9342 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9343 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9344 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9345 Weights: [0.35616436 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9346 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9347 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9348 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9349 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9350 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9351 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9352 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9353 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9354 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9355 Weights: [0.35616436 2.13242009] , error: 0.47374429223744186\n",
      "Step: 9356 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9357 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9358 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9359 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9360 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9361 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9362 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9363 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9364 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9365 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9366 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9367 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9368 Weights: [0.35616436 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9369 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9370 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9371 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9372 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9373 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9374 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9375 Weights: [0.35616436 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9376 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9377 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9378 Weights: [0.35616436 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9379 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9380 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9381 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9382 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9383 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9384 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9385 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9386 Weights: [0.35616436 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9387 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9388 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9389 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9390 Weights: [0.35616436 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9391 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9392 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9393 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9394 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9395 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9396 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9397 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9398 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9399 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9400 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9401 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9402 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9403 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9404 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9405 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9406 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9407 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9408 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9409 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9410 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9411 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9412 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9413 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9414 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9415 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9416 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9417 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9418 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9419 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9420 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9421 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9422 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9423 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9424 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9425 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9426 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9427 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9428 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9429 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9430 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9431 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9432 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9433 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9434 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9435 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9436 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9437 Weights: [0.35616436 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9438 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9439 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9440 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9441 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9442 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9443 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9444 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9445 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9446 Weights: [0.35616437 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9447 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9448 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9449 Weights: [0.35616437 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9450 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9451 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9452 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9453 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9454 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9455 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9456 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9457 Weights: [0.35616437 2.13242009] , error: 0.4737442922374437\n",
      "Step: 9458 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9459 Weights: [0.35616437 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9460 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9461 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9462 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9463 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9464 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9465 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9466 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9467 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9468 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9469 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9470 Weights: [0.35616437 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9471 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9472 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9473 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9474 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9475 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9476 Weights: [0.35616437 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9477 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9478 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9479 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9480 Weights: [0.35616437 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9481 Weights: [0.35616437 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9482 Weights: [0.35616437 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9483 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9484 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9485 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9486 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9487 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9488 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9489 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9490 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9491 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9492 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9493 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9494 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9495 Weights: [0.35616437 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9496 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9497 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9498 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9499 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9500 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9501 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9502 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9503 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9504 Weights: [0.35616437 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9505 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9506 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9507 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9508 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9509 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9510 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9511 Weights: [0.35616437 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9512 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9513 Weights: [0.35616437 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9514 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9515 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9516 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9517 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9518 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9519 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9520 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9521 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9522 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9523 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9524 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9525 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9526 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9527 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9528 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9529 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9530 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9531 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9532 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9533 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9534 Weights: [0.35616437 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9535 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9536 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9537 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9538 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9539 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9540 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9541 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9542 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9543 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9544 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9545 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9546 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9547 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9548 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9549 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9550 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9551 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9552 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9553 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9554 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9555 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9556 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9557 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9558 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9559 Weights: [0.35616437 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9560 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9561 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9562 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9563 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9564 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9565 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9566 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9567 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9568 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9569 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9570 Weights: [0.35616437 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9571 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9572 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9573 Weights: [0.35616437 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9574 Weights: [0.35616437 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9575 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9576 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9577 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9578 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9579 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9580 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9581 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9582 Weights: [0.35616437 2.13242009] , error: 0.4737442922374437\n",
      "Step: 9583 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9584 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9585 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9586 Weights: [0.35616437 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9587 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9588 Weights: [0.35616437 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9589 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9590 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9591 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9592 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9593 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9594 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9595 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9596 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9597 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9598 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9599 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9600 Weights: [0.35616437 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9601 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9602 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9603 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9604 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9605 Weights: [0.35616437 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9606 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9607 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9608 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9609 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9610 Weights: [0.35616437 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9611 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9612 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9613 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9614 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9615 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9616 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9617 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9618 Weights: [0.35616437 2.13242009] , error: 0.4737442922374441\n",
      "Step: 9619 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9620 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9621 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9622 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9623 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9624 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9625 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9626 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9627 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9628 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9629 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9630 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9631 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9632 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9633 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9634 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9635 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9636 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9637 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9638 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9639 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9640 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9641 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9642 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9643 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9644 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9645 Weights: [0.35616437 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9646 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9647 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9648 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9649 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9650 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9651 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9652 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9653 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9654 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9655 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9656 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9657 Weights: [0.35616437 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9658 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9659 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9660 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9661 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9662 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9663 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9664 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9665 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9666 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9667 Weights: [0.35616437 2.13242009] , error: 0.473744292237443\n",
      "Step: 9668 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9669 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9670 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9671 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9672 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9673 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9674 Weights: [0.35616437 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9675 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9676 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9677 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9678 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9679 Weights: [0.35616437 2.13242009] , error: 0.4737442922374422\n",
      "Step: 9680 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9681 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9682 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9683 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9684 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9685 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9686 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9687 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9688 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9689 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9690 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9691 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9692 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9693 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9694 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9695 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9696 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9697 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9698 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9699 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9700 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9701 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9702 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9703 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9704 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9705 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9706 Weights: [0.35616437 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9707 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9708 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9709 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9710 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9711 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9712 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9713 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9714 Weights: [0.35616437 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9715 Weights: [0.35616437 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9716 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9717 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9718 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9719 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9720 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9721 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9722 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9723 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9724 Weights: [0.35616437 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9725 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9726 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9727 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9728 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9729 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9730 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9731 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9732 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9733 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9734 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9735 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9736 Weights: [0.35616437 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9737 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9738 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9739 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9740 Weights: [0.35616437 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9741 Weights: [0.35616437 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9742 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9743 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9744 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9745 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9746 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9747 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9748 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9749 Weights: [0.35616437 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9750 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9751 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9752 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9753 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9754 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9755 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9756 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9757 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9758 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9759 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9760 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9761 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9762 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9763 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9764 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9765 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9766 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9767 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9768 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9769 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9770 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9771 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9772 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9773 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9774 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9775 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9776 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9777 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9778 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9779 Weights: [0.35616438 2.13242009] , error: 0.4737442922374422\n",
      "Step: 9780 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9781 Weights: [0.35616438 2.13242009] , error: 0.473744292237443\n",
      "Step: 9782 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9783 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9784 Weights: [0.35616438 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9785 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9786 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9787 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9788 Weights: [0.35616438 2.13242009] , error: 0.473744292237443\n",
      "Step: 9789 Weights: [0.35616438 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9790 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9791 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9792 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9793 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9794 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9795 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9796 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9797 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9798 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9799 Weights: [0.35616438 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9800 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9801 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9802 Weights: [0.35616438 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9803 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9804 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9805 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9806 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9807 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9808 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9809 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9810 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9811 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9812 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9813 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9814 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9815 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9816 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9817 Weights: [0.35616438 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9818 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9819 Weights: [0.35616438 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9820 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9821 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9822 Weights: [0.35616438 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9823 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9824 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9825 Weights: [0.35616438 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9826 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9827 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9828 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9829 Weights: [0.35616438 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9830 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9831 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9832 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9833 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9834 Weights: [0.35616438 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9835 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9836 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9837 Weights: [0.35616438 2.13242009] , error: 0.473744292237443\n",
      "Step: 9838 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9839 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9840 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9841 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9842 Weights: [0.35616438 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9843 Weights: [0.35616438 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9844 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9845 Weights: [0.35616438 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9846 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9847 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9848 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9849 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9850 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9851 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9852 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9853 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9854 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9855 Weights: [0.35616438 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9856 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9857 Weights: [0.35616438 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9858 Weights: [0.35616438 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9859 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9860 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9861 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9862 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9863 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9864 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9865 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9866 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9867 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9868 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9869 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9870 Weights: [0.35616438 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9871 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9872 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9873 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9874 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9875 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9876 Weights: [0.35616438 2.13242009] , error: 0.4737442922374422\n",
      "Step: 9877 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9878 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9879 Weights: [0.35616438 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9880 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9881 Weights: [0.35616438 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9882 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9883 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9884 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9885 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9886 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9887 Weights: [0.35616438 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9888 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9889 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9890 Weights: [0.35616438 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9891 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9892 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9893 Weights: [0.35616438 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9894 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9895 Weights: [0.35616438 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9896 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9897 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9898 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9899 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9900 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9901 Weights: [0.35616438 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9902 Weights: [0.35616438 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9903 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9904 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9905 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9906 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9907 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9908 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9909 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9910 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9911 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9912 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9913 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9914 Weights: [0.35616438 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9915 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9916 Weights: [0.35616438 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9917 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9918 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9919 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9920 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9921 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9922 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9923 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9924 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9925 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9926 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9927 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9928 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9929 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9930 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9931 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9932 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9933 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9934 Weights: [0.35616438 2.13242009] , error: 0.4737442922374422\n",
      "Step: 9935 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9936 Weights: [0.35616438 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9937 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9938 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9939 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9940 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9941 Weights: [0.35616438 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9942 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9943 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9944 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9945 Weights: [0.35616438 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9946 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9947 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9948 Weights: [0.35616438 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9949 Weights: [0.35616438 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9950 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9951 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9952 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9953 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9954 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9955 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9956 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9957 Weights: [0.35616438 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9958 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9959 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9960 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9961 Weights: [0.35616438 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9962 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9963 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9964 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9965 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9966 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9967 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9968 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9969 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9970 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9971 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9972 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9973 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9974 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9975 Weights: [0.35616438 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9976 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9977 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9978 Weights: [0.35616438 2.13242009] , error: 0.4737442922374418\n",
      "Step: 9979 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9980 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9981 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9982 Weights: [0.35616438 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9983 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9984 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9985 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9986 Weights: [0.35616438 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9987 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9988 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9989 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9990 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9991 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9992 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9993 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9994 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9995 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9996 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9997 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9998 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9999 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.35616438, 2.13242009])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getcoefficients(X,y,w,0.01,10000,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had put in the ability to plot too so why not plot the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35616438, 2.13242009])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getcoefficients(X,y,w,0.01,10000,False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should hopefully still get there\n",
    "\n",
    "With more complicated functions it might get \"stuck\" in one of those valleys like I said in class but thankfully this example does not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did the graph look like with the [20,50] initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35631862, 2.13240245])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getcoefficients(X,y,np.array([20,50]),0.01,5000, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error got smaller at an earlier epoch\n",
    "\n",
    "Other ML systems will use the idea of changing the learning rate every so often (Neural Networks with solver=adam does this), so it gets an initial kick with a higher learning rate to start, then when it pleateaus - it shrinks the learning rate to try and learn some more, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if it works with more features - It should as I wrote the functions to use numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,5,8,2,6], [1,2,8,-10,23], [1,2,8,10,-23],\n",
    "             [1,12,-2,5,23],[1,24,8,21,23],[1,53,4,6,12],[1,3,2,-5,-10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 5)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([8,-3,4,10,1,6,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time I'm setting the initial weights to be random numbers, hopefully it doesn't mess up below when you run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.uniform(size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.15677080e+01,  3.25267906e-03, -1.02505283e+00,  3.35661860e-02,\n",
       "       -1.36555447e-01])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any bigger alpha will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.15676270e+01,  3.25382500e-03, -1.02504420e+00,  3.35656483e-02,\n",
       "       -1.36555032e-01])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getcoefficients(X,y,w,0.001,50000,False,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should see that the .fit function is not just magic. This is the basis of what it is doing and whenever you want an ML system to learn, it has to do lots of these \"steps\" to get the best model it can find.\n",
    "\n",
    "Different models will use different error/lost/cost functions (Logistic Regressions uses the one I mentioned in class for example). You can control the number of epochs and the learning rates as these are hyperparameters. There are \"fancier\" gradient descent methods (such as Mini-batch Stochastic Gradient Descent) which makes things faster but still having good performance.\n",
    "\n",
    "Neural Networks are much more complicated than linear regression, finding the gradient for them is even more so - but we'll come to that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cars Example\n",
    "Let's try the age vs value cars example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([5,4,6,5,5,5,6,6,2,7,7]).reshape(-1,1)\n",
    "y=np.array([85,103,70,82,89,98,66,95,169,70,48])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add the 1s for the intercept to our x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [4],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [2],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onecolumn = np.ones([x.shape[0],1])\n",
    "onecolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((onecolumn, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 5.],\n",
       "       [1., 4.],\n",
       "       [1., 6.],\n",
       "       [1., 5.],\n",
       "       [1., 5.],\n",
       "       [1., 5.],\n",
       "       [1., 6.],\n",
       "       [1., 6.],\n",
       "       [1., 2.],\n",
       "       [1., 7.],\n",
       "       [1., 7.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([195.46846847, -20.26126126])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getcoefficients(X,y,np.random.uniform(size=2),0.01,50000,False,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195.46846846846847 -20.261261261261264\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x,y)\n",
    "print(model.intercept_, model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try mtcars.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "   carb  \n",
       "0     4  \n",
       "1     4  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load mtcars\n",
    "dfcars=pd.read_csv(\"mtcars.csv\")\n",
    "dfcars=dfcars.rename(columns={\"Unnamed: 0\":\"name\"})\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfcars['mpg']\n",
    "allX = dfcars.iloc[:, 2:]\n",
    "from sklearn.model_selection import train_test_split\n",
    "allX_train, allX_test, y_train, y_test = train_test_split(allX, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = allX_train[[\"wt\",\"hp\",\"drat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = allX_train[[\"wt\",\"hp\",\"drat\"]].values\n",
    "X_test = allX_test[[\"wt\",\"hp\",\"drat\"]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.935,  66.   ,   4.08 ],\n",
       "       [  3.73 , 180.   ,   3.07 ],\n",
       "       [  2.62 , 110.   ,   3.9  ],\n",
       "       [  3.44 , 175.   ,   3.15 ],\n",
       "       [  5.345, 230.   ,   3.23 ],\n",
       "       [  3.46 , 105.   ,   2.76 ],\n",
       "       [  3.78 , 180.   ,   3.07 ],\n",
       "       [  4.07 , 180.   ,   3.07 ],\n",
       "       [  3.84 , 245.   ,   3.73 ],\n",
       "       [  2.875, 110.   ,   3.9  ],\n",
       "       [  2.32 ,  93.   ,   3.85 ],\n",
       "       [  2.14 ,  91.   ,   4.43 ],\n",
       "       [  3.215, 110.   ,   3.08 ],\n",
       "       [  3.52 , 150.   ,   2.76 ],\n",
       "       [  1.513, 113.   ,   3.77 ],\n",
       "       [  3.435, 150.   ,   3.15 ],\n",
       "       [  1.615,  52.   ,   4.93 ],\n",
       "       [  2.78 , 109.   ,   4.11 ],\n",
       "       [  2.465,  97.   ,   3.7  ],\n",
       "       [  3.19 ,  62.   ,   3.69 ],\n",
       "       [  3.44 , 123.   ,   3.92 ],\n",
       "       [  5.25 , 205.   ,   2.93 ],\n",
       "       [  3.17 , 264.   ,   4.22 ],\n",
       "       [  1.835,  65.   ,   4.22 ],\n",
       "       [  3.57 , 245.   ,   3.21 ]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26234592, -1.21810835,  0.86474409],\n",
       "       [ 0.6147756 ,  0.64834799, -0.94426902],\n",
       "       [-0.54600707, -0.49772169,  0.54234571],\n",
       "       [ 0.31150805,  0.56648587, -0.80098086],\n",
       "       [ 2.30366208,  1.4669692 , -0.65769269],\n",
       "       [ 0.33242306, -0.57958381, -1.49951067],\n",
       "       [ 0.6670631 ,  0.64834799, -0.94426902],\n",
       "       [ 0.97033065,  0.64834799, -0.94426902],\n",
       "       [ 0.72980811,  1.71255556,  0.23785836],\n",
       "       [-0.27934078, -0.49772169,  0.54234571],\n",
       "       [-0.85973211, -0.7760529 ,  0.45279061],\n",
       "       [-1.04796714, -0.80879775,  1.49162982],\n",
       "       [ 0.07621427, -0.49772169, -0.926358  ],\n",
       "       [ 0.39516806,  0.15717527, -1.49951067],\n",
       "       [-1.70365248, -0.44860442,  0.30950244],\n",
       "       [ 0.3062793 ,  0.15717527, -0.80098086],\n",
       "       [-1.59698596, -1.44732229,  2.38718087],\n",
       "       [-0.37868704, -0.51409412,  0.91847715],\n",
       "       [-0.70809834, -0.71056321,  0.1841253 ],\n",
       "       [ 0.05007052, -1.28359805,  0.16621427],\n",
       "       [ 0.31150805, -0.28488018,  0.57816776],\n",
       "       [ 2.20431582,  1.0576586 , -1.19502332],\n",
       "       [ 0.02915551,  2.02363162,  1.11549838],\n",
       "       [-1.36692093, -1.23448078,  1.11549838],\n",
       "       [ 0.44745557,  1.71255556, -0.69351473]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "#model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.168 [-2.82706981 -2.22336158  0.94591045]\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept_,model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with our method. Initialise our weights randomely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64175404, 0.96830704, 0.89720845, 0.15324757])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.uniform(size=4)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.hstack((np.ones([allX_train[[\"wt\",\"hp\",\"drat\"]].values.shape[0],1]), allX_train[[\"wt\",\"hp\",\"drat\"]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs = np.hstack((np.ones([X_train.shape[0],1]), X_train))\n",
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217.43724767152932"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(Xs,ys,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.52624596,   6.6119963 ,   6.2187519 ,  -4.8722195 ])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullgrad(Xs, ys, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w - alpha*fullgrad(Xs,ys,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.168     , -5.64368926, -5.32154345,  5.02546707])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.792389454091776"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(Xs,ys,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.168     , -2.82706981, -2.22336158,  0.94591045])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getcoefficients(Xs,ys,w,0.1,10000,False, True, showall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above should hopefully give you the idea of what's happening with the .fit method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
